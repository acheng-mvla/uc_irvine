instructed “symbolic” trials should be affected similarly to inferred “symbolic” trials. The execution phase of “inferred symbolic”, trials, however, is the only point within our task paradigm that requires the resolution of a rule that refers to an internally–produced representation of an abstracted re sponse (i.e., the placeholder A or B). When the stimulus parity does not match that instructed by the rule, across both “con crete” and “symbolic” conditions, the participant must calcu late what to do in response to the evident parity. In “concrete” trials, inference does occur, but the result of that inference is a concrete motor effector, carrying little to no abstraction. In “symbolic” trials, the result of inference is a secondary abstraction (i.e., the placeholder letter) that, through lack of alternatives, must be bound to the apparent parity. PMd rTMS specifically increased response times while resolution of conditional associations between abstract and internally– produced representations was occurring, but not while simi lar resolution operations between relatively concrete or exter nally instructed stimuli were necessary. 
In conclusion, noninvasive stimulation of the dorsal premo tor cortex, a brain region implicated in conditional motor be havior, was found to selectively interfere with responses when task conditions required a resolution of a conditional associ ation referring to abstracted, internally-produced representa tions, but not when resolution between concrete or externally informed representations was necessary. This result suggests that PMd does subserve conditional rule-based behavior, but only when it is reliant on internally-produced representations that are abstracted away from concrete motor effectors. 
References 
Cole, M. W., Laurent, P., & Stocco, A. (2013). Rapid instructed task learning: A new window into the human brains unique capacity for flexible cognitive control. Cog nitive, Affective, & Behavioral Neuroscience, 13(1), 1–22. 
Grafton, S. T., Fagg, A. H., & Arbib, M. A. (1998). Dor sal premotor cortex and conditional movement selection: a PET functional mapping study. Journal of Neurophysiol ogy, 79(2), 1092–1097. 
Guye, M., Parker, G., Symms, M., Boulby, P., Wheeler Kingshott, C., Salek-Haddadi, A., . . . Duncan, J. (2003). Combined functional MRI and tractography to demonstrate the connectivity of the human primary motor cortex in vivo. NeuroImage, 19, 1349–1360. 
Halsband, U., & Freund, H. J. (1990). Premotor cortex and conditional motor learning in man. Brain, 113(1), 207– 222. 
Hanakawa, T. (2011). Rostral premotor cortex as a gateway between motor and cognitive networks. Neuroscience Re search, 70, 144–154. 
Kurata, K., Tsuji, T., Naraki, S., Seino, M., & Abe, Y. (2000). Activation of the dorsal premotor cortex and pre supplementary motor area of humans during an auditory conditional motor task. Journal of Neurophysiology, 84(3), 1667–1672. 
Lu, M., Preston, J. B., & Strick, P. L. (1994). Interconnec tions between the prefrontal cortex and the premotor areas in the frontal lobe. Journal of Comparative Neurology, 341, 375–392. 
Ohbayashi, M., Picard, N., & Strick, P. L. (2016). Inactiva tion of the dorsal premotor area disrupts internally gener ated, but not visually guided, sequential movements. Jour nal of Neuroscience, 36(6), 1971–1976. 
Oshio, R., Tanaka, S., Sadato, N., Sokabe, M., Hanakawa, T., & Honda, M. (2010). Differential effect of double-pulse TMS applied to dorsal premotor cortex and precuneus dur ing internal operation of visuospatial information. Neu roImage, 49, 1108–1115. 
R Core Team. (2013). R: A language and environment for statistical computing [Computer software manual]. Vienna, Austria. Retrieved from http://www.R-project.org/ 
Stadler, W., Ott, D. V. M., Springer, A., Schubotz, R., Schutz Bosbach, S., & Prinz, W. (2012). Repetitive tms suggests a role of the human dorsal premotor cortex in action predic tion. Frontiers in Human Neuroscience, 6(20), 1–11. 
Stocco, A., Lebiere, C., O’Reilly, R. C., & Anderson, J. R. (2012). Distinct contributions of the caudate nucleus, ros tral prefrontal cortex, and parietal cortex to the execution of instructed tasks. Cognitive, Affective, and Behavioral Neuroscience, 12(4), 611–628. 
Strange, B. A., Henson, R. N. A., Friston, K. J., & Dolan, R. J. (2001). Anterior prefrontal cortex mediates rule learning in humans. Cerebral Cortex, 11(11), 1040–1046. 
Taylor, M., & Creelman, C. D. (1967). Pest: Efficient esti mates on probability functions. The Journal of the Acous tical Society of America, 41(4A), 782–787. 
Tomassini, V., Jbabdi, S., Klein, J., Behrens, T., Pozzilli, C., Matthews, P., . . . Johansen-Berg, H. (2007). Diffusion weighted imaging tractography-based parcellation of the human lateral premotor cortex identifies dorsal and ventral subregions with anatomical and functional specializations. Journal of Neuroscience, 27(38), 10259–10269. 
Wallis, J. D., Anderson, K. C., & Miller, E. K. (2001). Single neurons in prefrontal cortex encode abstract rules. Nature, 411(6840), 953–956. 
Wickham, H. (2009). ggplot2: Elegant graphics for data anal ysis [Computer software manual]. Springer-Verlag New York. Retrieved from http://ggplot2.org 
Wise, S. P., Boussaoud, D., Johnson, P. B., & Caminiti, R. (1997). Premotor and parietal cortex: corticocortical con nectivity and combinatorial computations. Annual Review of Neuroscience, 20, 25–42. 
Wutz, A., Loonis, R., Roy, J. E., Donoghue, J. A., & Miller, E. K. (2018). Different levels of category abstraction by different dynamics in different prefrontal areas. Neuron, 97, 1–11. 
Xing, J., & Andersen, R. A. (2000). Models of the posterior parietal cortex which perform multimodal integration and represent space in several coordinate frames. Journal of Cognitive Neuroscience, 12(4), 601–614. 
947
Episodic Control as Meta-Reinforcement Learning 
S Ritter1,2∗, JX Wang1∗, 
Z Kurth-Nelson1,3, M Botvinick1,4 
1DeepMind, London, UK 
2Princeton Neuroscience Institute, Princeton, NJ 
3MPS-UCL Centre for Computational Psychiatry, London, UK 4Gatsby Computational Neuroscience Unit, UCL, London, UK {ritters, wangjane, zebk, botvinick} @google.com 
Abstract 
Recent research has placed episodic reinforcement learning (RL) alongside model-free and model-based RL on the list of processes centrally involved in human reward-based learning. In the present work, we extend the unified account of model free and model-based RL developed by Wang et al. (2017) to further integrate episodic learning. In this account, a generic model-free "meta-learner" learns to deploy and coordinate all of these RL algorithms. The meta-learner is trained on a broad set of novel tasks with limited exposure to each task, such that it learns to learn about new tasks. We show that when equipped with an episodic memory system inspired by theories of reinstatement and gating, the meta-learner learns to use the same pattern of episodic, model-free, and model-based RL observed in humans in a task designed to dissociate among the influences of these learning algorithms. We discuss implications and predictions of the model. 
Keywords: Reinforcement learning; model-based; deep learn ing; meta-learning; episodic memory 
Introduction 
Nearly every decision an intelligent organism makes is in formed by its memory of the results of its past decisions. To be successful, agents must distill the results of past decisions into memories, then make use of those memories to make better decisions in the future. Accordingly, much effort has been directed toward understanding 1) what humans and ani mals store after a sequence of actions and rewards, and 2) how they use that stored information to appraise the value of future actions. 
Model-free and model-based reinforcement learning (RL; Daw, Gershman, Seymour, Dayan, & Dolan, 2011; Sutton & Barto, 1998) offer distinct solutions to these two prob lems. Model-free RL stores statistics about the relationship between states, actions and rewards, and appraises actions by calculating how frequently they led to reward. Meanwhile, model-based RL stores estimated state-state transition proba bilities, and appraises actions by using this model to simulate sequences of states to predict future reward. Signatures of both model-free and model-based learning appear in behavior and in the brain (e.g. Daw et al., 2011), and a venerable tradition holds that they are implemented by dissociable neural systems (for review see Dolan & Dayan, 2013). 
However, the recent theory of meta-reinforcement learning (meta-RL) proposed that model-free learning, model-based 
* These authors contributed equally to this work. 
learning, and their sometimes complex interaction could all be explained by a simple unified mechanism (Wang, Kurth Nelson, Tirumala, Soyer, et al., 2017; Wang, Kurth-Nelson, Tirumala, Leibo, et al., 2017). In meta-RL, the weights of a recurrent neural network (RNN) are trained by model-free learning on a series of interrelated tasks, and given the reward signal as part of its input. Remarkably, this leads to the emer gence of an independent RL algorithm implemented in the activation dynamics. Through its recurrence, the network has access to the history of observations, actions, and rewards. It learns to distill this history into its activation dynamics (a form of working memory) and use this to select rewarding actions. The end result is a learned reinforcement learning al gorithm that operates even with the weights of the RNN frozen. This meta-learned algorithm can itself be model-based even though it was acquired through model-free learning (Wang, Kurth-Nelson, Tirumala, Soyer, et al., 2017). 
While meta-RL provides a full account of incremental learn ing as it is carried out in working memory, it does not account for the episodic learning processes to which attention has re cently been called (Gershman & Daw, 2017). In addition to learning by incrementally storing recent sequences of behavior in working memory, humans appear to learn by storing sum maries of individual episodes for long periods of time, then retrieving them when similar contexts are encountered. For example, cues triggering episodic memory retrieval impact reward-based learning, both for good and for ill (Bornstein, Khaw, Shohamy, & Daw, 2017; Wimmer, Braun, Daw, & Shohamy, 2014), and distinctive aspects of episodic memory function contribute to decision-making behavior (Vikbladh, Shohamy, & Daw, 2017; Bornstein & Norman, 2017). Such observations, along with some fundamental computational insights, have recently landed episodic learning a spot be side incremental model-free and model-based reinforcement learning on the list of processes centrally involved in decision making (RL; Gershman & Daw, 2017). 
In the present work, we develop a natural extension to meta RL that enables it to integrate episodic learning. The resulting theory explains how incremental and episodic learning, as well as the coordination between them can be meta-learned through purely model-free RL. The episodic meta-RL theory proposes the following: 
1. Meta-RL’s working memory is supplemented by a non 948
parametric long-term memory which itself stores working memory states. 
2. Each state is paired with a perceptual context embedding that is later used to retrieve the working memory state when similar perceptual contexts are encountered. 
3. The retrieved states are then gated into the working mem ory using a parameterized function, whose parameters are optimized toward the same model-free objective that trains working memory. 
This proposal is inspired in part by evidence that episodic memory retrieval in humans operates through reinstatement, triggering patterns of neural activity related to those that were induced by the original encoding of the relevant episode (see, e.g., Xiao et al., 2017), and evidence that reinstatement oc curs not only in perceptual systems, but also recreates pat terns of activity in neural circuits supporting working memory (see Hoskin, Bornstein, Norman, & Cohen, 2017; Cohen & O’Reilly, 1996). Our implementation of this proposal draws additional inspiration from recent work on differentiable mem ory systems (e.g., Graves et al., 2016), especially that of Pritzel et al. (2017), which makes use of context-based retrieval for RL. 
To empirically test this model, in this work we compare its behavior to that of humans observed by Vikbladh et al. (2017) in a task designed to dissociate the effects of multi ple types of incremental and episodic learning. Vikbladh and colleagues found evidence of the use of a model-based form of episodic memory, whereby traces of specific episodes are retrieved from long-term memory based on visual similarity, then used along with knowledge of the transition structure of the environment to select actions. This episodic model-based learning was present in conjunction with incremental model free and incremental model-based learning. In the following sections, we describe the task in detail and demonstrate that meta-RL with episodic memory replicates the qualitative pat tern of human behavioral results observed by Vikbladh et al. To conclude, we consider directions for future work, including testable predictions of the theory. 
Task 
The task we study is a version of the two-step task (Daw et al., 2011) augmented with episodic cues to previous trials. The task structure, which was inspired by Vikbladh et al. (2017), is diagrammed in Figure 1. Each trial consisted of two stages. On the first stage, state S0, the agent was either presented with the "no-cue" stimulus (a vector of all -1’s) if this was an uncued trial, or with a binary vector associated with a previously seen second-stage context if this was a cued trial (see Figure 1). In response, the agent chose either a1 or a2 and transitioned into one of two second-stage states S1 or S2 with probabilities P(S1|a1) = P(S2|a2) = 0.9 (common transition) and P(S1|a2) = P(S2|a1) = 0.1 (uncommon transition). On the second stage, the agent was presented with a stimulus representing the context of that second-stage state, followed by a final step in which it was shown the reward outcome. The 
  

Figure 1: Contextual two-step task modeled after Daw et al. (2011) and Vikbladh et al. (2017). (top) Two trial types are shown: uncued and cued. All trials start in state S0 at the first stage, at which point agents are presented with either a "no-cue" stimulus or are cued with a second-stage stimulus seen on a previous trial. Transition proba bilities after taking actions a1 or a2 are depicted in the graph. On uncued trials, S1 and S2 result in Bernoulli rewards with probabilities ra and rb. On cued trials, transitioning into the same state as the trial being cued results in the exact sampled reward as before, r∗a. (bottom) Trials within an episode are split into 4 blocks, with block 3 consisting of cued trials which are cued with stimuli from block 1, and block 4 cued from block 2. 
context thus represented the conjunction of having transitioned into that particular state and obtaining that particular reward. The transition probabilities P were fixed across episodes. On uncued trials, the states S1 and S2 yielded Bernoulli prob abilistic rewards of 0 or 1 according to [ra,rb] = [0.9,0.1] or [0.1,0.9], with the specific reward contingencies having a 10% chance of randomly switching at the beginning of each trial. On cued trials, if the agent transitioned into the same state as on the trial being cued (i.e. the context is the same), the agent was given the exact same reward as before. If the agent transitioned into the other state, the reward was determined as on uncued trials. 
The first half of every episode (50 trials) consisted of all uncued trials, and the second half consisted of only cued trials, with trials 51-75 being cued with stimuli from trials 1-25 and trials 76-100 cued with stimuli from trials 26-50, randomly sampled without replacement. This was done to reduce autocorrelation in the reward probabilities by enforcing a minimum of 25 trials between seeing the stimulus on the second stage and being cued with it on the first stage. 
The agent was trained for 10,000 episodes of 100 trials each, and evaluated with weights fixed on 500 further episodes. 
Learning Algorithms 
The two-step task with episodic cueing is designed to dissoci ate among the influences of four different learning strategies on choice. First, the incremental model-free strategy pre scribes taking the same action that was taken on the last trial if it was rewarded, and taking the opposite action if it was not 
949
  

Figure 2: (Left) A high-level schematic of the recurrent network (LSTM) that comprises the episodic meta-RL (EMRL) agent’s working memory. On each time step the LSTM receives an environment state, the action taken on the previous trial, and the reward received on the previous trial. The LSTM encodes this information incrementally into its cell state c, and then outputs a policy and value estimate (not shown). (Middle) The storage operation to long-term memory at a single LSTM time step. Storage is triggered when reward is received at the end of each two-step trial, at which point the agent appends the contextual cue along with its cell state to a non-parametric store of such items. (Right) The long-term memory retrieval operation which occurs on every time step. A search is carried out over the cues stored in long-term memory for the closest match to the current contextual cue. The working memory activations associated with the closest match are retrieved and reinstated to the working memory state. 
rewarded, regardless of whether the transition on the previous trial was common or uncommon. In contrast, the incremental model-based strategy prescribes staying only if the previous trial was rewarded and the the previous transition was com mon. If the previous transition was uncommon and the trial was rewarded, the agent will take the opposite action. Episodic model-free and model-based strategies operate like their in cremental counterparts, but with respect to the trial associated with the cue rather than the immediately previous trial. 
Model 
In the episodic meta-RL model, vectors represent working memory states, and the function that updates these states and selects actions based on them takes the form of a recurrent neu ral network, specifically a long short-term memory network (LSTM; Hochreiter & Schmidhuber, 1997). To implement context-based reinstatement of the activations in this working memory, we append to this architecture a long-term memory of previous working memory states, searchable by a second column containing representations of perceptual context. This could for instance be the agent’s visual representation of the current environment state or an externally provided stimu lus. Optimization was performed by an implementation of asynchronous actor-critic (Mnih et al., 2016). 
The episodic meta-RL (EMRL) agent writes its current working memory state and perceptual representation to the long-term memory array when appropriate. In our experiments with the two-step task, the agent writes when it receives reward at the end of the each trial. 
The agent reads from this long-term memory array on every time step by searching for the perceptual representation in the array with the smallest cosine distances to that of the current state, allowing it to retrieve the associated working memory state. The retrieved activations are next passed through a learned gating function that arbitrates among the influences on the current working memory state of 1.) current perceptual inputs 2.) the previous working memory state and 3.) the 
working memory state retrieved from long-term memory. This gating mechanism is a natural extension to the standard LSTM working memory, which uses gates to arbitrate between current inputs and previous memory state: 
ct = i ◦ cin + f ◦ cprev 
ctis the current working memory state, cin is the agent’s representation of its current input, cprev is the working memory activation from the previous timestep, and ◦ signifies element wise multiplication. 
The gates i and f are values between zero and one that allow (or disallow) inputs and and past working memory activations into the current state. These gates are computed accordingly: 
i = σ(Wxix+Whih+bi) 
f = σ(Wx f x+Wh f h+bf), 
where x is the perceptual input, h is a function of the previous working memory state, and the weight matrices W and bias vectors b contain learned parameters. 
To reinstate working memory activations retrieved from long-term memory without losing the current contents of work ing memory, our architecture adds the retrieved activations to the current working memory state, after passing them through a gate that is computed in a manner exactly analogous to the standard LSTM gates: 
ct = i ◦ cin + f ◦ cprev +r ◦ cltm 
r = σ(Wxrx+Whrh+br) 
cltm contains the retrieved activations from long-term mem ory. This reinstatement gate r is intended to learn to allow activations from long-term memory into working memory when they are useful, but not when they will interfere with the maintenance of important information in working memory. See Figure 2 for depictions of the architecture. To illustrate 
950
how this architecture works in practice, consider the episodic two-step task, wherein the working memory keeps track of the reward probabilities at each outcome state. In order to infer these quantities, it must maintain information about its past actions and states. When the agent receives reward in the final step of a two-step trial, it will save the activations of its current working memory - which encode the agent’s outcome state and reward - to its long-term memory. These are saved along with a representation of the context stimulus, which models the participant’s visual representation of the object images or fractals in the human experiments (Daw et al., 2011; Vikbladh et al., 2017). 
At the beginning of a future two-step trial, the agent will encounter this same stimulus. It will then search its long-term memory for matches for that stimulus, and will retrieve the hidden state from the past trial. Crucially, this hidden state will encode the state the agent encountered at the end of the last exposure to that stimulus as well as the reward received and the action taken. Possessing this crucial episodic information, the agent is able to exploit the structure of the episodic two-step task. Specifically, it can learn to implement model-based or model-free valuation with respect to trial information retrieved from long-term memory. 
Results 
After training, we assessed meta-RL’s performance on a set of evaluation episodes having the same structure as the training episodes. However, to isolate the behavior of the learned learning algorithm operating in the activation dynamics, all data shown in the Results were obtained with the network’s weights frozen. 
The learned algorithm obtained more reward on cued than uncued trials (Figure 3a; p < 10-10 by Fisher exact test), sug gesting it could make use of the information carried by the episodic cue. We also compared against a control agent (meta RL; MRL) that was trained and tested in exactly the same way, but did not have access to an episodic memory (r-gate was al ways fixed to zero). The agent with episodic memory (EMRL) performed significantly better on cued trials than MRL (Figure 3a; p < 10-16 by Fisher exact test). For comparison, random behavior in this task yields 0.5 reward per trial, while optimal behavior achieves 0.756 on average. 
Next, we asked whether, on uncued trials, EMRL exhibited the canonical pattern of model-based behavior first described in (Daw et al., 2011). In the two-step task, if action at was taken on timestep t, followed by a common transition and resulting in a high reward, then both model-based and model free learners are expected to increase their preference for at. However, if after action at, an uncommon transition was ob served, followed by high reward, a model-free learner will still increase its preference for at (since it was rewarded after taking this action), while a model-based learner will decrease its preference for at (by using its knowledge of the transition structure of the task to infer a higher value for the other action). We formally tested for these patterns of behavior by perform 
ing an ANOVA on the probabilities of repeating the previous action, with two binary factors: whether the previous trial was rewarded, and whether the previous trial had a common tran sition. A main effect of previous trial being rewarded would indicate a model-free strategy, while an interaction between previous trial being rewarded and previous trial being common would indicate a model-based strategy. 
On uncued trials (Figure 3b), we found a strong effect of the interaction term (F(1,1853) = 9134, p ≈ 0), indicating that the learned algorithm correctly exploited the transition struc ture of the task when no episodic information was available, replicating our previous work (Wang, Kurth-Nelson, Tirumala, Soyer, et al., 2017). On cued trials (Figure 3c), we also found an effect of the interaction term (F(1,1893) = 295, p ≈ 0), suggesting that EMRL partially attempted to continue to use the incremental strategy even though it had no reward benefit on cued trials. 
Next, most centrally, we asked whether – on cued trials – EMRL could apply model-based reasoning to information re trieved from episodic memory (Figure 3d). We performed the same ANOVA described above, but using as factors: whether the past trial was rewarded, and whether the past trial had a common transition. Since our task guaranteed receiving the same reward if the agent reached the same state as the past trial, the agent should prefer to take the opposite action as on the past trial if it experienced an uncommon transition and re ceived reward on that trial. We indeed found a strong effect of the interaction term in this analysis (F(1,1850) = 5975, p ≈ 0). This pattern mimics the behavior of humans on the task from which ours was directly inspired (Vikbladh et al., 2017). Note that we only performed this analysis on cued trials because the factors would be undefined on uncued trials. 
To supplement this analysis, we also fit a probabilistic choice model to EMRL’s behavior. In this model, action prob ability was the softmax of the weighted sum of four choice values: 
P(a0) = 1 
1+exp(−(βi fVi f +βibVib +βe fVe f +βebVeb)) 
where, for example, Vi f is the difference in incremental model free values: action a0 minus action a1. All incrementally learned values were updated with the same learning rate α, for a total of five parameters. These were estimated by maximum likelihood on the concatenated data of all 500 episodes (with incrementally learned values reset to 0.5 at the beginning of each episode). Cued and uncued trials were fit separately. Mirroring the human data in Vikbladh et al. (2017), we found a contribution of all systems except episodic model-free, and a reduction in the incremental model-based parameter on cued trials (Figure 4). 
Analysis of Reinstatement Gate Activations We performed a preliminary analysis of the activations of the reinstatement gates (see Figure 5). First, we plotted the time course of mean r-gate values averaged over 500 episodes. We split these time courses based on the stage in the two-step trial 
951
  
  
  
  
(a) Performance (b) Incremental Uncued (c) Incremental Cued (d) Episodic 
Figure 3: EMRL exhibits both incremental and episodic model-based behavior. (a) Average reward obtained by MRL and EMRL on cued and uncued trials. EMRL, but not MRL, makes use of episodic memory on cued trials to earn more reward. (b) Proportion of uncued trials in which EMRL repeated the action it took on the previous trial (t −1), split by whether it received reward on t −1 and whether the transition on t −1 was common. The interaction between those two factors is a sign of model-based learning, as in Daw et al. (2011). (c) Same as b, but for cued trials. (d) Same as b, but split by whether EMRL received reward on trial k and whether the transition on k was common. k refers to the past trial in which the cue was first encountered. 
  
  
  

(a) r-gate throughout an episode (b) r-gate correct vs incorrect 
Figure 5: (a) Time course of the mean values of the reinstatement 
gate averaged over 500 episodes, split up by stage of the trial. (b) 
Mean values of the reinstatement gate on cued trials on which the 
Figure 4: Parameter estimates in a model with weighted contributions of four decision systems. Model was fit to EMRL’s actions separately on cued and uncued trials. All systems except episodic model-free have positive contributions to EMRL’s behavior. The contribution of the incremental model-based system is reduced on cued trials relative to uncued trials. 
(see Figure 1). We first observed that the r-gate was more open during cued trials compared to uncued trials, consistent with the presence of useful episodic information on cued trials. Next, we observed that the r-gate was most open during the first stage of each trial. We believe this makes sense because it is critical to base action on the information retrieved from long-term memory. 
Next, we compared the mean r-gate values on correct cued trials versus cued trials where the agent made an error, and found the r-gate was significantly more open on correct tri als. We speculate that fluctuations in r-gate openness resulting from the multiplexing of episodic memory control with cur rent policy control might have driven some behavioral errors. Future work should analyze this phenomenon in detail. 
Discussion 
The experiments in this work establish that when trained on a task distribution with both incremental and episodic re ward structure, episodic meta-RL learns to simultaneously 
agent selected the optimal and on cued trials on which it selected the opposite action, averaged over all units. 
execute incremental model-based, incremental model-free, and episodic model-based learning strategies. Like the par ticipants in the study by Vikbladh and colleagues, our agent exhibits these three learning strategies, but does not exhibit episodic model-free learning. This striking match in behavior provides support for episodic meta-RL as a model of human decision making as it is implemented by working memory and episodic memory structures. 
Episodic meta-RL thus provides an empirically supported unified account of incremental and episodic learning processes, whereby a single model-free learning mechanism learns to ex ecute and deploy a variety of learning algorithms observed in humans. In addition to this support from behavioral data, the model accords in principle with a large neuroscientific litera ture which supports the notion that episodic memory retrieval recreates patterns of activity in neural circuits supporting work ing memory (see Cohen & O’Reilly, 1996; Lewis-Peacock & Postle, 2008; Staresina, Henson, Kriegeskorte, & Alink, 2012; Hoskin et al., 2017; Xiao et al., 2017). Further, the gating system that allows reinstated activations into working mem ory is formally equivalent to those in the LSTM that inspired neuroscientific theory which posits that multiple such gating 
952
mechanisms operate in prefrontal cortex (Chatham & Badre, 2015). 
The key takeaway from the success so far of the episodic meta-RL model is a proof of the sufficiency of a small set of well motivated architectural components, when trained to optimize a specific objective function, to produce the complex pattern of learning processes observed in humans. The archi tecture components are: 1) a recurrent working memory with 2) a non-parametric store of working memory activations that can be retrieved by context and reinstated through 3) a learned gating system. The objective function is total reward achieved on a distribution of learning tasks. 
Predictions 
This model makes a number of predictions which may be tested through further empirical work: 
• The pattern reinstatement seen during episodic RL tasks (Bornstein & Norman, 2017) should be observed in cases where the patterns in question are linked with working mem ory, rather than only immediate perception. 
• There is already strong neurobiological evidence for gating to regulate the flow of information into and out of working memory (Chatham & Badre, 2015). Analogous experiments should find evidence for a similar mechanism to gate re instated activations from long-term memory into working memory. 
• In a novel episodic RL task, we predict that relevant cues will trigger episodic recall, but this recall initially will not trigger reinstatement in the populations of cells responsible for working memory. As task experience increases, im provements in behavioral performance will be correlated with increased functional coupling between episodic and working memory. However, if DA-dependent plasticity is blocked during training, this increase in functional coupling will be slowed. 
Summary 
In summary, this work presents a new model that explains the collage of learning processes observed in humans during decision making as an interplay between working and episodic memory that is itself learned through training to maximize reward on a distribution of learning tasks. Future work may test the predictions made by this model and test the model’s ability to replicate additional sources of empirical data. 
References 
Bornstein, A. M., Khaw, M. W., Shohamy, D., & Daw, N. D. (2017). Reminders of past choices bias decisions for reward in humans. Nature Communications, 8. 
Bornstein, A. M., & Norman, K. A. (2017). Reinstated episodic context guides sampling-based decisions for re ward. Nature Neuroscience, 20. 
Chatham, C. H., & Badre, D. (2015). Multiple gates on working memory. Current Opinion in Behavioral Sciences. Cohen, J. D., & O’Reilly, R. C. (1996). A preliminary theory of the interactions between prefrontal cortex and hippocam 
pus that contribute to planning and prospective memory. In Prospective memory: Theory and applications. 
Daw, N. D., Gershman, S. J., Seymour, B., Dayan, P., & Dolan, R. J. (2011). Model-based influences on humans’ choices and striatal prediction errors. Neuron, 69(6), 1204–1215. 
Dolan, R. J., & Dayan, P. (2013). Goals and habits in the brain. Neuron, 80(2), 312–325. 
Gershman, S. J., & Daw, N. D. (2017). Reinforcement learning and episodic memory in humans and animals: An integrative framework. Annual review of psychology, 68. 
Graves, A., Wayne, G., Reynolds, M., Harley, T., Danihelka, I., Grabska-Barwinska, A., . . . others (2016). Hybrid comput- ´ ing using a neural network with dynamic external memory. Nature. 
Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735–1780. 
Hoskin, A. N., Bornstein, A. M., Norman, K. A., & Cohen, J. D. (2017). Refresh my memory: Episodic memory reinstatements intrude on working memory maintenance. bioRxiv, 170720. 
Lewis-Peacock, J. A., & Postle, B. R. (2008). Temporary activation of long-term memory supports working memory. Journal of Neuroscience, 28(35), 8765–8771. 
Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T. P., Harley, T., . . . Kavukcuoglu, K. (2016). Asynchronous methods for deep reinforcement learning. In Proc. of int’l conf. on machine learning, ICML. 
Pritzel, A., Uria, B., Srinivasan, S., Puigdomènech, A., Vinyals, O., Hassabis, D., . . . Blundell, C. (2017). Neural episodic control. arXiv preprint arXiv:1703.01988. 
Staresina, B. P., Henson, R. N., Kriegeskorte, N., & Alink, A. (2012). Episodic reinstatement in the medial temporal lobe. Journal of Neuroscience, 32(50), 18150–18156. 
Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning: An introduction (Vol. 1). MIT press Cambridge. 
Vikbladh, O., Shohamy, D., & Daw, N. (2017). Episodic contributions to model-based reinforcement learning. In Annual conference on cognitive computational neuroscience, CCN. 
Wang, J. X., Kurth-Nelson, Z., Tirumala, D., Leibo, J., Soyer, H., Kumaran, D., & Botvinick, M. (2017). Meta reinforcement learning: a bridge between prefrontal and dopaminergic function. In Cosyne abstracts. 
Wang, J. X., Kurth-Nelson, Z., Tirumala, D., Soyer, H., Leibo, J. Z., Munos, R., . . . Botvinick, M. (2017). Learning to reinforcement learn. Cognitive Science, CogSci. Retrieved from arXivpreprintarXiv:1611.05763 
Wimmer, G. E., Braun, E. K., Daw, N. D., & Shohamy, D. (2014). Episodic memory encoding interferes with reward learning and decreases striatal prediction errors. J Neurosci, 34. 
Xiao, X., Dong, Q., Gao, J., Men, W., Poldrack, R. A., & Xue, G. (2017). Transformed neural pattern reinstatement during episodic memory retrieval. Journal of Neuroscience, 37. 
953
Emergence of vowel-like organization in a color-based communication system 
Gareth Roberts (gareth.roberts@ling.upenn.edu) 
Department of Linguistics, 3401-C Walnut Street 
Philadelphia, PA 19104 USA 
Robin Clark (rclark@sas.upenn.edu) 
Department of Linguistics, 3401-C Walnut Street 
Philadelphia, PA 19104 USA 
Abstract 
Vowel systems exhibit organization, and several theoretical ac counts have been proposed to explain this. A prominent ac count explains organization in terms of maximizing the disper 
sion of vowels, increasing acoustic perceptibility while reduc ing articulatory effort. This implies modality-independence, 
but leaves open questions about the extent to which dispersion 
is driven by articulatory or acoustic pressures. We investigated 
whether vowel-like organization would emerge in a novel vi 
sual communication system in the laboratory, in which partic ipants took turns to send color signals to communicate a set of 
animal referents by moving their fingers around a color space. 
We manipulated the extent to which sender and receiver needs 
were aligned. Overall, systems exhibited significant levels of dispersion; participants also took into account receiver needs, withconsequences for the structure of the resulting systems. 
Keywords: language; phonology; experimental; communica tion game; experimental semiotics 
The phonologies of natural languages exhibit a high degree of organization in their choice and deployment of phonemes. This can be clearly demonstrated with vowels. A vowel is produced by allowing air from the lungs to pass through the vocal tract, with only low levels of constriction. Vowel qual ity is varied by varying the shape of the vocal tract, princi pally by moving the tongue and lips. This leads to variation in formant frequencies, prominent concentrations of acous tic energy. Several formants matter for speech perception, but the first and second are the most important. Tradition ally, the vowel phonemes of a language are plotted in a two dimensional space with the x axis corresponding to the sec ond formant (F2, shown as increasing in frequency from right to left), and the y axis to the first formant (F1, shown as in creasing from top to bottom); see Figure 1. These values cor respond well enough to tongue position that vowels located towards the top left of the space (i.e., with high F2 values and low F1 values) are standardly referred to as high front vow els; that is, these are vowels produced by raising the tongue towards the top front of the mouth (for a more detailed in troduction to the phonetics of vowels see Ladefoged & John son, 2015). The purpose of this paper is to present a novel experimental approach to understanding the origins of, and constraints on, the organization of such spaces. 
That vowel systems exhibit substantial organization has long been recognized (Liljencrants & Lindblom, 1972; Schwartz, Boe, Vall ¨ ee, & Abry, 1997; de Boer, 2000). While ´ the vowelspace is continuous, the vowel phonemes used in a given language are not simply distributed at random across it. Rather, they tend to be dispersed relatively efficiently. In 
Figure 1: Chart of the vowels of the world’s languages (based on charts produced by the International Phonetic Associa tion), with F1 and F2 axes indicated. The chart corresponds roughly to the mouth of a speaker facing left. For each pair of vowels, the vowel on the right is produced with lip rounding. 
a three-vowel system, for instance, it is extremely likely that one vowel will be a high front vowel /i/, one will be a high back vowel /u/, and the third will be a low vowel /A/ or /a/. Larger systems tend to exhibit similarly efficient structure. Several different categories of theory have been proposed to account for this observation (for reviews see de Boer, 2001; Vaux & Samuels, 2015). While some accounts focus on fea tures of individual vowels (e.g., classical “markedness”-based accounts; Jakobson & Halle, 1956; Chomsky & Halle, 1968), others focus on the relationship between vowels in a system. In dispersion theory, a particularly prominent account, op timization of the system is taken to be driven by the func tional pressures of minimizing effort (in particular that of the speaker) while maximizing the perceptual contrast between vowels (Liljencrants & Lindblom, 1972; Lindblom, 1986; de Boer, 2001). 
In fact, most accounts of vowel space organization – with markedness-based accounts a notable exception – claim es sentially that vowel space self-organization is driven by two basic demands: increasing acoustic perceptibility and re ducing articulatory load (Stevens & Keyser, 2010; Mrayati, Carre, & Gu ´ erin, 1988). These demands compete in some ´ cases. It is notable, for instance, that if dimensions beyond the first and second formant are taken into account, vowel systems do not in fact make maximal use of the resources available to them. By nasalizing one of the vowels in a three vowel system and pharyngealizing another, for instance, their 
954
mutual distinctiveness could be increased (cf. de Boer, 2001, p. 15). This is uncommon, however, and the explanation for that would appear to be that incorporating these extra dimen sions increases articulatory complexity for the speaker, and does not become necessary from the point of view of percep tual distinctiveness until the number of vowels in a system gets sufficiently large (Lindblom & Maddieson, 1988). 
Nevertheless, the details of how these demands relate to each other are still not fully clear, and in many respects they are hard to disentangle. It was noted above that the frequen cies of the first and second formants map somewhat well to tongue position, meaning that – in this respect at least – there is a reasonably consistent relationship between articulatory space and acoustic space. This makes it hard to distinguish speaker-driven constraints from listener-driven ones. It might seem intuitive that dispersion is likely to be driven by per ceptibility rather than articulatory ease, but this is in fact not obvious. The edges of the space are advantageous from an articulatory point of view, as they are easier to find than ar bitrary points within the space (for this reason, the corners of the space are particularly advantageous).1 To put the ques tion another way: If acoustic distinctiveness were reduced rather than increased by moving to the edges of the articula tory space, would we see the same pattern? If perceptibility is the main driving force, we should expect not to; if dis persion is driven more by articulatory constraints, then we should expect such a system to look similarly dispersed to real-world systems. Answering this question by manipulat ing the acoustic and articulatory space is in principle possible, but poses severe difficulties, not least reducing the influence of participants’ own natural language phonologies. In this paper, therefore, we present an experiment in which partici pants communicated visually, using fingers as articulators to produce colors as analogs of vowels. 
Our study has more than one goal. The first goal is to es tablish a new experimental approach to investigating vowel space organization. As this implies, it is anticipated that the general approach presented here will be applied to many rel evant questions. The second goal concerns the specific ques tion to which we applied the approach. This question has two parts. First, we tested whether a novel visual communication system would, through cooperative communication, begin to exhibit organization at greater than chance level. Second, we manipulated the extent to which the interests of the “speaker” aligned with those of the “listener” and tested whether, when those interests were not aligned, systems would take that into account and be organized differently. 
Our paradigm draws on a set of approaches that were pri marily developed, and have become an increasingly stan dard method, for investigating the emergence and cultural 
1A comparison can be made with consonants; stop consonants involve bringing articulators into complete contact, while frica tives involve holding them close enough that the air passes through with turbulence. Stop consonants are acquired earlier by children than fricatives and are more common in the world’s languages (Ladefoged & Maddieson, 1996). 
evolution of language. These approaches, which Galantucci (2009) dubbed Experimental Semiotics, involve human par ticipants learning or creating novel communication systems in the laboratory (for a review, see Galantucci, Garrod, & Roberts, 2012), and they involve a social dimension lack ing in traditional artificial-language-learning experiments. In experimental-semiotic studies, participants either engage in a communication task (e.g., Galantucci, 2005; Sneller & Roberts, 2018) or learn a miniature language based on the output of other participants (e.g., Kirby, Cornish, & Smith, 2008; Verhoef, Kirby, & de Boer, 2014). Taking an experimental-semiotic approach has a number of advantages. Analogues to change that would take many years in natural language can be observed in miniature languages over very short time periods; factors that cannot be manipulated outside the laboratory, or cannot be manipulated in natural languages even within the laboratory, can be manipulated in miniature languages with relative ease. By investigating processes of change in non-linguistic communication systems, particularly using novel signaling media, researchers can reduce the in fluence of the participants’ own languages (for further dis cussion of the advantages of this approach, see Galantucci & Roberts, 2012). Although few experimental-semiotic stud ies (to our knowledge) have investigated the organization of combinatorial units in phonological spaces (de Boer & Ver hoef, 2012, is something of an exception), several have in vestigated the emergence of combinatorial units from con tinuous signals (e.g., Roberts & Galantucci, 2012; Roberts, Lewandowski, & Galantucci, 2015; Verhoef et al., 2014; Del Giudice, 2012). Our study was influenced by these: Par ticipants played a cooperative signaling game, sending color signals to each other to communicate a set of animal referents. We manipulated the way different colors could be produced and measured the organization of the resulting systems. 
  

Figure 2: Sender’s screen. Labels are for clarity and were not shown to participants. 
Method 
Participants 
Sixty University of Pennsylvania students (34 female), none of whom suffered from color-blindness, participated in pairs for course credit.2 
2Owing to a software error, other demographic data such as age and handedness were not recorded. However, their distribution is 
955
  
  
Figure 3: Receiver’s screen. Labels are for clarity and were 
not shown to participants. 
Materials 
Participants sat in separate cubicles, each with a computer (a mid-2014 Apple iMac), running custom-designed software (written in Python and Kivy), and a wireless multitouch track pad (a 2009 Apple Magic Trackpad, measuring 13.01cm by 13.13cm). Participants could not see each other from their cubicles or hear each other easily. 
Procedure 
Pairs of participants played a cooperative communication game, taking turns to be Sender and Receiver.3 Each par ticipant (henceforth player) in a pair sat in a separate cubi cle and saw a screen divided vertically into two halves. (For the most part, the screen looked much the same whether the player was Sender or Receiver; Figures 2 and 3). In the left half of the screen, the referent panel, a set of referents were displayed (black animal silhouettes, a subset of those used by Roberts & Galantucci, 2012, Figure 4).4 The top right half of the screen, the color panel, appeared gray as default, but would change color depending on the behavior of the Sender. The same was true of a smaller section immediately below it, the sent-color panel, which was also gray by default and took up a quarter of the width of the screen as a whole and a quar ter of the height. (See Signaling medium Section below for a description of how the color panel and the sent-color panel worked.) To the right of the sent-color panel, a timer was dis played on a white background. Below this, taking up half the width of the screen, was a score panel displaying the pair’s joint score against a black background. 
The referent panel differed slightly for the Sender and the Receiver. First, the referents were not in the same places (and were redistributed randomly each round). Second, no refer ent was ever in the center of the Receiver’s referent panel; 
not expected to have deviated substantially from that of the wider undergraduate population at Penn. 
3It was important for our question that participants both have an opportunity to be Sender and Receiver. Had this not been the case, any differences between conditions could be explained in terms of a failure on the part of the Sender to appreciate the Receiver’s needs. This approach also had the advantage of greater ecological validity. 
4Roberts and Galantucci (2012) used 20 referents in total; we used a 12-referent subset of theirs in order to give participants time to refine their signaling systems. Given the time available, continu ing to add referents until there were twenty would have meant that systems would be in a constant state of flux. 
Figure 4: Referents used in the experiment. The top row ap peared at the beginning of the game; as players became more successful, the other rows were added in turn. 
the Sender, on the other hand, always had one referent in the center, against a red background (Figure 2). Third, the Receiver had a green cursor that could be moved around the referent panel by using the arrow keys on the computer key board (Figure 3). The Sender had no such movable cursor. The Sender’s task was to convey to the Receiver which refer ent they had in the center of their panel by sending colors to the Receiver (see Signaling medium Section below), and the Receiver’s task was to move the cursor to the correct referent and press enter. Both players would then receive feedback: The background of the correct referent would turn red for the Receiver and the background of the chosen referent would turn green for the Sender. This happened whether or not the Receiver chose correctly. If the Receiver did choose correctly, the pair would score one point; their total point score was dis played in the score panel at the bottom of the screen. After players started to do well at signaling the referents, more were added, in groups of four, up to a total of twelve. This would occur if, for all referents in the referent panel, the Receiver had selected them correctly at least 75% of the time over the previous four rounds in which they had occurred (cf. Roberts et al., 2015). 
A round lasted 20s in total, with feedback lasting an ad ditional 2s. If the Receiver had not chosen a referent by the time the 20s were up, the pair scored no point for that round. Whatever the outcome of the round, the players would swap roles for the following round. The game lasted for 80min in total, and would finish at the end of the current round when the 80min mark had been passed. At the start of the experi ment, players played four practice rounds that differed from the ordinary rounds in three ways: First, they lasted 60s; sec ond, the players’ score from these rounds did not carry over into the normal rounds; third, players were reminded at the start of each round whether they were Sender or Receiver. Beyond being told to move a finger around the pad and ob serve the screen, and to hold their finger down for 1s to send a color, players were not instructed how to use the signaling medium, but rather had to explore it on their own. 
956
Signaling medium 
To convey to the Receiver which referent to select, the Sender could send colors. The Sender could do this by moving one finger around on the trackpad. This would produce a color in the color panel on the top right of their screen (but not the Re ceiver’s screen), which would change in real time depending on the coordinates of the Sender’s finger. If the Sender took their finger off the pad or touched the pad with more than one finger, the color panel would appear gray. If the Sender held their finger in place on the trackpad for 1s or longer, the same color would appear for 2s both on the Receiver’s color panel and on the Sender’s sent-color panel. This was the only means by which the Sender could send information to the Receiver.5 A Sender could send as many colors as they liked, within the time available (20s). 
The relationship between the Sender’s finger position and the color produced was based on an RGB color space, with each color composed of red, green, and blue components, the contribution of each ranging from 0 to 1 (e.g., the vec tor [1,0,0], where the digits indicate the red, green, and blue components respectively, would correspond to a bright red color). The basic value for one of the three components in creased from 0 to 1 as the Sender’s finger moved from right to left on the pad, while another decreased from 1 to 0 in the same direction; the third color component increased as the finger moved vertically. Which color corresponded to which direction was counterbalanced, but for any trial, the exact cen ter of the pad corresponded to the vector [0.5, 0.5, 0.5]. If vertical position corresponded to the blue component, then placing the finger in the middle of the top edge of the pad would produce a mixture of red and green [0.5, 0.5, 0], while the middle of the bottom edge would produce a mixture of red, green, and blue, with blue predominating: [0.5, 0.5, 1]. Players were not in fact exposed precisely to the basic color values described here; instead, the values were modified in a way that varied between two conditions. The details of this are described in the Conditions section. 
Conditions 
There were two conditions. In the Bright-edge condition the basic color values described above were altered depending on how close the Sender’s finger was to the center of the pad (Figure 5). This was done by multiplying the color compo nent values by a modifier that ranged from 0 to 1. The mod ifier was calculated as d/doe, where d equals the Euclidean distance between the Sender’s finger and the center of the 
5In this respect, our study differs from earlier experimental semiotic work on combinatorial systems, which were primarily con cerned with investigating the emergence of atomic units from con tinuous media. Participants in those studies were thus not provided with pre-ordained means of producing units. This means that iden tifying how such units might be constituted is itself a challenging task (Roberts & Galantucci, 2012). Because of this, and because we were concerned not with the emergence of such units, but how they become organized, our task forced subjects to select units from a continuous space, thereby simplifying our analysis while still main taining a continuous signal space from which units could be drawn. 
space and doe equals the distance from the center of the space to the outer edge. This meant that colors towards the edges of the space were brighter, and therefore likely to be clearer for the Receiver to distinguish. Since the edges of the pad were also easier to find reliably for the Sender, the pressures acting on the Sender and Receiver were therefore relatively aligned in this condition. 
In the Bright-band condition this was not the case. Here, an imaginary line was drawn 30% of the way in from the edge of the pad. Between the real edge of the pad and this “inner edge”, the modifier was calculated as 1 − (d/doe). Once the Sender’s finger crossed the inner edge, however, the modifier changed to d/die, where die is the distance from the center of the pad to the inner edge. This meant that the colors got brighter as the Sender’s finger moved away from the center of the pad, but then began abruptly to get darker again. The most convenient parts of the pad for the Sender to select reli ably were still along the outer edge of the pad, but the easiest colors to distinguish for the Receiver were closer to the inner edge. The inner edge was in no way marked on the pad or screen; it became apparent to the Sender as they moved their finger around the pad and observed the effect. 
  

Figure 5: Example color spaces for Bright edge and Bright band conditions respectively. Note that participants never saw the space itself, only individual colors. 
Dependent variables 
For each player, we looked at the last successful signal for ev ery referent for which the player could be determined to have established a signal. In terms of the game, this meant that the referent had been successfully communicated in at least three of the last four times it had occurred. This gave us a set of “words” that that player had in their system, each of which was composed of a set of units – colors that had been chosen to be sent. Each unit consisted of an x and a y coordinate corresponding to the player’s finger position when the color was sent.6 We pooled all units across a player’s words and produced a “phoneme inventory”. As in natural language, it was assumed that players might reuse phonemes between words. We therefore trimmed each inventory by compar ing phonemes; if the distance between any two of them was less than 5% of the maximum distance available, one was re moved at random. This left an inventory ranging in size from 
6For the purposes of the analysis presented here, we will focus only on the finger position, ignoring the color coordinates produced. 
957
7 to 19 phonemes (Mean = 11.97). Figure 6a shows an exam ple 12-phoneme inventory from the Bright-edge condition. We then measured the following variables. In each case, the mean value for a pair forms the basis of the results re ported below. 
Phoneme inventory size. The number of phonemes in an in ventory. 
Dispersion. Two measures of dispersion were used: 
Mean pairwise distance. The mean Euclidean distance between all pairs of phonemes. This gives a measure of how well spread out the phonemes are within the space. This was then divided by the maximum possible distance to give a number between 0 and 1. 
Mean distance from center. The mean Euclidean dis tance between the center of the space and the phonemes. This was then divided by the distance from the center to the corner to give a number between 0 and 1. 
Number of referents. The number of referents for which a “word” had successfully been established. 
Success index. This measure was based on how many words a player successfully established and how fast they did so. For every round of a given game, we counted how many referents each player had an established word for (see above) at that point. We then calculated a success in dex as (∑nr1s)/12nr, where nris the number of rounds and the numerator is a cumulative count of s, the number of successfully established words in a given round.7 
We present comparisons between conditions for all vari ables below. For the second and third variables (mean pair wise distance and mean distance from center) we also gener ated random artificial data to provide a baseline. We did this by first counting the number of units in each inventory, be fore trimming (see above) had occurred. Then we generated a random inventory of phonemes of the same size, and trimmed that. Then we measured the mean pairwise distance and mean distance from center for the artificial data. This was repeated 10,000 times, and we counted the number of times the values for the variables in the randomly generated data were equal to or higher than the real data. If this occurred often, it would suggest that the real data did not exhibit particular high lev els of dispersion. In fact, the values in the baseline trials did not in any one of the 10,000 replications equal or exceed the values for the real data in either condition. 
Results 
Communication systems in the Bright-edge condition em ployed slightly more phonemes (M = 12.77; SD = 2.15) than 
7It should be noted that no player could actually score 1, as that would require them to have successfully communicated all twelve referents several times before the start of the game. While this could be accounted for, this would complicate the calculation, which we did not deem necessary for a relative measure of success. 
  

Figure 6: (a) Example inventory from Bright-edge condi tion. Coordinates are normalized by dividing by the width and height of the space; (b) Example (normalized) inventory from Bright-band condition. (c) Mean dispersion; (d) Mean success. Error bars show 95% CI. 
in the Bright-band condition (M = 11.17; SD = 1.81; t(27.19) = 2.2, p = 0.04). There was a positive correlation between the number of phonemes and the number of referents success fully communicated, r = 5.5, n = 30, p = 0.0018. 
Players in the Bright-band condition appear to have taken into account the Receiver’s interests: Phonemes in this con dition were less far from the center of the space (M = 0.53; SD = 0.05) than in the Bright-edge condition (M = 0.63; SD = 0.05; t(27.82) = 5.25, p < 0.0001; Figure 6c). The pair wise distance was also lower (M = 0.37; SD = 0.036) than in the Bright-edge condition (M = 0.45; SD = 0.035; t(27.99) = 5.79, p < 0.00001; Figure 6d). 
Players in the Bright-band condition also found the game harder (Figure 6b). They established successful signals for a mean of 8.3 referents (SD = 2.04), and their mean success index was 0.46 (SD = 0.12). The figures for the Bright-edge condition were significantly higher in each case: 10.83 refer ents (SD = 1.72; t(27.2) = 3.68, p = 0.001), with a mean suc cess index of 0.61 (SD = 0.14; t(27.303) = 3.15, p = 0.004). 
Success also correlated with both Mean distance from cen ter (r(28) = 0.39, p = 0.032) and Mean pairwise distance (r(28) = 0.39, p = 0.032)8 
Discussion 
We set out to answer two questions: First, whether a col laboratively constructed visual communication system would 
8An earlier version of this paper reported no correlation; this was an error based on correlating dispersal with number of referents – a more indirect proxy for success – rather than the success index. 
958
exhibit organization analogous to that of a vowel space; sec ond, whether receivers’ interests with respect to perceptibil ity would be allowed to trump senders’ interests with respect to ease of production. The answer to both questions was a clear yes. Our data provide support for dispersion-based ac counts of phonological organization (as opposed to accounts based on language-specific notions of markedness), suggest ing that the organizational principles involved are modality independent. There are some limitations of the current study. In natural language the articulatory space maps to the acous tic space in a particular way that has likely been subjected to evolutionary forces. The mapping of the trackpad space to the color space in our experiment is rather more arbitrary and has clearly not been subjected to the same kind of evolution ary forces. This has advantages (as our paradigm provides greater space for manipulating variables, and helps shield our data from natural-language influence), but in future work it would be worthwhile taking into account more specific de tails of natural-language speech production. Our study also did not take into account several factors that have been sug gested as playing a role in the organization of vowel spaces, not least generational transmission (Vaux & Samuels, 2015), which might be expected to amplify the biases operating in our experiment (Kalish, Griffiths, & Lewandowsky, 2007). There are well established methods that can be used to inves tigate this in future work (Kirby et al., 2008; Verhoef et al., 2014). However, we consider that, in this paper, we have pre sented a novel and useful experimental paradigm for inves tigating the cultural evolution of phonological spaces, which can be easily adapted to answer a number of questions. 
Acknowledgments 
We thank members of the Cultural Evolution of Language Lab for their work gathering data for this project. 
References 
Chomsky, N., & Halle, M. (1968). The sound patterns of English. Cambridge, MA: MIT Press. 
de Boer, B. (2000). Self-organization in vowel systems. Jour nal of Phonetics, 28(4), 441–465. 
de Boer, B. (2001). The origins of vowel systems. Oxford: Oxford University Press. 
de Boer, B., & Verhoef, T. (2012). Language dynamics in structured form and meaning spaces. Advances in Complex Systems, 15(3–4), 1150021 (20 pages). 
Del Giudice, A. (2012). The emergence of duality of pattern ing through iterated learning: Precursors to phonology in a visual lexicon. Language and Cognition, 4(4), 381–418. 
Galantucci, B. (2005). An experimental study of the emer gence of human communication systems. Cognitive Sci ence, 29(5), 737–67. 
Galantucci, B. (2009). Experimental Semiotics: A new ap proach for studying communication as a form of joint ac tion. Topics in Cognitive Science, 1(2), 393–410. 
Galantucci, B., Garrod, S., & Roberts, G. (2012). Experimen tal Semiotics. Language and Linguistics Compass, 6(8), 477–493. 
Galantucci, B., & Roberts, G. (2012). Experimental Semi otics: An engine of discovery for understanding human communication. Advances in Complex Systems, 15(3–4), 1150026. 
Jakobson, R., & Halle, M. (1956). Fundamentals of lan guage. The Hague: Mouton. 
Kalish, M. L., Griffiths, T. L., & Lewandowsky, S. (2007). It erated learning: Intergenerational knowledge transmission reveals inductive biases. Psychonomic Bulletin & Review, 14(2), 288–294. 
Kirby, S., Cornish, H., & Smith, K. (2008). Cumulative cul tural evolution in the laboratory: An experimental approach to the origins of structure in human language. Proceed ings of the National Academy of Sciences, 105(31), 10681– 10686. 
Ladefoged, P., & Johnson, K. (2015). A course in phonetics (Seventh ed.). Stamford, CT: Cengage Learning. 
Ladefoged, P., & Maddieson, I. (1996). The sounds of the world’s languages. Oxford: Blackwell. 
Liljencrants, J., & Lindblom, B. (1972). Numerical sim ulation of vowel quality systems: The role of perceptual contrast. Language, 48(4), 839–62. 
Lindblom, B. (1986). Phonetic universals in vowel systems. Experimental phonology, 13–44. 
Lindblom, B., & Maddieson, I. (1988). Phonetic universals in consonant systems. Language, Speech, and Mind, 62–78. Mrayati, M., Carre, R., & Gu ´ erin, B. (1988). Distinctive ´ regions and modes: A new theory of speech production. Speech Communication, 7(3), 257–286. 
Roberts, G., & Galantucci, B. (2012). The emergence of du ality of patterning: Insights from the laboratory. Language and Cognition, 4(4), 297–318. 
Roberts, G., Lewandowski, J., & Galantucci, B. (2015). How communication changes when we cannot mime the world: Experimental evidence for the effect of iconicity on com binatoriality. Cognition, 141, 52–66. 
Schwartz, J.-L., Boe, L.-J., Vall ¨ ee, N., & Abry, C. (1997). ´ Major trends in vowel system inventories. Journal of Pho netics, 25, 233–253. 
Sneller, B., & Roberts, G. (2018). Why some behaviors spread while others don’t: A laboratory simulation of di alect contact. Cognition, 170C, 298–311. 
Stevens, K. N., & Keyser, S. J. (2010). Quantal theory, en hancement and overlap. Journal of Phonetics, 38(1), 10– 19. 
Vaux, B., & Samuels, B. (2015). Explaining vowel systems: Dispersion theory vs. natural selection. The Linguistic Re view, 32(3), 573–599. 
Verhoef, T., Kirby, S., & de Boer, B. (2014). Emergence of combinatorial structure and economy through iterated learning with continuous acoustic signals. Journal of Pho netics, 43, 57–68. 
959
This and that back in context:  
Grounding demonstrative reference in manual and social affordances 
Roberta Rocca (roberta.rocca@cc.au.dk) 
Department of Linguistics, Cognitive Science and Semiotics,  
Aarhus University, Jens Chr. Skous Vej 2, 8000 – Aarhus C, Denmark 
Mikkel Wallentin (mikkel@cc.au.dk) 
Department of Linguistics, Cognitive Science and Semiotics & Center of Functionally Integrative Neuroscience,  Aarhus University, Jens Chr. Skous Vej 2, 8000 – Aarhus C, Denmark 
Cordula Vesper (cvesper@cc.au.dk) 
Department of Linguistics, Cognitive Science and Semiotics & Interacting Minds Centre,  Aarhus University, Jens Chr. Skous Vej 2, 8000 – Aarhus C, Denmark 
Kristian Tylén (kristian@cc.au.dk) 
Department of Linguistics, Cognitive Science and Semiotics & Interacting Minds Centre,  Aarhus University, Jens Chr. Skous Vej 2, 8000 – Aarhus C, Denmark 
Abstract 
Spatial demonstratives, i.e. words like this and that, serve as  important tools to establish joint attention, allowing  interlocutors to flexibly share spatial reference schemes.  However, little experimental work has investigated which  perceptual and social factors drive speakers’ choices of  demonstrative forms. We used a novel experimental paradigm  to explore 1) the role of relative placement of competing referents on the sagittal and lateral planes, 2) whether and how  the presence of an addressee modulates the speaker’s choice of  demonstrative forms. We found that the choice of  demonstratives is affected by the relative position of competing referents both on the sagittal and lateral plane.  Furthermore, we found that the presence of an interlocutor  shifts attraction for proximal demonstratives towards the  shared space of reference, but only in collaborative contexts.  Together, these results suggest that spatial deixis is grounded  in a contrastive organization of space tightly coupled to manual  and social affordances. 
Keywords: demonstratives; social cognition; spatial  cognition; spatial deixis 
Introduction 
The ability to establish joint attention on objects or locations  is a fundamental building block of human sociality (Tomasello, 2005). A wide spectrum of everyday activities  relies on the ability to coordinate on and navigate joint  attentional scenes. Natural languages are endowed with a  large inventory of strategies that can be used for spatial  referencing and coordination purposes (Tylén et al., 2010).  Among them, spatial demonstratives, i.e. words like this and  that, stand out, as attentional alignment isintegral to their use 
(Diessel 1999). Demonstratives are prominent items in  linguistic interaction. They are among the first lexical items  to be mastered during development, and alongside  
960
communicative pointing, they play a crucial role in bootstrap ping language acquisition (Diessel, 1999; Diessel, 2006).  Additionally, demonstratives can be regarded as cross linguistic universals (Diessel, 2006).  
In contrast to other strategies for verbal referencing, such  as the use of nouns and descriptions, demonstratives carry  minimal semantic specification of the intended referent, causing their interpretation to crucially hinge on the context  of the utterance (Diessel, 1999; Levinson, 1983). 
Physical context 
When used to refer to entities in the physical context of the  utterance, demonstratives are typically coupled with visual  signals such as pointing gestures (Clark, 1996; Cooperrider,  2016) or gaze cues (Perea-García et al., 2017), which deliver 
crucial information on the location of the intended referents  relative to the speaker. In an EEG/ERPs experiment, Stevens  & Zhang (2012) reported N400 effects for incongruence  between demonstratives and object location only when the  speaker and addressee in the scene established joint gaze on  the referent. As demonstratives are used as attention aligning  devices, participants perceived the absence of shared gaze as  a violation in their use. 
With the exception of very few languages, all  demonstrative systems explicitly encode at least a minimal dyadic contrast between proximal and distal referents. More  complex demonstrative systems display either more fine grained distance-based contrasts, e.g. via explicit lexical encoding of medial distances from the speaker, or additional  person-oriented contrasts, providing, for example, some  specification on the position of referents relative to the  addressee (Diessel, 1999).  
Previous studies have experimentally investigated the  motivations for this distance-based distinction, and provided empirical evidence for a mapping between the proxi mal/distal contrast in demonstrative systems and a functional  
representation of space in body-centered coordinates. In a  series of studies relying on a paradigm labelled the memory  game, Coventry and colleagues asked participants to point at  referents located at varying distances from the speaker on the  sagittal axis and to refer to them by either a proximal or a  distal demonstrative (Coventry et al, 2008; Coventry et al.,  2014; Gudde et al., 2016). They established a mapping  between distance-based contrasts in demonstratives and the  distinction between peripersonal and extrapersonal space,  consistent across a variety of genetically heterogeneous  languages. 
Interestingly, the choice of demonstratives along the  proximal / distal axis inherits the characteristic flexibility of the boundary between peripersonal and extrapersonal space  (Coventry et al., 2014). It has been shown that the use of  proximal demonstratives is sensitive to manipulations of the  scope of peripersonal space achieved with tool use (Longo &  Lourenco, 2006). Moreover, just like physical distance and  object attributes such as graspability and affective valence  interact in perceptual judgements of reachability (Valdés Conroy et al., 2012), the choice of demonstratives in dyadic 
systems is affected by perceptual parameters of the referent  (e.g. visibility), as well as by psychological parameters such  as ownership and familiarity (Coventry et al., 2014).  
However, spatial demonstratives resist a rigid mapping  onto body-centered representations of physical space.  Bonfiglioli et al. (2009) exploited well-established  interference effects between word meaning and movement  planning and execution (Glover et al., 2004) to explore the  semantics of spatial deixis. Participants were primed with  either a proximal demonstrative or a distal demonstrative,  then performed reach-for-grasp movements for objects  located at two different distances in peripersonal space. They  found that incongruence between demonstratives and spatial  locations affected reaction times in movement execution.  Together, these studies suggest that the use of demonstratives  is not alone determined by physical distance between a single referent and the speaker, but rather reflects a flexible and  context-sensitive implementation of the contrastive potential  of the demonstrative system as a whole (Kemmerer, 1999; 
2006). 
Social context  
In a recent series of EEG studies, Peeters and colleagues (2015) have questioned purely egocentric proximity-based  accounts of spatial deixis and stressed the role of the social  context of utterance. Based on N400 effects, they reported a  preference for proximal demonstratives for objects located in  space shared between two interlocutors, irrespective of the  distance of the referent from the speaker. Based on these  results, the authors argue in favor of a reference frame  
961
centered on the conversational dyad, rather than on the  speaker alone. This proposal is in line with accounts of linguistic reference as a collaborative process (Clark, 1996).  As pointed out within such frameworks, speakers design their  communicative acts by actively taking into account the  addressee’s perspective and their common ground (Clark et  al., 1983; Clark and Bangerter 2004). 
The present study 
The aim of the present study was to address a number of  outstanding questions related to how physical and social  context influence demonstrative use. First, as previous  experiments simplified reference resolution to single-referent  contexts (which would not capture naturalistic situations of  demonstrative use), we aimed to test how the presence of  competing referents modulates the choice of demonstrative  forms in interaction. We hypothesized that proximal  demonstratives are more likely to be used for referents  relatively closer to the speaker on the sagittal axis. 
Secondly, existing paradigms have put the emphasis  exclusively on the specifics of spatial deixis along the sagittal  axis. It is, however, widely established that biomechanical constraints, such as handedness, may be a prominent source  of asymmetries in perceptual space. Perceptual  representations of peripersonal space underlying planning  and execution of reaching movements rely on dynamic  transformations between hand-centered and retinocentric  coordinates (Makin et al., 2012). In the light of the hypothesis  that the proximal/distal contrast is grounded on functional  representations of space for reach and grasp (Coventry et al.,  2014), a hand-centered frame of reference might indeed be  crucial for the understanding of demonstrative reference. If the hand, rather than the locus of foveal fixation or the head,  is the center of the deictic frame of reference, a lateralized  bias for proximal demonstratives towards the hand used for  pointing would be expected which has not been captured by  previous experimental paradigms. Given these previous  findings, and with all our participants being right-handed, we  hypothesized a right-lateralized bias in favor of proximal  demonstratives. 
Last, existing literature has tackled deixis in individual  contexts, without the presence of a conversational partner.  However, while some languages lexicalize distinctions  between locations of referents relative to an addressee,  demonstrative choice in languages lacking an explicit  encoding of the addressee’s standpoint may still be affected  by perceptual common ground between interlocutors (Peeters  et al., 2015). Therefore, we hypothesized that physical biases would be attenuated by the presence of a social partner in  contexts of collaborative interaction. 
Baseline Complementary Collaborative “SQUARE” 
“THAT” 
“THIS” 
“THAT” “STAR” “THIS” 
“THAT” 
“THIS” 
Figure 1: Experimental setup of the three conditions  
To test our hypotheses, participants in the present study  saw pairs of targets briefly appearing on a 40’’ monitor lying  horizontally. Their task was to point at the location of the two  targets while referring to each of them by either a Danish  proximal (“den her”) or a distal demonstrative (“den der”).  Participants were tested under three conditions: an individual 
baseline, a complementary condition, where a confederate  performed a task unrelated to the participant’s pointing, and  a collaborative condition, in which the participant’s pointing  was functional to the confederate’s task. The hypotheses were 
preregistered on the Open Science Framework prior to  conducting the experiment. The preregistration is available  here: osf.io/gjnf9. 
Methods 
Participants 
80 right-handed participants (female = 43, age range = 19- 48, median = 26, sd = 7.6) with Danish as first language took  part in the experiment at the Cognition and Behavior Lab at  Aarhus University in return for a monetary compensation.  The authors and two student assistants took turns in the role  of experimenter (live-coding the subject’s responses) and confederate. 
Design & Procedure 
The task was presented as a spatial working memory test  (in line with Coventry et al., 2008; 2014). In each trial, a grid  of circles would appear on the screen for 500 ms. Then the  grid disappeared and two target shapes (circles, triangles,  squares, hexagons, stars) appeared on the screen for a random  interval between 200 – 800 ms. Then the grid would reappear  and the participants were prompted to designate the target  positions. The position of targets was randomized across  trials. Subjects were instructed to remember the locations of  targets, then point at them while referring to the objects with  the Danish demonstratives “den her” or “den der”. They were  explicitly instructed to use both demonstrative forms in each  trial, and were reminded to do so whenever they disregarded  the rule. No explicit instructions were given on the order of  
962
the points nor on the order of deictic forms. There were 132  trials per condition per subject.  
Participants performed the task across three conditions. In the  baseline condition, subjects performed the task alone. In the  complementary condition, a confederate stood to the left of  the subject and named the target shapes (e.g. “star, circle”)  after the participant was done pointing. There was no  interaction between the two tasks, and therefore neither the  participant nor the confederate depended on the information  provided by the other to perform their own task. In the  collaborative condition, the confederate would close her eyes  during target exposure and only opened them after a click  sound. The participant then pointed at the location of both  targets so to allow the confederate to report them on a touch  screen device placed next to the big screen. The baseline was  always performed first. The order of the complementary and  collaborative conditions was counterbalanced. 
Analysis 
The relative distances between the x coordinates and the y  coordinates of the two targets were used as predictors for a mixed effects logistic regression using the glmer function  from lme4 package in RStudio. For each trial, one of the two  targets (henceforth: T1) was randomly selected and logged as  target of interest. The relative distances on each of the axes  were computed by subtracting the x coordinates and the y  coordinate of the competitor target (henceforth: T2) from  those of T1. The relative distance on the x axis took positive  values if T1 was further to the right than T2, whereas their  distance on the y axis took positive values if T1 was further  away from the speaker than T2 on a sagittal axis. The fixed  effects structure of the model included the relative distance  between the two targets on the y axis, the relative distance  between the two targets on the x axis, and condition, as well  as all interactions.  
The demonstrative form (proximal or distal) chosen to refer  to T1 was used as outcome variable in the model. The distal  demonstrative (“den der”) was set as reference level, while  the proximal form (“den her”) was coded as success outcome.  
The random effect structure included random intercepts for  each participant as well as random slopes for relative distance  on the y axis. 
Proportion of demonstratives, RelY 100 
75 
50 
25 
0 
Proportion of demonstratives, RelX 
DER 
HER 
0.0 0.15 0.3 0.60 0.75 −1.2 −0.2 0 1 
−0.75 −0.6 −0.45 −0.3 −0.15 0.45 Distance between targets on Y axis 
−1.4 −1 −0.8 −0.6 −0.4 0.2 0.4 0.6 0.8 1.2 1.4 Distance between targets on X axis 
Figure 2: proportion of demonstratives across values of RelY (left) and RelX (right) across all conditions 
Parameters were estimated using maximum likelihood  estimation with Laplace approximation. The power  simulation for the model is reported in the preregistration,  yielding 70-100% power for fixed effects and two-way  interactions. Planned contrasts for the categorical predictor  compared the subject’s behavior in the baseline condition  with cumulative behavior in the social condition, as well as  the complementary condition against the collaborative  condition. 
Results 
After discarding invalid responses, a total of 31394 out of  31680 data points was included in the analysis. As shown in  Figure 2 (left), the proportion of proximal demonstratives  decreases as a function of increases in the value of RelY, i.e.  as T1 moves further away from the speaker on the sagittal  axis relative to T2. Figure 2 (right) displays the pattern for  RelX: there was an increase in proportion of proximal  demonstratives as a function of an increase in the value of  RelX, i.e. as T1 moves further to the right relative to T2.  
A mixed effects logistic regression model with RelX, RelY  and condition as predictors, and including all interactions, confirms the statistical reliability of these patterns. The model displays a significant effect of RelY, β = -2.59, se = 0.27, z =  -9.7, p < .001 and of RelX, β = 0.32, se = 0.02, z = 16.77, p < .001. 
Planned contrasts reveal a significant interaction between RelX and Condition when comparing the complementary and  collaborative condition, β = 0.05, se = 0.02, z = 2.17, p < .05.  No such effect is observed when cumulatively comparing the  baseline to the social conditions, β = -0.001, se = 0.01, z = - 0.079, p = .93.  
Moreover, the interaction between RelY and Condition reaches statistical significance both in the contrast between baseline and the two social conditions, β = -0.07, se =0.03, z = -2.51, p < 0.01, and between the complementary and  
collaborative condition, β = -0.11, se = 0.05, z = - 2.45, p <  .01. None of the three-way interactions reached statistical  significance. 
963
Discussion 
In the following, we discuss the results with respect to our  three hypotheses.  
Relative distance on the sagittal axis As shown by the main effect of RelY, the relative distance between targets on the sagittal axis had an impact on the use of demonstratives.  As the sagittal distance between the two referents increased,  the likelihood of observing a distal demonstrative  progressively increased. While the latter point is in line with  the well-established preference for distal demonstratives for  referents placed far from the speaker (Coventry et al., 2008),  such a finding adds to current knowledge along some  intriguing dimensions. First, it provides empirical evidence  for the hypothesis that demonstrative reference is grounded  on the construction of a contrastive space of competing 
referents, in addition to a mapping between deictic space and  near/far space. In other words, in the context of competing  referents, the organization of deictic space is set up  contrastively, by taking into account the interplay between  distances of the intended referent from the speaker’s body  and from competing referents. 
Right-lateralized bias within peripersonal space Across  all conditions, we found a right-lateralized preference for  proximal demonstratives. The preference for proximal  demonstratives was strengthened as the distance between the  target referent and the competing referent increased. This  finding is in line with previous research hypothesizing a  lateralized bias in peripersonal space, and can be attributed to  space being encoded in hand-centered coordinates, which  facilitates fast execution of hand movements by reducing the  load of sensorimotor transformations (Makin et al., 2012).  This correspondence between the organization of  demonstrative space and hand-based encoding of space is in  line with the link between the proximal/distal distinction and  reach for grasp actions, which has previously been  established in the literature on demonstratives use (Coventry  et al., 2014; Bonfiglioli et al., 2009). While Coventry and  colleagues (2008; 2014) frame this relationship in terms of  binary (though flexible) distinction between space within reach and out of reach, Bonfiglioli and coworkers (2009)  argue that the conceptual space for this and that is grounded  on differences in distance even within peripersonal space. 
Baseline Complementary Collaborative Figure 3: Heat maps displaying the proportion of proximal demonstratives across values of RelX (x-axis) and RelY (y-axis)   
Together, our findings provide evidence in favor of  proximal/distal distinctions being grounded on gradient  affordance for manual interaction rather than on an absolute  mapping. While the present investigation does not fully  explore manipulations of target locations going significantly  beyond peripersonal space, the paradigm allowed to show  that the proximal/distal organization of space is indeed  grounded in biomechanics, with objects more readily  affording grasp being more likely to be labelled via a  proximal demonstrative. 
This further underlines the integral role of multimodal  components in deictic reference, as the right-lateralized bias  in the organization of space probably reflects a bias towards  the pointing hand. However, in the experiment we did not  manipulate which hand is used for pointing nor did we  include any left-handed participant. Therefore, the current  results might either be due to a bias in favor of the hand used  for pointing (independently of handedness) or in favor of the  dominant hand (independently of the hand used for pointing). 
Further research including relevant manipulations is required  in order to disentangle such possibilities. An additional  explanation is that asymmetries are due to a general  perceptual bias. However, previous studies have mostly  reported left-lateralized biases in perceptual tasks and visual  imagery, which have been attributed to reading direction  (Jewell & McCourt, 2000; Stoustrup & Wallentin, 2017). Our  results point in the opposite direction, thus suggesting that  biomechanical constraints tend to override purely perceptual  sources of asymmetries when motor components are essential  for the task at stake. 
It is to be pointed out that we initially predicted lateralized  biases to be detected in the form of an interaction between  RelX and RelY, as we expected it to apply only to referents with low absolute values of RelY. The observed main effect  of RelX rather suggests that the right-lateralized bias is  independent of the position of the targets on the y-axis, which shows that such bias might be even more prominent than  expected in influencing demonstrative production. This  consideration also applies to the interaction between RelX  and Condition reported below, which was initially expected  in the form of a three-way interaction with RelY.  
Social presence and collaboration For demonstration  purposes, Figure 3 displays the distribution of proximal  demonstratives as a function of variation in RelX and RelY.  The heat maps are oriented so to display higher values of  RelX towards the right, and higher values of RelY towards the  
964
top. As figure 3 suggests, the baseline and the complementary  condition display a similar pattern, with a slightly more  pronounced bias in the complementary condition. In the  complementary condition, the confederate’s task was to name  which shapes lit up on the screen. When the confederate takes  up the semantic part of the task, the speaker’s increased focus  on the spatial location of the referents resulted in a more  pronounced right-lateralized bias. 
However, the bias is significantly attenuated in the  collaborative condition, i.e. when the speaker and addressee  are engaged in a task involving actual collaboration and,  therefore, functional, communicative pointing. This result  provides evidence for the fact that, when pointing, the  participant factors in the position of the addressee, which  induces a shift in the proximal space towards the space shared  between the two interlocutors. Interestingly, this is not the  case for mere co-presence of another participant (in the  complementary condition), but rather requires involvement  of the interlocutors in a collaborative interaction. In this case,  since the information conveyed by the speaker’s pointing is  functional to the addressee’s task, the speaker might  spontaneously facilitate the interlocutor’s task by adjusting  her proximal space towards shared space. 
The effect of RelY also seems to be modulated across  conditions, with the preference for proximal demonstratives  for closer referents becoming weaker in the two social  conditions compared to the baseline, an effect which is likely  to be driven by the collaborative condition. Although it has  to be acknowledged that this effect was not part of our initial  set of hypotheses, it affords an interpretation compatible with  our previous remarks. Indeed, the effect suggests that the  purely hand-based contrastive space set up in the baseline is  attenuated by the presence of an addressee in favor of an  organization of space which takes social components into  account.  
Moreover, the heat map for the collaborative condition  indicates higher frequency of proximal demonstratives for  negative RelX and higher RelY (centre left of the map) than  the complementary condition and the baseline, which  corresponds to proportionally more proximal demonstratives  for cases in which T1 is located more towards the left of the  speaker (and therefore closer to the addressee) but further away from the speaker. This suggests that such effect might  be mostly driven by data points with high values of RelX. 
Conclusion 
We investigated the effect of object location and social  presence in use of demonstratives. Our results suggest that  participants’ tendency to use proximal demonstratives  increases as the target of interest gets closer to the speaker 
and further away from the competing target, which suggests  that deictic space is organized as a contrastive space rather  than relying uniquely on a fixed mapping between  peripersonal and extrapersonal space. 
Additionally, we observed a right-lateralized bias in the  use of proximal demonstratives. This provides evidence  towards a tight link between the organization of space in  spatial deixis and action, under the hypothesis that proximal  demonstratives are more likely to be used for referents  affording easier manual interaction. Finally, we observed that  both the effect of relative distance on the y axis and the effect  of relative distance on the x axis are modulated by the  presence of an addressee cooperating with the speaker in  solving a shared task. Speakers shift their proximal space towards shared space, a finding which suggests that the  organization of space in demonstrative reference is tightly  coupled to social affordances. 
Acknowledgements 
This project was funded via a seed-funding grant from the  Interacting Minds Centre at Aarhus University. Roberta  Rocca is funded by the DCOMM grant (EU H2020 ITN  Marie Skłodowska-Curie Actions; grant agreement 676063). 
We wish to thank Sergio Gonzalez de la Higuera Rojo and  Caroline Kildahl for their assistance with data collection. 
References  
Bonfiglioli, C., Finocchiaro, C., Gesierich, B., Rositani, F., &  Vescovi, M. (2009). A kinematic approach to the  conceptual representations of this and that. Cognition,  111(2), 270-274. 
Clark, H. H. (1996). Using language. Cambridge University  Press. 
Clark, H. H., Schreuder, R., & Buttrick, S. (1983). Common  ground at the understanding of demonstrative  reference. Journal of verbal learning and verbal  behavior, 22(2), 245-258. 
Clark, H. H., & Bangerter, A. (2004). Changing ideas about  reference. In Experimental pragmatics (pp. 25-49).  Palgrave Macmillan UK. 
Cooperrider, K. (2016). The co-organization of  demonstratives and pointing gestures. Discourse  Processes, 53(8), 632-656. 
Coventry, K. R., Valdés, B., Castillo, A., & Guijarro-Fuentes,  P. (2008). Language within your reach: Near–far perceptual  space and spatial demonstratives. Cognition, 108(3), 889- 895. 
Coventry, K. R., Griffiths, D., and Hamilton, C. J. (2014).  Spatial demonstratives and perceptual space: describing  
965
and remembering object location. Cogn. Psychol. 69, 46– 70. 
Diessel, H. (1999). Demonstratives: Form, function and  grammaticalization, John Benjamins Publishing. Diessel, H. (2006). Demonstratives, joint attention, and the  emergence of grammar. Cognitive linguistics, 17(4), 463- 489. 
Glover, S., Rosenbaum, D. A., Graham, J., & Dixon, P.  (2004). Grasping the meaning of words. Experimental  Brain Research, 154(1), 103-108. 
Gudde, H. B., Coventry, K. R., & Engelhardt, P. E. (2016).  Language and memory for object location. Cognition, 153,  99-107. 
Jewell, G., & McCourt, M. E. (2000). Pseudoneglect: a  review and meta-analysis of performance factors in line  bisection tasks. Neuropsychologia, 38(1), 93-110. 
Kemmerer, D. (1999). “Near” and “far” in language and  perception. Cognition, 73(1), 35-63. 
Kemmerer, D. (2006). The semantics of space: Integrating  linguistic typology and cognitive  neuroscience. Neuropsychologia, 44(9), 1607-1621. 
Levinson, S. C. 1983. Pragmatics. Cambridge University  Press.  
Longo, M. R., & Lourenco, S. F. (2006). On the nature of  near space: Effects of tool use and the transition to far  space. Neuropsychologia, 44, 977-981.  
Makin, T. R., Holmes, N. P., Brozzoli, C., & Farnè, A.  (2012). Keeping the world at hand: rapid visuomotor  processing for hand–object interactions. Experimental  brain research, 219(4), 421-428. 
Perea-García, J. O., Ehlers, K. R., & Tylén, K. (2017). Bodily  constraints contributing to multimodal referentiality in  humans: The contribution of a de-pigmented sclera to  proto-declaratives. Language & Communication, 54, 73- 
81. 
Peeters, D., Hagoort, P., and Özyürek, A. (2015).  Electrophysiological evidence for the role of shared space  in online comprehension of spatial demonstratives.  Cognition 136, 64–84 
Stevens, J., & Zhang, Y. (2013). Relative distance and gaze  in the use of entity-referring spatial demonstratives: An  event-related potential study. Journal of  Neurolinguistics, 26(1), 31-45. 
Stroustrup, S., & Wallentin, M. (2017). Grammatical  category influences lateralized imagery for  sentences. Language and Cognition, 1-15. 
Tomasello, M., Carpenter, M., Call, J., Behne, T. and Moll,  H. (2005). Understanding and sharing intentions: the  origins of cultural cognition. Behavioral and Brain  Sciences, 28, 675–91; discussion, 691-735. 
Tylén, K., Weed, E., Wallentin, M., Roepstorff, A., & Frith,  C. D. (2010). Language as a tool for interacting  minds. Mind & Language, 25(1), 3-29. 
Valdés-Conroy, B., Román, F. J., Hinojosa, J. A., & Shorkey,  S. P. (2012). So far so good: Emotion in the  peripersonal/extrapersonal space. PLoS one, 7(11),  e49162. 
Dynamic speech adaptation to unreliable cues during intonational processing 
Timo B. Roettger (timo.roettger@northwestern.edu) 
1Northwestern University, Department of Linguistics 
2016 Sheridan Rd, Evanston, IL 60208 USA 
2University of Cologne, IfL Phonetics 
Herbert-Lewin-Strasse 6, 50931 Köln, Germany 
Michael Franke (mchfranke@gmail.com) 
Universität Tübingen, Seminar für Sprachwissenschaften 
Wilhelmstr. 19–23, 72074 Tübingen, Germany 
Abstract 
Human behavior is often remarkably flexible, showing the ability to quickly adapt to the statistical peculiarities of a particular local context. When it comes to language, previ ous work has shown that listeners’ anticipatory interpretations of intonational cues are adapted dynamically when cues are observed to be stochastically unreliable. This paper reports novel empirical data from manual response dynamics (mouse tracking) on how listeners adapt their predictive interpretation when some intonational cues are occasionally unreliable while others are consistently reliable. A model of rational belief dy namics predicts that listeners adapt differently to different un reliable intonational cues, as a function of their initial eviden tial strength. These predictions are borne out by our data. 
Keywords: intonation; mouse-tracking; prosody; rational pre dictive processing; speech adaptation 
Introduction 
Variable environments require the ability to quickly adapt ex pectations and behavior. Language is no exception. Indeed, language users have been shown repeatedly to adapt read ily to their immediate local context in syntax (e.g. Fine & Jaeger, 2013; Jaeger & Snider, 2013), pragmatics (e.g. Grod ner & Sedivy, 2011; Yildirim, Degen, Tanenhaus, & Jaeger, 2016), and speech (e.g. Norris, McQueen, & Cutler, 2003; Kleinschmidt & Jaeger, 2015). While previous work look ing at speech adaptation has mainly focused on local phe nomena within small temporal windows (e.g. adaptation to segments), there is only little work on adaptation of speech patterns across larger domains. Here, we focus on listeners’ ability to adapt to the selective and partial reliability of into national cues, and ask whether observed adaptations are con sistent with a model of rational belief dynamics. 
Intonation plays an integral role in comprehending spoken language. In English or German, for instance, the position and form of a pitch accent can signal a referent as discourse new or contrastive (Ladd, 2008). Deviating from a traditional categorical view (e.g. Pierrehumbert & Hirschberg, 1990), recent work identifies intonational form-function mappings as highly variable and probabilistic (e.g. Grice, Ritter, Nie mann, & Roettger, 2017; Roettger, 2017). Comprehenders can nevertheless rapidly process intonational cues to antici pate a likely speaker-intended referent even before encoun tering disambiguating lexical material (e.g. Dahan, Tanen haus, & Chambers, 2002; Weber, Braun, & Crocker, 2006; Kurumada, Brown, Bibyk, Pontillo, & Tanenhaus, 2014a). 
Listeners also adapt their anticipatory cue interpretation based on experimental pre-exposure to either reliable or un reliable input (Kurumada, Brown, Bibyk, Pontillo, & Tanen haus, 2014b). Unfortunately, pre-exposure manipulation of cue reliability does not allow inferences about the temporal dynamics of listener adaptation during exposure. Roettger and Franke (2017) therefore investigated the development of listener interpretation behavior over the course of the experi ment when listeners are exposed to either occasionally unreli able or, in a different group, consistently reliable intonational cues. For reliable input, listeners quickly learned to predic tively exploit the absence of an early pitch accent, while ex ploiting the presence of this cue right from the start (see Ma terials section for details). Unreliable exposure occasionally featured unnatural uses of all relevant intonational cues. This inhibited anticipatory interpretations mainly for the presence of an early pitch accent, but did not strongly affect the condi tion with an absent pitch accent. 
Roettger and Franke (2017) argue that these results are compatible with the assumption that comprehenders expect reliable intonational information initially and gradually adapt these expectations rationally under reliable or unreliable in put. A Bayesian model of the evidential strength of into national cues (to be introduced presently) predicts that the stronger (weaker) a cue, the more (less) it will be affected by learning that it is unreliable, and the less (more) it will be af fected by learning that it is reliable. This model also predicts that listeners should adapt differently to scenarios where only one cue is learned to be unreliable, while the other is reliable. We here report on an experiment, extending that of Roettger and Franke (2017), designed to test these predictions. 
Rational Predictive Processing 
Bayesian comprehenders derive their rational predictive inter pretation from differences in the likelihood with which they expect speakers to produce particular intonational contours to signal a certain discourse status of a referent. By Bayes rule, the posterior odds in favor of referent r1 over r2 after observ ing a (possibly partial) utterance u are calculated as the prod uct of the likelihood ratio (how likely a speaker produces u for ri) and the prior odds (how likely a speaker refers to ri): 
966
P(r1 | u) P(r2 | u) | {z } posterior odds 
=P(u | r1) P(u | r2) 
| {z } 
likelihood ratio 
P(r1) 
P(r2) 
| {z } prior odds 
pants heard either a topic question like (1), which introduced a referent as discourse-given, or the neutral question (2): (1) 
(1) Hat der Wuggy dann die Geige aufgesammelt? Did the wuggy then pick up the violin? 
(2) Was ist passiert? What happened? 
If utterance u with its specific intonational contour is more likely to be produced for r1 than for r2, an observation of u shifts the listener’s beliefs towards r1 and away from r2. Ob serving u would therefore be observational evidence in favor of r1 relative to r2 (Jaynes, 2003). The likelihood ratio there fore quantifies the evidential strength of a cue u. 
A direct experimental measure of comprehenders’ dynam ically evolving posterior odds between two candidate in terpretations can be obtained from mouse-movements in a forced-choice decision task. Roettger and Stoeber (2017) and Roettger and Franke (2017) show that listeners integrate into national information early on and move their mouse towards a likely target referent even before they have processed dis ambiguating lexical information. This is in line with numer ous experiments demonstrating that the continuous uptake of sensory input and dynamic competition between simultane ously active representations is reflected in subjects’ hand or finger movements (e.g. Magnuson, 2005; Spivey, Grosjean, & Knoblich, 2005; Freeman & Ambady, 2010) and falls in line with recent papers using mouse tracking to investigate the processing of pragmatic inferences (e.g. Tomlinson, Gotzner, & Bott, 2017). 
Concrete model predictions for a mouse-tracking experi ment in which some intonational cues are unreliable while others are reliable are spelled out below, after the design and materials have been introduced in more detail. 
Experiment 
The following experiment was preregistered on the 27th of November 2017, prior to data collection. The preregistra tion file can be retrieved with all materials, data, and analysis scripts from https://osf.io/49q2r/. 
Participants and Procedure 
Sixty native German speakers participated, all with self reported normal or corrected-to-normal vision and normal hearing (21 male, 39 female, mean age = 24.4 (SD = 3.4)). 
Subjects were seated in front of a Mac mini 2.5 GHz Intel Core i5. They controlled the experiment via a Logitech B100 corded USB Mouse. Cursor acceleration was linearized and cursor speed was slowed down (to 1400 sensitivity) using the CursorSensec application (version 1.32). Slowing down the cursor ensured that motor behavior was recorded in a smooth trajectory as the acoustic signal unfolded. 
Subjects learned about a ‘wuggy’, a fantasy creature which picks up objects. There were 12 objects to pick up (bee, chicken, diaper, fork, marble, pants, pear, rose, saw, scale, vase, violin), all with German grammatical gender feminine. 
Each trial exposed subjects to a context screen, shown for 2500ms and providing a specific discourse context. Partici 
Next, participants saw a response screen with 2 response alternatives, each depicting one object in the upper left and right corner, respectively. After 1000ms a yellow circle ap peared at the bottom center of the screen. A click on it initi ated playback of an audio recording of a statement specifying which object was picked up, e.g. (3) or (4). 
(3) Der Wuggy hat dann die Geige aufgesammelt. Then the wuggy has picked up the violin. 
(4) Der Wuggy hat dann die Birne aufgesammelt. Then the wuggy has picked up the pear. 
Subjects were instructed to move their mouse upwards im mediately after clicking the initiation button (see Spivey et al., 2005) and to choose their response as quickly as possible. 
Material 
Statements were acoustically manipulated to exhibit three dif ferent intonation contours. Depending on the preceding con text question (1) or (2), statements in (3) and (4) are prototyp ically realized with different intonation contours (e.g. Grice et al., 2017). After a neutral question (2), both subject and object are discourse-new which can be prosodically encoded by specific pitch accents on both constituents (often referred to as broad focus). A common contour in these cases is a rising accent on the subject, followed by a high stretch of f0 and a high or falling accent on the object. After a polar topic question (1), the utterance in (3), which affirmatively picks up the given referent, can prosodically emphasize that the propo sition in question is true, for example, by verum focus, which manifests itself here in the form of a high rising accent on the German auxiliary hat (Engl. has). Finally and as opposed to the latter, the answer in (4) corrects the topic question (1). It affirmatively mentions a contrastive referent, which is typi cally realized by contrastive focus, an intonation contour with a high rising accent on Birne (pear). Figure 1 illustrates the Verum and Contrast contours schematically. Statements for each experimental item (n = 12) came with these three into nation contours (Broad, Verum, and Contrast), resulting in 36 different target sentences overall. 
There were two sets of acoustic stimuli: questions provid ing a discourse context presented on the context screen and statements triggering participants’ responses on the response screen, with one question and one statement corresponding to each object. 
Acoustic stimuli were recorded by a trained phonetician. To ensure that the three different contexts exhibit the same temporal characteristics for each sentence (i.e. the lexical information become available at the same time across fo cus conditions), sentences were manipulated and resynthe 
967

Figure 1: f 0 contours and average temporal landmarks for the resynthesis of Verum and Contrastive focus. 
sized using Praat (Boersma & Weenink, 2016). The re sulting stimuli differed only in the pitch contour and ac companied intensity envelope. The preregistration report https://osf.io/49q2r/ contains additional information about the resynthesis process. 
Design 
There were two experimental groups. The unreliable verum (UV) group was exposed to consistently natural con trastive focus contours but occasionally encountered unreli able verum focus contours; reversely for the unreliable con trast (UC) group. ‘Unreliable’ use of intonation is defined as follows. In the context of question (1), the speaker would use statement (3) realized with a pitch accent on the object as if to indicate a contrastive referent and statement (4) realized with a pitch accent on the auxiliary as if to indicate a given ref erent, creating a mismatch between information status, pitch accent position and disambiguating lexical information. Oc casional exposure to unreliable cues undermines the possibil ity to confidently predict the likely speaker-intended referent earlier than after lexical disambiguation. 
Subjects were exposed to 12 blocks of 8 stimuli each. In the UV group, each block contained 2 reliable contrastive fo cus statements, 2 reliable verum focus statements, 1 unreli able verum focus statement, and 3 broad focus statements. In the UC group, each block contained 2 reliable verum focus statements, 2 reliable contrastive focus statements, 1 unre 
tories were processed with the package mousetrap (Kieslich & Henninger, 2017) using R (R Core Team, 2017). There were a total of 84 target trials per participant. We only analysed target trials with reliable mappings between discourse context and intonation. For each trial, we compute the turn towards the target (TTT) as the latest point in time at which the trajectory did not head towards the target (where “heading towards the target” is operationalized by approxi mating the first derivative to the x- and y-coordinates of a tra jectory; see function get_TTT_derivative() in the analysis scripts at http://osf.io/49q2r). 
We fitted Bayesian hierarchical linear models which pre dict TTT measurements as a function of FOCUS, GROUP and BLOCK and their three-way interaction, using the pack age brms (Bürkner, 2016). The models included maximal random-effect structures, allowing the predictors and their in teractions to vary by subjects (FOCUS - BLOCK) and experi mental items (FOCUS - BLOCK- GROUP). We used weakly informative Gaussian priors centered around zero with σ = 100 for all population-level regression coefficients (Gelman, 2006), as well as standard priors of the brms package for all other parameters. Four sampling chains with 4000 iter ations each were run for each model, with a warm-up period of 2000 iterations, ensuring convergence. We report, for rel evant predictor levels and difference between predictor lev els, 95% credible intervals (CIs) and the posterior probability that a respective posterior distribution β is smaller than zero P(β < 0). We judge there to be evidence for an effect if zero is (by a reasonably clear margin) not included in the CI and P(β < 0) is close to zero or one. 
Model predictions 
Our link hypothesis is that the TTT measure is a strictly de creasing function of posterior odds, as defined in Eq. (1). In the experimental context, where any object appeared equally likely as given/contrastive referent, it is reasonable to assume that prior odds are roughly 1. Consequently, we consider a mapping from likelihood ratios (i.e., evidential strength) to TTT, which ideally should have a finite lower bound to which it converges from above as evidential strength grows to in finity. One natural choice is an exponential decay function: TTT ∼ exp(1−evidential strength). 
To model belief dynamics, we assume that listen ers increment non-normalized scores, which might, for simplicity, represent numbers of recent remembered in stances where utterance u was used to refer to referent r. For example, the speaker’s propensity to 
liable contrastive focus statement, and 3 broad focus state ments. 
Analysis 
choose verum (V) or contrast (C) focus for either given (rg) or competitor refer ent (rc) could be derived from scores like in the adjacent table. This yields condi 
V C 
rg 35 15 rc 5 45 
The screen coordinates of the computer mouse were sampled at 100Hz using the mousetrap plugin (Kieslich & Henninger, 2017) implemented in the open source experimental software OpenSesame (Mathôt, Schreij, & Theeuwes, 2012). Trajec 
tional production probabilities after normalization, like so: P(V | rg) = 35 
35+15 = 0.7. In each experimental trial, listeners 
observe both utterance and referent (by final lexical disam biguation), and so increment the relevant score by 1. 
968
Figure 2: Model predictions for main text example. 
Experiment initially, listeners will have default expecta tions about speakers’ form-function mappings. For proficient speakers of German, these should satisfy some natural con straints. We assume that (i) the base rate of C is higher than that of V, P(C) > P(V) where P(u) = ∑riP(u | ri) P(ri), as verum focus is infrequent in German; (ii) verum focus is more natural for a given than for a competitor referent, P(V | rg) > P(V | rc); (iii) for realizing reference to the competitor, con trastive focus is more natural, P(C | rc) > P(V | rc). 
These assumptions and constraints define an infinite class of models. Nonetheless, we can derive general qualitative predictions. Given the assumed base rate difference, V has higher evidential strength than C. For the example above, we have P(V|rg) 
P(V|rc) = .7, but P(C|rc) 
P(C|rg) = .3. Most importantly, we pre dict that the higher (lower) the evidential strength of a cue, the more (less) it will be affected by learning that it is unre liable, and the less (more) it will be affected by learning that it is reliable. An example, based on the numbers from the ta ble above for the exact belief updates induced by the present experiment is in Figure 2. Concretely, in the UC condition we predict no noteworthy additional inhibition of contrast fo cus (intuitively: because it is a weak cue from the start, i.e. the absence of a pitch accent is not an informative predictor of the discourse status of an upcoming referent, because its presence is not very expected by low base rate) and consider even a small facilitation possible for some model parameter values (because participants still see more reliable contrast fo cus uses than unreliable ones even in the UC condition). Nei ther would we expect a noteworthy additional facilitation of verum focus exploitation (because it is a reliable cue from the start). In the UV condition we predict both a noteworthy in hibition of verum focus exploitation (because a high-fidelity cue’s reliability is now undermined), as well as a learning effect in the exploitation of contrast focus (because learning raises the initially low evidential value). These model-derived predictions were preregistered at https://osf.io/49q2r/. 
Results and Discussion 
Following pre-registered protocol, the whole data set of a par ticipant was excluded whenever he/she (a) exhibited initia 
Figure 3: Estimates and CIs for the TTT measurement. Semi transparent points are average values for each subject. Solid grey lines group individual subject’s values across conditions. The dotted line indicates average acoustic onset of referent. 
parameter mean 95% CI P(β < 0) 
Contrast (UC) - Broad (UC) −56 (-88;-26) 1 Contrast (UC) - Verum (UC) 252 (206;297) 0 Broad (UC) - Verum (UC) 309 (265;356) 0 Contrast (UV) - Broad (UV) −117 (-151;-81) 1 Contrast (UV) - Verum (UV) 77 (23;136) 0 Broad (UV) - Verum (UV) 194 (139;254) 0 Contrast (UC) - Contrast (UV) 36 (-16;87) 0.09 
Broad (UC) - Broad (UV) −25 (-75;22) 0.84 Verum (UC) - Verum (UV) −140 (-207;-73) 1 Slope Contrast (UC) 2 (-5;8) 0.3 Slope Broad (UC) −2 (-8;4) 0.68 Slope Verum (UC) 1 (-7;9) 0.4 Slope Contrast (UV) −2 (-9;5) 0.72 Slope Broad (UV) 3 (-4;10) 0.21 Slope Verum (UV) 7 (-2;16) 0.08 
Table 1: Posterior estimates of differences between condi tions (rows 1-9) and posterior estimates of the effect of ex perimental block for each condition (rows 10-15). 
tion times above 350ms in more than 15% of the trials, (b) exhibited more than 10% errors, or (c) exhibited movement behavior violating instructions in more than 15% of the trials. We excluded one subject for each exclusion criterion. We fur ther had to exclude two subjects due to experimental malfunc tions. Trials with initiation times greater than 350ms (1.3%) and incorrect responses (0.3%) were discarded on a trial-by trial basis. Additionally, trials that exhibited movement be havior violating instructions were discarded, too (1%). 
Figure 3 displays the mean and 95% CIs of the posterior distribution (conditioned on the middle of the experiment, i.e. scaled block number = 0). There is substantial evidence that the three different focus conditions elicit different TTT patterns, with Broad being the slowest (UC: β = 884, CI = (850;920); UV: β = 909, CI = (869;949)) followed by Con trast (UC: β = 828, CI = (791;863); UV: β = 793, CI = (756;833)) and Verum (UC: β = 576, CI = (532;621); UV: β = 716, CI = (660;769)). (Posterior differences between con ditions are summarized in Table 1.) 
These patterns are in line with Roettger and Franke (2017). The acoustically early cue associated with verum focus al 
969
lows listeners to infer the intended referent long before the lexical material becomes available. Beyond that, listeners also use the absence of this cue (no accent on the auxiliary) to anticipate the contrastive interpretation. This inference does not happen as fast as in the verum focus condition but earlier than lexical disambiguation (Broad > Contrastive > Verum). 
Looking across groups, neither Contrast nor Broad show clear indications of an impact of the group manipulation (Contrast: β = 36, CI = (-16;87), P(β < 0) = 0.09; Broad: β = -25, CI = (-75;22), P(β < 0) = 0.84). Verum, however, is clearly slower in the UV group (β = -140, CI = (-207;-73), P(β < 0) = 1). These results are compatible with our predic tions. We predicted a difference mainly in the Verum condi tion, where TTT measures should be slower. Since we only predicted no facilitation for the Contrast condition in the UC group, these results are fully compatible with model-derived predictions. 
Figure 4 displays how these temporal effects change over the experiment. In comparison to the patterns described by Roettger and Franke (2017), the present effects do not change much across the experiment. There is not sufficient evidence that the development of participants’ anticipatory behaviour over the course of the experiment (slope of the lines) is dif ferent from zero (= a flat line) (see Table 1), although our posterior belief in the predicted positive slope for the Verum condition in the UV group is about 0.92. 
Despite the absence of conclusive evidence for dynamic changes of TTT measures throughout the experiment, there are suggestive patterns comparing the start and end of the experiment. In the UV group, Contrast is initially eliciting similarly late TTTs as Broad (CI intervals overlap, see Figure 4). Throughout the experiment, TTTs seem to increasingly become later in Broad and earlier in Contrast, leading to a substantial differences between these categories by the end of the experiment. Thus, listeners seem to learn to exploit the absence of a pitch accent on the auxiliary as a predictive cue to an upcoming contrastive referent. Learning happens despite occasional unreliable form-function mappings in the Verum condition. 
Contrary to this, at the beginning of the experiment, the Verum condition in the UV group starts with a temporal ad vantage over Contrast. However, throughout the experiment, listeners’ TTTs in Verum appear to become later approach ing the temporal performance of Contrast by the end of the experiment (CI intervals are heavily overlapping). Listeners appear to selectively unlearn the expected speaker production probabilities for verum focus, while learning to predictively exploit the form function mapping in the Contrast condition. 
General Discussion 
This study replicates earlier findings that listeners rapidly ex ploit intonational cues to predict speaker intentions (Dahan et al., 2002; Weber et al., 2006; Kurumada et al., 2014a). Hear ing an early pitch accent (or its absence), listeners’ manual response dynamics indicate an early bias towards one inter 
Figure 4: Estimated TTT values (lines) as a function of block number (scaled), dependent on focus condition and listener group. Shaded ribbons are 95% CIs. Semi-transparent points correspond to average values for each block. 
pretation over another (Roettger & Stoeber, 2017). Our re sults further replicate and expand findings by Roettger and Franke (2017) showing that intonational cue exploitation de pends on the estimated reliability of form-function mappings. If listeners learn that a cue is uninformative, they appear to down-weight the informational value of that cue (c.f. Kuru mada et al., 2014b). This selective adaptation further shows a tendency to change dynamically throughout exposure. A Bayesian model of predictive cue integration and belief dy namics, paired with an exponential link function from poste rior odds to the TTT measure, predicts interesting asymme tries in listeners’ responses and their temporal development, which are supported by the data to some extent. 
These results also point to interesting follow-up research. Infinitely different numerical models are compatible with the naturalness constraints on speaker production we postulated here. We have focused on assessing general qualitative pre dictions only. The question arises whether a quantitative fit, using model parameter estimation based on the data, is possi ble. Doing so will likely also highlight aspects in our data that the present model does not seem to capture. Figure 4 suggests that already in the first block there is a large effect of unrelia bility on the processing of verum focus. Our model does not predict this (Figure 2). It is conceivable if not likely that lis teners have a more elaborate belief update process than mod elled here. Already after the first example of an unreliable use of what is normally a high-fidelity cue, listeners might be immediately alerted. This, for instance, could lead them to immediately adjust their readiness to deviate from their de fault beliefs. Plasticity of listener beliefs is represented as the sums over rows in our tables of non-normalized weights: the higher the sum, the less swiftly beliefs adapt. Our model pre dictions were derived based on fixed plasticity rates for which the model gives non-trivial predictions, but it is worthwhile for future work to explore, both empirically and in modelling, the possibility that listeners also quickly adjust their beliefs about optimal plasticity based on the relative surprisal of ob 
970
served speaker utterances. 
Despite these open issues, the present study contributes to our understanding of how listeners deal with ubiquitous un certainty in processing intonation; how listeners infer speaker intentions based on bottom-up acoustic cues and probabilistic expectations about likely intonational contours; and whether listeners’ flexible adaptation behavior is compatible with ra tional belief dynamics. 
Acknowledgments 
Timo Roettger was supported by the "Zukunftskonzept" of the University of Cologne as part of the Excellence Initiative. We thank Nastassja Bremer and Kim Rimland for their help during data collection. 
References 
Boersma, P., & Weenink, D. (2016). Praat: Doing phonetics by computer. [computer program]. version 6.0.17. Bürkner, P.-C. (2016). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Soft ware, 80(1), 1–28. 
Carpenter, B., Gelman, A., Hoffman, M., Lee, D., Goodrich, B., Betancourt, M., . . . Riddell, A. (2016). Stan: A proba bilistic programming language. Journal of Statistical Soft ware, 20, 1–37. 
Dahan, D., Tanenhaus, M. K., & Chambers, C. G. (2002). Accent and reference resolution in spoken-language com prehension. Journal of Memory and Language, 47(2), 292– 314. 
Fine, A. B., & Jaeger, F. T. (2013). Evidence for implicit learning in syntactic comprehension. Cognitive Science, 37(3), 578–591. 
Freeman, J. B., & Ambady, N. (2010). Mousetracker: Soft ware for studying real-time mental processing using a com puter mouse-tracking method. Behavior Research Meth ods, 42(1), 226–241. 
Gelman, A. (2006). Prior distributions for variance parame ters in hierarchical models (comment on article by Browne and Draper). Bayesian analysis, 1(3), 515–534. 
Grice, M., Ritter, S., Niemann, H., & Roettger, T. B. (2017). Integrating the discreteness and continuity of intonational categories. Journal of Phonetics, 64, 90-107. 
Grodner, D., & Sedivy, J. C. (2011). The effect of speaker specific information on pragmatic inferences. The process ing and acquisition of reference, 239. 
Jaeger, T. F., & Snider, N. E. (2013). Alignment as a conse quence of expectation adaptation: Syntactic priming is af fected by the prime’s prediction error given both prior and recent experience. Cognition, 127(1), 57–83. 
Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press. 
Kieslich, P. J., & Henninger, F. (2017). Mousetrap: An in tegrated, open-source mouse-tracking package. Behavior Research Methods, 1–16. 
Kleinschmidt, D. F., & Jaeger, T. F. (2015). Robust speech perception: Recognize the familiar, generalize to the sim 
ilar, and adapt to the novel. Psychological review, 122(2), 148. 
Kurumada, C., Brown, M., Bibyk, S., Pontillo, D., & Tanen haus, M. (2014b). Rapid adaptation in online pragmatic interpretation of contrastive prosody. In Proceedings of the cognitive science society (Vol. 36). 
Kurumada, C., Brown, M., Bibyk, S., Pontillo, D., & Tanen haus, M. K. (2014a). Is it or isn’t it: Listeners make rapid use of prosody to infer speaker meanings. Cognition, 133(2), 335–342. 
Ladd, D. R. (2008). Intonational phonology. Cambridge University Press. 
Magnuson, J. S. (2005). Moving hand reveals dynamics of thought. Proceedings of the National Academy of Sciences of the United States of America, 102(29), 9995–9996. 
Mathôt, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. Behavior research methods, 44(2), 314–324. 
Norris, D., McQueen, J. M., & Cutler, A. (2003). Perceptual learning in speech. Cognitive psychology, 47(2), 204–238. Pierrehumbert, J., & Hirschberg, J. B. (1990). The meaning of intonational contours in the interpretation of discourse. Intentions in communication, 271–311. 
R Core Team. (2017). R: A language and environment for statistical computing. Vienna, Austria. Retrieved from https://www.R-project.org/ 
Roettger, T. B. (2017). Tonal placement in Tashlhiyt: How an intonation system accommodates to adverse phonological environments (Vol. 3). Language Science Press. 
Roettger, T. B., & Franke, M. (2017). Task-oriented adaptation in intonation-based intention recognition. (un published manuscript, preprint on OSF repository at http://osf.io/dnbuk) 
Roettger, T. B., & Stoeber, M. (2017). Manual response dynamics reflect rapid integration of intonational infor mation during reference resolution. In G. Gunzelmannn, A. Howes, T. Tenbrink, & E. Davelaar (Eds.), Proceedings of CogSci 39 (pp. 3010–3015). Cognitive Science Society. 
Spivey, M. J., Grosjean, M., & Knoblich, G. (2005). Con tinuous attraction toward phonological competitors. Pro ceedings of the National Academy of Sciences of the United States of America, 102(29), 10393–10398. 
Tomlinson, J., Gotzner, N., & Bott, L. (2017). Intonation and pragmatic enrichment: How intonation constrains ad hoc scalar inferences. Language and Speech, 60(2), 200–223. 
Weber, A., Braun, B., & Crocker, M. W. (2006). Finding ref erents in time: Eye-tracking evidence for the role of con trastive accents. Language and Speech, 49(3), 367–392. 
Yildirim, I., Degen, J., Tanenhaus, M. K., & Jaeger, T. F. (2016). Talker-specificity and adaptation in quantifier inter pretation. Journal of memory and language, 87, 128–143. 
971
Black Dialect Activates Violent Stereotypes 
Rebecca K. Rosen1 Laura Staum Casasanto2 Amritpal Singh3 Daniel Casasanto1,3,4  (rkrosen@uchicago.edu) (laura.staum@gmail.com) (as3695@cornell.edu) (casasanto@cornell.edu) 
Departments of 1Psychology and 2Linguistics, University of Chicago, Chicago, IL, 60637 
Departments of 3Human Development and 4Psychology, Cornell University, Ithaca, NY, 14853 
Abstract 
After viewing Black males faces, US participants are typically faster to categorize weapons and slower to categorize tools than after  viewing White male faces, revealing the activation of implicit stereotypes linking Black males with violent crime. Here we tested whether hearing Black male voices speaking in African American Vernacular English (AAVE) activates these same threat-related  stereotypes. In a national US sample, participants were faster to categorize weapons compared to tools after hearing race-neutral  names spoken in AAVE than after hearing them spoken in Standard American English (SAE). Like Black faces, Black voices can  activate violent stereotypes, affecting visual discrimination of objects. 
Keywords: implicit bias; race; dialect; AAVE 
972
The Phenomenology of Eye Movement Intentions and their Disruption in Goal-Directed Actions 
Maximilian K. Roszko (maximilian.roszko@gmail.com) 
Lars Hall (lars.hall@lucs.lu.se) 
Petter Johansson (petter.johansson@lucs.lu.se) 
Lund University Cognitive Science, Lund University, Helgonavägen 3, 221 00 Lund, Sweden Philip Pärnamets (philip.parnamets@ki.se) 
Lund University Cognitive Science, Lund University, Helgonavägen 3, 221 00 Lund, Sweden Division of Psychology, Department of Clinical Neuroscience, Karolinska Institutet, 171 65, Solna, Sweden 
Abstract 
The role of intentions in motor planning is heavily weighted in classical psychological theories, but their role in generat ing eye movements, and our awareness of these oculomotor intentions, has not been investigated explicitly. In this study, the extent to which we monitor oculomotor intentions, i.e. the intentions to shift one’s gaze towards a specific location, and whether they can be expressed in conscious experience, is investigated. A forced-choice decision task was developed where a pair of faces moved systematically across a screen. In some trials, the pair of faces moved additionally as soon as the participants attempted to gaze at one of the faces, prevent ing them from ever viewing it. The results of the experiment suggest that humans in general do not monitor their eye move ment intentions in a way that allows for mismatches between planned gaze landing target and resulting gaze landing target to be consciously experienced during decision-making. 
Keywords: eye movements; intentions; goal-directed actions; awareness; decision making 
Intentions 
Psychological models attempting to explain how actions are planned and decided often assume that people generally are aware of what their goals, desires, and attitudes are, and sub sequently know their intentions prior to the corresponding planned actions (see e.g. Ajzen, 1991; Dickinson & Balleine, 1994). Furthermore, theories on the sense of agency often position intentions centrally as a type of mental event that are used to directly gauge agency and self-control, where mis matches between one’s intention and the outcome of the cor responding action can negatively affect this feeling of agency (Haggard, 2017; Hommel, 2015). 
The existence of intentions as clearly distinguishable and introspectively accessible mental events can be questioned though (see also Dennett, 1991). More dynamical approaches to cognition aim to build a complete cognitive architecture without invoking constructs like intentions. Instead, minds might act intelligently through their direct dynamical cou pling with the body and environment, as the environment and body directly constrain the possible actions and pro vide immediate feedback that can be used to tune actions (Van Gelder, 1995; Wojnowicz et al., 2009; Pärnamets et al., 2015). In line with this, much evidence have accumulated against the position that humans have veridical access to their cognitive processes that determine decision-making and ac tion (see e.g. Nisbett & Wilson, 1977; Johansson et al., 2005; Carruthers, 2011). 
However, a specific domain which has received very lit tle research in reference to awareness and goal-directed ac tion models are eye movements, and the potential oculomo tor intentions guiding them. This is surprising as the connec tions eye movements have with decision-making are consid erable. They have for instance been shown to reflect ongoing thought processes and behavioral goals (Yarbus, 1967), and to be tightly coupled with visual attention (Deubel & Schneider, 1996; Carrasco, 2011); and manipulating people’s gaze be havior in real-time can affect preference formations for stim uli and dynamically alter the decision process (Shimojo et al., 2003; Armel et al., 2008; Pärnamets et al., 2015). On top of that, the oculomotor system has been extensively researched, so that much is known about how and which brain areas are involved in controlling eye movements (Girard & Berthoz, 2005; Sparks, 2002). Thus, as eye movements can be mea sured very precisely and accurately, they serve as good mod els for studying goal-directed movements (Sparks, 2002). 
Following goal-directed action models, one would assume that for every seemingly planned eye movement, there is a corresponding intention that could be brought to awareness should a person want to. But as far as we are aware, no study has investigated whether this actually is the case (closely re lated studies have for instance mostly investigated low-level factors involved in detecting changes across saccades, e.g. Henderson & Hollingworth, 1999). Typically, our visual ex perience is acquired in an seamless and effortless fashion, suggesting that even ‘planned’ eye movements often are pro cessed automatically outside of conscious thought. Yet, com mon sense suggests that we nevertheless can access and report these plans if called upon, as everyone has had the experience of scanning a scene and purposefully shifting one’s gaze to wards a particular target within the visual field (for example, when evaluating the flavors on display in an ice cream parlor). 
Thus, oculomotor intentions should be particularly salient when a person performs an evaluative task, as they shift their gaze to a specific location or object. Given this, an obvious way to investigate oculumotor awareness would be to manip ulate the outcome of someone’s eye movements, such that the object she intended to move her gaze towards shifted position during the eye movement. During saccades, visual percep tion is limited such that it is possible to mask movements of objects (Beeler, 1967; Bridgeman et al., 1975). Therefore, if humans monitor their oculomotor intentions, participants 
973

Figure 1: The difference between a manipulated and non-manipulated decision trial. Only manipulated trials were gaze contingent (the window was not visible). A fixation marker could appear at any of eight horizontally spaced locations, and after a random time between 1 and 2 seconds the faces would appear with the ’back’ face (the face at the back of the movement direction) always appearing where the fixation marker was located. The ’front’ face appeared either to the left or right of the back face depending on the trial’s movement direction. The faces jumped 5 degrees each time (unless they reappeared at the other end of the screen) according to the time pattern, or as soon as a participant’s gaze entered the gaze-contingent window. 
would become aware of a mismatch between the intention and the outcome when exposed to the manipulation. It would register as a visual error, a curious instance of misseeing. 
Here we introduce a novel paradigm to investigate this exact experimental situation. We gave our participants the task of choosing which of two faces moving across a screen they found most attractive. The setup was covertly gaze contingent in some trials, where our aim was to completely prevent the participants from ever looking at one of the faces in the pair - i.e. as soon as we detected a saccade directed at the target face, both of the images immediately shifted, so that the gaze ended up just where it started. Thus, participants only ever got to fixate on one of the alternatives on those tri als (see Figure 1). By making participants’ eye movements fail repeatedly in this way, we are able to investigate if ocu lomotor intentions are consciously monitored. Furthermore, if the effects of disrupting the link between gaze targets and outcomes should go unnoticed, our paradigm can be used to explore how allocation of visual attention might bias the de cisions of our participants, and how it influences their recog nition and source memory for stimuli and choices. 
Method 
Participants 
31 participants (17 female, 14 male) recruited at Lund Uni versity, mostly students (mean age = 26.1 years, SD = 7.1), took fully part in the experiment. All participants reported 
normal or corrected-to-normal vision with contact lenses. The participants received compensation in the form of a gift voucher valid at the movie theater for participating. 
Materials and stimuli 
The participants had their heads on a chin rest 80 cm in front of a 27-inch LCD monitor (resolution at 1920 x 1080 pixels) with a refresh rate at 120 Hz. The eyes were measured us ing the Eyelink 1000 (SR Research, Ontario) that recorded monocularly at 1000 Hz, while the experiment was run on Python 2.7.3 using the PsychoPy module (Peirce, 2007). All eye movement data were recorded online after a nine-point calibration (average measured accuracy = 0.47, SD = 0.33). 
The faces came from the Chicago Face Database (Ma et al., 2015). All faces used were frontal-view Caucasian with neutral expression, rated for a number of attributes including attractiveness, on a 7 point scale. Faces were paired by gen der and attractiveness. The faces were divided into three at tractiveness groups, the highest 25% belonging to the ‘high’ attractiveness group, the middle 50% belonged to the ‘mid’ group, and the lowest 25% belonged to the ‘low’ group. The images of the faces were resized to 244 (wide) x 172 (high) pixels, with a raised cosine edge to provide softness. The dis tance between the centers of the images in a pair was approxi mately 5 visual degrees (230 pixels on the screen at a distance of 80 cm from the eyes, 33 pixels/cm). 
974
Table 1: The set of interview questions, translated into English from Swedish. The primary questions were always asked, while the follow-up questions interjected whenever a participant expressed difficulties in seeing the faces during the experiment. 
Primary questions Follow-up questions 
1. How do you feel about the experiment? 1. Why do you think it was like that? 2. Did you think about anything in particular during the experiment? 2. Was it difficult to see the faces in a particular position? 3. How did it feel to make the decisions? 3. Could you fixate both faces? 
4. Was there anything in particular that you thought about regarding the decisions? 
4. Could you see both faces? If not, what strategy did you use when making the decisions? 
5. Did you evolve any strategies for decision-making? 5. Did the decisions feel free or dejected when it was difficult to see? 6. How do you feel about the faces? 
7. Was there anything in particular that you thought about the faces? 
8. Did you notice anything weird about the experiment? 
9. If you had to guess about an undisclosed purpose of the experi 
ment, what would you guess? 
Procedure 
Participants were introduced to the experiment, and were told that the purpose of the experiment was to investigate how the movement of alternatives in a decision affected their decision making. They were told that their pupil sizes would be mea sured among other measures, but nothing about eye move ments. They were also told to make their decisions without feeling pressured for time. The experiment consisted of 60 decision trials and 180 memory trials. 
Decision trials and gaze-contingent manipulation In the decision trials, a fixation marker spawned at one of 8 possible positions, and after a random time between 1-2 seconds, the pair of faces appeared, such that the ’back’ face (the face at the back of the movement direction) appeared directly where the fixation marker had been, and the ’front’ face appeared on the side which would be the direction the faces would jump according to (Figure 1). The pair of faces started their move ment pattern immediately after appearing, and the participant had unlimited time to make their decision by button-press de pending on which face they preferred. After each decision a confidence-scale appeared, where the participant could in put their confidence in the previous decision on a continuous scale from 1.00 to 6.00. 
The first 5 decision trials were always non-manipulated, while the remaining 55 trials could be either gaze-contingent or not with 50% likelihood for either. The manipulation was programmed to force the participants to view the back face. 
In non-manipulated trials the base rate at which the faces jumped was dependent on a few conditions designed to mask the fact that the manipulated trials were gaze-contingent. The time a pair would remain in position was a number of frames of equal probability between 20-35, times the length of time for each frame (at 120 Hz each frame was about 8.3 ms), such that the pair could stay in the same position between 166-292 ms. Additionally, there was a 10% probability that the faces would jump after only 5 frames (42 ms), to produce a more jittery behavior that resembles the gaze-pattern of participants attempting to view a blocked face in purely gaze-contingent 
conditions. If the faces ever reached the edge of the screen, they would reappear at the other side. 
In manipulated trials, the face pair would additionally jump whenever the participant attempted to view the front face. The gaze-contingent jump was governed by a covert gaze contingent window placed over the front face (see Figure 1). The window had borders distanced 5 visual degrees away from the center of the front face, except in the direction to wards the back face, where the window’s border extended 3.6 degrees. Whenever the participants’ eye gaze was de tected within the window a jump was triggered. Otherwise, the movement of the faces continued according to the rules for the non-manipulated trials. 
Memory trials Following the decision trials participants completed the memory trials. During each memory trial a face appeared, with instructions asking if they recognized the face. If they answered positively, they were additionally asked whether they think they chose that face in the decision trial it was part of or not. Two-thirds of the faces had been presented previously, while the participants were told that the ratio between old and new faces varied between the partici pants and would not necessarily be 50/50. 
Post-experiment interview After the two phases, the par ticipants were interviewed. There were 9 primary questions asked, but if a participant expressed some suspicion regard ing the movement of the faces, or if they expressed that they could not perceive both faces sometimes, a set of follow-up questions intervened (Table 1). 
Measures and analysis 
To determine whether participants monitored oculomotor in tentions consciously to any extent, a set of questions (Table 1) was devised that would probe the participants’ subjective experiences, while trying to limit the extent of leading ques tions that could produce post hoc rationalizations. A set of primary questions was devised to scan for any experiences that could relate to oculomotor intentions. If any response from the participants sufficiently seemed as there could be 
975
Table 2: The frequency of participants belonging to the each category of awareness. 
Degree of awareness Amount 
remarks. Those participants who noticed the manipulation clearly expressed for instance that "I tried to understand how it worked, it felt as if when the eyes moved a lot the pictures moved even more," or that "it felt as if the system did that, 
1. No reflections regarding perceiving the faces clearly 
2. Experienced difficulties perceiving both faces clearly sometimes 
3. Suspicious that faces were sometimes ma nipulated to be faint/blurry/unclear 4. Experienced feelings that faces sometimes moved according to eye movements 5. Suspicious that faces moved according to eye movements 
that you should look at the picture in the back." 
3 
Quantitative data 
18 
The time spent per decision trial differed significantly be 
7 
tween the trial types, as the participants spent on average more time on the manipulated trials (M = 6.41 s, SD = 5.12 
0 
s; for non-manipulated trials: M = 4.69 s, SD = 3.65 s), t(30) = 5.49, p < .001. Participants’ average confidence responses 
3 
were also significantly lower for the manipulated trials (M = 3.17, SD = 1.32; for non-manipulated trials: M = 4.01, SD 
some relevant awareness, a set of follow-up questions were interjected, returning back to the primary questions after the follow-up questions were completed. The degree of aware ness was divided into 5 categories specifically related to this experiment and are listed in Table 2. The answers the par ticipants provided to the questions asked were then used to categorize them accordingly. 
To determine how the manipulation affected decision making and memory of the faces, generalized linear mixed models (GLMM) were calculated using the lme4 package in R (Bates et al., 2015). Random effects were modeled as per participant intercepts, and reflecting the fixed effects structure to the closest degree such that convergence was achieved. 
Results 
Interviews 
The division of participants according to the defined degrees of awareness can be seen in Table 2. Very few participants (3) explicitly noticed the manipulation that took place in the experiment, while most participants (18) did not notice the manipulation, but expressed experiencing visual difficulties. 
The type of response that was frequent for participants who were categorized in group 2 was for instance that "many of the faces blurred together" or that "they moved so fast that you could not see both clearly." What separated class 2 from class 3 responses were that in the latter case participants ex plicitly stated that they were suspicious to some degree that the faces were manipulated (although not the movement of the faces specifically). A typical class 3 response was for in stance that "I thought about whether the faces were recycled, and whether they were modified," or that "it felt as if it was made up sometimes, as if they were not real people, as if the faces’ widths were extended." Importantly, participants be longing to class 3 never expressed that their eye movements affected the movement of the faces, although they could have expressed that where they looked first in a trial might have affected which face got manipulated into looking unreal. No participant was categorized to class 4, as those participants who expressed that their eye movements affected the move ment of the faces did so with confidence or highly accurate 
= 1.10), t(30) = -7.36, p < .001. While the participants were biased in manipulated trials to only view the back face due to the gaze-contingency, there was also a bias to have spent more time on the the back face for the non-manipulated trials (average time spent on the back face = 1.40 s, SD = 1.20 s; average time spent on the front face = 0.77 s, SD = 0.73 s; av erage relative time spent on the back face = 65%, SD = 13%). The participants triggered the gaze-contingent manipulation on average 29.3 times per manipulated trial, SD = 24.2. 
Decisions The chosen factors for the model on the partic ipants’ decision-making were trial type, attractiveness, and their interaction. Non-manipulated, high attractiveness trials were used as baselines. There was a significant effect for ma nipulated trials as compared to the non-manipulated trials, β = 0.65, SE = 0.22, p = 0.0025, for low attractiveness, β = -0.53, SE = 0.18, p = 0.0036, and the interaction between ma nipulated trial type and low attractiveness, β = -0.75, SE = 0.28, p = 0.0083. No significant effects were found for the mid attractiveness, β = -0.29, SE = 0.15, p = 0.065, or their interaction, β = -0.23, SE = 0.24, p = 0.33. The model predic tions for choosing the back face can be seen in Figure 2. In summary, significant effects on the decisions were found for manipulation, low attractiveness and the interaction between manipulation and low attractiveness. 
Memory The participants answered correctly whether the faces they saw were part of the decision trials in 2766 out of 5580 trials (49.6%). Out of the memory trials which pro gressed into the participant deciding whether she thought she chose the face in the decision it was part of, they were correct in 649 out of 1566 trials (41.4%). 
A GLMM was calculated to compute the effects of trial type, attractiveness, the position of the face and the interac tion between the position and trial type, on being able to cor rectly recognize faces in the memory phase. The significant fixed effects were front position as compared to the back po sition, β = -0.41, SE = 0.11, p <.001; low attractiveness as compared to high attractiveness, β = -0.26, SE = 0.13, p = .034; and low compared to mid attractiveness, β = -0.26, SE = 0.096, p = .0067. The fixed effect manipulated as compared to non-manipulated trial type showed no significance accord 
976

Figure 2: The predicted probabilities and their standard errors on choosing the back face, which in manipulated trials was the only possible face to directly fixate on. The values include the effect of the interaction between attractivity and trial type. 
ing to this model, β = -0.13, SE = 0.10, p = .19, and the interaction between manipulated trial type and front position was not significant either, β = -0.094, SE = 0.15, p = .54. In summary, recognition memory was superior for the back face compared to front face, and high attractiveness faces com pared to low and middle. 
Trial type, attractiveness, position and interaction between position and trial type were the factors used to model the task of answering the source memory question correctly. Signif icant fixed effects were found for manipulated trials as com pared to non-manipulated trials, β = 0.47, SE = 0.22, p = .033, and for the interaction between manipulated trials and the front position, β = -0.88, SE = 0.39, p = 0.025. Non significant effects were found for low attractiveness as com pared to high, β = -0.20, SE = 0.17, p = 0.23, low compared to mid attractiveness, β = -0.16, SE = 0.14, p = 0.27, and front position as compared to the back position, β = 0.31, SE = 0.21, p = 0.15. The model probabilities for correctly re membering whether preferred the faces they recognized can be seen in Figure 3. In summary, significant effects were found for the manipulation and the interaction between the manipulation and the front position. 
Discussion 
In this paper we introduced a novel gaze-contingent manipu lation technique to introduce mismatches between oculomo tor intentions and their outcomes. We found that participants generally do not monitor their oculomotor intentions to the degree that would be posited by goal-directed action models. Additionally, we found that the effect of forcing participants’ gaze towards one option in this specific way biased their de cisions and later memories. 
Figure 3: The predicted probabilities and their standard errors on responding correctly to the source memory task. The pre dictors are face position (either back or front in the direction movement), trial type, and attractiveness, with an interaction between trial type and face position. The model excluded recognition trials with new faces. 
Degree of awareness 
The results from the interview provided with the surprising data that most of the participants did not become aware of the manipulation in the experiment. It was surprising because of the high number of manipulations each participant was ex posed to, which was on average 29.3 times per manipulated trial (although not all of these are the result of a direct sac cade from the back to the front face). That means that every participant was exposed to on average almost a thousand ma nipulations, even if each manipulation was subtle. But one thing that made it even more surprising that so few partici pants expressed awareness of their eye movements failing to reach one of the faces on some trials, was that each participant had full control over their exposure to the gaze-contingency, as they were the one’s who decided when the trial ended, by making their choice. By choosing themselves when to end the decision, without any experiment-based time pressure, they made the indication that they were satisfied with mak ing a decision, at least to some degree, even if they felt that it was difficult to see one of the alternatives. And the results on the memory tasks supports the fact that the manipulation was successful in blocking the seeing of the front face in manip ulated trials, as there was a significant reduction in recogni tion memory for blocked faces in the manipulation trials. The same holds for the data on the participants’ source memory, as they were better at correctly remembering if they chose a back face if it took part in a manipulated trial compared to a non-manipulated trials, which likely was due to the increased exposure to back faces on average on manipulated trials com pared to non-manipulated. Participants were also worse at 
977
correctly remembering if they chose a front face that was part of a manipulated trial compared to a non-manipulated trial, which reasonably results from the manipulation block ing them from viewing that face. This leads us to believe that we are not monitoring our oculomotor intentions in a direct conscious way, at least when engaged in decision-making. 
On the other hand, it is highly possible that the manipu lation affected participants consciously in other ways, such as their sense of agency, and confidence in their ability to make accurate decisions in the visually demanding task. This would require further investigations, which would provide with information that could improve our models on goal directed actions. 
Decision-making 
Given that most participants were naive to the manipulation, the effect the manipulation had on their decision-making is of general interest. On manipulated trials, if the face was part of the high attractivity group, the participants had about a 15% increased likelihood (from about 55 to 70%) of choosing the back face (to which their gaze was forced). That effect is not small, and supports previous research on the effect the dy namics of eye movements have in decision-making (Shimojo et al., 2003; Pärnamets et al., 2015). But what is also interest ing is how the direction of the effect switches for low attrac tivity faces. Here, the participants were more biased in their choices towards the front face instead, with the likelihood of choosing the back face dropping down to about 40%. The striking thing here is that in manipulated trials the participants could not see the front face, yet were more likely to choose that face which they did not see. This supports the view that more exposure to unappealing stimuli decreases ones prefer ence for it (Armel et al., 2008). Again, follow-up work is necessary to replicate and fully understand these findings. 
Acknowledgments 
The authors gratefully acknowledge Lund University Human ities Lab for lending their equipment. 
References 
Ajzen, I. (1991). The theory of planned behavior. Orga nizational behavior and human decision processes, 50(2), 179-211. 
Armel, K. C., Beaumel, A., & Rangel, A. (2008). Biasing simple choices by manipulating relative visual attention. Judgment and Decision Making, 3(5), 396-403. 
Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1-48. 
Beeler, G. W. (1967). Visual threshold changes resulting from spontaneous saccadic eye movements. Vision research, 7(9), 769–775. 
Bridgeman, B., Hendry, D., & Stark, L. (1975). Failure to detect displacement of the visual world during saccadic eye movements. Vision research, 15(6), 719–722. 
Carrasco, M. (2011). Visual attention: The past 25 years. Vision research, 51(13), 1484–1525. 
Carruthers, P. (2011). The opacity of mind: an integrative theory of self-knowledge. OUP Oxford. 
Dennett, D. C. (1991). Real patterns. The journal of Philos ophy, 88(1), 27–51. 
Deubel, H., & Schneider, W. X. (1996). Saccade target selec tion and object recognition: Evidence for a common atten tional mechanism. Vision research, 36(12), 1827–1837. 
Dickinson, A., & Balleine, B. (1994). Motivational control of goal-directed action. Animal Learning & Behavior, 22(1), 1–18. 
Girard, B., & Berthoz, A. (2005). From brainstem to cor tex: computational models of saccade generation circuitry. Progress in neurobiology, 77(4), 215–251. 
Haggard, P. (2017). Sense of agency in the human brain. Nature Reviews Neuroscience, 18(4), 196–207. 
Henderson, J. M., & Hollingworth, A. (1999). The role of fix ation position in detecting scene changes across saccades. Psychological Science, 10(5), 438–443. 
Hommel, B. (2015). Action control and the sense of agency. In P. Haggard & B. Eitam (Eds.), The sense of agency (pp. 307–326). Oxford Scholarship Online. 
Johansson, P., Hall, L., Sikström, S., & Olsson, A. (2005). Failure to detect mismatches between intention and out come in a simple decision task. Science, 310(5745), 116– 119. 
Ma, D. S., Correll, J., & Wittenbrink, B. (2015). The chicago face database: A free stimulus set of faces and norming data. Behavior research methods, 47(4), 1122–1135. 
Nisbett, R. E., & Wilson, T. D. (1977). Telling more than we can know: Verbal reports on mental processes. Psycholog ical review, 84(3), 231. 
Pärnamets, P., Johansson, P., Hall, L., Balkenius, C., Spivey, M. J., & Richardson, D. C. (2015). Biasing moral decisions by exploiting the dynamics of eye gaze. Proceedings of the National Academy of Sciences, 112(13), 4170–4175. 
Peirce, J. W. (2007). Psychopy—psychophysics software in python. Journal of neuroscience methods, 162(1), 8–13. Shimojo, S., Simion, C., Shimojo, E., & Scheier, C. (2003). 
Gaze bias both reflects and influences preference. Nature neuroscience, 6(12), 1317–1322. 
Sparks, D. L. (2002). The brainstem control of saccadic eye movements. Nature Reviews Neuroscience, 3(12), 952– 964. 
Van Gelder, T. (1995). What might cognition be, if not com putation? The Journal of Philosophy, 92(7), 345–381. Wojnowicz, M. T., Ferguson, M. J., Dale, R., & Spivey, M. J. (2009). The self-organization of explicit attitudes. Psycho logical Science, 20(11), 1428–1435. 
Yarbus, A. L. (1967). Eye movements and vision. New York: Plenum Press. 
978
Topics and Trends in Cognitive Science (2000-2017) 
Anselm Rothe1,∗(anselm@nyu.edu) 
Alexander S. Rich1,∗(asr443@nyu.edu) 
Zhi-Wei Li2,∗(zhiwei.li@nyu.edu) 
1Department of Psychology, 2Center for Neural Science 
New York University 
Abstract 
What are the major topics of the Cognitive Science Society conference? How have they changed over the years? To an swer these questions, we applied an unsupervised learning al gorithm known as dynamic topic modeling (Blei & Lafferty, 2006) to the 2000–2017 Proceedings of the Cognitive Sci ence Society. Unlike traditional topic models, a dynamic topic model is sensitive to the temporal context of documents and can characterize the evolution of each topic across years. Us ing this model, we identify historical trends in the popularity of topics over time, and shifts in word use within topics indicative of changing focuses within the field. We also measure the cor relation across topics, and use the model to highlight the topic structure of particular papers and labs. We believe dynamic topic models present an important tool towards understanding Cognitive Science as it continues to grow and evolve over time. 
Keywords: topic models; trends; scientometrics; cognitive science 
From August 13th to 16th in 1979 the first conference of the Cognitive Science Society took place. The conference program listed talks by 42 researchers, grouped into five cat egories in a single track: cognitive science and education, psychology of categorization, human development, language processing, and belief systems. In comparison, last year’s conference in 2017 had 255 talks grouped into 54 categories that ran in 11 parallel tracks. The 11-fold increase in cate gories and tracks is modest evidence for the increasing com plexity of the field of cognitive science. 
To shed more light on the evolution of topics within the field, we used a dynamic topic model to analyze the raw text of the annual Proceedings of the Cognitive Science Society. 
Dynamic Topic Models 
Topic modeling is an approach to unsupervised text under standing in which documents are posited to be generated by a set of underlying word distributions known as topics. Topic models have been used successfully to capture structure in large text corpora and make these corpora more human understandable (Blei et al., 2003). However, traditional topic models do not capture the temporal ordering of documents, thus not directly modeling how topics change over time. Dy namic topic models address this issue by allowing the distri bution of words in topics to change as a function of time (Blei & Lafferty, 2006). For example, a topic devoted to articles about communication could give high probability to words related to fax machines 20 years ago, but shift to include more words related to the Internet today. 
∗All authors contributed equally to this work. 
Related work 
Topic models have been used to understand the structure of academic publishing in the past. The archives of the jour nal Science have been used as a test dataset for dynamic topic models (Blei & Lafferty, 2006), as well as other topic model extensions (Blei & Lafferty, 2007). Cohen Priva & Austerweil (2015) applied topic modeling to the field of cog nitive psychology, using the archives of the journal Cogni tion. However, they used a static topic model, and visualized the change of topics over time in an ad-hoc manner using the empirical frequency of words within each topic. Thus, the present project represents the first attempt to directly model changes in the field of cognitive science over time. 
Problem definition and algorithm 
In standard topic modeling, also known as Latent Dirichlet Allocation (LDA; Blei et al., 2003), the goal is to infer a fixed set of latent topics underlying a corpus of documents. Let β1:K be K topics, each of which is a multinomial distribution over a fixed vocabulary, and let α be a hyperparameter that governs the topic-distribution of documents. For each doc ument, we assume that topic proportions θ are drawn from Dirichlet(α). We then assume that each word in the docu ment is drawn with topic assignment z ∼ Mult(θ) and identity w ∼ Mult(βz). 
In LDA, the time at which a document was published would have no effect on word distributions of its underlying topics. In the dynamic topic model (DTM), we relax the as sumption that β1:K are fixed over all time points. Instead, we replace βk with βt,k, denoting the word distribution of topic k at time t. This means that DTM allows for the words within a given topic to change over time. 
To model the drifting of β over time, we represent β in an unconstrained space described by the natural parameters of the multinomial. We assume that the terms of β drift over time according to Gaussian noise, 
βt,k|βt−1,k ∼ N (βt−1,k,σ2I) 
The function π then maps β back to a standard representation of a multinomial, 
π(βk,t)w =exp(βk,t,w) 
∑w exp(βk,t,w) 
979
This means that the complete generative process assumed by the DTM is: 
1. Draw topics βt|βt−1 ∼ N (βt −1,σ2I). 
2. For each document, choose topic proportions θ from Dirichlet(α). 
3. For each word in each document: 
(a) Choose a topic assignment Z ∼ Mult(θ). 
(b) Choose a word W ∼ Mult(π(βt,z)). 
Once the generative model has been defined, variational in ference is used to infer β, as well as θ for each document. We note that in a more complete model the prior over topic proportions α could vary across topics and over time, and could be inferred from the data along with β. However, in the existing implementation of variational inference for the DTM, α is fixed, presumably to decrease computational com plexity. Thus our analyses assume a fixed α across topics and over time. 
Method 
Data 
We downloaded 6920 PDF files from the Cognitive Science Conference archives, representing submissions from 2000 to 20171. In general, each submission is a 6 page paper. We con verted each entire PDF to text using an automated pdftotxt utility. We tokenized the text based on whitespace, and re moved lines in which few tokens were English words, be cause these lines tended to contain equations. We also re moved words that were less than four characters long and were not in a standard English dictionary, as these were of ten produced by errors in the PDF parser. We then lemma tized the words to standardize pluralizations and verb tenses. Finally, we removed tokens that occurred in fewer than 36 documents (i.e., 2 documents per year on average), as well as tokens that occurred in more than 50% of documents. Our final vocabulary contained 9710 words. 
Model fitting 
We used a modified version of the Blei lab’s C implemen tation of the dynamic topic model (https://github.com/blei lab/dtm) which uses a variational inference algorithm to es timate an approximate model posterior from data. Following Blei & Lafferty’s analysis of Science we assumed 20 topics2, and chose α = .05 (using 1/(num. topics) as a rule of thumb). The model used for our qualitative results was fit using all 6920 pdf files from all 18 years. To determine optimal topic variance parameter (σ2), we fit a series of DTM models with σ2 = {.0001,.0003,.001,.003,.01} up to 2017, and evaluated 
1For years before 2000, only large PDF files concatenating all papers from a year were available and not one PDF per paper. 2We found that the log-likelihood of held-out data actually im proved slightly up through 100 topics, the highest number tested, but remained with a 20 topic model for reasons of computational costs and human interpretability. 

Figure 1: Model performances on the next year’s data, after training on previous years. The y-axis shows negative log likelihoods (i.e., lower score is better) relative to the LDA (all years) model (i.e., the black base line). LDA (all years) and DTM (all years) were trained on all data up to the held-out year. LDA (prev year) was only trained on the year prior to the held-out year. 
them by determining the negative log likelihood assigned to the 2017 documents. 
Model comparison 
To evaluate the DTM compared to LDA, we fit a series of models in which we trained the model up to a given year, and then inferred the negative log-likelihood of the data for the given year. We compared the DTM with optimal σ2trained on all data up to the held-out year, LDA trained on all data up to the held-out year, and LDA trained only on the last year of data before the held-out year. The DTM for each year was initialized using the inferred topics from the LDA fit on the same training set, to maximize comparability across condi tions. We conducted this procedure for each year from 2002 to 2017. 
Results 
Model evaluation 
We found that the optimal value of σ2 was.001, slightly lower than the value of .005 used by Blei & Lafferty (2006) in their DTM analysis of Science. This optimal value was used for all of our other fits of the DTM model. The results of testing the DTM and LDA models on a held out year are displayed in Figure 1. Because the all-years LDA model tended to perform best over all, the results of the DTM and of the previous year LDA model are shown in relation to this model. We found that with fewer years, the DTM performs far worse than LDA. However as the number of training years increases, the DTM’s relative performance gradually improves, becoming roughly equal to the static LDA model by 2017. LDA trained on only one previous year, in contrast, gradually loses ground as the the last year’s data becomes a smaller proportion of the 
980
training set. 
Our finding that the DTM performs poorly with few years, 
0.100 
and improves with a temporally broader training set, com ports with the idea that the DTM is a more complex model 
0.075 
that can capture temporal variation but can also over-fit train ing sets with little temporal structure. However, this result 0.050 
differs from that of Blei & Lafferty (2006), who found that the DTM outperformed LDA strongly when trained on only y 
c
a few early years of Science, and that LDA’s relative perfor 
0.025 
n
e
u
mance improved over time. It will be interesting to see if 
q
e
r
f
 
the performance of the DTM relative to LDA continues to 
d
e
t
0.100 
a
improve as the training set of Cognitive Science Proceedings 
m
i
t
s
increases in future years. 
E
0.075 
Topics and trends 
0.050 
Topics in DTM are generated in an unsupervised way and thus do not naturally come with a meaning, but it is useful to 0.025 
name these topics in order to talk about them. There are at least two ways to interpret a topic: by looking at the terms with highest weights in the topic-term distribution (β), and 
rising 
falling 
2000 2004 2008 2012 2016 Year 
Probabilistic modeling 
Decision making 
Developmental psychology 
Text processing and creativity 
Mathematical psychology 
Spatial cognition and embodied cognition Causal reasoning 
Communication 
Visual attention 
Face and emotion perception 
Educational psychology 
Reasoning 
Memory 
Consciousness and identity 
Neural network 
Sequential learning 
Language: syntax 
Language: semantics 
Categorization 
Knowledge structure 
the papers with highest weights on this topic (θ). The inter pretations from these two perspectives should agree with each other. 
Our procedure of deciding topic labels proceeded as fol lows. First, we looked into the most frequent words in each topic cluster. For example, the most frequent term for topic 17 is “probability”, followed by “distribution”, “parameter” and “prior”—all are typical in a probabilistic modeling re search. Second, we looked into the most typical papers in each topic, formally defined as the paper with the highest pro portion on the given topic among all papers in the same year. We checked their titles and keywords to confirm our intuition. Through this method we manually labeled all the 20 topics, and these labels are used throughout. 
Trends in CogSci Using the DTM’s inferred topic-year word distributions (β) and topic-document distributions (θ), we created several visualizations to understand how the field of Cognitive Science has changed over the last two decades. 
Figure 2 shows the overall proportion of each of the 20 topics over the last 18 years. Since we assumed a flat prior on topic proportions (α), these proportions were estimated empirically by averaging the topic proportions in all docu ments in a given year, and then smoothing the curve using a LOESS regression. Some topics have remained fairly sta ble over the years. Others have become much more or less popular. The topic Probabilistic modeling, for example, has more than doubled in popularity to become the most popular topic. Decision making has become much more popular as well. The topic Neural network, in contrast, has decreased in popularity from its earlier heyday, but is starting to show a resurgence. 
Trends in the topic Neural network Here we provide a de tailed study of one specific topic, the Neural network topic, which seems to contain subtopics with different trends across 
Figure 2: Rising and falling popularity of each topic over the last 18 years. The upper panel shows topics with a rising trend, defined by a higher estimated frequency in 2017 than in 2000, and the lower panel shows all remaining topics. 
years. This can be demonstrated by the changing theme in typical papers across years. For each year, the paper that had the largest topic proportion (θ) for this topic, was selected as the most typical. When inspecting these papers, there seems to be a shift over the years in the predominant theme of the topic. From 2000 to 2005, most typical papers are shown in the upper half of Table 1. The overarching theme seems to be connectionist neural models depicting cognitive pro cesses. This differs from the typical papers in the last five years, shown in the lower half of Table 1 where the models become more and more biologically focused and related to neuroscience studies on neurons and circuits. 
The shift within the Neural network topic is also notice able in the trends of particular words relevant for the topic. This can be shown with the terms whose weights increased or decreased most over the years (see Figure 3). 
A similar analysis also applies to other topics. For exam ple, we found in the Probabilistic modeling topic, words such as “Bayesian,” “fit,” “prior,” and “sample” show the most in creasing trends, which may indicate that Bayesian methods have become more prominent over time. 
Similarities of topics Figure 4 shows a visualization of the similarity structure of the topics. The similarity between two topics is obtained by correlating their document vectors (of θ values), where a higher correlation indicates a more sim ilar scoring pattern across documents. The complete topic by-topic correlation matrix was projected into two dimen sions using the R package qgraph (Epskamp et al., 2012). 
981
Table 1: Each year’s most typical paper for the topic Neural network. Up to 2005 the theme is more tuned towards artificial intelligence (e.g., connectionism), after 2012 more towards neuroscience (e.g., neural circuits). 
Year Title 
2000 Representing Categories in Artificial Neural Networks Using Perceptual Derived Feature Networks 2001 Neural Synchrony Through Controlled Tracking 
2002 Preventing Catastrophic Interference in Multiple-Sequence Learning Using Coupled Reverberating Elman Networks 2003 A Split Model to Deal with Semantic Anomalies in the Task of Word Prediction 
2004 A Neural Model of Episodic and Semantic Spatiotemporal Memory 
2005 A Connectionist Implementation of Identical Elements 
2012 How many Neurons for your Grandmother Three Arguments for Localised Representations 
2013 Simultaneous unsupervised and supervised learning of cognitive functions in biologically plausible spiking neural networks 2014 Learning and Variability in Spiking Neural Networks 
2015 Lateral Inhibition Overcomes Limits of Temporal Difference Learning 
2016 Improving with Practice A Neural Model of Mathematical Development 
2017 A Plausible Micro Neural Circuit for Decision-Making 
Due to the fact that all θs for a given document must add 
y c
n
e
u
q
e
r
f
 
d
e
t
a
m
i
t
s
E
0.015 0.010 0.005 
0.04 0.03 0.02 0.01 
rising falling 
neural 
layer 
vector 
neuron 
computational dynamic 
brain 
field 
signal 
component 
network 
input 
simulation 
unit 
activation 
output 
node 
weight 
rule 
connectionist 
to 1 and are thus in competition, the topics were naturally slightly anti-correlated at -0.05, as determined by shuffling topic-assignments within documents. We set this value to be the baseline and rescaled all correlation coefficients, resulting in the line widths in Figure 4. Interestingly, of all topics, Ed ucational psychology had both the strongest similarity with another topic, namely Text processing and creativity, as well as the strongest dissimilarity, with Probabilistic modeling. 
Characterizing a lab or author in the topic space DTM gives us a method not only for identifying trends in the whole field but also a reference frame to characterize a subset of documents of interest. Here we provide an example of this kind of analysis, namely locating a lab in the topic space by averaging the topic proportions of all the documents produced by this lab. We chose the Computation and Cognition Lab at New York University (our database had 29 out of 32 CogSci publications listed on http://smash.psych.nyu.edu/papers.php), and the Stanford Language and Cognition Lab (with 58 out of 59 publications listed on http://langcog.stanford.edu/). The averaged topic proportion across all papers in each lab are shown in Fig ure 5, which agrees with our intuition for these labs’ themes. Worth noting is that this analysis is specific to publications in CogSci only. It may well be a lab has other directions of study that are not published in CogSci and are therefore not visible in this analysis. 
2000 2004 2008 2012 2016 
Year 
Figure 3: Trends within the Neural network topic. The upper panel shows the ten words with largest increase in frequency from 2000 to 2017, as estimated by the DTM. The lower panel shows the ten words with the largest decrease. We can see that the words becoming less popular in this topic are more closely related to connectionist neural networks (e.g., connectionist, nodes, input, output) while the more rising words are more related to biologically relevant neural models (e.g., brain, neuron), and maybe also to deep learning models (e.g., layer, vector). 
Recommending interesting papers We can also use the model to identify papers that are similar to a target paper, based on the cosine angle between their topic vectors. Since our model is fitted to all years at once, the similarity search is not constrained to papers that were published in the same year as the target paper. For demonstration3, we took a re cent CogSci publication from one author of the present paper: Rothe et al. (2016). Table 2 shows the most similar papers, which come from the same, earlier and later years then the pa 
3See https://anselmrothe.github.io/dtm/ for a web based, interactive version of our recommendation system. 982
Text 
processing 
and 
creativity Educational 
psychology Reasoning 
Consciousness 
and identity 
Spatial 
cognition 
Causal 
reasoning 
and embodied cognition 
Visual 
attention 
Communication 
Face and 
emotion 
perception 
Language: syntax 
Mathematical psychology 
Neural 
Knowledge 
Decision 
making 
Probabilistic 
modeling 
Memory network 
Language: 
semantics 
structure 
Categorization 
Sequential learning 
Developmental psychology 
Figure 4: Similarity structure of the topics. Stronger links between two nodes indicates a stronger similarity of the topics. NYU Computation and Cognition Lab Stanford Language and Cognition Lab 
Decision making 
Probabilistic modeling 
Categorization 
Causal reasoning 
Memory 
Consciousness and identity 
Educational psychology 
Visual attention 
Text processing and creativity 
Mathematical psychology 
Developmental psychology 
Neural network 
Spatial cognition and embodied cognition Sequential learning 
Reasoning 
Communication 
Face and emotion perception 
Knowledge structure 
Language: semantics 
Language: syntax 


	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	



0.0 0.1 0.2 0.0 0.1 0.2 
Figure 5: Dominant topics in two selected labs, the Stanford Language and Cognition Lab and the NYU Computation and Cognition Lab. For ease of comparison, the topics were ordered by their score for the NYU lab. 
983
Table 2: Papers similar to Asking and evaluating natural language questions (Rothe et al., 2016). Cosine Year Title 
0.986 2016 The distorting effect of deciding to stop sampling 
0.983 2013 Non-parametric estimation of the individuals utility map 
0.980 2016 Searching large hypothesis spaces by asking questions 
0.978 2017 A computational model for decision tree search 
0.977 2010 Cognitive Models and the Wisdom of Crowds A Case Study Using the Bandit Problem 
per itself, and which have cosine angles close to 1, indicating a strong similarity. Interestingly, on a first glance the match of the titles is not striking at all. For example, words from the titles such as “sampling”, “utility”, or “computational mod els” do not seem very close to “natural language questions” from the target paper’s title. However, knowing the content of the target paper, these words fit neatly to the account on question asking pursued in this article. 
Discussion 
We applied a dynamic topic model (DTM) to the last 18 years of Cognitive Science Society Proceedings. The model in ferred 20 distinct topics, which appear to reasonably corre spond to different subfields of cognitive science. We applied the DTM to two directions of analysis. First, we identified historical trends in the whole field as well as the detailed evo lution of a specific topic. Second, we characterized individ ual documents in the topic space, which enabled comparing different labs’ topic orientations as well as recommending pa pers of similar topic composition. 
It is worth noting that the interpretations we offer are only one of many ways to look at the field of cognitive science and simplify its complexity. Specifically, the topics we identified are dependent on stochasticity in the dataset and limitations in data preprocessing and model fitting and specification. Future work can extend our analyses to yield new insight in a number of ways. 
DTM improvements Our model assumes a fixed number of 20 topics. Future models could be more flexible and esti mate the best fitting number of topics, perhaps better captur ing human intuitions about the subdivisions of the field (see, e.g., Griffiths & Steyvers, 2004). Also, our model assumed a uniform prior over topic frequencies. In future work, a prior should be estimated from the data that can reflect the distri bution of topic frequencies (i.e., not assuming not all topics are equally likely), and that can evolve over time (Blei & Laf ferty, 2006). This would allow one to measure the changing popularity of topics in a more Bayesian manner. Finally, sim ply allowing more time to pass (and more data, in the from of CogSci proceedings, to be collected) may continue to im prove the performance of the DTM relative to LDA. 
LDA extensions Adding temporal drift is one way to ex tend traditional topic models. But it is not the only extension that might capture interesting patterns in the field of cogni 
tive science. Correlated topic models (Blei & Lafferty, 2007) can explicitly account for topics that tend to occur together in the same article, providing a formal avenue to understanding the kinds of connections between topics visualized in Fig ure 4. The document influence model (Gerrish & Blei, 2010) is an extension of the DTM that integrates the idea that some articles have a greater influence than others on future arti cles’ word composition. Using this approach, one could iden tify influential papers in an automated way, and investigate whether this measure of influence maps well to citation count or tends to be associated with mixtures of previously less connected topics. The approach could also be combined with that of Leydesdorff & Goldstone (2014) to determine how document influence relates to the citation of journals outside the field. 
Acknowledgments We thank everyone in the NYU Com putation and Cognition Lab for helpful discussions. 
References 
Blei, D. M., & Lafferty, J. D. (2006). Dynamic topic models. Pro ceedings of the 23rd international conference on Machine learn ing - ICML ’06, 113–120. 
Blei, D. M., & Lafferty, J. D. (2007). A correlated topic model of science. The Annals of Applied Statistics, 1(1), 17–35. 
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of Machine Learning Research, 3, 993–1022. 
Cohen Priva, U., & Austerweil, J. L. (2015). Analyzing the history of cognition using topic models. Cognition, 135, 4–9. 
Epskamp, S., Cramer, A., Waldorp, L., Schmittmann, V., & Bors boom, D. (2012). qgraph: Network visualizations of relationships in psychometric data. Journal of Statistical Software, Articles, 48(4), 1–18. 
Gerrish, S., & Blei, D. M. (2010). A language-based approach to measuring scholarly impact. In Icml (Vol. 10, pp. 375–382). 
Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings of the National Academy of Sciences, 101, 5228– 5235. 
Leydesdorff, L., & Goldstone, R. L. (2014). Interdisciplinarity at the journal and specialty level: The changing knowledge bases of the journal cognitive science. Journal of the Association for Information Science and Technology, 65(1), 164–177. 
Rothe, A., Lake, B. M., & Gureckis, T. M. (2016). Asking and eval uating natural language questions. In A. Papafragou, D. Grodner, D. Mirman, & J. Trueswell (Eds.), Proceedings of the 38th An nual Conference of the Cognitive Science Society. Austin, TX. 
984
Movement as a message: inferring communicative intent from actions  
Amanda Royka (amanda.royka@yale.edu), Rosie Aboody (rosie.aboody@yale.edu), Julian Jara-Ettinger  (julian.jara-ettinger@yale.edu) 
Department of Psychology, 2 Hillhouse Avenue 
New Haven, CT 06520 USA 
Abstract 
Humans often communicate through seemingly arbitrary  actions, like winks, waves, and nods. While these non-iconic  gestures derive their meanings from cultural consensus,  people, and especially children, must be able to identify these 
movements as gestures. Here we propose that people expect  that communicative actions will be shaped to reveal that they  have no external goal. In Experiment 1, we show that people  judge inefficient actions as more likely to be communicative.  In Experiment 2, we show that these judgments are truly  driven by efficiency, rather than a movement’s visual  complexity. Finally, in Experiment 3, we show that repetition  – which unambiguously reveals that the goal of the action is  the movement itself – has a strong influence on inferences  about communicativeness, independent of the motion’s  efficiency. Our findings show how expectations about non iconic communicative actions can be folded into a general  goal inference framework structured around an expectation  for efficiency. 
Keywords: Action understanding; gesture; social cognition  
Introduction 
Beginning in infancy, people interpret others’ actions in  terms of goals (Woodward, 1998), and they infer these goals  by assuming that agents act efficiently (see Jara-Ettinger et  al., 2016 for review; Csibra et al., 2003; Gergely et al.,  1995; Jara-Ettinger et al., 2015; Jara-Ettinger et al., 2017;  Király et al., 2003; Scott & Baillargeon, 2013; Skerry,  Carey & Spelke, 2013; Southgate, Johnson & Csibra, 2008).  For example, if Billy takes a straight path towards a box of  oranges, we can infer that his goal is to get an orange. If  instead, Billy moves erratically until he reaches the box of  oranges, we may infer that he was originally undecided  about his goal, or that he did not know how to complete it. 
Goal inference is most commonly conceptualized in terms  of “external” goals, such as manipulating objects, reaching  locations, or searching for items. Yet many intentional  actions serve a different purpose: to communicate. When  people wave, wink, or nod, their goal is not to act on an  external object, but to share a message: acknowledging  someone’s presence; indicating that they are in on a joke; or  agreeing with someone’s argument. For a communicative  action to fulfill its goal, however, people must be able to  recognize it. 
The most obvious way to identify a gesture and recognize  its meaning is through iconicity. For example, if Sally wants  to remind Anne to cut the tag off of her dress, Sally may  hold out her index and middle fingers and move them  together and apart to represent a pair of scissors. The  movement’s inefficiency with respect to plausible external  
985
goals and its physical representation of the subject matter  may enable Anne to infer that Sally is trying to tell her  something. Indeed, people readily label hand motions as  gestures when the movements mime the act of grabbing  nearby objects (Novak et al., 2016). Even four-year-olds  map iconic motions to referents faster than they map  arbitrary motions to referents (Magid & Pyers, 2017),  suggesting an early emerging sensitivity to the relationship  between a movement’s form and its meaning. 
In some cases, however, it is impossible to produce iconic  gestures because the meaning does not map onto an action  or material referent. For example, it is difficult to conceive  of an iconic gesture that represents gratitude or uncertainty.  Moreover, many common communicative gestures, such as  shaking one’s head, or giving the thumbs up, are not iconic,  showing that iconicity is not the only means of conveying  communicative intent. 
Because non-iconic gestures get their meaning through  cultural consensus, they are only useful when the recipient  is already familiar with the gesture. Yet we can also  recognize new gestures even if we do not know what they  mean. Imagine, for instance, watching someone raise her  arm with an open hand and her palm facing inwards. Even if  you do not know that this means “thank you” in some  cultures, chances are that you will still suspect that this  movement is a gesture. More importantly, all gestures are, at  some point, novel to children, who nonetheless manage to  learn their meaning and use them effectively even before  their second birthday (Guidetti, 2005; Harris, et al., 2017). 
Here we propose that people expect non-iconic  communicative actions to be shaped so as to reveal that they  have no external goals. Most directly, this predicts that  people should see less efficient movements as more likely to  be communicative. However, under this account, not all  inefficiency is created equal: motions that quickly reveal the  absence of an external goal should be seen as more likely to  be communicative.  
One way to indicate the absence of an external goal is  through repetition. By repeating a movement without  changing any physical aspect of the world, observers can  quickly infer that the goal is nothing more than to produce  the action itself, therefore revealing the action’s  communicative intent. Thus, we predict that people should  perceive a repetitive movement as more likely to be  communicative than a non-repetitive movement, even if  both movements are equally inefficient. 
Here we present three experiments that support our  hypothesis. Using a simple paradigm of dots moving in two dimensional planes (which have been shown to convey  
enough information to elicit rich mental state reasoning in  adults; Heider & Simmel, 1944), we explore people’s  intuitions about the structure of non-iconic communicative  actions, independent of ostensive cues that may accompany  communicative actions in natural contexts.  
In Experiment 1, we test whether people believe that less  efficient motions are more likely to be communicative.  Inefficient paths, however, are also more likely to be  visually complex. Therefore, in Experiment 2, we test  whether people’s inferences about communicativeness are  better explained by a path’s inefficiency or by its superficial  complexity. In Experiment 3, we show that people infer  that a movement is communicative based on its  repetitiveness, independent of its inefficiency. All stimuli,  data, and analyses are available at https://osf.io/ehb48/. 
Experiment 1 
In Experiment 1, we test whether people judge less efficient  paths as more likely to be communicative. If people assume  that communicative actions are shaped to reveal that they do  not have external goals, then participants should rate  inefficient movements as more communicative than  efficient movements.  
Methods 
Participants 30 participants (M = 32.87 years, range = 22- 63) from the US (as indicated by their IP addresses) were  recruited through Amazon’s Mechanical Turk platform. 
Stimuli The stimuli consisted of 23 seven-second videos of  a white dot moving around a green screen. A short red tail  trailed behind the dot, in order to make the movements  easier to track. 
Figure 1: Examples of paths from the eight categories: a) maximally  efficient paths, b) paths that retrace themselves back to their origin, c) paths  that move towards more than one quadrant, d) paths that move towards only  one quadrant, e) paths that retrace a part of themselves, but do not start and  end in the same position, f) paths that intersect themselves, but do not start  and end in the same position, g) paths that have repeated components that  form a pattern, and h) paths that do not retrace themselves, but start and end  
in the same position. The full red trails depicted above are included here for  reference. In the experiment, the red trail was one and a half times as long  as the diameter of the dot, and then faded. 
Paths were constructed by combining 4 of 16 possible  primitive path segments, which were a set of horizontal,  vertical, diagonal, and 90 degree arc segments. This resulted  
986
in a set of 4,520 unique paths, which we sorted into eight  categories based on a priori features of interest that impact  the path’s efficiency (see Figure 1 for descriptions and  examples of path categories). We then randomly selected  two random paths from the first category (Fig 1A) and three  random paths from all other categories (FigB-H) for a total  of 23 paths. Four additional paths were also selected for use  as warm-up videos. 
Procedure Participants first read a brief cover story: 
There is an anthropologist doing research on a remote island.  Once a week, a helicopter flies over the island and the  anthropologist has to signal the helicopter if he needs additional  supplies. Because the tree cover on the island is so thick, the  helicopter operator can only track the anthropologist's movements  using an infrared camera. The camera is very good at capturing  motion. Because of this, the anthropologist signals different  requests using previously agreed-upon walking movements.  
Some days, the anthropologist needs supplies and will move to  communicate a message to the helicopter. Other days, the  anthropologist will not need to communicate anything and will  continue doing his research and maintaining his base camp. 
You will be shown videos of the anthropologist’s movements on  different days and asked to rate how likely you think it is that the  anthropologist was communicating something to the helicopter  that day on a scale of one (definitely not communicating) to seven  (definitely communicating). 
 After reading the cover story, participants completed a  three-question quiz to ensure that they read and understood  the scenario. Participants had to reread the scenario and  repeat the survey until they answered all questions correctly.  Next, participants were next shown four warm-up videos in  order to familiarize them with the types of movements the  anthropologist could make. Before proceeding onto the test  phase, participants were reminded of the rating scheme. And  finally, participants were told that the anthropologist was  trying to communicate in roughly half of the videos. 
 In the test phase, each video looped continuously and was  presented on a separate screen. Under each video was a 7- point scale, where participants rated how likely it was that  the anthropologist was trying to communicate, from 1  (definitely not communicating) to seven (definitely  communicating). The order of the videos in the warm-up  phase and the order of the videos in the test phase were  randomized.  
Results and Discussion 
We quantified each path’s efficiency as 
��� � = �⋆ � 
� �(1) 
where � � is the actual distance travelled and �⋆ � is  shortest distance between the start and the end points.  Therefore, paths that start and end in the same location have  efficiency=0, while straight (maximally efficient) paths  have efficiency=1. As predicted, we found a strong negative  
correlation between path efficiency and average participant  judgments (r = –0.80 p < 0.001; Figure 2), with the two  straight (and therefore maximally efficient) paths receiving the lowest average communicativeness ratings. 
Method 
Participants 30 participants (M = 40.83 years, range = 25 - 73) were recruited in the same manner as Experiment 1.  Individuals who participated in Experiment 1 were excluded  from participation. 
) 
7
-
1
( 
g
n
i
t
a
R
 
s
s
e
n
e
v
i
t
a
c
i
n
u
m
m
o
C 
e
g
a
r
e
v
A
●B
	

	●F 
	

	

	●G
	

	

	●B
	●F
	

	

	

	

	

	

	●H 
	●F
	

	

	

	

	

	

	H 
● 
H
●
	

	●E
	●E
	

	

	

	

	

	

	

	●C
	

	● G 
	

	

	

	

	

	●
	●C 
E
	

	●D
	●G
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	C
●D ● 
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	●D
	

	

	

	

	

	

	

	

	



5.0 
4.5 
4.0 
3.5 
3.0 
A 
● 
A 
● 
2.5 
Stimuli The stimuli consisted of twelve pairs of identical  paths (total videos = 24) presented in two ways: one in  which the dot’s path was closely bordered on both sides by  lakes (constrained trials), and one in which the path was not  closely bordered by lakes (unconstrained trials; see Figure 3  for static images). Eight of the twelve paths were obtained  by selecting one random path from each of the a priori  categories used in Experiment 1 (see Figure 1).  Additionally, because we were especially interested in paths  that were perceived as highly communicative in Experiment  1, we selected four additional random paths from the set  with highest communicative appearance (average  
0.00 0.25 0.50 0.75 1.00 Efficiency 
Figure 2: The relationship between path efficiency (x axis; 0, least efficient  to 1, most efficient) and average communicativeness rating (y axis; 0, least  likely to be communicative to 7, most likely to be communicative). 
However, efficiency was not the only feature that guided  participants’ judgments. Among the least efficient paths  (those that began and ended in the same location; categories  B and H in Figure 1, with efficiency 0 in Figure 2), the  paths with repetition (category B) were rated as more likely  to be communicative relative to paths with no repetition  (category H; p < 0.005 in a linear model constrained to H  and B predicting communicativeness rating from category),  suggesting that specific types of inefficiency, such as  repetition, are salient cues to communicativeness. Similarly,  one path from category G that formed a wave-like pattern  (the example in Figure 1G) was judged as highly  communicative even though it was relatively efficient,  further suggesting that structural aspects of the motion, and  not efficiency alone, drive judgments of  communicativeness.  
Experiment 2 
Experiment 1 suggests that people judge less efficient  motions as more likely to be communicative. However, it is  possible that people’s judgments were not driven by a path’s efficiency, but by its shape or complexity. We evaluate this  possibility in Experiment 2 by contrasting paths similar to  those from Experiment 1 with paths that are visually  identical, but now efficient due to lakes on the island  (Figure 3). If judgments of communicative intent track the  movement’s efficiency, then participants should judge the  version of each path bordered by lakes to be less  communicative than the version that is not bordered by  lakes. However, if judgments of communicative intent are  tracking complexity, then the presence of the lakes should  not affect participants’ ratings, and both versions of the  same path should be rated as equally communicative.  
987
communicativeness rating > 4.25 in Experiment 1) for a  total of 12 basic paths. 
Figure 3: Static images of a constrained trial (left) and an unconstrained  trial (right) from Experiment 2. 
Procedure The pre-test phase in Experiment 2 was identical  to Experiment 1. However, the scenario included an  additional description explaining that there are lakes on the  island and the quiz included a fourth question about the  lakes. The test phase was also identical to Experiment 1,  except that participants were assigned to one of five trial  orders, which were all pseudo-randomized so that the two  versions of the same path were never presented  consecutively. Additionally, after the test phase, we asked  the participants whether they used any explicit strategies  when rating the videos.  
Results and Discussion 
Figure 4 shows the average perceived communicativeness  for each path when it was constrained (x-axis) and when it  was unconstrained (y-axis). Overall, participants rated the  unconstrained paths (M=4.64) as significantly more  communicative than the constrained paths (M=2.99; t(11)= - 
8.03, p < 0.001). The only path that did not follow this trend  was the straight path. However, adding external constraints  does not change this path’s efficiency because a straight line  is already the most efficient way to travel between two  points, whereas in the case of the nonlinear paths, the lakes  make the inefficient movements efficient given the external constraints. 
 To analyze the roles of efficiency and the presence of  the lakes, we ran a linear regression, predicting average  communicativeness rating as a function of the path’s  efficiency (irrespective of the presence of lakes; Eq. 1),  condition (constrained vs. unconstrained), and their  interaction. In line with Experiment 1, we found a general  effect of efficiency (β= -1.24; p < .01) and, as predicted, a  general effect of condition (β=2.01; p < .001). We also found a marginally significant interaction between the  condition and path efficiency (β= -1.14; p = .059),  suggesting that the effect of adding lakes had a greater  impact on less efficient paths. 
question. Only 9 out of 30 participants mentioned explicitly  paying attention to the lakes when rating the videos,  suggesting that participants were not simply responding to  the presence or absence of lakes. Also, it is important to  note that if people’s judgments were only driven by the  presence or absence of lakes, then responses should have  been bimodal, with no variance within each category.  Instead, consistent with the results of Experiment 1,  people’s judgments were also sensitive to each path’s  efficiency 
 As in Experiment 1, the communicativeness ratings for  the unconstrained versions of paths that started and ended in  the same location were higher for the paths that returned to  
● 
● 
B 
their origin by retracing themselves (category B; Figure 1)  B 
than for the paths that did not retrace themselves (category  
  
r
o
f 
g
n
i
t
a
R
 
s
s
e
n
e
v
i
t
a
c
i
n
u
m
m
o
C 
e
g
a
r
e
v
A
) 7
−
1
( 
s
ht
a
P 
d
e
n
i
a
r
t
s
n
o
c
n
U
5 4 3 2 


	●G
	●
	●F 
H
	●
	H
	

	

	C
	

	 
H
● 
F 
● 
	

	

	

	

	●
	

	●E
	

	

	

	D
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	



● 
A 
● 
2.5 3.0 3.5 4.0 Average Communicativeness Rating 
for Constrained Paths (1−7) 
H; Figure 1). Although paths in both categories were  equally inefficient, participants rated the paths that repeated  the same movement as more communicative. This suggests  that specific types of inefficiency, such as repetition, may be  salient cues to communicativeness. 
Experiment 3 
If communicative actions are structured to reveal their  communicative intent, then these movements may boast  features that “efficiently” demonstrate their inefficiency  with regards to external goals. Here we test the prediction  that repetitive movements are viewed as more likely to be  communicative, independent of their efficiency. To do this,  we manipulate the number of times a path is repeated, while  keeping the path’s basic shape and total distance constant. If  
Figure 4: The average communicativeness rating (1, least likely to be  communicative to 7, most likely to be communicative) for the constrained  and unconstrained versions of each path. Letters correspond to the  categories in Figure 1. The “X” indicates the average communicativeness  for all constrained and all unconstrained paths and x=y is shown as a dotted  line. 
 This pattern of results is striking. Even though nothing  about the shape of the paths changed, by using situational  constraints, we were able to alter people’s judgments about  the communicative intent behind each movement. This  provides strong evidence that people track inefficiency, and  not complexity, when inferring whether a movement was  done with communicative intent.  
 To ensure the robustness of the results, we also did a  meta-analysis combining the results of Experiments 1 and 2,  predicting the participants’ individual (rather than average)  answers based on the path’s efficiency (Equation 1) and  condition (constrained vs. unconstrained) 1 with random  intercepts for participant and path category. Consistent with  our past results, we found a main effect of efficiency (p < 0.01), a main effect of condition (p < 0.001), and a  significant interaction between efficiency and condition (p =  0.002).  
 Finally, to determine whether participants used any  explicit strategies in the task, we analyzed the free response  
 
1 All paths from Experiment 1 were coded as unconstrained for  condition. 
988
the repetitiveness of a path spurs judgments of  communicative intent, then participants should rate versions  of a path with more repetitions as more communicative  relative to versions of that path with fewer repetitions.  However, if repetitiveness is not a cue to  communicativeness, then the number of repetitions should  not affect participants’ ratings. 
Methods 
Participants 30 participants (M = 34.23 years, range = 23- 59) were recruited in the same manner as Experiment 1.  Individuals who participated in Experiments 1 and 2 were  excluded from participation. 
Stimuli The stimuli consisted of 21 seven-second videos  similar to the ones used in Experiment 1. The stimuli were  designed by first creating seven “basic” paths composed of  two primitive path segments each (see Figure 5). The final  stimuli set consisted of three versions of each basic path: the  basic path (no repetition), the basic path that then retraced  itself back to its origin (one repetition), and the basic path  that retraced itself back to its origin, and then repeated that  path again back to its origin (two repetitions). In order to  obscure the critical manipulation, paths with one repetition  were rotated 90 degrees counterclockwise and reflected over  the x-axis, and paths with two repetitions were rotated 180  degrees counterclockwise. Additionally, we altered the  
length of each path segment so that the total distance  traveled by each version of the basic paths was matched.  
Procedure The cover story, warm-ups, and test phase were  identical to Experiment 1, except that after the test phase,  we asked participants whether they used any strategies when  rating the videos. 
General Discussion 
Our findings provide the first evidence that people assume  that movements made with communicative intent are shaped  to reveal that they are not instrumental to external goals. In  Experiment 1, we found that people judged less efficient  motions as more likely to be communicative. In Experiment  2, we found that these judgments were driven by the path’s  inefficiency rather than by its complexity. Finally, in  
) 7
−
1
( 
g
n
it
a
R 
s
s
e
n
e
v
i
t
a
c
i
n
u
m
m
o
C 
e
g
a
r
e
v
A
7 


	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	



6 
5 
4 
3 
2 
1 

Condition 
No repetition 
One repetition 
Two repetitions 
Experiment 3, we found that participants judged repetitive  motions as more likely to be communicative. 
Although people assume that communicative actions will  be inefficient in regards to alternative external goals, not all  inefficient movements are communicative. For example,  someone may perform unnecessary inefficient steps out of  ignorance or ritual. People appear to believe that movements  that quickly reveal the absence of external goals (such as  repetitions) are more likely to be communicative,  independent of the movements’ efficiency. Thus, taken  together, our results suggest that people’s expectations  
Figure 5: The average communicativeness rating (1, least likely to be  communicative to 7, most likely to be communicative) for paths with no  repetition, one repetition, and two repetitions. Vertical bars show 95%  confidence intervals. Images along the x-axis show the shapes of the  unrepeated basic paths and are ordered based on the basic path’s efficiency  (see Eq. 1). 
Results and Discussion 
As in Experiments 1 and 2, we averaged participant ratings  to obtain a mean communicativeness rating for each path.  To analyze the role of repetition and efficiency, we ran a  linear regression predicting average communicativeness  rating as a function of the path’s base efficiency, and the  number of repetitions. Consistent with Experiments 1 and 2,  we found a general effect of efficiency (β= -1.16; p = .001)  and, as predicted, a general effect of repetitions (β=1.40; p <  .001). We did not find a significant interaction between  repetitions and base path efficiency (β= 0.31; p = .407). 
 When asked whether they used any strategies, 17 of the  30 participants mentioned paying attention to the amount of  repetition, back-tracking, or patterns while watching the  stimuli. However, participants also rated less efficient paths  as more communicative, suggesting that even if participants  were explicitly basing their judgments on repetition, they  were also still implicitly tracking how efficiently the  movements mapped onto external goals independent of the  number of repetitions. Additionally, there was nothing in  the experimental set-up that indicated that communicative  movements ought to be more repetitive than goal-directed  movements. Indeed, one could plausibly infer the opposite:  that moving from one point to another in the exact same  way is instrumental in the pursuit of a specific external goal.  
Participants’ attention to repetition provides evidence that  people expect communicative actions to be structured in a  way that reveals that they are not directed at external goals.  With each repetition, participants found the same basic  movement to be more communicative, even though the  distance and duration of travel were held constant.  
989
about communicative actions are not guided by inefficiency  alone, but rather by inefficiency that quickly reveals that the  goal is in the action itself. 
The experiments presented here are consistent with work  showing that when a movement is intentional, but does not  efficiently accomplish an external goal, people infer that the  goal of the action is the movement itself (Schachner &  Carey, 2013). One critical difference, however, is that  Schachner and Carey (2013) did not find an effect of  repetitiveness on the inference of movement-based goals.  Importantly, in their study, the agent was alone and there  was no prior mention of possible communicative intent.  This difference further suggests that repetition is associated  with communicative actions, rather than with the broader  class of actions where the goal is the movement itself (such  as dancing). 
Here we focused on people’s expectations about the  structure of communicative actions, rather than on the  structure of communicative actions themselves. Intuitively,  however, the assumption that communicative actions are  shaped to reveal that they have no external goal is  reasonable and related work has shown that when people  need to create communicative systems through motion, they  tend to use repetitive and inefficient trajectories to  disambiguate their communicative intent (Scott-Phillips, et  al., 2009). Additionally, many gestures in the US–such as  winking or extending one’s index finger and pinky to  inform someone to “rock on”–consist of movements that are  rarely produced when pursuing external goals. Moreover,  gestures that may be confounded with external goals are  often repeated. For example, Lisa could shake her head to  look quickly in another direction or to move a piece of hair  from her face, but if she repeats the movement, an observer  can infer that her goal is not to accomplish those external  goals, but to signal disagreement.  
In these cases, conventional communicative gestures may  take their repetitive form due to cultural evolution; gestures  that gain meaning through cultural consensus and survive  
over time may be those that effectively reveal that they are  communicative. Alternatively, communicative gestures may  be shaped from their onset to reveal that they are not  directed towards external goals. If someone is trying to  communicate something with her body, then engaging in  on-line reasoning about whether an observer will recognize  that she is trying to communicate may cause her to favor  movements that do not seem to pursue external goals. Work  investigating the production of novel gestures or gesture  production across development could help to disambiguate  the origins of the inefficiency and repetition that seem to exist in conventional communicative gestures. 
In each experiment, we told participants that roughly half  of the movements were done with communicative intent.  This explicit communicativeness prior enabled us to  uncover what types of inefficiency seem most 
communicative. All of the paths used in our experiments  (except for the two straight paths) were inefficient.  Therefore, according to our theory, it would have been reasonable for participants to rate all inefficient paths as  communicative. However, because we were interested in  relative ratings of communicativeness, rather than absolute  judgments of communicativeness, setting the explicit prior  of 50 percent allowed us to get graded responses. Future  work will investigate whether inefficiency and  repetitiveness also affect the tendency to spontaneously  infer that a movement is communicative.  
In our studies, we used large-scale two-dimensional  movements, rather than footage of hand or arm movements  in order to control for subtle cues that may be encoded in  biological motion (e.g., Vaziri-Pashkam, Cormiea &  Nakayama, 2017). In real life, ostensive cues often  accompany communicative gestures (e.g., Behne et al.,  2005; Lempers, 1979) and may simplify the task of inferring  the communicative intent of a movement. However, we  predict that that our findings should hold even with more  naturalistic stimuli (e.g., hands, arms) and future work will  investigate this question. Additionally, our studies show that  even in the absence of these cues, people assume that  communicative movements are structured in a way that  would not be an efficient means to accomplishing an  external goal. Thus, together with ostensive cues, these  assumptions may allow people to rapidly infer  communicative intent from the myriad possible alternative  goals. 
Acknowledgments 
We thank Madison Flowers for her help with piloting and  data collection. 
References  
Behne, T., Carpenter, M., & Tomasello, M. (2005). One year-olds comprehend the communicative intentions  behind gestures in a hiding game. Developmental science. 
990
Csibra, G., Bıró, S., Koós, O., & Gergely, G. (2003). One year-old infants use teleological representations of actions  productively. Cognitive Science. 
Gergely, G., Nádasdy, Z., Csibra, G., & Bíró, S. (1995).  Taking the intentional stance at 12 months of age.  Cognition. 
Guidetti, M. (2005). Yes or no? How young French children  combine gestures and speech to agree and refuse. Journal  of Child Language. 
Harris, P. L., Bartz, D. T., & Rowe, M. L. (2017). Young  children communicate their ignorance and ask  questions. Proceedings of the National Academy of  Sciences. 
Heider, F., & Simmel, M. (1944). An experimental study of  apparent behavior. The American journal of psychology. Jara-Ettinger, J., Gweon, H., Tenenbaum, J. B., & Schulz,  
L. E. (2015). Children’s understanding of the costs and  rewards underlying rational action. Cognition. 
Jara-Ettinger, J., Gweon, H., Schulz, L. E., & Tenenbaum, J.  B. (2016). The naïve utility calculus: computational  principles underlying commonsense psychology. TiCS. 
Jara-Ettinger, J., Floyd, S., Tenenbaum, J. B., & Schulz, L.  (2017). Children believe that agents maximize expected  utilities. JEP: General. 
Király, I., Jovanovic, B., Prinz, W., Aschersleben, G., &  Gergely, G. (2003). The early origins of goal attribution  in infancy. Consciousness and cognition. 
Lempers, J. D. (1979). Young children's production and  comprehension of nonverbal deictic behaviors. The  Journal of Genetic Psychology. 
Magid, R. W., & Pyers, J. E. (2017). “I use it when I see it”:  The role of development and experience in Deaf and  hearing children’s understanding of iconic gesture.  Cognition.  
Novack, M. A., Wakefield, E. M., & Goldin-Meadow, S.  (2016). What makes a movement a gesture?. Cognition. Schachner, A., & Carey, S. (2013). Reasoning about  ‘irrational’ actions: When intentional movements cannot  be explained, the movements themselves are seen as the  goal. Cognition. 
Scott, R. M., & Baillargeon, R. (2013). Do infants really  expect agents to act efficiently? A critical test of the  rationality principle. Psychological science. 
Scott-Phillips, T. C., Kirby, S., & Ritchie, G. R. (2009).  Signalling signalhood and the emergence of  communication. Cognition. 
Skerry, A. E., Carey, S. E., & Spelke, E. S. (2013). First person action experience reveals sensitivity to action  efficiency in prereaching infants. PNAS. 
Southgate, V., Johnson, M. H., & Csibra, G. (2008). Infants  attribute goals even to biomechanically impossible  actions. Cognition. 
Vaziri-Pashkam, M., Cormiea, S., & Nakayama, K. (2017).  Predicting actions from subtle preparatory movements.  Cognition. 
Woodward, A. L. (1998). Infants selectively encode the goal  object of an actor's reach. Cognition. 
Joint inferences of speakers’ beliefs and referents based on how they speak 
Paula Rubio-Fernández (paula.rubio-fernandez@ifikk.uio.no) 
Department of Philosophy, University of Oslo, Blindernveien 31, 0315 Oslo 
Julian Jara-Ettinger (julian.jara-ettinger@yale.edu) 
Department of Psychology, Yale University, 2 Hillhouse Avenue, New Haven, CT 06520-8205 
Abstract 
For almost two decades, the poor performance observed with  the so-called Director task has been interpreted as evidence of  limited use of Theory of Mind in communication. Here we  propose a probabilistic model of common ground in referential  communication that derives three inferences from an utterance:  what the speaker is talking about in a visual context, what she  knows about the context, and what referential expressions she  prefers. We tested our model by comparing its inferences with  those made by human participants and found that it closely  mirrors their judgments, whereas an alternative model  compromising the hearer’s expectations of cooperativeness  and efficiency reveals a worse fit to the human data. Rather  than assuming that common ground is fixed in a given  exchange and may or may not constrain reference resolution,  we show how common ground can be inferred as part of the  process of reference assignment. 
Keywords: common ground; computational modeling;  reference resolution; Theory of Mind 
Introduction 
Imagine you are on a plane and the passenger next to you is  reading the news and comments: ‘Trump has done it again’.  You would probably interpret ‘Trump’ to mean Donald  Trump, but what if your best friend in college also went by 
the name ‘Trump’: would you even consider that your fellow  passenger could be talking about your friend?  
An old debate in theoretical and experimental pragmatics  addressed precisely this question: whether names (or definite  descriptions, more generally) are interpreted relative to the  interlocutors’ mutually shared knowledge, or common  ground. Clark and Marshall (1981) argued that indeed,  considerations of common ground should constrain  demonstrative reference. However, Keysar (1997) responded  that a real test of this view should separate the speaker’s and  listener’s perspectives (as in the example above), otherwise  the listener may simply rely on their own private knowledge  and assume common ground with the speaker.  
Keysar and colleagues designed the so-called ‘Director task’ to test whether listeners use common ground to  constraint reference interpretation. In this task, a participant  follows the instructions of a confederate to move around  various objects in a vertical grid of squares. The confederate  sits on the other side of the grid and cannot see all of the  objects, because some of the cells are occluded on her side.  Crucially, the confederate is supposed to be ignorant of the  contents of those cells, and when she asks the participant to  ‘move the small candle,’ for example, the smallest of three  candles is visible only to the participant. Over a long series  of studies, participants have shown a tendency to consider,  
991
and sometimes even reach for, the smallest candle in their  privileged view before picking up the medium-sized candle  in open view (e.g., Keysar et al., 2003; Lin et al., 2010).  
Keysar et al. interpreted this pattern of results as evidence  of an ‘egocentric bias’ in communication, according to which  listeners initially comprehend language egocentrically and  only use common ground as a correction mechanism. This  view renewed the old debate on reference and common  ground when other studies using the Director task showed  that listeners can use common ground information from the  earliest stages of interpretation (e.g., Nadig & Sedivy, 2002;  Hanna & Tanenhaus, 2004). However, the negative results  observed with the Director task have also been interpreted in  social cognition research as evidence that we make limited use of Theory of Mind in communication (e.g., Apperly &  Butterfill, 2009; Apperly et al., 2010). 
We have recently argued that the Director task is not a  reliable test of Theory of Mind use in communication since  optimal performance in the task (according to the usual  metrics of interference) is possible by using a selective 
attention strategy, without necessarily deriving any epistemic  inferences about the speaker (Rubio-Fernández, 2017). 
Inferring common ground 
While allowing to separate the speaker’s and hearer’s  perspectives, the Director task makes some unnatural  assumptions that rarely apply in everyday communication.  The first is that participants must assume that the confederate  only knows about the objects that she can see in the grid and  will not refer to any other object. In reality, however,  speakers often refer to entities outside their visual field.  Given the high selective attention demands of this paradigm,  participants’ fixations on the hidden objects in the grid need  not be a form of egocentric behavior. 
A second unnatural assumption in the Director task is how  common ground is fixed at the start of the game, rather than  being inferred during the exchange. A more reliable test of  Theory of Mind use in communication would be to see  whether participants are able to infer common ground given  the Director’s instructions. For example, if the confederate  asked the participant for ‘the blue cup’ and there was a red  cup in an occluded cell, would participants infer that the  confederate knows about the red cup and used color  contrastively? The results of Rubio-Fernández (2017) show  precisely this, suggesting that when participants keep track of  the contents of the occluded cells in the grid, they may still  be making sophisticated epistemic inferences, rather than  failing to use their Theory of Mind. 
Heller et al. (2016) have recently proposed a probabilistic  model of reference resolution based on the results of the  Director task. Rather than assuming that participants interpret  the instructions either from their own egocentric perspective,  or according to their common ground with the Director, this  model integrates both perspectives by giving each a  probabilistic weight. Heller et al.’s model accounts for some  discrepancies in the results of previous studies but assumes  that common ground is determined by shared visual context, and does not allow for the possibility that (1) the speaker may  be aware of objects that she cannot currently see, or (2) that  the listener can infer and reconsider what the speaker knows. 
In this study we present and test a probabilistic model of  referential communication that assigns reference to an  expression in a given visual context by jointly deriving epistemic inferences based on the speaker’s choice of  referential expression and adjusting their expectations about  the speaker’s linguistic preferences. For example, if a rational  and cooperative speaker produced an under-specific  description (e.g., ‘the cup’ when there are two cups from the  listener’s perspective), the listener would assume that the  speaker only knows about one of the objects. Likewise, if the  same speaker produced a modified description (e.g., ‘the blue  cup’), the listener could assume that the speaker was either  preempting an ambiguity (between the two cups) or using the  adjective redundantly (rather than contrastively). Our model  therefore tries to account for three pragmatic phenomena  given a referential expression: what the speaker is talking  about in the visual context (referent), what she knows about  the context (beliefs) and how she talks (efficiency). 
Computational framework 
Our model (http://github.com/julianje/CommonGround)  consists of two components: a generative model of how speakers choose their utterances given a target referent, and a  Bayesian model of how listenersinferspeakers’ referents and  beliefs given their utterances. Our framework builds upon the  strengths of reference resolution models in language (Frank  & Goodman, 2012; Franke & Degen, 2013; Kehller & Rohde,  2013; Shafto, Goodman, & Griffiths, 2014; Stevens, 2017) 
and mental-state inference models (Baker, Jara-Ettinger,  Saxe, & Tenenbaum, 2017; Jara-Ettinger, Schulz, &  Tenenbaum, under review). We begin by describing the  generative model of a speaker, and we then explain how our  model of a listener uses this speaker model to infer the  speaker’s beliefs and referents given their utterances. 
Speaker model 
In our generative model, the speaker has a set of beliefs  (which, in our task, corresponds to what the speaker can see) and a goal (which, in our task, is to communicate a referent) that together determine the speaker’s utterance. To generate  the utterance, the speaker has an intuitive model of a simple  
 
1 Naturally, speakers can be under-informative for many reasons,  including distraction, accidents, and maliciousness. Here, we call the under specification parameter the ‘Uncooperativeness parameter’ for simplicity,  
992
listener, which she uses to reason which potential utterances  are sufficiently informative. 
The simple listener model takes a set of beliefs and an  utterance and returns a uniform probability distribution over  all potential referents that match the utterance. For instance,  the utterance ‘the triangle’, combined with a belief that there  is only one triangle among all the objects, returns a  probability of 1 for the triangle and a probability of 0 for all  other potential referents in the space of beliefs. Through this  model, the speaker would determine that the utterance ‘the  triangle’ is sufficiently informative. By contrast, if the simple  listener’s beliefs contained two triangles, then it would return  a probability of 1/2 for each of these triangles, and a  probability of 0 for all other potential referents. The speaker  would therefore conclude that the utterance is not sufficiently  informative. Using this model of a simple listener, the  generative model of a speaker finds an utterance which is  sufficiently informative to identify the intended referent (i.e.  where the referent has a probability of 1 based on the simple  listener model). 
Intuitively, speakers can accidentally be under- or over specific. Thus, we include a small probability that the speaker  will produce an utterance that is insufficiently informative  (the Uncooperativeness parameter1), and a small probability  that the speaker will produce redundant modifiers (the  Redundancy parameter). We estimate both parameters  through participant judgments (see Parameter estimation  study). Formally, the Uncooperativeness parameter is the  probability that the speaker will believe that a proposed  utterance is sufficiently informative, independently of the  output from the simple listener model. Similarly, the  Redundancy parameter is the probability that the speaker will  consider using a modified expression without evaluating if a  simpler one would have been sufficiently informative. 
Listener model 
Our model of participants as listeners consists of a Bayesian  inference mechanism for inferring a speaker’s beliefs and  intended referent through the generative model of the  speaker. 
We treat the probability of under-specification (the  Uncooperativeness parameter) as observable and constant  across all speakers. That is, we assume that listeners do not  question that speakers are generally cooperative, but they  nonetheless understand that they can accidentally fail to  specify the referent. 
By contrast, we treat the probability of over-specification  (the Redundancy parameter) as unobservable and variable  across speakers. That is, we assume that listeners believe that  different speakers may be more or less likely to use adjectives  redundantly and that each speaker’s individual tendency to  use redundant adjectives must be inferred. Nonetheless, we  assume that participants have prior beliefs about how often  people speak redundantly. 
but it is intended to capture the general expectation that speakers may be  under-informative, regardless of the underlying reason. 
Given an utterance, our listener model performs a joint  inference over the speaker’s beliefs, intended referents and  degree of redundancy using Bayes’ rule: 
�(�,�, �|�) ∝ �(�|�,�, �)�(�,�, �) (1) 
where b is the speaker’s belief, t is the target (i.e. the  speaker’s intended referent), r is the speaker’s level of  redundancy, and u is the utterance the speaker produced. The prior distribution, �(�,�, �), is given by 
�(�,�, �) = �(�|�)�(�)�(�) (2) 
where the prior beliefs about the speaker’s level of  redundancy (�(�)) and the speaker’s beliefs (�(�)) are  independent, and the probability of a target referent depends  on the speaker’s beliefs (�(�|�)), such that only objects that  the speaker knows about have positive probability of being  the target. In our task (see Experiment), we use a prior  distribution over beliefs, a beta distribution (fit to  participants’ priors in the Parameter estimation task) over  redundancy, and a uniform distribution over the referents,  conditioned on the speaker being aware of these potential  referents. Finally, the likelihood function, �(�|�,�, �), is  computed through the generative model described above. 
Parameter estimation study 
Methods 
Participants 50 participants from the US (as determined by  their IP addresses) were recruited using Amazon’s  Mechanical Turk Framework. 
Stimuli 24 displays of shapes of different colors were  generated. 20 of these displays consisted of a single shape (circle, rectangle, square, star and triangle) in 4 colors (blue,  green, red and yellow) surrounded by a black border. The  remaining 4 displays consisted of two shapes of the same type in different colors with one of these shapes (the target)  surrounded by a black border (target side counterbalanced).  The single shapes were used to measure over-specification  (and estimate expectations about redundancy) and the double  shapes to measure under-specification (and estimate  expectations about cooperativeness). 
Procedure Participants were told they would see a set of  images with a target surrounded by a black border and that  their task would be to select which of two utterances an  average speaker would use to refer to it given the visual  display. The two utterances were always an unmodified  description of the target (e.g., ‘The triangle’) and a modified  description of the target (e.g. ‘The blue triangle’). Thus,  selecting the modified description in the single-shape trials  (e.g., preferring ‘The blue triangle’ when there is only one  triangle) reveals expectations about over-specification, while  selecting the unmodified description in the dual-shape trials  (e.g., preferring ‘The triangle’ when there are two triangles)  reveals expectations about under-specification. 
993
Results 
Our model’s Uncooperativeness parameter (see  Computational Framework) was set to the proportion of times  that participants chose an under-specific description in the  dual-shape trials: 5.5% of trials. By contrast, because our  model infers each speaker’s degree of redundancy, we used  participants’ choices in the single-shape trials to build a prior  distribution (see prior over Redundancy parameter in  Computational Framework). To do so, we fit a beta  distribution to participants’ choices using maximal  likelihood. The resulting prior distribution was a Beta  distribution with parameters α=0.39 and β=0.32. 
Experiment 
Methods 
Participants 60 participants (mean age (SD) = 35.22 years  (10.66 years), range = 18-73 years) from the US (as  determined by their IP address) were recruited using  Amazon’s Mechanical Turk Framework. 
Stimuli 
Each trial included two displays of 4 geometrical shapes  (circles, squares, stars and triangles) in 4 different colors  (blue, green, red and yellow), each with a referential  expression for the target (see Figure 1 for examples). The  description of the target appeared above each display, and  could be either modified (e.g., ‘The blue triangle’) or  unmodified (e.g., ‘The triangle’). The combination of shapes  and instructions yielded four conditions for each individual  display: Unique (single shape/ no color adjective),  Contrastive (two shapes/ color adjective), Redundant (single  shape/ color adjective), Ambiguous (two shapes/ no color  adjective). The possible overlap between the positions of the  target and the contrast shape (when present) in the two  displays yielded six types of position overlap: No Overlap,  Target-Target, Contrast-Contrast, Target-Contrast, Double Same (2 Targets and 2 Contrasts), Double-Crossed (2 Target Contrast). A total of 28 combinations were included in 2 lists  of 14 trials with a balanced number of condition  combinations. We only excluded 3 combinations because one  did not allow any common ground inference (Ambiguous 
Ambiguous/No Overlap) or rendered two impossible combinations where the target or the contrast in one display  would correspond with the blind spot in the other  (Ambiguous-Contrastive/Contrast-Contrast and Ambiguous Contrastive/Double-Crossed). 
Procedure 
Participants played a coordination game with a virtual  speaker and followed her instructions to select a shape in a  display. The virtual speaker giving the instructions could  only see 3 shapes in each display, whereas participants could  see 4. The virtual speaker did not know that she had a blind  spot, but always tried to be helpful. Each trial contained two 
displays and the speaker’s blind spot was the same quadrant  in both displays, although it varied across trials. The  speaker’s choice of referential expression to single out the 
Figure 1. Six trials from the Experiment along with model predictions. Each trial consisted of two displays of four shapes and an instruction for each  display. Using separate 2-dimensional trackpads, participants had to infer (1) which cell the speaker was referring to on the left-hand side display, (2) which  cell the speaker was referring to on the right-hand side display, and (3) which cell was the speaker’s blind spot in both displays. In each panel, the region  of the right shows average participant judgments on the overlaid trackpads, along with model predictions. Speaker judgments are shown in red and model  predictions are shown in blue. Each relation from a model prediction to a participant judgment is connected by a black line. L refers to the inferred referent  on the left-hand side display, R refers to the inferred referent on the right-hand side display, and B refers to the inferred blind spot. 
target was written above each display. See Figure 1 for  examples. The pairs of displays were randomly ordered and  rotated in each trial. 
Participants had to answer three questions in each trial:  which shape the virtual speaker was referring to in each  display and which quadrant was the blind spot in both  displays. Participants used three separate 2-dimensional  trackpads shown on the screen to enter their responses while  indicating their certainty (i.e. the closer they moved the  button towards a corner, the greater their certainty that that  was the referent or the blind spot; see Figure 1). Participants  were given two examples of how to use the 2D trackpads and  two examples of complete trials to show them how to reason  about the blind spot by considering both displays. 
Results 
Participant judgments on the trackpad were interpreted as  marginal probabilities that the referents or blind spots were  on the left or right side (x value) and on the top or bottom (y value). Model predictions were transformed to points in the  2D trackpad. The top row of Figure 2 shows our model  predictions (x-axis) plotted against average participant  judgments (y-axis). Our model showed a correlation of 0.95  for belief inferences (95% CI: 0.92-0.97) and a correlation of  0.99 (95% CI: 0.989-0.997) for referent inferences. 
Figure 1 shows the six trials and the corresponding graphs  showing participant inferred referents in red (L for the  referent in the left-hand side display and R for the referent in 
994
the right-hand side display) and inferred blind spot (B) along  with model predictions in blue (connected by a black line). Figure 1a (Unique-Contrastive) shows how our model and  participants infer common ground based on the inferred  referents. The target in the display on the left overlaps with  the contrast shape in the display on the right, making the  probability that the blind spot is in each of the two top cells  1/2. Figure 1b (Contrastive-Contrastive) shows how contrastive adjectives affect our model and participant inferences. Again, the speaker in Figure 1b refers to each of  the two bottom cells, but because the two contrast shapes are  in the top left cell, participants beliefs about the blind spot  shift towards the top right cell. 
Figure 1c (Unique-Contrastive) shows how our model and  participants infer common ground using contrast. The two  instructions unambiguously identify targets in opposite  quadrants, but people and our model infer that the contrast  shape in the right display is also in common ground. Figure 
1d (Ambiguous-Contrastive) shows how our model and  participants can combine under-specification with contrast to jointly infer common ground and resolve referential  ambiguity. The left display suggests that the speaker is either  referring to the bottom left cell or to the top right cell, and  that she can only see one of them. Although the right display makes no direct reference to either of these cells, the contrast  shape suggests that the speaker can see the bottom left cell.  Having inferred common ground, participants and our model infer that the speaker was referring to the bottom left cell in  
the left display and that she cannot see the top right cell. Note  that our model does not show full confidence in this joint  inference (because it is also possible that the speaker was  uncooperative) and neither do participants. 
Figure 1e (Redundant-Contrastive) shows the effects of  redundancy in our model predictions. Here, because the  speaker is redundant in the left display, speakers and our  model do not treat the contrast on the right display as  informative when inferring common ground. Finally, Figure 
1f (Unique-Contrastive) shows how our model and  participants inferences are sensitive to the possibility that the  speaker is being uncooperative. The speaker unambiguously  refers to the triangle in the left display, revealing that she can  see the bottom left cell. The speaker then ambiguously refers  to either of the two triangles on the right display. Under  perfect rationality, the speaker must be referring to the 
bottom left cell in both displays and her blind spot would be the right top cell. However, our model’s confidence about the  inferred referent decreases in the right display because of the  speaker’s possible uncooperativeness, accurately predicting  this fine-grained difference in participant judgments. 
Figure 2. Model predictions against participant judgments. The top row  shows our model and the bottom row shows the model after specification  lesion (where the model no longer draws any inferences through the  presence or absence of modification). Each point corresponds to a  participant judgment. Blue lines show best linear fit. 
Model lesion predictions 
Having found that our model predicted participant judgments  with high quantitative accuracy, we next evaluated the role of under-specification (Uncooperativeness parameter) and over specification (Redundancy parameter) by lesioning the  model. In the lesioned model we set the Uncooperativeness parameter to 0.99 (i.e. an expectation that speakers rarely  recognize when they are being under-specific, making the  absence of adjectives uninformative) and we set the prior  distribution over Redundancy to a Beta distribution with  parameters α=10 and β=1 (i.e. an expectation that speakers  are often redundant, making the presence of adjectives  uninformative). Thus, our lesioned model continues to expect  that the speaker will correctly identify the referents, but now  assumes that the use or absence of adjectives is  uninformative. 
995
The bottom row of Figure 2 shows the inferences from the  lesioned model. This model showed a correlation of 0.55  (95% CI: 0.28-0.75) on belief inferences and a correlation of  0.99 (95% CI: 0.989-0.996) on referent inferences. Our main  model was reliably better than the lesioned model on belief  inferences (correlation difference = 0.4; 95% CI on  difference: 0.22-0.67) but not on referent inferences  (correlation difference = 0.0006; 95% CI on difference: - 0.0039 – 0.0051). 
Although the lesioned model was generally able to infer  referents (largely because the target is unambiguously  identifiable in all cases, except when the speaker is under specific), Figure 2 suggests that the lesioned model was less  sensitive to features of the trials relative to participants. To  investigate this, we did a post-hoc analysis of trials where the  lesioned model failed to identify the referents. Two of these  corresponded to the trials shown in Figures 1d and 1f. Figure 3 shows the lesioned model’s inferences along with  participant judgments in these trials. In the displays in Figure 1d, the lesioned model incorrectly infers that the blind spot is  in the top left cell and fails to make any inferences about  which circle the speaker is talking about in the left-hand side  display (see left display in Figure 3). This shows how loss of  sensitivity to contrast impairs the model’s ability to infer the  referents and the blind spot. In Figure 1f, participants make  stronger inferences about the speaker’s blind spot and the  inferred referent in the right display. Our lesioned model fails  to derive these inferences because it does not rely on the  under-specification to infer the blind spot and consequently  uncover the referent (see right display in Figure 3). 
Figure 3. Model lesion against participant judgments. Predictions  correspond to the trials shown in Figure 1d (left) and Figure 1f (right).  Consistent with Figure 1, average participant judgments are shown in red.  Model lesion predictions are shown in green. 
Discussion 
We presented a formal model of definite reference  interpretation and common ground that captures three  fundamental pragmatic inferences in referential  communication: what the speaker is referring to, what she  knows about the context, and what preferences she has when  choosing referential expressions. Our model inferences  closely mirrored participant judgments, while an alternative  model compromising the hearer’s expectations of  cooperativeness and redundancy was less successful. 
Our model shows that common ground can be computed as  part of the process of reference assignment, rather than being  established a priori, as assumed in the Director task (e.g.,  Keysar et al., 2003) and related computational models(Heller  et al., 2016). Our results are consistent with work showing  that participants in a modified version of the Director task can derive sophisticated epistemic inferences given a speaker’s  choice of referential expression (Rubio-Fernández; 2017). 
Critically, participants in that study derived pragmatic inferences spontaneously, suggesting that interlocutors can derive epistemic inferences in referential communication without being instructed to do so. 
Although our model performs three inferences from each  utterance (see Eq. 1), here we only evaluated people’s  inferences about speaker’s intended referents and their  beliefs, but we did not ask participants to explicitly infer the  speaker’s level of redundancy. Existing work already  suggests that people can infer speaker’s redundancy and  adjust their inferences accordingly (Grodner & Sedivy,  2011). In future work, we will evaluate this capacity  quantitatively. 
Similarly, our model framework and implementation can  handle an arbitrary number of useful adjectives, favoring  more informative adjectives over less informative ones, and  combining them when necessary. Here we focused on simple  situations where the potential referents could only be  disambiguated by their shape or their color. In future work, 
we will explore situations where speakers have several ways  of drawing contrast to evaluate how listeners adjust their  inferences based on their priors for redundancy (e.g., listeners  tend to expect color to be used redundantly more often than  size) and the efficiency of these contrasts. 
Finally, our results suggest that testing people’s ability to  derive epistemic inferences in referential communication is a  more reliable test of Theory of Mind use in communication  than the standard Director task, which imposes highly  unnatural demands on participants’ selective attention.  Although our model fits do not imply that participants were  actively mentalizing when doing our task, they do show that,  if people are not mentalizing, whatever mechanisms they use  to circumvent mentalistic reasoning must be sufficiently  complex to accurately approximate Theory of Mind  inferences. 
Acknowledgments 
This research was supported by a Young Research Talent  Grant from the Research Council of Norway (Ref. 230718)  awarded to PRF and a Google Faculty Research Award to  JJE. 
References  
Apperly, I. A., & Butterfill, S. A. (2009). Do humans have  two systems to track beliefs and belief-like  states? Psychological Review, 116(4), 953. 
Apperly, I. A., Carroll, D. J., Samson, D., Humphreys, G. W.,  Qureshi, A., & Moffitt, G. (2010). Why are there limits on  Theory of Mind use? Evidence from adults’ ability to  
996
follow instructions from an ignorant speaker. Quarterly  Journal of Experimental Psychology, 63(6), 1201-1217. Baker, C. L., Jara-Ettinger, J., Saxe, R., & Tenenbaum, J. B.  (2017). Rational quantitative attribution of beliefs, desires  and percepts in human mentalizing. Nature Human  Behaviour, 1(4), 0064. 
Clark, H. H., & Marshall, C. R. (1981). Definite reference  and mutual knowledge. In A. K. Joshi, B. Webber, and I.  Sag (Eds.), Elements of discourse understanding.  Cambridge: Cambridge University Press. 
Frank, M. C., & Goodman, N. D. (2012). Predicting  pragmatic reasoning in language  games. Science, 336(6084), 998-998. 
Franke, M., & Degen, J. (2016). Reasoning in reference  games: Individual- vs. population-level probabilistic  modeling. PloS one, 11(5), e0154854. 
Grodner, D., & Sedivy, J. (2011). The effect of speaker specific information on pragmatic inferences. In N.  Pearlmutter and E. Gibson (Eds.), The processing and  acquisition of reference. MIT Press: Cambridge, MA 
Hanna, J. E., & Tanenhaus, M. K. (2004). Pragmatic effects  on reference resolution in a collaborative task: Evidence  from eye movements. Cognitive Science, 28(1), 105-115. 
Heller, D., Parisien, C., & Stevenson, S. (2016). Perspective taking behavior as the probabilistic weighing of multiple  domains. Cognition, 149, 104-120. 
Jara-Ettinger, J., Schulz, E., & Tenenbaum, J.B., (under  review). The naïve utility calculus as a foundation for  action understanding. 
Kehler, A., & Rohde, H. (2013). A probabilistic  reconciliation of coherence-driven and centering-driven  theories of pronoun interpretation. Theoretical  Linguistics, 39(1-2), 1-37. 
Keysar, B. (1997). Unconfounding common  ground. Discourse Processes, 24(2-3), 253-270. Keysar, B., Lin, S., & Barr, D. J. (2003). Limits on Theory of  Mind use in adults. Cognition, 89(1), 25-41. 
Lin, S., Keysar, B., & Epley, N. (2010). Reflexively  mindblind: Using Theory of Mind to interpret behavior  requires effortful attention. Journal of Experimental Social  Psychology, 46(3), 551-556. 
Nadig, A. S., & Sedivy, J. C. (2002). Evidence of  perspective-taking constraints in children's on-line  reference resolution. Psychological Science, 13(4), 329- 336. 
Rubio-Fernández, P. (2017). The Director task: A test of  Theory-of-Mind use or selective attention? Psychonomic  Bulletin & Review, 24(4), 1121-1128. 
Shafto, P., Goodman, N. D., & Griffiths, T. L. (2014). A  rational account of pedagogical reasoning: Teaching by,  and learning from, examples. Cognitive Psychology, 71,  55-89. 
Stevens, J. (2017). Biases and labeling in iterative pragmatic  reasoning. Proceedings of the 39th Annual Meeting of the  Cognitive Science Society. 
Endogenous orienting in the archer fish 
William Sabana,b,1, Liora Sekelya,b, Raymond M. Kleinc, and Shai Gabaya,b,1 
aDepartment of Psychology, University of Haifa, Haifa, Israel 3498838; bThe Institute of Information Processing and Decision Making, University of Haifa, Haifa, Israel 3498838; and cDepartment of Psychology and Neuroscience, Dalhousie University, Halifax, Nova Scotia B3H 4R2, Canada 
Edited by Michael E. Goldberg, Columbia University College of Physicians, New York, NY, and approved June 8, 2017 (received for review January 12, 2017) 
The literature has long emphasized the neocortex’s role in volitional processes. In this work, we examined endogenous orienting in an evolutionarily older species, the archer fish, which lacks neocortex like cells. We used Posner’s classic endogenous cuing task, in which a centrally presented, spatially informative cue is followed by a tar get. The fish responded to the target by shooting a stream of water at it. Interestingly, the fish demonstrated a human-like “volitional” facilitation effect: their reaction times to targets that appeared on the side indicated by the precue were faster than their reaction times to targets on the opposite side. The fish also exhibited inhi bition of return, an aftermath of orienting that commonly emerges only in reflexive orienting tasks in human participants. We believe that this pattern demonstrates the acquisition of an arbitrary con nection between spatial orienting and a nonspatial feature of a centrally presented stimulus in nonprimate species. In the literature on human attention, orienting in response to such contingencies has been strongly associated with volitional control. We discuss the implications of these results for the evolution of orienting, and for the study of volitional processes in all species, including humans. 
volitional orienting | subcortical regions | endogenous orienting | IOR | attention 
Humans are commonly assumed to have volitional abilities that 
species lacking a neocortex (e.g., fish and amphibians) do not have. The literature has long emphasized the role of cortical mech anisms in these exclusive cognitive abilities. But is a neocortex nec essary for a species to manifest behaviors that have been attributed to volitional control? To examine this question, we tested whether the archer fish (Toxotes chatareus) is capable of endogenous orienting. 
Driven by bottom-up stimulation, reflexive orienting is fast and automatic as a result of tuning through natural selection. Volitional orienting is relatively nonreflexive and is tuned to local contingencies and/or the immediate goals of the individual (1). In the current study, we adopt the typical perspective regarding spatial attention, as put forward by Posner (2), which is characterized by two distinctions: whether covert or overt adjustments are made, and whether these adjustments are under endogenous (volitional) or exogenous (re flexive) control. The most common methods for examining reflexive and volitional attentional processes are two versions of Posner’s cuing task (2, 3). In this task, participants are presented with a cue followed by a peripheral target to which they are instructed to respond. Two task properties are important for determining which mode of ori enting is generated. The first is whether or not the cue is informative about the location of the upcoming target, and the second is whether or not the input pathway of the upcoming target might be stimulated by the cue. When studying reflexive orienting, the peripheral location where a target might appear, or one nearby, is stimulated by a cue that is uninformative about the location of the upcoming target. When the interval [stimulus onset asynchrony (SOA)] between the cue and the target is varied, the typical pattern of results is an early facilitation of responses to targets at the cued location, followed by a later inhibitory effect (4) that has been called inhibition of return (IOR) (5, 6). When studying volitional orienting, a property of a central cue that does not stimulate the possible target locations pro vides information about which of the peripheral locations is more likely to contain the subsequent target. The typical pattern of results elicited in covert orienting is a gradually developing facilitation at the 
cued location as the interval between the cue and the target increases. When measuring endogenous saccadic effects (overt orienting), most studies demonstrate a facilitatory effect at a wide range of SOAs (up to 1,250 ms; e.g., refs. 7–9). 
It has been suggested that reflexive attention may be phylogenet ically older than volitional attention (10). Consistent with this sug gestion, volitional orienting is often linked to cortical regions (11–14), whereas reflexive orienting is linked to subcortical processing (15–19). Most pertinent to the present study, a recent study (20) demonstrated that the archer fish, which lacks cortical structures, shows the pro totypical reflexive pattern of early facilitation followed by later IOR (20). In nature, the archer fish spits a jet of water to shoot down prey resting on foliage above the water. In an experimentally controlled environment, the archer fish can learn to respond to targets pre D 
S 
sented on a computer monitor above its tank. The finding that archer 
E
N
C
 A
fish, a nonprimate species, have similar reflexive attentional pro 
N
L
E
I
A
cesses, namely, facilitation and IOR (20), suggests these attentional 
C
C
 S
I
G
E
processes in humans have an evolutionary ancestor. Fish lack lami 
O
V
I
L
T
nated and columnar neural organization (21, 22), visual cortex, and 
O
I
H
N
C
G
frontal and parietal cortical regions (which in humans are thought to 
Y
O
S
C
P
guide volitional orienting). However, the fish does possess an optic tectum, which implies that subcortical mechanisms are probably in volved in these types of reflexive processes. Recently, it has been E 
suggested that fish telencephalon is not composed mostly of basal 
C
N
E
I
ganglia (subpallium), but also includes pallial regions that might be 
C
S
homologous with the mammalian neocortex, and potentially might 
O
R
U
serve functions similar to the neocortex (23–27). However, despite 
E
N
these possible homologies, the fish brain has significantly less com putational power than the cortices of higher organisms such as pri mates (28–32). As a consequence, investigation of cognitive processes in fish provides vital evidence for the complexity of the neural cir cuitry essential for a specific function. This is even more pronounced for cognitive abilities that have been traditionally considered to be limited to primates (e.g., volitional abilities). 
Although several studies have explored attention in nonprimates, it is worth noting several features of the used tasks that limit the ability to conclude that purely endogenous attentional processes were studied. For example, in studies with rats (e.g., ref. 33) and 
Significance 
Volitional orienting, most commonly explored in humans using the classic Posner endogenous cuing task, is often linked to neocortical regions. We applied this task in a species lacking a neocortex (i.e., archer fish). Our study provides a demonstration of facilitation and inhibition of return as a result of a purely endogenous (centrally presented, informative, and symbolic) cue. The results have major implications for our understanding of the evolution of orienting (reflexive and volitional), and for the paradigms used to study “volitional” processes.
	



Author contributions: W.S. and S.G. designed research; W.S. and L.S. performed research; W.S. and S.G. analyzed data; and W.S., R.M.K., and S.G. wrote the paper. 
The authors declare no conflict of interest. 
This article is a PNAS Direct Submission. 
1To whom correspondence may be addressed. Email: williamsaban@gmail.com or shaigaba@gmail.com. 
This article contains supporting information online at www.pnas.org/lookup/suppl/doi:10. 1073/pnas.1700574114/-/DCSupplemental. 
www.pnas.org/cgi/doi/10.1073/pnas.1700574114 PNAS Early Edition | 1 of 5 997
chickens (e.g., ref. 34) that used a Posnerian cuing paradigm, the cues were both informative and peripheral. By combining methods used for studying endogenous (informative) and exogenous (pe ripheral) orienting, these studies likely generated a hybrid mode of orienting, with an indeterminate mixture of reflexive and voluntary effects (35). A methodological mixture of this kind precludes the ability to assess purely endogenous processes. 
It has been known for some time that the orienting behavior of human observers can be sensitive to the information value of the properties of the scene being inspected (36). Chun and Jiang (36) referred to this as “contextual cuing,” an implicitly acquired contin gency between where to look and the properties of the scene. It was recently demonstrated that the orienting behavior of pigeons (37, 38), similar to that of humans, can be sensitive to the information value of the properties of a scene. In the context of the present exploration, we must note that this form of cuing is different from that explored using Posner’s endogenous cuing paradigm in two important respects: the property that signals the more fruitful locus of attention is in the scene (not presented in a precue before the presentation of the tar get), and hence, the contextual cuing paradigm does not require the organism to maintain the information provided by the cue, and the contextual cuing paradigm has never been touted as one suitable for exploring the voluntary control of behavior. 
We are not aware of any study in nonprimates that tried to generate attentional orienting using a purely endogenous (centrally presented, informative, and symbolic) cue before the presentation of a target. To fill this gap, the present experiment uses Posner’s endogenous cuing task: An arbitrary, centrally presented, spatially informative cue and its ensuing peripheral target were presented to the archer fish (Fig. 1). To assess the fish endogenous orienting abilities in an ecological setting, fish were swimming freely in the tank, and the reaction time (RT) of its localization of the targets 
(by spitting at them) was measured. If endogenous orienting is governed by neocortical structures, then it might be predicted that lacking such structures, the archer fish will not show orienting in this purely endogenous cuing paradigm. Two SOAs were used to explore the time course of endogenous orienting (if observed) in the archer fish. 
Results 
Trials in which the fish responded very slowly, with RT longer than 2,500 ms, were excluded from the analyses. To explore the time course of any orienting effects our procedures might have generated, we first conducted separate analyses of variance on the RTs of each fish (Materials and Methods) with the factors of SOA and validity. As illustrated in Fig. 2, each fish exhibited facilitation at the 200-ms SOA and inhibition (IOR) at the 800-ms SOA. To follow the standard analysis procedure used in conventional experiments, we also con ducted a group analysis on the mean RTs for the three fish. Signif icant interaction between SOA and validity was observed across all fish [F(1,2) = 33.20; P < 0.05; η2p = 0.94]. Follow-up simple effects tests revealed significant facilitation at the 200-ms SOA and signifi cant IOR at the 800-ms SOA [F(1,2) = 24.16 (P < 0.05; η2p = 0.92); F(1,2) = 41.51 (P < 0.05, η2p = 0.95), respectively]. 
Discussion 
Archer fish studies have focused on spitting accuracy (39–42), biomechanics of spitting (43–46), neural coding (47), and learn ing sensorimotor skills (48–50). In addition, a recent study also demonstrated that archer fish can learn to discriminate a large number of human face images (51). However, little is known about whether archer fish have volitional processes. 
In the present study, while exploring the behavior of the archer fish during Posner’s endogenous orienting attention task, we found 
Location markers*3 200 ms 
600 ms 
600 ms 
Cue: 600 ms 
SOA: 200 or 800 ms  
Target: 3500 ms or until  
response  
Fig. 1. The sequence of events in a typical experimental trial. Each trial began with the flickering of three black location markers, presented three times for 200 ms with a 600-ms interval between presentations. Six hundred milliseconds after the location markers disappeared, a red or green predictive (valid 80% of the time) cue box appeared for 100 ms at the center of the fixated location. After a variable SOA (200 ms, 800 ms), a black target asterisk appeared for 3,500 ms or until a response was detected. The target could appear at the cued location or at the opposite location (valid or invalid conditions, respectively). After the target disappeared, a blank screen was presented between trials for 10 s. 
2 of 5 | www.pnas.org/cgi/doi/10.1073/pnas.1700574114 Saban et al. 998

Fig. 2. RT as a function of SOA and validity for the three fish. All fish completed 21 sessions of the experiment. In an analysis of variance, a significant interaction between SOA and validity was observed in all the fish [F(1,20) = 14.29 (P < 0.005; η2p = 0.42); F(1,20) = 8.91 (P < 0.01; η2p = 0.31); and F(1,20) = 27.95 (P < 0.001; η2p = 0.58) for fish 1, 2, and 3, respectively]. Follow-up simple effects tests revealed the appearance of facilitation at the 200-ms SOA [F(1,20) = 8.49 (P < 0.01); F(1,20) = 4.56 (P < 0.05); and F(1,20) = 10.73 (P < 0.005), for fish 1, 2, and 3, respectively] and IOR at the 800-ms SOA [F(1, 20) = 4.91 (P < 0.05); F(1,20) = 4.79 (P < 0.05); and F(1,20) = 29.33 (P < 0.001), for fish 1, 2, and 3, respectively]. Ninety-five percent confidence intervals are shown in the error bars. *P < 0.05; **P < 0.01. The two functions have been slightly offset horizontally to allow visualization of the error bars. 
an indication of volitional orienting. The fish were able to learn the predictable symbolic value of the cue, and their spitting RTs at the short SOA were modulated accordingly, with faster RTs at targets appearing at the cued (more probable) location. In addition to the early facilitation observed at the short SOA, the fish also demon strated IOR at the long SOA. This is a demonstration of the ap pearance of an early endogenous facilitation effect that was superseded by IOR in nonhumans. 
Research on voluntary attention has focused mainly on primates. The literature has emphasized the role of the cerebral cortex in voli tional attentional orienting. In this study, the archer fish, a nonprimate species that lacks a neocortex, yield a result that is similar to that of humans at early SOAs (i.e., endogenous facilitation). This demon strates that such an organism, which developed very early in evolution, can exhibit orienting behavior in a purely endogenous cuing paradigm. 
In the next two sections, we explore possible explanations for the unexpected appearance of IOR at the late SOA and the implications of our finding of endogenously generated facilitation at the early SOA. By any explanation, we believe that the finding of endoge nously generated facilitation has two major aspects: using the most widely accepted task (Posner’s endogenous cuing paradigm) for studying volitional orienting in humans, this is a demonstration of purely endogenous orienting in a nonprimate species; and in addition 
D 
S 
to the major methodological and conceptual differences between 
E
N
C
 A
previous studies and our task (reviewed in the Introduction), there are 
N
L
E
I
A
C
phylogenetical differences between lower vertebrates (e.g., fish) and 
C
 S
I
G
E
higher ones (e.g., birds) (52–54). From an evolutionary perspective, 
O
V
I
L
T
O
I
the more than 200 million-year phylogenetic distance that separates 
H
N
C
G
Y
fish from other vertebrates (e.g., humans, monkeys, and even pi 
O
S
C
P
geons) presents an invaluable opportunity for a comparative in vestigation of brain and cognition development during evolution. The current findings allow the inference that endogenous orienting and 
E 
C
IOR are much more fundamental and primitive abilities for the 
N
E
I
survival of organisms and are shared by highly distinct species. 
C
S
O
R
U
Inhibition of Return After an Endogenous Cue: Evolutionary Perspectives. 
E
N
Humans are born with a bundle of reflexes that, through ontoge netic development, come under cortical inhibitory control enabling goal-directed behavior (e.g., ref. 55). From a phylogenetic per spective, the ability to predict and to voluntarily control basic pro cesses was developed through the evolution of the species. In addition, all living organisms are information processing systems. The information collected about the environment by each such system is used, reflexively and/or volitionally, to direct behavior. 
Fish represent a taxonomic group that diverged from the other vertebrates ∼450 million years ago (56). In the present study, the archer fish, a vertebrate species that is evolutionarily distant from humans, demonstrated human-like endogenous facilitation (which will be discussed in greater detail in the next section), but also pre sented an IOR effect, which commonly emerges in reflexive ori enting tasks. Hence, the presence of IOR in an endogenous orienting task was unexpected. 
It could be suggested that the fish response preparation might involve body orientation toward the predicted location, thus resulting in a shift of the fish area centralis (57) toward the attended location. Similarly, the appearance of IOR might be a result of a tendency to orient toward the uncued location at the long SOA when the target does not appear at the cued location at the short SOA. This latter possibility is improbable because at both the short and long SOAs, target probability is higher at the cued location, and hence there is no incentive for the fish to attend the uncued location at any SOA. Fish are able to learn associations across larger time spans than the one used in the current task (58, 59); therefore, it is more likely that an inhibitory process is influencing performance and producing the observed IOR pattern of results. 
Two explanations for the unexpected appearance of IOR in an endogenous orienting task are discussed. Both explanations ac knowledge that the archer fish demonstrated probability-appropriate 
Saban et al. PNAS Early Edition | 3 of 5 999
overt orienting tendencies (Implications for the Study of Volitional Processes) in response to the endogenous cue, which facilitate responding at the short SOA. The two explanations also recognize, as originally proposed by Posner and Cohen (4), that the inhibitory effects attributed to IOR can be present at the same time as the facilitative effects of the present locus of attention. Subsequent studies (60, 61) support this proposal and demonstrate that facili tation and inhibition might have additive effects on performance. Finally, both explanations assume that regardless of the observed underlying mechanism for early facilitation, it is transient in the ar cher fish and no longer operating by the time of our long SOA (800 ms after the appearance of the cue). 
One explanation is based on the suggestion (62) that in human participants, endogenous preparation of overt (oculomotor) orienting is accompanied by IOR, which is overshadowed by facilitation while expectancy is maintained. The archer fish demonstrates a similar, endogenously generated overt orienting tendency. Once the archer fish (or human participant) fails to maintain the target expectancy generated by the cue, the already-present inhibitory effect is revealed. From this perspective, it might be assumed that maintaining expec tancy for more than a few hundred milliseconds requires cortical control, which the archer fish lacks. This explanation is critically de pendent on the observation by Rafal et al. (63) that cancellation of an endogenously generated oculomotor preparation is followed by IOR (63). As Chica et al. (64) were unable, in successive attempts, to replicate this critical finding reported by Rafal et al. (63), we do not favor this explanation. 
We prefer the simpler alternative explanation in which IOR is generated primarily by subcortical structures (5, 17, 65), and in primates, it may be modulated by cortical regions (15, 66). In line with previous research (25), in fish, spatial learning is dependent on the pallium region, and it is plausible that the fish telen cephalon contributes to endogenous orienting. However, in contrast to primates’ neocortical control, pallial influence over the optic tectum might be insufficient to inhibit IOR generated by the preparation of an overt orienting response. 
Accordingly, it has recently been suggested that in primates, the primary visual cortex (V1) creates a saliency map of the visual world (67). In lower vertebrates, such as fish, V1 is absent and the superior colliculus (which is called the optic tectum in lower vertebrates) receives retinal input. Hence, it is possible that through evolution, this saliency map of the visual world migrated from the optic tectum to the V1. It has been suggested (67) that reflexive cuing effects observed in humans should also be present in lower vertebrates. Therefore, it is possible that when attention is guided by a saliency map at the optic tectum (as in fish), IOR (which is a reflexive at tentional process guided by the optic tectum) is activated in both modes of orienting (exogenous and endogenous). As a consequence, we recommend conducting neuroscientific studies of the archer fish and of humans performing our task to test these possibilities. 
Implications for the Study of Volitional Processes. The present study has important implications for conceptual understanding of volitional control processes and their operationalization in cognitive sciences. To explore these issues, it will be helpful if, in contrast to the common conflation of the terms “endogenous” and “voluntary,” we explicitly distinguish between them, using “endogenous” to refer to the com bination of methods used and “voluntary” to refer to a conceptual attribution. As described in the introduction and used in the present study, perhaps the most common method for exploring the voluntary control of orienting is Posner’s endogenous cuing paradigm. 
One possible interpretation of our finding of facilitation in the archer fish shortly after a centrally presented, informative cue is that the archer fish is demonstrating voluntary control. For those who find this implausible because of the limited cortical circuitry in this species, or for other reasons, we offer a plausible alterna tive. We propose that the archer fish has learned the conditional contingency between the cue’s color and the later target’s location. 
This learning process generates activation of the conditionally probable orienting response, which accelerates the correct re sponse on valid trials. This account, in terms of conditional dis crimination learning, coincides with a recent study of human performance (68), suggesting that implicit learning of cue-target contingencies plays a role in the magnitude of endogenous cueing effects when the validity of the cue is manipulated. 
Researchers interested in the volitional control of behavior need to be aware of the fact that probability manipulation, which is in herent in the endogenous cuing paradigm pioneered by Posner, al lows for cuing effects that are implicitly acquired, and therefore may not reflect volitional control. Researchers who use this paradigm are therefore obliged to obtain converging evidence from other para digms that are not subject to the possibility of associative learning. 
Conclusion 
The present study provides a demonstration of facilitation and IOR as a result of a purely endogenous (central, informative, and symbolic) cue in a species lacking a neocortex. As we have dis cussed, the results may have major implications for our under standing of the evolutionary development of orienting processes (facilitation and IOR) and for the paradigms used to study voli tional control processes in all species, including humans. 
Materials and Methods 
The experiment was conducted in accordance with Haifa University regulations and the State of Israel’s laws on animal care and experimentation. Our ex periment involved testing, individually, three archer fish in a specially arranged tank, as described here. Each fish was swimming freely in the water tank during the task. A 21-inch Samsung LCD monitor (model S24C650PL) was placed on a glass shelf 41 cm above water level. The fish were trained to shoot at the target stimuli and were recorded using a GigE Camera color (120 fps 640 × 480 1/4). RT was calculated by measuring the time from target ap pearance until the fish’s shooting onset. Successful shots were determined when the water jet landed on the surface of the target. After each successful shot, the fish received a pellet of food and the experimenter cleaned the water from the glass shelf. The cue was predictive regarding target location; that is, the target appeared at the predicted location in 80% of the trials. 
In each session, each fish performed 40 trials (32 valid and 8 invalid), composed of two different SOAs (200 ms or 800ms) and two validity conditions (valid and invalid). Before we started to collect data, the fish were trained in the task until they achieved proficiency (training sessions were similar to the testing sessions: five sessions for each fish separately, one training session per day). Each trial began with the flickering of three black location markers (4.2° height and 6.95° width), with centers positioned 8.3° from each other. Flickering was achieved by flashing the three location markers three times (i.e., they appeared for 200 ms at a time with a 600-ms interval between appearances). One thousand two hundred milliseconds after the location markers disappeared, a red (predicting a target to the left of the cued box) or green (predicting a target to the right of the cued box) cue box (4.2° in height and 6.95° in width) appeared for 100 ms at the center of the screen. After a variable SOA (200 or 800 ms), a black target asterisk (2.1° in height and 2.8° in width) appeared for 3,500 ms or until a response was detected. The target could appear at the cued location or at the opposite location. After the target dis appeared, a blank interval screen was presented between trials for 10 s. After the training period, we ran each fish through the task for a period of about 2 mo. Each fish performed 21 sessions, and each session included 40 trials, so that overall, each fish had 840 experimental trials. In general, at the beginning of each trial and during cue presentation, the fish swam close to the water level and was relatively still awaiting target presentation. When the target was presented, the fish initiated its response by elevating its mouth above water level and shooting a stream of water on the target stimuli (Movie S1). The fish made no anticipatory errors and did not respond to the cued location on invalid trials. The target was the only stimulus presented long enough for the fish to respond. When responses were initiated, all fish were 100% accurate in all conditions. The percentage of trials in which the fish did not respond to target appearance in each condition is: valid, 200 ms SOA, 12.5; valid, 800 ms SOA, 8.8; invalid, 200 ms SOA, 8.3; invalid, 800 ms SOA, 9.1; and no significant effects were observed at each SOA (P > 0.1). In every session, the average RT was computed for each experimental condition: valid 200 ms SOA, valid 800 ms SOA, invalid 200 ms SOA, and invalid 800 ms SOA. 
ACKNOWLEDGMENTS. This research was supported by the Israel Science Foundation (Grant 1124/14 to S.G.). 
4 of 5 | www.pnas.org/cgi/doi/10.1073/pnas.1700574114 Saban et al. 1000
1. Klein RM, Lawrence MA (2012) On the modes and domains of attention. Cognitive Neuroscience of Attention, ed Posner MI (Guilford Press, New York), 2nd Ed, pp 11–28. 2. Posner MI (1980) Orienting of attention. Q J Exp Psychol 32:3–25. 3. Klein RM (2005) On the role of endogenous orienting in the inhibitory aftermath of exogenous orienting. Developing individuality in the human brain: A tribute to Michael Posner, eds Mayr U, Awh E, Keele S (American Psychological Association, Washington, DC), pp 45–64. 
4. Posner MI, Cohen Y (1984) Components of visual orienting. Atten Perform X Control Lang Process 32:531–556. 
5. Posner MI, Rafal RD, Choate LS, Vaughan J (1985) Inhibition of return: Neural basis and function. Cogn Neuropsychol 2:211–228. 
6. Klein RM (2000) Inhibition of return. Trends Cogn Sci 4:138–147. 7. Henik A, Rafal R, Rhodes D (1994) Endogenously generated and visually guided sac cades after lesions of the human frontal eye fields. J Cogn Neurosci 6:400–411. 8. Hodgson TL, Muller HJ (1999) Attentional orienting in two-dimensional space. Q J Exp Psychol Sect A 52:615–648. 
9. Posner MI, Nissen MJ, Ogden WC (1978) Attended and unattended processing modes: The role of set for spatial location. Modes of Perceiving and Processing Information (Erlbaum, Hillsdale, NJ), pp 137–157. 
10. Carrasco M (2011) Visual attention: The past 25 years. Vision Res 51:1484–1525. 11. Corbetta M, Kincade JM, Ollinger JM, McAvoy MP, Shulman GL (2000) Voluntary orienting is dissociated from target detection in human posterior parietal cortex. Nat Neurosci 3:292–297. 
12. Kincade JM, Abrams RA, Astafiev SV, Shulman GL, Corbetta M (2005) An event related functional magnetic resonance imaging study of voluntary and stimulus driven orienting of attention. J Neurosci 25:4593–4604. 
13. Peelen MV, Heslenfeld DJ, Theeuwes J (2004) Endogenous and exogenous attention shifts are mediated by the same large-scale neural network. Neuroimage 22:822–830. 14. Rosen AC, et al. (1999) Neural basis of endogenous and exogenous spatial orienting. A functional MRI study. J Cogn Neurosci 11:135–152. 
15. Dorris MC, Klein RM, Everling S, Munoz DP (2002) Contribution of the primate su perior colliculus to inhibition of return. J Cogn Neurosci 14:1256–1263. 16. Gabay S, Behrmann M (2014) Attentional dynamics mediated by subcortical mecha nisms. Atten Percept Psychophys 76:2375–2388. 
17. Sapir A, Soroker N, Berger A, Henik A (1999) Inhibition of return in spatial attention: Direct evidence for collicular generation. Nat Neurosci 2:1053–1054. 18. Self MW, Roelfsema PR (2010) A monocular, unconscious form of visual attention. J Vis 10:1–23. 
19. Zackon DH, Casson EJ, Zafar A, Stelmach L, Racette L (1999) The temporal order judgment paradigm: Subcortical attentional contribution under exogenous and en dogenous cueing conditions. Neuropsychologia 37:511–520. 
20. Gabay S, Leibovich T, Ben-Simon A, Henik A, Segev R (2013) Inhibition of return in the archer fish. Nat Commun 4:1657. 
21. Wullimann MF (1997) The central nervous system. The Physiology of Fishes, ed Evans DH (CRC Press LLC, New York), pp 245–281. 
22. Northcutt RG (2011) Do teleost fishes possess a homolog of mammalian isocortex? Brain Behav Evol 78:136–138. 
23. Wullimann MF, Mueller T (2004) Teleostean and mammalian forebrains contrasted: Evidence from genes to behavior. J Comp Neurol 475:143–162. 
24. Jarvis ED, et al.; Avian Brain Nomenclature Consortium (2005) Avian brains and a new understanding of vertebrate brain evolution. Nat Rev Neurosci 6:151–159. 25. Portavella M, Vargas JP (2005) Emotional and spatial learning in goldfish is de pendent on different telencephalic pallial systems. Eur J Neurosci 21:2800–2806. 26. Rodríguez JP, et al. (2006) Trade-offs across space, time, and ecosystem services. Ecol Soc 11:28. 
27. Costa SS, et al. (2011) Sex differences in the dorsolateral telencephalon correlate with home range size in blenniid fish. Brain Behav Evol 77:55–64. 
28. Van Essen DC, Anderson CH, Felleman DJ (1992) Information processing in the pri mate visual system: An integrated systems perspective. Science 255:419–423. 29. Hansel D, Sompolinsky H (1996) Chaos and synchrony in a model of a hypercolumn in visual cortex. J Comput Neurosci 3:7–34. 
30. Kawai H, Arata N, Nakayasu H (2001) Three-dimensional distribution of astrocytes in zebrafish spinal cord. Glia 36:406–413. 
31. Hill A, Howard CV, Strahle U, Cossins A (2003) Neurodevelopmental defects in ze brafish (Danio rerio) at environmentally relevant dioxin (TCDD) concentrations. Toxicol Sci 76:392–399. 
32. Horton JC, Adams DL (2005) The cortical column: A structure without a function. Philos Trans R Soc Lond B Biol Sci 360:837–862. 
33. Marote CF, Xavier GF (2011) Endogenous-like orienting of visual attention in rats. Anim Cogn 14:535–544. 
34. Sridharan D, Ramamurthy DL, Schwarz JS, Knudsen EI (2014) Visuospatial selective attention in chickens. Proc Natl Acad Sci USA 111:E2056–E2065. 
35. Klein R (2009) On the control of attention. Can J Exp Psychol 63:240. 
36. Chun MM, Jiang Y (1998) Contextual cueing: Implicit learning and memory of visual context guides spatial attention. Cognit Psychol 36:28–71. 
37. Wasserman EA, Teng Y, Castro L (2014) Pigeons exhibit contextual cueing to both simple and complex backgrounds. Behav Processes 104:44–52. 
38. Wasserman EA, Teng Y, Brooks DI (2014) Scene-based contextual cueing in pigeons. J Exp Psychol Anim Learn Cogn 40:401–418. 
39. Herald ES (1956) How accurate is the archer fish. Pac Discovery 9:12–13. 40. Bekoff M, Dorr R (1976) Predation by “shooting” in archer fish, Toxotes jaculatrix: Accuracy and sequences. Bull Psychon Soc 7:167–168. 
41. Timmermans P, Ja (2000) Prey catching in the archer fish: Marksmanship, and en durance of squirting at an aerial target. Neth J Zool 50:411–423. 
42. Timmermans PJ (2001) Prey catching in the archer fish: Angles and probability of hitting an aerial target. Behav Processes 55:93–105. 
43. Myers GS (1952) How the shooting apparatus of the archer fish was discovered. Aquarium J 23:210–214. 
44. Lüling KH (1958) Morphologisch-anatomische und histologische untersuchungen am auge des schützenfisches Toxotes jaculatrix (Pallas 1766) (Toxotidae), nebst be merkungen zum spuckgehaben. Zoomorphology 47:529–610. 
45. Milburn O, Alexander R (1976) The performance of the muscles involved in spitting by the archerfish Toxotes. J Zool 180:243–251. 
46. Elshoud GCA, Koomen P (1985) A biomechanical analysis of spitting in archer fishes (Pisces, Perciformes, Toxidae). Zoomorphology 105:240–252. 
47. Segev R, Schneidman E, Goodhouse J, Berry MJ, 2nd (2007) Role of eye movements in the retinal code for a size discrimination task. J Neurophysiol 98:1380–1391. 48. Timmermans PJ, Vossen JM (2000) Prey catching in the archer fish: Does the fish use a learned correction for refraction? Behav Processes 52:21–34. 
49. Schuster S, Rossel S, Schmidtmann A, Jäger I, Poralla J (2004) Archer fish learn to compensate for complex optical distortions to determine the absolute size of their 
D 
aerial prey. Curr Biol 14:1565–1568. 
S 
E
N
50. Schuster S, Wöhl S, Griebsch M, Klostermeier I (2006) Animal cognition: How archer 
C
 A
N
L
E
fish learn to down rapidly moving targets. Curr Biol 16:378–383. 
I
A
C
C
 S
51. Newport C, Wallis G, Reshitnyk Y, Siebeck UE (2016) Discrimination of human faces by 
I
G
E
archerfish (Toxotes chatareus). Sci Rep 6:27523. 
O
V
I
L
T
52. Jerison HJ (1973) Evolution of the Brain and Intelligence (Academic Press, New York). 
O
I
H
N
53. Zoccolan D, Cox DD, Benucci A (2015) Editorial: What can simple brains teach us about 
C
G
Y
O
S
how vision works. Front Neural Circuits 9:51. 
C
P
54. Rosa Salva O, Sovrano VA, Vallortigara G (2014) What can fish brains tell us about visual perception? Front Neural Circuits 2014;8:119. 
55. Rafal R, Henik A (1994) The neurology of inhibition: Integrating controlled and au E 
tomatic processes. Inhibitory Processes in Attention, Memory and Language, eds C
N
Dagenbach D, Carr T (Academic Press, San Diego), pp 1–50. 
E
I
C
56. Kumar S, Hedges SB (1998) A molecular timescale for vertebrate evolution. Nature S
O
392:917–920. 
R
U
57. Ben-simon A, Ben-shahar O (2017) Visual acuity in the archerfish: Behavior, anatomy, E
N
and neurophysiology. J Vis 12:1–19. 
58. Hughes RN, Blight CM (1999) Algorithmic behaviour and spatial memory are used by two intertidal fish species to solve the radial maze. Anim Behav 58:601–613. 59. Portavella M, Torres B, Salas C (2004) Avoidance response in goldfish: Emotional and temporal involvement of medial and lateral telencephalic pallium. J Neurosci 24:2335–2342. 60. Berger A, Henik A, Rafal R (2005) Competition between endogenous and exogenous orienting of visual attention. J Exp Psychol Gen 134:207–221. 
61. Berlucchi G, Chelazzi L, Tassinari G (2000) Volitional covert orienting to a peripheral cue does not suppress cue-induced inhibition of return. J Cogn Neurosci 12:648–663. 62. Rafal R, Machado L, Ro T, Ingle H (2000) Looking forward to looking: Saccade prepa ration and control of the visual grasp reflex. Control of Cognitive Operations: Attention and Performance XVIII, eds Monsell S, Driver J (MIT Press, Cambridge, MA), pp 155–174. 63. Rafal RD, Calabresi PA, Brennan CW, Sciolto TK (1989) Saccade preparation inhibits re orienting to recently attended locations. J Exp Psychol Hum Percept Perform 15:673–685. 64. Chica AB, Klein RM, Rafal RD, Hopfinger JB (2010) Endogenous saccade preparation does not produce inhibition of return: Failure to replicate Rafal, Calabresi, Brennan, & Sciolto (1989). J Exp Psychol Hum Percept Perform 36:1193–1206. 
65. Klein RM, Hilchey MD (2011) Oculomotor inhibition of return. The Oxford Handbook of Eye Movements, eds Liversedge S, Gilchrist I, Everling S (Oxford University Press, Oxford, United Kingdom), pp 471–492. 
66. Behrmann M, Zemel RS, Mozer MC (1998) Object-based attention and occlusion: Evidence from normal participants and a computational model. J Exp Psychol Hum Percept Perform 24:1011–1036. 
67. Zhaoping L (2016) From the optic tectum to the primary visual cortex: Migration through evolution of the saliency map for exogenous attentional guidance. Curr Opin Neurobiol 40:94–102. 
68. Risko EF, Stolz JA (2010) The proportion valid effect in covert orienting: Strategic control or implicit learning? Conscious Cogn 19:432–442. 
Saban et al. PNAS Early Edition | 5 of 5 1001
Efficiency of learning vs. processing: Towards a normative theory of multitasking 
Yotam Sagiv (ysagiv@princeton.edu), Sebastian Musslick (musslick@princeton.edu), Yael Niv (yael@princeton.edu), Jonathan D. Cohen (jdc@princeton.edu) 
Princeton Neuroscience Institute 
Princeton University 
Abstract 
A striking limitation of human cognition is our inability to ex ecute some tasks simultaneously. Recent work suggests that such limitations can arise from a fundamental trade-off in net work architectures that is driven by the sharing of representa tions between tasks: sharing promotes quicker learning, at the expense of interference while multitasking. From this perspec tive, multitasking failures might reflect a preference for learn ing efficiency over parallel processing capability. We explore this hypothesis by formulating an ideal Bayesian agent that maximizes expected reward by learning either shared or sep arate representations for a task set. We investigate the agent’s behavior and show that over a large space of parameters the agent sacrifices long-run optimality (higher multitasking ca pacity) for short-term reward (faster learning). Furthermore, we construct a general mathematical framework in which ratio nal choices between learning speed and processing efficiency can be examined for a variety of different task environments. 
Keywords: multitasking; cognitive control; Bayesian infer ence; capacity constraints; 
Introduction 
The human brain’s ability to simultaneously perform distinct tasks contains a curious tension. On one hand, we are able to concurrently carry out a large number of actions (e.g. breathe, speak, chew gum, etc.) seemingly without exerting any effort. In contrast, some behaviors defy parallel execution (e.g. solv ing calculus problems and constructing shopping lists) and require serialization to successfully execute. 
The distinction between sets of tasks that can be executed concurrently and those that cannot is often referred to in terms of a fundamental distinction between controlled and auto matic processing (Posner & Snyder, 1975; Shiffrin & Schnei der, 1977). Early theories attributed the inability to carry out multiple control-demanding tasks in parallel to reliance on a single, limited-capacity, serial processing mechanism – a hypothesis that has continued to dominate major theories of cognition (e.g., Anderson, 2013). The “multiple-resource hy pothesis” presents a challenge to this view, arguing that mul titasking limitations may reflect competition for the use of local resources (e.g., shared task-specific representations) by sets of tasks, rather than common reliance on a central con trol mechanism (Allport, Antonis, & Reynolds, 1972; Navon & Gopher, 1979; Meyer & Kieras, 1997). Under this view, the role of cognitive control is to resolve such conflicts when they arise by limiting processing to only a single task at a time (Cohen, Dunbar, & McClelland, 1990; Botvinick, Braver, Barch, Carter, & Cohen, 2001). That is, limiting processing is the purpose of control, rather than a reflection of a constraint on the control system itself. Recent computational work has provided a formal grounding for this argument, showing that even modest amounts of overlap between task representations 
can drastically limit the number of tasks a network can engage at the same time without invoking interference among them (Feng, Schwemmer, Gershman, & Cohen, 2014; Musslick et al., 2016). Critically, this number appears to be relatively in sensitive to the size of the network. 
The findings above raise an important question: insofar as shared representation between tasks impose limitations on multitasking, why would a neural system prefer shared rep resentations over separate ones? Insights into this question can be gained from the machine learning literature, where the learning of shared representations between tasks is con sidered a desirable outcome (Baxter, 1995; Caruana, 1998; Bengio, Courville, & Vincent, 2013). For instance, work on multi-task learning1suggests that shared representations be tween tasks promote faster learning, as well as better general ization performance across tasks (Caruana, 1997; Collobert & Weston, 2008). Moreover, learning dynamics in neural networks themselves promote the learning of shared repre sentation based on shared structure in the task environment (Hinton, 1986; Saxe, McClelland, & Ganguli, 2013). Thus, there appears to be a fundamental trade-off in neural networks between the efficiency of learning (and generalization) on the one hand, and the efficiency of processing (i.e. multitasking capability) on the other hand (Musslick et al., 2017). 
The trade-off between learning and processing efficiency constitutes an optimization problem that is dependent on the demands of the task environment. The work described here examines this optimization problem as a function of critical parameters, such as the differences in rate of learning for shared vs. separated representations, and the benefits gained by parallel over serial task performance. Analysis of this problem may help provide a formally rigorous, and even nor mative account of longstanding, well-characterized psycho logical phenomena, such as the common trajectory in skill acquisition from controlled to automatic processing (Shiffrin & Schneider, 1977; Logan, 1980). 
Ideally, our analysis would build on formal characteriza tion of the learning rate for different types of representations, given a specified learning algorithm (e.g. backpropagation). However, since this is not immediately available, to con struct a probabilistic generative model we begin by assuming simple functional forms for the learning trajectory associated with shared vs. separated task representations in a multitask ing environment, and then use the generative model to define 
1Note that the term ’multi-task’ differs from the term ’multitask ing’. The former refers to the paradigm of training the same network on multiple tasks, whereas the latter refers to the process of carrying out multiple tasks concurrently. 
1002
an ideal Bayesian agent that behaves optimally inside that en vironment. Taken together, the environment and agent mod els provide a simple, normative framework in which ques tions about the learning-processing trade-off can be explored. 
A rational model of multitasking 
We begin our analysis of the optimal balance between learn ing and processing efficiency by formalizing the task envi ronment. We then describe how the agent model chooses be tween the use of shared vs. separate representations in that environment to optimize performance, which we define as maximizing reward over the entire horizon of performance. 
Task Environment 
We consider an environment in which a task can be defined as a process (e.g. naming the color of a stimulus) that maps the dimension of a stimulus (e.g. color) to a particular response modality (e.g. verbal response). Here we assume that stimuli consist of N dimensions (e.g. color, shape, and texture) and that responses are carried out over K response modalities (e.g. naming, pointing, or looking), resulting in NK possible tasks in any environment. We adopt a formal definition of multi tasking from earlier work (Musslick et al., 2016; Alon et al., 2017), in which a multitasking condition is defined as the re quirement to execute multiple tasks at the same time, none of which share a stimulus or response dimension. Consequently, at most min{N,K} tasks can be carried out concurrently. 
The agent is asked to optimize performance over a series of τ multitasking trials. On each trial, the agent is asked to perform α tasks, where α is drawn from a latent multinomial distribution. We introduce multitasking pressure by specify ing a reward schedule that favors concurrent performance of tasks. For every task answered correctly, the agent receives 1 unit of reward, resulting in α rewards if the agent is able to perform all tasks with maximal accuracy at the same time. However, if the agent chooses instead to perform all tasks sequentially, it loses jC reward units on task j, where j in dexes the tasks from 0 to α − 1 (so that the agent receives ∑α−1 
j=01 − jC rewards given maximal accuracy). C is termed the “serialization cost” or “time cost”. The per-task loss is linear in time taken, making the per-trial (cumulative) loss over all assigned tasks quadratic. 
Optimization is defined as the choice, on each trial, of a performance strategy that maximizes total future reward; that is, summed over the current trial and the potentially dis counted reward anticipated for each future trial. This requires estimating and convolving the expected multitasking require ments over trials, performance for executing the tasks concur rently vs. individually as a function of the estimated learning rate for each (see below), and the serialization costs associ ated with performing tasks sequentially. 
Agent 
The agent is considered to be a rational decision-maker that chooses between two independent, trainable processing strategies that result from two extremes of how multiple tasks 
can be represented in a single network. The first represen tation strategy is as a minimal basis set, in which all tasks relying on the same stimulus dimension encode the stimuli using the same (shared) set of hidden representations (i.e. N sets of hidden representations) that are then mapped to the output dimensions for each of the tasks. The second strategy uses tensor product representations, in which each task en codes its stimuli using its own set of (separated) hidden rep resentations (resulting in NK sets of hidden representations) that are mapped to the output dimension for the task. While the minimal basis set provides a more efficient encoding of the stimuli, it does not permit multitasking since the use of shared representations introduces crosstalk between any pair of simultaneously activated tasks (see Figure 1; Feng et al., 2014; Musslick et al., 2016; Alon et al., 2017). Thus, use of the minimal basis set forces a serialization cost of jC reward units for task j = 1,2,...,α−1. Conversely, the tensor prod uct representation permits multitasking without interference, since each task is assigned its own set of hidden representa tions that comprise independent processing pathways in the network. We assume that the agent has the potential to de velop both forms of representation, but these must be learned. 
Figure 1: Schematic of network schemes that maximize rep resentation overlap (a) vs. multitasking capability (b). C, S, T designate the stimulus dimensions (”color”, ”shape”, and ”texture”), while W, K, P designate the output modalities 
(”word”, ”keyboard”, ”point”). The hidden-layer representa tion of the stimulus in (a) is shared for all three tasks involving the same input dimension (minimal basis set representation), whereas in (b) a separate hidden-layer representation is dedi cated to each task (tensor product representation). 
Previous work has shown that, for a set of tasks that are in principle multitaskable, training using shared representa tions (such as a minimal basis set) leads to faster acquisition than learning separate representations for each task (such as a tensor product), as the former enables the sharing of learning signals across tasks (Musslick et al., 2017). We implement these effects by assuming that 1) the agent learns these two types of representations (i.e. processing strategies) by select ing and executing one or the other on each trial; 2) perfor mance for each strategy improves as a function of the number of trials selected, and 3) learning is faster for the minimal ba sis strategy than for the tensor product strategy, as described below. 
1003
To model the learning of tasks, we define a probability of success function (aka “training function”) for each of the two processing strategies. Let fB, fT : N≥0 → [0,1] denote these training functions for the minimal basis set and tensor product strategies, respectively. These serve as explicit characteriza tions of the agent’s learning dynamics; fX (t) implements the learning curve by evaluating the probability of success on a given task after representation X has been selected t times. That is, every time the agent chooses to process the tasks in the trial using strategy X, the success probability for the task under strategy X increases for the next time step. More for mally, let x1, x2,..., xn be a sequence of n choices of repre sentation. We define the probability that an agent succeeds when employing strategy X on a task in trial t as: 
t−1 
regression (intuitively, this can be understood as the agent in ferring how fast it will learn). In this model, k and t0 have independent normal priors centered on their true values with high variance. Finally, we assume that the agent already knows τ, the sequential processing cost C, and the tempo ral discounting function µ(t). 
Once the expected values are computed, the agent must select an action. We assume this is done using a standard explore-exploit algorithm, the ε-greedy rule, in which the agent picks the action associated with greatest value with probability 1−ε, and uniformly otherwise. 
Formal analysis of equilibrium 
We begin by analyzing an agent that has perfect knowledge about the task environment and learning rate, in order to as 
PX (success on a task in trial t) = fX ( 
∑ i=0 
1xi=X ) 
sess performance independently of noise that might be gener ated by an inference process over these factors. This allows us 
For convenience, we use the logistic function fX (t| k,t0) = 1 
1+e−k(t−t0). However, our analysis applies to any learning function that is monotonically increasing and bounded be tween fX (0) ≈ 0 and limt→∞ fX (t) = 1. As noted above, we assume that learning occurs at a faster rate for the minimal basis set strategy as compared to tensor product strategy, and examine the influence of this difference by exploring a range of values for k, t0 that together determine the rate of learning. 
The agent uses standard Bayesian machinery to infer the expected reward given each representation, and then selects the representation that maximizes total discounted future re ward. Specifically, let EX [R] denote the expected reward for strategy X, EX [R|t] denote the expected reward on trial t, and µ(t) be the temporal discounting function. Then we have that EX [R] = ∑τt=0µ(t)EX [R|t]. Though temporal discounting can 
to analytically derive equilibrium conditions under which the agent should be indifferent between the minimal basis set and the tensor product strategies. For this section, we let N < K so that N = min{N,K} without loss of generality. 
Observe that the expressions in Equation (1) reduce to: EB[R|t] = fB(t)E[g(α,C)] 
ET [R|t] = fT (t)E[α](2) 
where g(i,C) = ∑i−1 
j=0(1− jC). Note that g(i,C) encodes the 
amount of reward accrued by the agent for completing i tasks in a serial fashion with time cost C. Plugging Equation (2) into the expression for the expected reward of both strategies we can express the condition for which the agent should be indifferent between them: 
E[g(α,C)] =∑τt=0µ(t)fB(t) 
be irrational in many contexts, we note that a fully rational agent can be achieved with µ(t) = 1. 
E[α] 
∑τt=0µ(t)fT (t)(3) 
Recall that α is the randomly assigned number of tasks re quired to be performed on a given trial. By marginalizing over α, we get that the expected reward on each individual trial is EX [R|t] = ∑min{N,K} 
i=1 P(α = i)EX [R|t,α = i]. Thus, the 
expected rewards for the minimal basis set and tensor product strategies correspond to 
An interesting property of this result is that agent-related and environmental parameters are analytically separable. Ob serve that the expectation terms on the left correspond to the agent’s expected reward at asymptotic performance lev els, and that the sum terms on the right denote the number of expected successes in a critical time period specified by 
EB[R|t] = ET [R|t] = 
min{N,K} ∑ 
i=1 
min{N,K} ∑ 
i=1 
P(α = i) P(α = i) 
i−1 ∑ j=0 
i−1 ∑ j=0 
PB(success)(1− jC) PT (success)(1) 
the conjunction of the temporal discounting function and the training function. The indifference point can be understood intuitively as a surface over which the ratio of expected even 
(1) 
tual rewards is equal to the ratio of times at which they are likely to be accrued (discounted by time). That is, the left side contains the ratio of the rewards the agent expects to earn if it 
In order to compute the expected reward terms in Equa tion (1), the agent must be able to evaluate P(α = i) and PX (success) by inferring the multinomial task distribution, as well as the training function fX . The first can be inferred 
is always correct, whereas the right side is a ratio of functions that weight when the agent prefers to receive the rewards. Recall that E[g(α,C)] corresponds to E[∑i−1 
j=0(1 − jC)] = 
using Bayes’ theorem, by keeping track of the number of E 
hα2 1 + [1 − (α − 1)C] i. Since C is a constant, it can be 
times each particular α value was seen, in conjunction with a Dirichlet prior (we start from a uniform prior, implying ab 
isolated from the expectation in Equation (3) to get an expres sion for the precise value of the serialization cost that charac 
sence of strong a priori belief about the distribution). 
terizes the indifference surface. That is:   
Inferring the parameters for the two training functions fB, fT can similarly be done by tracking the history of suc 
  
2E[α] 
1−∑τt=0µ(t)fT (t) ∑τt=0µ(t)fB(t) 
cesses and failures and then performing a Bayesian logistic 1004
Ceq = 
E[α(α−1)] (4) 
Equation (4) provides a rigorous characterization of the trade-off between basis set and tensor product learning in multitasking environments described in the Introduction: 1. As the average number of parallel tasks increases, the cost 
of serialization must vanish for minimal basis set represen tations to remain preferable: E[α] → ∞ =⇒ Ceq → 0. 2. As the learning benefit of shared representations dimin ishes, the value of shared representations disappears. That is, as the ratio between the (discounted) tensor product and basis set training functions approaches unity, for the lat ter to remain preferable the cost of serialization must tend toward zero: ∑τt=0µ(t)fT (t) 
ing functions. Here we relax these assumptions, and use nu merical simulations2to evaluate the behavior of an agent that must infer these parameters. We assess the agent’s perfor mance across a series of task environments and learning spec ifications by crossing a set of reasonable parameter ranges. 
We let τ = 1000. We set C ∈ [0,1], varying from no pun ishment to receiving no reward for a correct answer. We use an exponential discounting scheme µ(t) = γ−0.025tfor γ ∈ [0.5,1.0]. This covers the range from extreme discounting to no discounting at all. We characterize the training func tions as logistic with fX (t) = 1 
1+e−0.1(t−tX ). This allows us to 
precisely characterize difference in learning rates through the 
3. ∑τt=0µ(t)fT (t) 
∑τt=0µ(t)fB(t) → 1 =⇒ Ceq → 0. 
ratio tT /tB. To that end, we set tB = 200, reflecting the speed 
∑τt=0µ(t)fB(t) → 0 =⇒ Ceq → 2E[α] 
E[α(α−1)]: As the ratio of 
the discounted training functions for the tensor product and minimal basis set representations approaches 0, the equilibrium-defining serialization cost becomes a function of the number of tasks required to be performed. Partic ularly, Ceq is the serialization cost that sets expected re ward for the minimal basis set representation to 0. This implication is not immediately obvious. Consider the task distribution P[α = 1] = P[α = 2] = 1/2. In this environ ment, Ceq = 3 and at asymptotic performance levels, the agent expects to win 1 reward unit when α = 1, or win −1 when α = 2. This makes sense; if learning tensor prod uct representations is so much slower than minimal basis set representations that the ratio of the sums goes to 0, the agent is indifferent only if the expected earnings are 0. 
Finally, we note that we have used arbitrary reward func tions for the analyses above. However, it is possible to gen eralize the equilibrium condition in Equation (3) to any sta tionary reward function (i.e. does not change over the course of the experiment). Let gB(α, j,C) denote a reward function with arbitrary dependence on the number of tasks currently being executed α, the index of the task currently being ex ecuted j, or the serialization cost C; specifically, gB is the reward function used when the tasks are being executed seri ally. Furthermore, let hB(i,C) be the total reward gathered when gB is applied to each of the i assigned tasks so that hB(i,C) = ∑i−1 
j=0gB(i, j,C). Finally, define gT ,hT analogously for the case the tasks are being processed concurrently. Then a generalized equilibrium condition is: 
E[hB(α,C)] =∑τt=0µ(t)fB(t) 
of minimal basis set learning, and let tT vary in [200,600]. We let N = K = 4 and define the distribution over tasks as P(α = 1) = 0.7, P(α = 2) = P(α = 3) = P(α = 4) = 0.1 so that the intensity and frequency of multitasking trials is suf ficient to permit either strategy given appropriate parameters. We set ε = 0.1 to facilitate early exploration of the tensor product option in the face of immediate rewards due to the minimal basis set option. Finally, we quantify the agent’s strategy preference as P(pick X) = number of times X was picked 
τ, 
and track how P(pick basis set) varies with the parameters3. Figure 2: Simulation results for the inference model. tT /tB refers to the midpoint ratio of the tensor product and minimal basis set training functions. Time cost denotes the value of C. Note that the agent increases their preference for the minimal basis set representation when the time cost is decreased, the 
E[hT (α,C)] 
∑τt=0µ(t)fT (t)(5) 
learning rate ratio is increased, or gamma is decreased. 
Observe that for gB = 1− jC and gT = 1, hB = g and hT = α from Equation (3). The existence of this generalized equilib rium condition allows a large set of questions to be phrased within this framework. For example, it is easy to include an explicit cost of cognitive control (e.g. Shenhav et al., 2017) by adding a term to the basis set reward function that imple ments a cost that increases with the number of tasks executed. 
Numerical analysis with parameter inference The analysis above characterized the behavior of an agent with perfect knowledge of the task environment and its learn 
The results (see Fig. 2) show that there is a broad range of parameterizations under which the agent will opt for se lecting the minimal basis set strategy over the tensor prod uct strategy (P(pick basis set) > 0.5). These preferences align with the normative analysis of how the parameters should affect overall preference: preference for the mini 
2code available at https://github.com/yotamSagiv/thesis 3We can use Equation (4) to show that even with weak discount ing (γ = 0.90) and a modest learning rate ratio tT /tB = 2, the impor tance of fast training is such that the time cost must nearly equal the reward value (Ceq ≈ 0.75) for indifference in this environment. 
1005
mal basis set strategy increases with relative speed of learn ing, decreases with serialization cost, and increases with the strength of temporal discounting as indicated by the linear model fit P(select basis set) ∼ b1 ×tTtB+b2 ×timeCost+b3 × γ (b1 = 0.25,t(78) = 47.26, p < 0.001; b2 = −0.52,t(78) = −49.38, p < 0.001; b3 = −0.64,t(78) = −35.78, p < 0.001). Discussion 
The constraints on human multitasking abilities present an interesting puzzle given the enormous processing capability of the brain. Here, we explored the hypothesis that this re flects a fundamental trade-off between learning and process ing efficiency (Musslick et al., 2017), in which preference for learning to perform a set of tasks faster, which relies on the use of shared representations (Caruana, 1998; Baxter, 1995), comes at the expense of multitasking efficiency (Allport et al., 1972; Navon & Gopher, 1979; Meyer & Kieras, 1997; Feng et al., 2014; Musslick et al., 2016). This trade-off between the value of shared vs. separated representations is reminiscent of the complementary learning systems hypoth esis (McClelland, McNaughton, & O’Reilly, 1995), which proposes the existence of two independent learning mecha nisms. The first relies on shared representations to support in ference, and the second uses separate representations to avoid the cost of catastrophic interference for memory encoding and retrieval. Thus, the trade-off between shared and sepa rated representations appears to a fundamental one, that has different consequences in different processing contexts. Here, we have provided a normative analysis of this trade-off in the context of task performance that, under various assumptions, defines the conditions under which limitations in multitasking ability can be viewed as a result of optimal decision-making. 
Agent behavior in our model was governed by several fac tors: the distribution of multitasking opportunities within the environment, the cost of serial vs. parallel performance, the rate at which each strategy is learned, and the discount rate for future rewards. The broad range of these factors over which the minimal basis set strategy was optimal suggests that the theory provides a plausible account of why so many skills (e.g. driving a car, playing an instrument) seem to rely on cognitive control and serial execution during acquisition. 
Theories of bounded rationality (Simon, 1955, 1982; Gigerenzer, 2008) assume that suboptimalities in human be havior arise from the use of heuristics rather than full deliber ation, given the bounds of limited multitasking capacity and limited available information. Research in artificial intelli gence has suggested that such behavior is normative; that is, it may reflect bounded optimality, in which an agent maxi mizes reward per unit time given intrinsic limitations in its computational architecture (Russell & Subramanian, 1995). The principles of bounded optimality are reflected in psycho logical models of cognition, in which humans perform opti mally within the constraints of the cognitive system (Griffiths, Lieder, & Goodman, 2015; Gershman, Horvitz, & Tenen baum, 2015). Yet, these accounts do not explain why com putational limitations exist in the first place, other than the 
assumption of limited processing power/speed. The work here suggest that the bounds may arise from a normative re sponse to constraints imposed by trade-offs intrinsic to any network architecture, whether neural or artificial – specifi cally, the trade-off between the advantages of faster learning and generalization provided by shared representations, and the advantages of concurrent parallelism and processing effi ciency provided by separated representations (Musslick et al., 2017). Under this framework the source of the limitation is not in the brain/computing device, but rather in the fact that time in life is finite (i.e. the benefits of learning a task quickly far outweigh the value of learning it “optimally”). 
Of course, the model we described is relatively simple, and can be extended in a number of ways. Rather than using a logistic function to characterize learning, it may be more reasonable to scale the benefit of shared representations by the number of tasks (e.g. as in Musslick et al., 2017), or to implement the learning dynamics of actual neural networks on similar task spaces. Additionally, a cost of control pa rameter could be incorporated that scales with the number of tasks being executed and/or the complexity of the task en vironment (Shenhav, Botvinick, & Cohen, 2013). It is also plausible to consider the transfer of learning between the two strategies (i.e. generalization). This may be an important fac tor in shaping how representations evolve from the minimal basis set to tensor product forms over the course of training, as suggested by some neural evidence (Garner & Dux, 2015). 
One might also consider meta-learning. The simulated agents learned about their task environment and learning functions, but always began with the same predetermined, static priors. It is possible that repeated experience over dif ferent task domains could inform these priors, improving the initial estimates of the learning functions. This would in duce a higher rate of convergence to the optimal decision for cases in which the agent’s prior experiences are relevant, and might also explain any reluctance to switch away from sub optimal decision-making in contexts where its experience is misleading. Such effects could be informative to similar lines of inquiry regarding separate mechanisms for goal-directed and habitual responding in mammals undergoing instrumen tal conditioning (Yin & Knowlton, 2006). 
In sum, the results presented here strongly support the proposal that constraints in multitasking observed in human performance may arise from a normative approach to an in escapable trade-off between the value of rapidly acquiring a set of novel skills, and optimizing the efficiency with which these skills can be exercised. Such a normative theory of multitasking may have value not only for understanding hu man performance, but also for the design of artificial systems. Having a formal language with which to consider the trade off between learning efficiency and multitasking capability (and the closely related constructs of controlled vs. automatic processing) will facilitate precise analysis of the design of autonomous agents that are capable not only of guiding their own actions, but also of learning the best ways of doing so. 
1006
References 
Allport, A., Antonis, B., & Reynolds, P. (1972). On the division of attention: A disproof of the single channel hy pothesis. Quarterly Journal of Experimental Psychology, 24(2), 225-235. doi: 10.1080/00335557243000102 
Alon, N., Reichman, D., Shinkar, I., Wagner, T., Musslick, S., Cohen, J. D., . . . Ozcimder, K. (2017). A graph-theoretic approach to multitasking. In Advances in neural informa tion processing systems (pp. 2097–2106). 
Anderson, J. R. (2013). The architecture of cognition. Psy chology Press. 
Baxter, J. (1995). Learning internal representations. In Pro ceedings of the eighth annual conference on computational learning theory (pp. 311–320). 
Bengio, Y., Courville, A., & Vincent, P. (2013). Repre sentation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelli gence, 35(8), 1798–1828. 
Botvinick, M. M., Braver, T. S., Barch, D. M., Carter, C. S., & Cohen, J. D. (2001). Conflict monitoring and cognitive control. Psychological Review, 108(3), 624. 
Caruana, R. (1997). Multitask learning. Machine learning, 28(1), 41–75. 
Caruana, R. (1998). Multitask learning. In S. Thrun & L. Pratt (Eds.), Learning to learn (pp. 95–133). Boston, MA: Springer US. doi: 10.1007/978-1-4615-5529-2 5 
Cohen, J. D., Dunbar, K., & McClelland, J. L. (1990). On the control of automatic processes: A parallel distributed pro cessing model of the stroop effect. Psychological Review, 97. 
Collobert, R., & Weston, J. (2008). A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on machine learning (pp. 160–167). 
Feng, S., Schwemmer, M., Gershman, S. J., & Cohen, J. D. (2014, 01). Multitasking versus multiplexing: Toward a normative account of limitations in the simultaneous exe cution of control-demanding behaviors. Cognitive, affec tive & behavioral neuroscience, 14. 
Garner, K., & Dux, P. E. (2015, 10). Training conquers multitasking costs by dividing task representations in the frontoparietal- subcortical system. Proceedings of the Na tional Academy of Sciences. 
Gershman, S. J., Horvitz, E. J., & Tenenbaum, J. B. (2015). Computational rationality: A converging paradigm for intelligence in brains, minds, and machines. Science, 349(6245), 273–278. 
Gigerenzer, G. (2008). Why heuristics work. Perspectives on psychological science, 3(1), 20–29. 
Griffiths, T. L., Lieder, F., & Goodman, N. D. (2015). Ratio nal use of cognitive resources: Levels of analysis between the computational and the algorithmic. Topics in cognitive science, 7(2), 217–229. 
Hinton, G. E. (1986). Learning distributed representations of concepts. In Proceedings of the 8th confererence of 
the Cognitive Science Society (pp. 1–12). Hillsdale, NJ: Lawrence Erlbaum Associates. 
Logan, G. D. (1980). Attention and automaticity in stroop and priming tasks: Theory and data. Cognitive psychology, 12, 523-53. 
McClelland, J., McNaughton, B., & O’Reilly, R. (1995). Why there are complementary learning systems in the hip pocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory. Psychological Review, 102. 
Meyer, D., & Kieras, D. (1997, 02). A computational theory of executive cognitive processes and multiple-task perfor mance: Part 1. basic mechanisms. Psychological Review, 104, 3-65. 
Musslick, S., Dey, B., Ozcimder, K., Mostofa, M., Patwary, ¨ A., Willke, T., & Cohen, J. D. (2016, 08). Controlled vs. automatic processing: A graph-theoretic approach to the analysis of serial vs. parallel processing in neural network architectures. In Proceedings of the 38th annual conference of the Cognitive Science Society (pp. 1547–1552). 
Musslick, S., Saxe, A., Ozcimder, K., Dey, B., Henselman, ¨ G., & Cohen, J. D. (2017, August). Multitasking capability versus learning efficiency in neural network architectures. In Proceedings of the 39th Annual Meeting of the Cognitive Science Society (p. 829-834). 
Navon, D., & Gopher, D. (1979). On the economy of the human-processing system. Psychological Review, 86. Posner, M., & Snyder, C. (1975). attention and cognitive con trol. In Information processing and cognition: The loyola symposium (pp. 55–85). 
Russell, S. J., & Subramanian, D. (1995). Provably bounded optimal agents. Journal of Artificial Intelligence Research, 2, 575–609. 
Saxe, A. M., McClelland, J. L., & Ganguli, S. (2013). Learn ing hierarchical category structure in deep neural networks. In Proceedings of the 35th annual meeting of the cognitive science society (pp. 1271–1276). 
Shenhav, A., Botvinick, M., & Cohen, J. D. (2013, 07). The expected value of control: An integrative theory of anterior cingulate cortex function. Neuron, 79, 217-40. 
Shenhav, A., Musslick, S., Lieder, F., Kool, W., L Griffiths, T., D Cohen, J., & Botvinick, M. (2017, 01). Toward a rational and mechanistic account of mental effort. Annual Review of Neuroscience, 40. 
Shiffrin, R., & Schneider, W. (1977, 03). Controlled and auto matic human information processing: II. Perceptual learn ing, automatic attending and a general theory. Psychologi cal Review, 84, 127-190. 
Simon, H. A. (1955). A behavioral model of rational choice. The quarterly journal of economics, 69(1), 99–118. Simon, H. A. (1982). Models of bounded rationality. 1982. Cambridge: MIT Press. 
Yin, H., & Knowlton, B. (2006). The role of the basal ganglia in habit formation. Nature reviews. Neuroscience, 7. 
1007
A Rational Distributed Process-level Account of Independence Judgment 
Ardavan S. Nobandegani1,2Ioannis N. Psaromiligkos1 
{ardavan.salehinobandegani@mail.mcgill.ca, ioannis.psaromiligkos@mcgill.ca} 
1Department of Electrical & Computer Engineering, McGill University 
2Department of Psychology, McGill University 
Abstract 
It is inconceivable how chaotic the world would look to hu mans, faced with innumerable decisions a day to be made un der uncertainty, had they been lacking the capacity to distin guish the relevant from the irrelevant—a capacity which com putationally amounts to handling probabilistic independence relations. The highly parallel and distributed computational machinery of the brain suggests that a satisfying process-level account of human independence judgment should also mimic these features. In this work, we present the first rational, dis tributed, message-passing, process-level account of indepen dence judgment, called D∗. Interestingly, D∗shows a curi ous, but normatively justified tendency for quick detection of dependencies, whenever they hold. Furthermore, D∗ outper forms all the previously proposed algorithms in the AI litera ture in terms of worst-case running time, and a salient aspect of it is supported by recent work in neuroscience investigating possible implementations of Bayes nets at the neural level. D∗ exemplifies how the pursuit of cognitive plausibility can lead to the discovery of state-of-the-art algorithms with appealing properties, and its simplicity makes D∗ potentially a good can didate as a teaching tool. 
Keywords: Rational process models; Distributed computing; Probabilistic independence judgment; Pearl’s d-separation 
1 Introduction 
Is there any connection between the quality of your last night sleep and the color of the shirt your colleague happened to be wearing at work today? How about Mars’ current weather and your mood today? We humans judge innumerable such possible connections a day rather effortlessly, appearing to be quite good at teasing apart pertinent from impertinent factors when making decisions. But how does the mind do that? The famous frame problem (Icard & Goodman, 2015; Nobande gani & Psaromiligkos, 2017), a puzzle in philosophy of mind and epistemology, further highlights this intriguing ability of the mind in distinguish the relevant from the irrelevant, and asks a closely related question: “How do we account for our apparent ability to make decisions on the basis only of what is relevant to an ongoing situation without having explicitly to consider all that is not relevant?” (Stanford Encyclopedia of Philosophy). Computationally, the mind’s ability of dis tinguishing the relevant from irrelevant can be characterized in terms of handling probabilistic (in)dependence relations, with ‘dependency’ implying the existence of connection or relevance between factors and ‘independence’ the contrary (Pearl, 1986, 1988, 2000). For example, assuming that the random variable x encodes the quality of your sleep, and y the color of the shirt your colleague happened to wear the next day, the nonexistence of any connection between x and y (which seems to be a rational judgment) can be formally characterized using the notion of probabilistic independence: 
x ⊥⊥ y (read x is independent of y, and, by virtue of symmetry, y is independent of x). 
In this work, we are concerned with developing a plausi ble, process-level account of human independence judgment. Adopting causal Bayes nets (CBNs) (Pearl, 1988; Gopnik et al., 2004, inter alia) as a normative model to represent how the reasoner’s internal causal model of the world is struc tured (i.e., reasoner’s mental model), the aforesaid task com putationally amounts to checking for independencies in the distribution encoded by a CBN. Interestingly, Pearl (1986) put forth a graph-theoretic notion called d-separation, allow ing for reading off probabilistic independence relations from the mere structure of a CBN (Pearl, 1986).1 Ever since its inception, d-separation has proved fundamental in a va riety of domains in artificial intelligence, e.g., probabilistic reasoning (Pearl, 1988), causal reasoning (Pearl, 2000), de cision making (Shachter, 1998; Koller & Friedman, 2009), and has played important roles in a broad range of areas, e.g., handling missing data (Mohan & Pearl, 2014), extrap olation across populations (Pearl & Bareinboim, 2014), and deep learning (Goodfellow et al., 2016). In that light, algo rithms for implementing d-separation could potentially serve as a rational, process-level model of human independence judgment. But what should such a model look like? The highly parallel and distributed computational machinery of the brain suggests that a satisfying process-level account of human independence judgment should also mimic these fea tures. Sadly enough, all past algorithms for the implemen tation of d-separation have been sequential (aka serial), i.e., without any parallelism in computation, and, arguably worse, centralized, i.e., their executions are fully coordinated by a supervisory unit, analogous to a homunculus (Geiger et al., 1989; Lauritzen et al., 1990; Shachter, 1998; Koller & Fried man, 2009; Butz et al., 2016). These features strongly call into question their psychological plausibility. 
The notion of (conditional) probabilistic independence is a quintessential feature of CBNs, and, interestingly, the re alization that probabilistic independence plays a crucial role in human cognition was a key element in the development of the CBN formalism (Pearl, 1986). In Pearl’s (1986) words: “Whereas a person may show reluctance to giving a numeri cal estimate for a conditional probability P(xi|xj), that person can usually state with ease whether xi and xj are dependent or independent, namely, whether or not knowing the truth of xj will alter the belief in xi.” He then continues: “Likewise, 
1More accurately, Pearl’s (1986) d-separation is equally valid for Bayes nets wherein the edges do not enjoy causal interpretations. 
1008
people tend to judge the three-place relationships of condi tional dependency (i.e., xiinfluences xj given xk) with clarity, conviction, and consistency. This suggests that the notions of dependence and conditional dependence are more basic to human reasoning than are the numerical values attached to probability judgments.” Some psychological literature, how ever, does not fully embrace the statement “with clarity, con viction, and consistency” as Pearl put it. For example, the experimental work by Rehder (2014) suggests that adults ex hibit deviations from the Markov condition (i.e., CBN’s inde pendencies entailed by d-separation). In contrast, drawing on the experimental studies of Park and Sloman (2013), Sloman and Lagnado (2015) conclude that people indeed uphold the Markov condition and the reason behind the observed devia tions is that, under experimental conditions, people may not solely adhere to the information provided by the experimenter and may bring their own background knowledge into the ex periment (see also Rehder & Waldmann, 2017). Specifically, Park and Sloman (2013) found strong support for their con tradiction hypothesis followed by the mediating mechanism hypothesis, and finally concluded that people do conform to Markov condition once the causal structure people are using is correctly specified (i.e., people’s mental causal models). 
In this work, we present the first rational, distributed, process-level account of independence judgment, called D∗. More formally, D∗is the first asynchronous, message passing, distributed algorithm for implementing d-separation, with substantial parallelism in computation, and without any 
2 Preliminaries and Notations 
Let us introduce the notation adopted in this work. Lower bold-faced letters (e.g., x) denote random variables and upper bold-faced letters (e.g., X) represent sets of random variables. A generic d-separation relation is denoted by (A ⊥⊥ B|C)G with A,B, and C representing three mutually disjoint sets of variables belonging to the directed acyclic graph (DAG) G, where G represents the topology of the underlying CBN. Read (A ⊥⊥ B|C)G as follows: C d-separates A from B in DAG G. Similarly, (A 6⊥⊥ B|C)G denotes that C does not d separate A from B in DAG G. For ease of notation, we use (A ⊥⊥ B|C)G to denote both a d-separation relation (i.e., C d separates A from B in DAG G) and to denote a d-separation query (i.e., does C d-separate A from B in DAG G?); the dis tinction should be clear from the context. Let also GAn(K) denote the ancestral graph for the variables in set K belong ing to the underlying DAG G (Lauritzen et al., 1990), i.e., the set of nodes for GAn(K) comprises the nodes in K and all the ancestors of the nodes in K (hence, GAn(K)is an induced subgraph of the underlying DAG G). 
Informally speaking, throughout that paper, (A ⊥⊥ B|C)G should be interpreted as follows: “A and B are probabilisti cally independent of each other, given C,” and, in the query format, as follows: “Are A and B probabilistically indepen dent of each other, given C?” Likewise, (A 6⊥⊥ B|C)G should be interpreted as follows: A and B are dependent, given C.2 
Next, a notion called refutation-module is introduced; this will be used later in our formal analysis of D∗. 
need for a supervisory unit to coordinate its execution (i.e., no synchrony is assumed in D∗’s execution)—fully in the spirit of the celebrated parallel distributed processing (PDP) re search program in brain and cognitive sciences (McClelland, 1989). Similar to the well-known belief propagation infer ence algorithm (Pearl, 1986, 1988), which has played impor 
t1 t3 t5 t2 t4 
v 
x y z 
t2 t4 
v 
x y z 
t3 
t2 t4 
x y 
tant roles in the theoretical neuroscience literature (see e.g., Gershman & Beck, 2017; George & Hawkins, 2009; Litvak & Ullman, 2009; Rao, 2004; Lochmann & Deneve, 2011), D∗is a message-passing algorithm, wherein computation is carried out by propagating messages between computational units. Interestingly, D∗shows a curious, normatively justified tendency for quick detection of probabilistic dependencies, whenever they hold. Furthermore, D∗ outperforms all the previously proposed algorithms in the AI literature in terms of worst-case running time, and a salient aspect of it is sup ported by recent work in neuroscience investigating possible implementations of Bayes nets at the neural level (e.g., Ger shman & Beck, 2017; Lochmann & Deneve, 2011). 
We provide a comprehensive analysis of the computational properties of D∗, along with several refined time-complexity bounds. In the Discussion section, we provide a detailed com parison between D∗and previously proposed algorithms, and elaborate on the implications of the work presented here for neuroscience and psychology. Formal proofs of the results presented can be found in an extended version of this paper available on arXiv: https://arxiv.org/abs/1801.10186. 
(a) (b) (c) 
Figure 1: Examples for refutation modules. (a) The underlying DAG G is depicted, for which (x 6⊥⊥ y|z)G. (b,c) Two refutation modules for the query (x ⊥⊥ y|z)G are depicted. Note, z = ∅ in (c). 
Def. 1. (Refutation-Module) Let X,Y,Z be three mu tually disjoint sets belonging to a DAG G. Let also (X 6⊥⊥ Y|Z)G. A connected subgraph of G, M(X6⊥⊥Y|Z)G, serves as a refutation-module for the query (X ⊥⊥ Y|Z)G, iff M(X6⊥⊥Y|Z)G satisfies the following two conditions: (1) M(X6⊥⊥Y|Z)Gcon tains an active path P (Pearl, 1986) between a node x ∈ X and a node y ∈ Y, and (2) for every head-to-head node v on P, M(X6⊥Y|Z)Gcontains a directed path between v and a node z ∈ Z. See Fig. 1 for some examples. 
Def. 2. (Minimal Refutation-Module) Let X,Y,Z be three disjoint sets of nodes belonging to a DAG G. Also, let 
2Formally, the said interpretations are not fully granted; how ever, for all purposes of this work, they can be taken to be accurate enough characterizations (see Pearl, 2000, for a complete elabora tion on the precise relation between d-separation and conditional independence.) 
1009
(X 6⊥⊥ Y|Z)G. Let M ∗(X6⊥Y|Z)Gdenote the refutation-module for the d-separation query (X ⊥⊥ Y|Z)G which possesses the smallest number of edges. We refer to M ∗(X6⊥Y|Z)Gas the min imal refutation-module in G for the query (X ⊥⊥ Y|Z)G. 
It is easy to prove by construction that the minimal refutation-module M ∗(X6⊥Y|Z)Gneed not be unique. 3 The Three-Color Algorithm D∗ 
In this section, we show how the proposed algorithm D∗al lows us to decide if a generic d-separation query of the form (A ⊥⊥ B|C)G holds in a DAG G; D∗is an asynchronous, dis tributed, message-passing algorithm. More specifically, in D∗, nodes of the underlying DAG G—symbolizing computa tional units—autonomously engage in communicating mes sages to their immediate neighbors via the edges of the DAG G—symbolizing communication channels. We assume that communication channels are reliable, bidirectional, and first in first-out (FIFO) (Lynch, 1996). 
The proposed algorithm D∗is outlined next. Throughout an execution of D∗, variables in C ignore all messages re ceived from any of their children, and do not send any mes sage to any of their children. The variables in the sets A, B, and C initially activate in the states represented by col ors green (•), red (•), and white (◦), respectively. Follow ing the prescriptions of the original Belief Propagation algo rithm (Pearl, 1986, Sections 1.3 and 2.2.3), we assume that the variables in the sets A,B,C acquire their initial states in a self-activated manner. Assuming that a CBN’s node can be represented at the neural level by a single (Deneve, 2008b,a) or a population of neurons (Ma et al., 2006), self-activation reflects the content-addressability of the corresponding mem ory traces. D∗ begins with nodes in A,B, and C sending their colors as messages to their parents. Node x, upon receiving a message, follows two simple steps in the following order: 
(i) If x’s current color differs from that of the received mes sage, x replies by sending back its own color as a message to the transmitter node. If x is in the state of having no color (denoted by ∅) prior to the receipt of the message, it does not send back any message to the transmitter node. 
(ii) x updates its color in accord with the following primitive rules, altogether composing the Color Update Grammar (CUG): 
(∅,•) → •,(∅,•) → •,(∅,◦) → ◦, 
(•,•) → •,(•,•) → •,(◦,◦) → ◦, 
(◦,•) → •,(◦,•) → •, 
(•,◦) → •,(•,◦) → •, 
(•,•) → clash,(•,•) → clash, 
where the syntax is: (x’s current color, received message) → x’s new color. If x’s new color turns out to be differ ent from its old color, with the exception of the transmitter node, x sends its new color as a message to all its parents, 
and only those children of x with which x has communi cated before. 
The rules given in the first row of the CUG correspond to white-, green-, and red-colored nodes sending their colors to their yet-uncolored parents. Rules in the second row ensure that the colors of white-, green-, and red-colored nodes persist upon interacting with nodes of the same color. Rules stated in the third row bear on the key understanding that the white color functions as a mere place-holder getting “replaced” by interacting with green-, or red-colored nodes. Rules in the fourth row guarantee the persistence of colors green and red upon interacting with white. Finally, rules given in the last row correspond to the clash event the implication of which is discussed in Remark 1 below. 
Remark 1. A clash between colors green (•) and red (•) at a node, any time throughout an execution of D∗, signals the falsity of the input d-separation query, upon which D∗ decides that (A 6⊥⊥ B|C)G. 
Note that the asynchrony of D∗stems from the fact that there exists no global clock for the system and hence any node, upon receiving a message, follows Steps (i) and (ii) au tonomously, i.e., informally, without having to attend to what computations other nodes in G are performing. 
Some of the computational properties of the proposed al gorithm D∗are formally articulated in Proposition 1 below. Proposition 1. The following statements hold for D∗. 
(1) For a given d-separation query (A ⊥⊥ B|C)G and DAG G, 
“C does not d-separate A from B in G” ⇐⇒ 
“Clash takes place during D∗’s execution”. 
(2) D∗’s message-passing is confined within the ancestral graph GAn(A∪B∪C). 
(3) During D∗’s execution, either a clash between colors red (•) and green (•) takes place (see Remark 1) upon which D∗ decides that (A 6⊥⊥ B|C), or a state of equilibrium will be reached in O(lAn(A∪B∪C)) time where lAn(A∪B∪C) denotes the length of the longest undirected path in the ancestral graph GAn(A∪B∪C). 
(4) Message-passing terminates in O(1) time after reaching the state of equilibrium, thereby guaranteeing the termi nation of D∗. 
(5) Message-complexity of D∗is O(|EAn(A∪B∪C)|) where EAn(A∪B∪C)is the set of the edges of the ancestral graph GAn(A∪B∪C). 
(6) Communication-complexity of D∗is O(|EAn(A∪B∪C)|) bits where EAn(A∪B∪C)is the set of the edges of the ancestral graph GAn(A∪B∪C). 
1010
3.1 High-Level Understanding of D∗ 
D∗ has a simple machinery as we informally discuss here. Upon variables in A∪B∪C sending their colors to their par ents, colors white (◦), green (•), and red (•) begin to propa 
neighboring node acquires such colors (Figs. 2(d-f)). Even tually, in the configuration depicted in Fig. 2(f), a clash takes place between colors green and red at a node (circled node in Fig. 2(f)), upon which D∗ decides that (X 6⊥⊥ Y|Z)G. 
gate in a backwards manner throughout the network. In the midst of this process, white-color nodes which have a neigh 
t3 
t2t4 
t5 
t6 
boring node colored either red (•) or green (•), change their 
z 
z 
z 
t1 
t7 
color to that of their neighbors, and if a clash ever occurs x1 
between colors red and green, D∗ decides that the input d separation query is false (i.e., it is a NO-instance d-separation query). Informally put, white-color nodes function as relays, which, by copying the colors of their neighbors, facilitate the possibility of a (permissible) collision between red and green. 
3.2 A Note On The Termination of D∗ 
x1 
According to Proposition 1, if the input d-separation query presented to D∗is true (i.e., it is a YES-instance d 
x2 y y1 2 w 
(a) 
z 
x2 y y1 2 w 
(d) 
x1 x1 
x2 y y1 2 w 
(b) 
z 
x2 y y1 2 w 
(e) 
x1 x1 
x2 y y1 2 w 
(c) 
z 
x2 y y1 2 w 
(f) 
separation query), the system reaches a state of equilibrium in O(lAn(A∪B∪C)) time and message-passing is guaranteed to ter minate in O(1) time after that. However, due to its local view, a node cannot know if such a global state has been reached. This is a fairly standard situation for an asynchronous dis tributed algorithm to find itself in (Mattern, 1987; Tel, 2000), leading to the introduction of the fundamental concept of Termination-Detection (TD) in the distributed systems liter ature; see Tel (2000, Ch. 8). There exist a variety of TD al gorithms in the literature (e.g., Dijkstra et al., 1983; Mattern, 1987; Mittal et al., 2004, 2007). For example, Mittal et al. (2004) proposed two TD algorithms, each having detection latency of O(D) where D is the diameter of the underlying graph G, and G is allowed to have an arbitrary topology. 
4 D∗in Action: A Case Study 
In this section, we present an example to illustrate an execu tion and highlight the simplicity of D∗. Consider the CBN depicted in Fig. 2(a). Let the posed d-separation query be (X ⊥⊥ Y|Z)G where X = {x1,x2}, Y = {y1,y2}, and Z = {z}. According to the d-separation criterion (Pearl, 1988), obser vation of z activates the path x1 ← t1 ← t2 ← t3 → t4 ← t5 → t6 → t7 → y1, thereby yielding the falsity of the d-separation query (X ⊥⊥ Y|Z)G (hence, the input is a NO-instance query); see Fig. 2(a). An execution of D∗is illustrated using succes sive snapshots shown in Figs. 2(b-f) with each figure depict ing the global state of the system (i.e., nodes’ colors) at some instance in global time (aka system’s configuration). As de picted in Fig. 2(b), variables in sets X,Y, and Z initially self activate in the states represented by colors green (•), red (•), and white (◦), respectively. Also recall that, as explicated in Sec. 3, variables in Z ignore any message received from any of their children, and also do not send any message to any of their children—depicting the downlinks of the variables in Z in a dash-dotted format simply illustrates this statement pic torially in Fig. 2(b). The colors green (•), red (•), and white (◦) propagate in a backwards manner (Figs. 2(c-d)). Also, the color of a white node gets replaced by green or red once a 
Figure 2: Illustrative example. The underlying DAG G is shown in (a). The initial configuration of the system is portrayed in (b), wherein variables in sets X,Y, Z self-activate in the states repre sented by green (•), red (•), and white (◦), respectively. Depicting the downlinks of the variables in Z in a dash-dotted format sim ply symbolizes that the variables in Z ignore any message received from any of their children, and also do not send any message to any of their children. D∗ begins by nodes in X,Y, Z sending their col ors as messages to their parents and proceeds as shown in (c-f) with each figure depicting a snapshot of the global state of the system at some instance in global time. Eventually, upon occurrence of a clash between colors green and red (at the circled node in (f)), D∗ decides that (X 6⊥⊥ Y|Z)G. A better-quality version of this figure can be found on arXiv: https://arxiv.org/abs/1801.10186 
Notice that, since w is unobserved (Fig. 2(a)), the path x2 → w ← y2indeed remains blocked (Pearl, 2000); this is nicely captured by the machinery of D∗. Algorithm D∗ pre vents x2 and y2from sending their colors in the forward di rection (i.e., along the edges pointing to w), thereby guar anteeing the occurrence of no clash along the blocked path x2 → w ← y2. Also notice that, since z is observed (Fig. 2(a)), the path x2 ← z → y2is blocked as well (Pearl, 2000). Once again the machinery of D∗, due to z refraining from engaging in message-exchange with its children, ensures that no clash takes place due to the blocked path x2 ← z → y2. 
5 Technical Discussion 
A number of algorithms for the implementation of d separation are proposed in the literature (Geiger et al., 1989; Lauritzen et al., 1990; Shachter, 1998; Koller & Friedman, 2009; Butz et al., 2016). Assuming |E| ≥ |V|, to decide if (A ⊥⊥ B|C)G holds in G, the worst-case running time of Geiger et al.’s, Koller and Friedman’s, Shachter’s, and Butz et al.’s is O(|E|) and that of Lauritzen et al.’s algorithm3is O(|V|2) where |V| and |E| denote the number of the nodes and the edges of the underling DAG G, respectively. Note that, since for any DAG G, |E| ≤ |V|2, an O(|E|)-time algo rithm (e.g., Geiger et al.’s) outperforms an O(|V|2)-time algo 
3The reader is referred to Geiger et al. (1989) for a detailed anal ysis of the running-time of Lauritzen et al.’s algorithm. 
1011
rithm (e.g., Lauritzen et al.’s) in terms of worst-case runtime4 (see Geiger et al., 1989, for more discussions on this). Ac cording to Proposition 1, the time-complexity of the proposed algorithm D∗is O(lAn(A∪B∪C)) where lAn(A∪B∪C) denotes the length of the longest undirected path in the ancestral graph GAn(A∪B∪C). Since, for any DAG G, lAn(A∪B∪C) ≤ |E| ≤ |V|2, the proposed algorithm D∗ outperforms all the previously proposed algorithms in terms of the worst-case running time.5 Particularly, the gain is significant in dense DAGs. Note that, in the limit as the underlying DAG G gets denser, the worst case runtime performances of the previously proposed algo rithms become identical, i.e., O(|V|2). 
Another noteworthy property of D∗is its tendency to ward quick detection of false d-separation queries (i.e., NO instance queries), manifested in an occurrence of a clash ac cording to Remark 1. For a NO-instance d-separation query, Proposition 2, below, gives a more refined upper-bound: 
Proposition 2. Let A = {ai}i, B = {bj}j, C = {ck}k be three disjoint sets of nodes belonging to a DAG G. Let ldAn(A∪B∪C)denote the length of the longest directed path in the ancestral graph GAn(A∪B∪C), and li jAn(A∪B∪C)the length of the shortest unblocked path between the nodes ai and bj in GAn(A∪B∪C). As a convention, if all paths between ai and bj are blocked, li jAn(A∪B∪C) = ∞. If (A 6⊥⊥ B|C)G then a clash between colors green (•) and red (•) occurs in time 
i, jli jAn(A∪B∪C) , upon which D∗ decides that 
OldAn(A∪B∪C) +min 
(A 6⊥⊥ B|C)G. 
In Sec. 2, we formally defined a notion called refutation module (see Def. 1). In the language of computational com plexity and theorem-proving, a refutation-module M(X6⊥Y|Z)G can serve as a certificate (or witness) for disproving a d separation query (X ⊥⊥ Y|Z)G. This interpretation is re lated to the verifier-based definition of the complexity class coNP. Next, in Proposition 3, we provide an even more re fined upper-bound on the time required for an occurrence of a clash, thereby strengthening our claim as to D∗’s tendency toward quick detection of false d-separation queries. 
Proposition 3. Let X,Y,Z be three disjoint sets of nodes belonging to a DAG G. Also, let (X 6⊥⊥ Y|Z)G. Let M(X6⊥Y|Z)G denote a refutation-module for the query (X ⊥⊥ Y|Z)G with ldMand |PM | denoting the length of the longest directed path and the shortest unblocked path in M(X6⊥Y|Z)G, respectively. 
4The gain is particularly significant in sparse graphs. 5According to Proposition 1, a NO-instance d-separation query can be decided by D∗in time O(lAn(A∪B∪C)). The upper-bound O(lAn(A∪B∪C)) is an improvement over the worst-case runtime of all the previously proposed algorithms. Also note that, adopting a TD algorithm with detection latency of O(D) (see Mittal et al., 2004, 2007, for such TD-algorithms), a YES-instance d-separation query can be decided by D∗in time O(lAn(A∪B∪C) + D) where D is the diameter of G. Once again, since lAn(A∪B∪C) ≤ |E|,D ≤ |E|,|E| ≤ |V|2, the upper-bound O(lAn(A∪B∪C) + D) is an improvement over the worst-case runtime of all the previously proposed algorithms. (Notice that, for any DAG G,12(lAn(A∪B∪C) + D) ≤ |E|, hence fol lows |E| = Ω(lAn(A∪B∪C) +D).) 
Finally, let M ∗(X6⊥Y|Z)Gdenote the minimal refutation-module for the query (X ⊥⊥ Y|Z)G, with EM ∗(X6⊥⊥Y|Z)Gdenoting the set of the edges of M ∗(X6⊥Y|Z)G. Then the following statement holds true: A clash between colors green (•) and red (•) occurs in time O(minM(X6⊥⊥Y|Z)G{ldM+|PM |}) ≤ O(|EM ∗(X6⊥⊥Y|Z)G|), upon which D∗ decides that (X 6⊥⊥ Y|Z)G. 
Finally, we would like to point out an interesting property of the CUG, referred to as order-invariance, which is charac terized informally as follows: The order according to which nodes in the network receive their messages is irrelevant. 
6 General Discussion 
The Algorithm D∗, in the spirit of Pearl’s (1986) belief prop agation scheme, employs the edges of the underlying CBN as the medium through which message-passing between nodes takes place. The latter echos Pearl’s (1986) insight when he advocated the idea that a CBN must not be viewed as “merely a passive parsimonious code for storing factual knowledge but also a computational architecture for reasoning about that knowledge.” D∗adheres to this idea. Recent literature in neu roscience investigating possible implementation of CBNs at the neural level supports Pearl’s idea (see Lochmann & Den eve, 2011; Gershman & Beck, 2017). Lochmann and Den eve (2011) advocate the idea that a CBN’s node can be rep resented at the neural level by a single (Deneve, 2008a,b) or a population of neurons (Ma et al., 2006) with the neu ral network resembling a “mirror image” of the CBN it implements—though sometimes not a ‘perfect’ mirror (see Fig. 1 in Lochmann and Deneve, 2011)—and the links of the neural network providing the medium for inference to be car ried out, either in the form of belief propagation or sample based methods like Gibbs sampling. 
Interestingly, the peculiar tendency of D∗toward quick de tection of NO-instance d-separation queries is consistent with our pre-theoretical intuition that humans tend to detect possi ble dependencies between concepts and propositions rather swiftly, once such dependencies do exist. The following question then presents itself: Could this tendency be sup ported based on any rational grounds? In what follows we provide an argument supporting the rationality of the fore going tendency. (†) Assuming that the mind incurs a higher rate of loss (defined as incurred cost per unit of time) for dis covering a dependency when one does exist, compared to the condition wherein one does not exist and the mind recognizes that, we formally show that the foregoing tendency is sim ply a consequence of the mind acting as a boundedly-rational satisficer (Simon, 1957), trying to attain good performance in terms of expected accumulative cost. But why should the rate of loss under the condition wherein a dependency does exist be higher? Informally put, why should the mind be so hasty in detecting dependencies under that condition? One possible explanation is that it is crucial for the mind to swiftly detect dependencies under that condition, with the rationale being that delay in detecting those dependencies could be harmful 
1012
to the reasoner and potentially jeopardize their life, hence im portant from an evolutionary standpoint. Furthermore, given the prominent role that explanation and inference play in hu man cognition (see Lombrozo, 2016), it is crucial for the mind to promptly detect those factors deemed relevant to the task faced by the reasoner. 
Let us formally characterize a general condition under which the aforesaid tendency can be given a rational basis. Let CA denote the accumulative cost of an algorithm A im plementing d-separation criterion, πYES and πNO denote the prior probability of the input being a YES-instance and NO instance d-separation query, respectively. Let also TYES 
Aand 
Adenote the worst-case runtime of A on YES-instance and 
TNO 
NO-instance d-separation queries, respectively. Finally, let LYES,LNO ∈ R>0 denote the cost per unit of time incurred by A for delay in detecting a YES-instance and NO-instance d-separation query, respectively. Then, for any DAG G, the following holds true: E[CA] ≤ LYESTYES 
AπYES +LNOTNO 
AπNO, 
where the expectation E[·] is taken with respect to the (un known) distribution of all d-separation queries. It is then easy to show that, under the condition (∗) LNOπNO ≥ LYESπYES, it is rational for the mind trying to attain good performance in terms of expected accumulative cost to demonstrate the said tendency toward quick detection of NO-instance d-separation queries. The setting portrayed in (†) above is a special case of Condition (∗): It corresponds to Condition (∗) subject to the assumptions πNO = πYES (reflecting the reasoner’s unin formative, a priori expectation that YES- and NO-instance queries are equiprobable) and LNO ≥ LYES (reflecting a higher rate of loss for erring on NO-instance queries, as alluded to earlier). Future work should experimentally investigate if humans demonstrate the forgoing normatively justified ten dency in probabilistic (in)dependence judgment tasks, or that, on the contrary, they systematically deviate from that. 
Also interestingly, the forgoing tendency of D∗toward fo cusing its search on the minimal refutation module can be taken as evidence for its least-effort-like characteristic, and is fully consistent with recently proposed frameworks which seek rational understanding of the mind at the algorithmic level of analysis by appealing to the notion of economical use of limited computational and cognitive resources (in our case, by striving for minimizing the size of the module required to be investigated for refuting a false d-separation query); see Nobandegani (2017) and Griffiths et al. (2015). Although we briefly discussed the idea of termination detection for asyn chronous distributed algorithms, a boundedly-rational agent may decide to only run an asynchronous distributed algorithm for a period of time which is justified based on the oppor tunity cost incurred by delaying another task. In that light, the boundedly-rational agent may plausibly decide to adopt termination detection algorithms only in settings wherein the opportunity costs involved would be relatively low. Also no tably, D∗exemplifies how the pursuit of cognitive plausibility can lead to the discovery of state-of-the-art algorithms. 
Perhaps the biggest limitation of D∗(and, likewise, of be 
lief propagation) is the assumption that communication chan nels are faultless, allowing for reliable message exchange. The brain’s neural circuits involve much stochasticity and re sponse variability (e.g., Ma & Jazayeri, 2014; Ma, Beck, and Pouget, 2008; Summerfield & Tsetsos, 2015), undermining this assumption. Future work should investigate extensions of D∗that are more robust to neural noise. While many questions remain open, we hope to have made some progress toward understanding human probabilistic (in)dependence judgment at the algorithmic level, a capacity without which the world would seem too chaotic for humans to live by. 
Acknowledgments: We would like to thank Michael Pacer for providing constructive comments on an earlier draft of this work, and, Tom Shultz and Luc Devroye for helpful discussions. This work was supported in part by NSERC under grant RGPIN 262017. 
References 
Butz, C. J., Dos Santos, A. E., & Oliveira, J. S. (2016). Relevant path separation: A faster method for testing independencies in bayesian networks. Proceedings of the Eighth International Conference on Probabilistic Graphical Models (PGM), 74–85. 
Deneve, S. (2008a). Bayesian spiking neurons II: Learning. Neural Computation, 20(1), 118–145. Deneve, S. (2008b). Bayesian spiking neurons I: Inference. Neural Computation, 20(1), 91–117. Dijkstra, E. W., Feijen, W. H., & Van Gasteren, A. M. (1983). Derivation of a termination detection 
algorithm for distributed computations. Information Processing Letters, 16(5), 217–219. Geiger, D., Verma, T., & Pearl, J. (1989). d-separation: from theorems to algorithms. Fifth Workshop on Uncertainty in Artificial Intelligence, pp. 118–125. 
George, D., & Hawkins, J. (2009). Towards a mathematical theory of cortical micro-circuits. PLoS Computational Biology, 5(10), e1000532. 
Gershman, S. J., & Beck, J. M. (2017). Complex probabilistic inference: From cognition to neural computation. In Computational Models of Brain and Behavior, ed A. Moustafa. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press. Griffiths, T. L., Lieder, F., & Goodman, N. D. (2015). Rational use of cognitive resources: Levels of analysis between the computational and the algorithmic. Topics in Cognitive Science, 7(2), 217–229. 
Icard, T. F., & Goodman, N. D. (2015). A resource-rational approach to the causal frame problem. Proc. of the 37th Annual Meeting of the Cognitive Science Society. 
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT. Lauritzen, S. L., Dawid, A. P., Larsen, B. N., & Leimer, H. G. (1990). Independence properties of directed markov fields. Networks, 20(5), 491–505. 
Litvak, S., & Ullman, S. (2009). Cortical circuitry implementing graphical models. Neural Computa tion, 21(11), 3010–3056. Lochmann, T., & Deneve, S. (2011). Neural processing as causal inference. Current Opinion in Neurobiology, 21(5), 774–781. 
Lombrozo, T. (2016). Explanatory preferences shape learning and inference. Trends in Cognitive Sciences, 20(10), 748–759. 
Lynch, N. A. (1996). Distributed Algorithms. Morgan Kaufmann. 
Ma, W. J., Beck, J. M., Latham, P. E., & Pouget, A. (2006). Bayesian inference with probabilistic population codes. Nature Neuroscience, 9(11), 1432–1438. 
Ma, W. J., Beck, J. M., & Pouget, A. (2008). Spiking networks for bayesian inference and choice. Current Opinion in Neurobiology, 18(2), 217–222. 
Ma, W. J., & Jazayeri, M. (2014). Neural coding of uncertainty and probability. Annual Review of Neuroscience, 37, 205–220. 
Mattern, F. (1987). Algorithms for distributed termination detection. Distributed Computing, 2(3), 161–175. 
McClelland, J. L. (1989). Parallel distributed processing: Implications for cognition and develop ment. In: Morris mgm, editor. parallel distributed processing, implications for psychology and neurobiology. , Oxford: Clarendon Press; pp. 8-45. 
Mittal, N., Venkatesan, S., & Peri, S. (2004). Message-optimal and latency-optimal termination de tection algorithms for arbitrary topologies. In International symposium on distributed computing (disc) (pp. 290–304). 
Mittal, N., Venkatesan, S., & Peri, S. (2007). A family of optimal termination detection algorithms. Distributed Computing, 20(2), 141–162. 
Mohan, K., & Pearl, J. (2014). On the testability of models with missing data. In AISTATS. Nobandegani, A. S. (2017). The Minimalist Mind: On Mininality in Learning, Reasoning, Action, & Imagination. McGill University, PhD Dissertation. 
Nobandegani, A. S., & Psaromiligkos, I. N. (2017). The causal frame problem: An algorithmic perspective. Proc. of the 39th Annual Meeting of the Cognitive Science Society. Park, J., & Sloman, S. A. (2013). Mechanistic beliefs determine adherence to the markov property in causal reasoning. Cognitive Psychology, 67(4), 186–216. 
Pearl, J. (1986). Fusion, propagation, and structuring in belief networks. Artificial Intelligence, 29(3), 241–288. 
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Pearl, J. (2000). Causality. Cambridge university press. 
Pearl, J., & Bareinboim, E. (2014). External validity: From do-calculus to transportability across populations. Statistical Science, 29(4), 579–595. 
Rao, R. P. (2004). Bayesian computation in recurrent neural circuits. Neural Computation, 16(1), 1–38. 
Rehder, B. (2014). Independence and dependence in human causal reasoning. Cognitive Psychology, 72, 54–107. 
Rehder, B., & Waldmann, M. R. (2017). Failures of explaining away and screening off in described versus experienced causal learning scenarios. Memory & Cognition, 45, 245-260. Shachter, R. D. (1998). Bayes-ball: Rational pastime (for determining irrelevance and requisite information in belief networks and influence diagrams). In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI) (pp. 480–487). 
Simon, H. A. (1957). Models of Man. Wiley. 
Sloman, S. A., & Lagnado, D. (2015). Causality in thought. Annual Review of Psychology, 66, 223–247. 
Summerfield, C., & Tsetsos, K. (2015). Do humans make good decisions? Trends in Cognitive Sciences, 19(1), 27–34. 
Tel, G. (2000). Introduction to Distributed Algorithms. Cambridge University Press. 
1013
Ecological Psychology and the Environmentalist Promise of Affordances 
Guilherme Sanches de Oliveira (sanchege@mail.uc.edu) 
Department of Philosophy, 2700 Campus Way, 206 McMicken Hall 
Cincinnati, OH 45221 USA 
Abstract 
What is ecological about Gibsonian Ecological Psychology? Well-known senses in which Gibson’s scientific program is ‘ecological’ have to do with its theoretical, ontological and methodological foundations. But, besides these, the Gibsonian framework is ‘ecological’ in an additional sense that has re mained understudied and poorly understood—a sense of “eco logical” that connects Gibson’s view to the environmentalism of environmental psychology and environmental ethics. This paper focuses on the latter sense of ‘ecological’, and explores the relevance of Gibson’s notion of “affordance” for thinking about environmental issues like deforestation, pollution and climate change. One existing account is criticized and an al ternative is proposed. 
Keywords: affordances; perception; environmental ethics; en vironmental psychology; moral psychology; responsibility. 
Introduction 
We live in a time of dramatic environmental challenges. Ac cording to the Food and Agriculture Organization of the United Nations (FAO 2016), from 1990 to 2015 almost 130 million hectares of forests were destroyed worldwide, an area about the size of South Africa. The United Nations Environ ment Programme (UNEP 2017) reports that over 80% of the world’s wastewater is released into the environment without receiving any treatment, and that around 12 million tons of plastic waste end up in the ocean every year. Deforestation and pollution have a high impact on biodiversity. The World Wide Fund For Nature (WWF 2016) estimates that, since 1970, wild vertebrate populations have on average declined by 58%, with the strongest decline rate afflicting freshwater species (81%). Air and water pollution also take a high toll on human health. The World Health Organization estimates that 92% of the world population is exposed to air below mini mum quality standards, which causes up to 6.5 million deaths per year (2017). The WHO also reports that more than 2 billion people worldwide drink water from sources contam inated by fecal matter, leading to over 800,000 deaths every year from diarrhea alone (i.e., not including other diseases caused by polluted water). 
This ecological situation is not independent from human activity. Deforestation and the pollution of air, land and water, especially at their present levels, are not naturally occurring ecological events. Rather, they happen as the result of direct and indirect human activity—that is, either through active ex traction and depletion of natural resources or, for most of us, through daily reliance on goods and services that exert that negative ecological impact. Environmental degradation poses threats to human health at the immediate and local scale, as in the case of polluted air and water which cause millions of deaths every year. Environmental degradation also presents more long-term and widespread hazards by contributing to 
global climate change, which endangers whole ecological niches and all sorts of animal and plant species that we also depend on. Awareness of our ecological entanglements has, over the past century, led to the rise of an “environmental” or “ecological” consciousness, a broad and multi-faceted social, political and cultural movement. 
In the humanities, the environmental movement has mo tivated thinkers to question the anthropocentrism character istic of the Western ethical tradition. From Ancient Greece through the medieval and modern periods, philosophers have, by an large, held that humans have a higher status than non human animals, plants, and other environmental elements (White 1967). In this traditional view, human beings alone are intrinsically valuable and are full members of the “moral community”: non-human animals, plants and other natural entities are valuable only as means to achieving human goals, and the way we treat non-human entities cannot in and of it self be judged as moral or immoral, only as more or less con venient for us. Environmental ethics questions the adequacy of these anthropocentric assumptions. Aldo Leopold, one of the pioneers in the field, proposed a view he called the “land ethic,” namely an ethical framework in which moral value is holistic rather than individual and is to be found in entire biotic communities. For Leopold, by “thinking like a moun tain” rather than as individual organisms fighting for survival, we come to understand that “a thing is right when it tends to preserve the integrity, stability, and beauty of the biotic com munity. It is wrong when it tends otherwise” (1949). That is, according to Leopold’s land ethic, it is a mistake to think that polluting a river is only wrong when it harms other hu man beings—rather, polluting a river is wrong to the extent that it damages the whole biotic community, regardless of the consequences it may have for other people. Leopold’s land ethic has been criticized, defended, modified and expanded by many after him (see an overview of various reactions in Callicott 1987, 1999). Importantly, whether Leopold’s in sights were right or not, his work and that of other pioneers in the environmental movement has drawn attention to the ethi cal dimension of our ecological situation. 
The environmental or ecological movement has also influ enced developments in psychology and cognitive science. In the field of environmental psychology, two lines of research have been particularly productive. The first line focuses on the psychological effects of having contact with natural and built environments. The experimental evidence indicates that mental well-being is closely linked to experiencing nature. A longitudinal study has suggested, for example, that relo cation from low-income housing to a new environment with access to more “natural” elements such as a garden space or 
1014
windows with a view of trees was associated with improved cognitive performance, especially increased attentional abil ity, in children from 7 to 12 years of age (Wells 2000). But the effects are not limited to long-term relocation in closer proximity with nature. Studies also suggest that even a brief walk in nature can have significant affective and cognitive effects, e.g., leading to stress relief (Tyrvinen, Ojala, Kor pela, Lanki, Tsunetsugu & Kagawa 2014), decreased anxi ety and increased working memory performance (Bratman, Daily, Levy & Gross 2015). A comprehensive review of this literature revealed that there is strong evidence that “knowing and experiencing nature makes us generally happier, healthier people” (Russell, Guerry, Balvanera, Gould, Basurto, Chan, Klain, Levine & Tam 2013). 
Another major line within environmental psychology seeks to understand our attitudes toward nature, how those atti tudes affect our behavior, and what can be done to promote more environmentally-friendly behavior. Studies suggest that spending time in nature and feeling connected to nature lead to more ecological concern and sustainable action: in chil dren, this is associated to their perceived family value toward nature (Cheng & Monroe 2010); and in adults, contact with nature leads to more pro-environmental intentions and behav ior particularly when ecological problems are perceived as social dilemmas (Zelenski, Dopko & Capaldi 2015). But the literature also indicates that merely providing access to infor mation about environmental issues (e.g., the data presented at the beginning of this Introduction) is insufficient to generate more pro-environmental behavior in individuals. People tend not to go out of their way to act more sustainably out of per sonal conviction, but they form and act out pro-environmental convictions when it is easy to do so—for example, individu als recycle more when they have more opportunities to do so (Vining and Ebreo 1992). In line with this and related findings, Lucas, Brooks, Darnton & Jones (2008) suggest that public policies will be most effective when they encour age pro-environmental behavior at multiple levels: measures that target individuals’ motivation and attitudes toward nature will not be sufficient to generate sustainable behavior if there are no system-wide mechanisms to facilitate and even reward pro-environmental behavior. 
Research in these two main strands of environmental psy chology is closely aligned with, and lends itself to appli cations in, the moral and political dimensions of environ mentalism. The same does not seem to be the case with the independent but similarly-named scientific tradition of Gibsonian ecological psychology. Scholars working within the Gibsonian framework have made important contribu tions to the study of perception-action dynamics in organism environment relations, but they have had surprisingly little to say about the environmental challenges we face, such as de forestation, pollution, and climate change. The goal of this paper is to investigate how, if at all, the Gibsonian framework and particularly the notion of “affordances” can contribute to the environmentalism of environmental ethics and environ mental psychology. 
What is “Ecological” in Ecological Psychology? The label “ecological psychology” has been applied to dif ferent scientific traditions (Heft 2001), but, given our present focus, in the remainder of this article that phrase will be used to refer to the one initiated by James J. Gibson (1966, 1979). The present section overviews some of the key themes in Gib son’s vision for ecological psychology in order to elucidate what exactly was “ecological” about it. Four related senses of ecological are identified: theoretical, ontological, method ological, and ethical. 
A good starting point to understand the Gibsonian ecologi cal framework is to consider its theoretical scope and context. Contemporary ecological psychology has been identified as a radical embodied approach to cognitive science (Chemero 2009), but understanding Gibson’s own work in these terms is anachronistic. At the time of its inception in the 1960s and 1970s, ecological psychology was meant as an alternative to both behaviorism and cognitivism. From a behaviorist per spective, the scope of psychology as a science was limited to observable or otherwise measurable responses in association with stimuli or reinforcements. This corresponded, in the ory and in practice, to black-boxing internal processes, which were seen as scientifically uninteresting or, perhaps for radi cal behaviorists, inexistent. In contrast, from the perspective of the then emerging approach of cognitivism, the task of sci entific psychology was to investigate the internal cognitive processing that occurs in between sensory input and behav ioral output—precisely what behaviorism had long neglected. In line with the computer metaphor, cognition was seen as the internal computational processing of what had been ob tained from, and would then be exhibited by, the peripherals. While being different in various repects, both behaviorism and cognitivism accepted the same theoretical model for sci entific psychology, disagreeing mainly on what the focus of inquiry should be (see Figure 1). 
(a) 
stimulus response 
(b) 
input cognition output 
Figure 1: The scope of psychological science indicated in red for (1a) behaviorism and (1b) cognitivism. 
Gibson rejected the theoretical and ontological assump tions endorsed by behaviorists and cognitivists. Instead, his vision for psychology was “ecological” in that it shifted the theoretical scope of psychology to study informational action-perception dynamics, and, this, grounded on an on tology of organism-environment systems as single ecological units. To make this clear, consider first how the traditional model in Figure 1 draws a clear distinction between percep tion and action (i.e., between stimulation and response, or be tween input and output, in each case). Gibson saw the two as 
1015
inseparable: perception is an action and it is for action, that is, we perceive by acting and in order to act, and no action is ever divorced from perception. Now, Gibson spoke of there being a mutuality or reciprocity between organism and en vironment. He claimed that “information about a world that surrounds a point of observation implies information about the point of observation that is surrounded by a world. Each kind of information implies the other” (1979: 75). This means that as an organism acts/perceives, it generates rela tional ecological information, that is, information that speci fies “affordances,” or what the organism can do given its own abilities and what the environment is like. In this way, eco logical psychology is “ecological” in related theoretical and ontological senses: first, the theoretical scope of psychology is organism-environment relations (rather than internal pro cessing or behavior conditioning); and second, this is based on the ontological view that there is relational information inherent to action-perception dynamics which organisms can directly perceive or “pick up” (see Figure 2). 
information 
organism environment 
Figure 2: The theoretical scope (in red) and ontological ba sis of ecological psychology: the information generated by action-perception dynamics in an organism-environment sys tem specifies the same relational dynamics—the information points both ways, hence the bidirectional arrows. (Inspired by diagram in Turvey and Carello 1986: 143) 
These related theoretical and ontological senses in which Gibson’s framework was “ecological” also led him to be con cerned with the ecological validity of psychological experi ments—which brings us to the methodological sense of “eco logical” at play in ecological psychology. Psychological ex periments typically require participants to perform artificial actions in artificial situations. Consider, for example, how research in experimental psychology often asks participants to perform tasks they have never tried before, and to do so under conditions they are not familiar with. Participants are often shown stimuli that are ambiguous, that generate some illusion, that are shown only partially or too fast to be fully perceived. Moreover, they are often expected to hold still (e.g., if in an fMRI machine) and to focus their sight and at tention to the task at hand. Ecological psychology sees all of these as dangerous constraints, and calls for a methodological approach that is closer to the real tasks participants perform in real environments. To be sure, scientific experiments in any discipline are by nature artificial: they are man-made sit uations, tailored to some interest, and carefully designed so as to control for confounding variables and unwanted influ ences. But Gibson was among the first to explicitly call for experiments that were “ecologically valid.” As Gibson (1979) explains, “natural vision” is not static and punctate like the snapshots of a camera, but we see by looking around by mov ing our eyes, moving our head, and walking around: “the 
evidence suggests that visual awareness is in fact panoramic and does in fact persist during long acts of locomotion” (p. 2). For this reason, if we are to understand vision as it oc curs in reality, we should design our studies accordingly: “It is not true that ‘the laboratory can never be like life.’ The laboratory must be like life!” (p. 3) As Brian Rogers (2017) explains, the methodology of cognitivism has relied on ex perimental setups “where the perceptual system makes mis takes,” while researchers in ecological psychology typically design “situations where the perceptual systems provide cor rect answers—for instance, where there is a clear link be tween the information available in the spatio-temporal pat terning of light reaching the eye(s) and the control of our actions” (p. 27). This captures the methodological sense in which ecological psychology is “ecological”: it strives to study psychological phenomena in ecologically valid situa tions. 
These theoretical, ontological and methodological “eco logical” aspects of ecological psychology are well known. But an additional sense of “ecological” is at play in the Gibso nian framework which has not received nearly as much atten tion. This is the ethical sense of “ecological” which connects ecological psychology to the environmentalist ideals behind environmental psychology and environmental ethics. There is good evidence that Gibson was sympathetic to values guiding the ecological movement and that he understood the urgency of environmental issues. In his 1979 book he points out, for example, that “we human animals have altered [the world] to suit ourselves” but he adds that “[we] have done so wastefully, thoughtlessly, and, if we do not mend our ways, fatally” (p. 130). Gibson’s focus was not on advancing the environmen talist agenda—articulating new foundations for psychological science was challenging enough! Still, passages like this sug gest that he saw his framework as having important implica tions for understanding the ethical and political dimensions of our environmental situation, and that perhaps even the choice of the label “ecological psychology” was meant to capture such connotations as well. 
Perception and Environmental Issues 
Edward Casey’s (2003) account is one of very few to explic itly apply the framework of ecological psychology to think ing about our current environmental challenges. Casey’s goal is to ground environmental ethics on the experience of envi ronmental destruction, or “the sheer and simple fact of be ing struck by something wrong happening in the surrounding world” (p. 187). He claims that ethicists too often focus on the morality of our actions and neglect what makes that ac tion possible, namely our experience of the world. Casey thus proposes that we consider “the moment of the glance” as the “first moment of ethical responsiveness” (p. 188). By this he means that seeing is not only what chronologically precedes moral action but it is what gets it started and is already inte gral to moral action: seeing or refusing to see is itself an ac tion—a morally relevant one—and it should accordingly have 
1016
a more prominent place in our study of moral psychology and environmental ethics. 
The view of perception underlying Casey’s proposal is de cidedly Gibsonian. As briefly suggested earlier, in ecologi cal psychology perception is the direct pick up of ecological information. This means that we do not need to internally represent and process information so as to infer some mean ing (as is assumed in the cognitivist tradition). Rather, we directly perceive (or “pick up”) information that is relational and is therefore informative of what the environment means to us—it is information that specifies what actions the en vironment affords, or what we can do in that environment. Drawing from this view of perception as the pick up of eco logical information, Casey proposes: “A glance suffices not just to see distress and disorder. It also picks up the impera tive to do something about that disarray” (p. 198). Casey il lustrates his point by describing his experience of happening upon a mountainside that had been deforested. He claims that the mere sight of that deforested area included the detection of an ethical imperative to fix the situation: “The imperative for ecological action stemmed from the intensity of the scene itself, its damaged surfaces speaking dramatically to my bare apperception” (p. 199). Casey’s proposal thus corresponds to two key ideas to be examined independently: (1) that in per ceptual experience we can directly detect natural distress or disorder, and (2) that in perceptual experience we also detect an ethical imperative to fix that disorder. 
The Direct Perception of Natural Disorder Consider first Casey’s claim that we directly perceive natural distress and disorder. Casey proposes that certain events pro vide the ‘direct presentation of environmental distress’, such as in his own experience of seeing a deforested area: “When I glimpse clearcutting on a mountain slope or the dumping of waste in a swamp or the ruination of soil on a farm, I am wit nessing disorder in the environment” (p. 197). By “disorder” Casey means “any feature of the layout that goes contrary to the natural order,” further adding that in such cases, “instead of an optical array that is well-ordered with regard to being and well-being, we are confronted with manifest disarray” (ibid.). Thus construed, the claim that we directly perceive natural disorder is problematic for two reasons. 
The first problem concerns the “direct perception” part of the claim. Althouh the “directness” of perception assumed by Casey aligns with the Gibsonian ecological framework he means to adopt, the idea that something like environmental distress or disorder can be directly perceived does not. As indicated earlier, ecological psychology takes it that what is directly accessible in perception is ‘ecological information’: that is, not information that is absolute (i.e., what an element in the environment is like in and of itself, without reference to an interacting organism) but instead information that is re lational (i.e., information that specifies what an element in the environment affords to a particular organism). The prob lem is that environmental distress, as Casey describes it, is an absolute rather than relational feature of the environment. 
He claims that the mountain slope, the swamp or the farm soil have their well-being “trespassed and undermined” (p. 197). To be sure, in all of these cases what threatens the en vironmental element’s well-being is a relation or interaction (namely, human action); still, to frame the result as a loss in well-being is to frame it as an absolute change in that envi ronmental element. And if environmental disarray and lack of order are absolute features of that environment, then, strictly speaking, we could not directly perceive them because per ception only detects relational features. 
The second problem with Casey’s idea that we directly per ceive natural disorder concerns the “natural disorder” part of the claim. Casey seems to assume that nature has some essential, human-independent order and that human activity disrupts that naturalness, almost as if humans were some how breaking into the realm of the natural from outside of it. Philosophers working in environmental ethics have ques tioned the adequacy of this common understanding of “nat ural” as being opposed to “artificial” or “man made” (e.g., Elliot 1982, Katz 1992, Vogel 2015). But even earlier, Gib son himself had vehemently rejected this form of dualism: “It is a mistake to separate the natural from the artificial as if there were two environments”; instead, “This is not a new environment—an artificial environment distinct from the nat ural environment—but the same old environment modified by man” (Gibson 1979: 130). Humans are as natural as any other animal, and the environmental effects of human activ ity (including deforestation, pollution and climate change) are as natural as the environmental effects of the activity of any other species. Strictly speaking, then, it seems we cannot di rectly perceive “natural disorder,” as Casey claims, because “natural disorder” does not exist. The environmental prob lems we face are real, of course, but they are not adequately understood as the disruption of natural order. The clearcut mountain slope Casey saw is perfectly natural even though it was created by humans: deforestation transforms previous environmental dynamics, but so do other non-human-initiated ecological events such as hurricanes and volcanic eruptions. For this reason, framing our environmental situation in terms of “natural disorder” is problematic not only because it places it outside the scope of perceptual experience (as an absolute feature), but also because it implies an untenable dualism ac cording to which human action disrupts some independent natural order, as if humans were not part of nature. 
The Picking Up of Ethical Imperatives 
Independently of the reasons given above for rejecting Casey’s claim that we perceive natural disorder, there is good reason to question his further claim that we also perceive an ethical imperative to fix natural disorder. This is because Casey’s idea that the perception of natural disorder already in cludes imperatives of a moral sort is based on a scientifically questionable understanding of the notion of “affordances”. 
Casey quotes Gibson in saying that through perception we come to know “what [the substances of the habitat] afford, what they are good for,” to which Casey adds: “This points 
1017
in the direction of the ethical, which allows us as well as commands us to be and do good in terms of what the sur faces of our immediate environment afford—what they are ‘good for”’ (p. 196). As this makes clear, Casey interprets affordances as having some moral dimension to them: in his view, ‘what things are good for’ refers to the actions that are justified or called for morally. But this is a gross misunder standing of “affordance” as the technical term is used in eco logical psychology. To be sure, there has been intense de bate in the ecological psychology community about the on tological status of affordances, namely if they are to be un derstood as dispositions (Turvey 1992, Scarantino 2003), re sources (Reed 1996), or relations (Chemero 2003, 2009). But it is generally understood that affordances have only instru mental value. For example, basic affordances of fire include illumination, warmth, and injury to the skin; “once control is learned” fire also affords cooking, boiling water, glazing clay, reducing minerals to metals (Gibson 1979: 39), and to this list we can add slash-and-burn agriculture and injury to others by combining fire with gunpowder. Similarly, trees can afford climbing and shelter from sun or rain, as well as injury through collision, and cutting down to clear an area for agriculture or to extract wood with which to create shel ter, tools, or fire. Strictly speaking, then, affordances cannot “point in the direction of the ethical,” as Casey suggests, be cause things can be ‘good for’ all sorts of purposes, including the immoral and the amoral. If it makes sense to say that affordances contain any ‘imperative’ for action, then this im perative has to be purely instrumental rather than moral. For this reason, Casey’s claim that we perceive an ethical impera tive to fix natural disorder is incompatible with the Gibsonian ecological theory Casey means to advocate: the same defor ested mountainside that affords protection and reforestation also affords further clearing for agricultural ends; if any im perative for action is picked up in perception, it cannot have inherent moral valence. 
Perception, Learning, and Responsibility 
Having examined some of the challenges with applying the framework of ecological psychology to understanding our en vironmental situation, we can now move closer to a positive account that is more theoretically sound. 
Earlier I quoted Gibson’s (1979) claim that we humans have altered the world ‘wastefully’, ‘thoughtlessly’ and pos sibly ‘fatally’ (p. 130). In the same passage Gibson also ex plains why we have done so: 
“Why has man changed the shapes and substances of his envi ronment? To change what it affords him. He has made more available what benefits him and less pressing what injures him. In making life easier for himself, of course, he has made life harder for most of the other animals. Over the millennia, he has made it easier for himself to get food, easier to keep warm, easier to see at night, easier to get about, and easier to train his offspring” (Gibson 1979: 130) 
As this suggests, we could only get to our current environ mental situation by acting on the affordances of the environ 
ment. Natural resources afforded extraction and transforma tion, forests afforded cutting down, rivers afforded a rudi mentary way of getting rid of sewage, and the air afforded getting noxious smoke outside of our houses and factories, and it was only because all of this was afforded by the envi ronment that we developed these practices in the first place. These interactions with the environment—our acting on what it affords—necessarily transforms the environment and what it affords as well: the deforested area affords us agricultural cultivation but it no longer affords inhabiting by various other species, therefore no longer affording us hunting; water and air, once polluted, can afford poisoning and death to us and various organisms exposed to them. All environmental chal lenges we currently face follow the same pattern, arising from interactions that the environment afforded, followed by the transformation of those affordances and the creation of new ones that may be more or less desirable from a variety of perspectives. These ecological facts of perception and ac tion support the idea that our current environmental situation (which includes pollution, deforestation and climate change) is perfectly natural: humans are not outside of the realm of nature, and we, just like all other living beings, can only ever act on what we detect that the environment affords. But nat uralizing anthropogenic environmental impact should not be seen as entailing passivity or fatalism, as if being natural also made something like climate change good or unavoidable. 
Instead, the ecological facts of perception and action de scribed above are inadequately understood if we do not also take into account the various ways in which perception is flex ible and fine-tunable, or how it is shaped by learning and the “education of attention” (Gibson 1966, Jacobs and Michaels 2007, Araujo and Davids 2011). The education of attention is the differential attunement of a perceptual system to eco logical informational variables—put simply, it is the process by which, through practice, we become more sensitive to in formation that is more relevant for certain actions (this ex plains the skill of the expert wine taster, as well as any adult’s skill in reading and doing mathematics, for example). And a key reason why the flexibility and educability of attention is important for the present discussion is that it helps to make clear how our perception of environmental resources and en vironmental challenges can develop. Even if deforestation and pollution arise naturally from our acting on what the en vironment affords, we can equally naturally come to better perceive other affordances that may be more adaptive. The fine-tuning of perception thus enables us to more fully un derstand our situation and see that, as Gibson put it, “Some ecological events are reversible sequences, whereas others are nonreversible” (1979: 101). This in turn empowers us to make more informed decisions, and to choose, for exam ple, to limit our contribution to nonreversible events that will have undesirable consequences (e.g., climate change). The fine-tuning of perception can thus guide which affordances we choose to act on and which new affordances we choose to create. 
1018
Further developing this view of our environmental situa tion in Gibsonian ecological terms—in terms of the ecologi cal facts of affordance-based perception-action dynamics and the education of attention—will make an important contri bution to the environmental movement in its various facets. In environmental ethics, the Gibsonian ecological framework motivates not an ethics of imperatives (Casey 2003) but an ethics of ‘responsibility’ (Vogel 2015): coming to see our selves as responsible for the environment means, first, real izing that we have caused it to become what it is now and, second, taking ownership of it and managing it in light of the knowledge that, even if we can never bring nature back to some pristine state, we can make life better for ourselves and others we share the environment with. This in turn mo tivates more research in environmental psychology toward a better understanding of how to design the built environment and societal systems so that they afford behavior that is envi ronmentally sustainable rather than (self)destructive. 
References 
Araujo, D., & Davids, K. (2011). What exactly is acquired ´ during skill acquisition? Journal of Consciousness Studies, 18(3-4), 7–23. 
Bratman, G. N., Daily, G. C., Levy, B. J., & Gross, J. J. (2015). The benefits of nature experience: Improved af fect and cognition. Landscape and Urban Planning, 138, 41–50. 
Callicott, J. B. (1987). Companion to a sand county almanac: Interpretive and critical essays. Univ of Wisconsin Press. Callicott, J. B. (1999). Beyond the land ethic: more essays in environmental philosophy. SUNY Press. 
Casey, E. S. (2003). Taking a glance at the environment: Preliminary thoughts on a promising topic. In C. S. Brown & T. Toadvine (Eds.), Eco-phenomenology: Back to the earth itself (p. 187-210). State University of New York Press, Albany. 
Chemero, A. (2003). An outline of a theory of affordances. Ecological Psychology, 15(2), 181–195. 
Chemero, A. (2009). Radical embodied cognitive science. MIT press. 
Cheng, J. C.-H., & Monroe, M. C. (2012). Connection to nature: Childrens affective attitude toward nature. Envi ronment and Behavior, 44(1), 31–49. 
Elliot, R. (1982). Faking nature. Inquiry, 25(1), 81–93. FAO. (2016). Global forest resources assessment 2015 (Tech. Rep.). Food and Agriculture Organization of the United Nations. 
Gibson, J. J. (1966). The senses considered as perceptual systems. Houghton Mifflin. 
Gibson, J. J. (1979). The ecological approach to visual per ception. Houghton Mifflin. 
Heft, H. (2001). Ecological psychology in context: James gibson, roger barker, and the legacy of william james’s rad ical empiricism. Lawrence Erlbaum Associates Publishers. 
Jacobs, D. M., & Michaels, C. F. (2007). Direct learning. Ecological psychology, 19(4), 321–349. 
Katz, E. (1992). The big lie: Human restoration of nature. Research in Philosophy and Technology, 12, 231-241. Leopold, A. (1949). Sand county almanac, and sketches here and there. Oxford University Press. 
Lucas, K., Brooks, M., Darnton, A., & Jones, J. E. (2008). Promoting pro-environmental behaviour: existing evidence and policy implications. Environmental Science & Policy, 11(5), 456–466. 
Reed, E. S. (1996). Encountering the world: Toward an ecological psychology. Oxford University Press. Rogers, B. (2017). Perception: A very short introduction. Oxford University Press. 
Russell, R., Guerry, A. D., Balvanera, P., Gould, R. K., Ba surto, X., Chan, K. M., . . . Tam, J. (2013). Humans and nature: how knowing and experiencing nature affect well being. Annual Review of Environment and Resources, 38, 473–502. 
Scarantino, A. (2003). Affordances explained. Philosophy of Science, 70(5), 949–961. 
Turvey, M. T. (1992). Affordances and prospective control: An outline of the ontology. Ecological psychology, 4(3), 173–187. 
Turvey, M. T., & Carello, C. (1986). The ecological approach to perceiving-acting: A pictorial essay. Acta Psychologica, 63(1-3), 133–155. 
Tyrvainen, L., Ojala, A., Korpela, K., Lanki, T., Tsunetsugu, ¨ Y., & Kagawa, T. (2014). The influence of urban green environments on stress relief measures: A field experiment. Journal of Environmental Psychology, 38, 1–9. 
UNEP. (2017). Towards a pollution-free planet background report (Tech. Rep.). United Nations Environment Pro gramme. 
Vining, J., & Ebreo, A. (1992). Predicting recycling be havior from global and specific environmental attitudes and changes in recycling opportunities. Journal of applied so cial psychology, 22(20), 1580–1607. 
Vogel, S. (2015). Thinking like a mall: Environmental phi losophy after the end of nature. MIT Press. 
Wells, N. M. (2000). At home with nature: Effects of green ness on childrens cognitive functioning. Environment and Behavior, 32(6), 775–795. 
White Jr, L. (1967). The historical roots of our ecologic crisis. Science, 155(3767), 1203–1207. 
WHO. (2017). World health statistics 2017: monitoring health for the sdgs, sustainable development goals (Tech. Rep.). World Health Organization. 
WWF. (2016). Living planet report 2016: Risk and resilience in a new era (Tech. Rep.). World Wide Fund For Nature. Zelenski, J. M., Dopko, R. L., & Capaldi, C. A. (2015). Coop 
eration is in our nature: Nature exposure may promote co operative and environmentally sustainable behavior. Jour nal of Environmental Psychology, 42, 24–31. 
1019
Emotion as a Form of Perception: Why William James was not a Jamesian 
Guilherme Sanches de Oliveira (sanchege@mail.uc.edu) 
Department of Philosophy, 2700 Campus Way, 206 McMicken Hall 
Cincinnati, OH 45221 USA 
Abstract 
Two main views have informed the literature on the psy chology of emotion in the past few decades. On one side, cognitivists identify emotions with processes such as judg ments, evaluations and appraisals. On the other side, advo cates of non-cognitive approaches leave the “intellectual” as pects of emotional experience out of the emotion itself, in stead identifying emotions with embodied processes involv ing physiological changes. Virtually everyone on either side of the cognitive/non-cognitive divide identify William James’ view, also known as the James-Lange theory, fully on the non cognitivist side. But this is a mistake. Re-interpreting James’ writings in its scientific context, this paper argues that he actu ally rejected the cognitive/non-cognitive divide, such that his view of emotions did not fit either side—that is, James was not a “Jamesian” in the sense the term is used in the literature. 
Keywords: emotion; cognitivism; James-Lange theory; per ception; sensation; physiological changes. 
Introduction 
It seems uncontroversial to say that emotions are often asso ciated with physiological events, such as changes in heartbeat rate, breathing, sweating, and bodily sensations and feelings of pleasure or discomfort. The real challenge is to explain exactly what the nature of the relationship between emo tions and such bodily changes is. Against the view that bod ily “disturbances” are the outcome of emotions—i.e. that they are the physical “manifestation” or “expression” of emo tions—William James famously proposed: “our feeling of [bodily] changes as they occur IS the emotion” (James 1884: 189-190, emphasis original). Over the years James’ thesis has received both praise and criticism. On the one hand, many scholars took James at face value and, inspired by his sugges tion, focused exclusively on investigating the bodily changes involved in specific emotional experiences—in this Jamesian approach, understanding physiological processes allows us to understand emotions because emotions just are those physi ological processes, after all. Many researchers, on the other hand, have found the Jamesian view to be inadequate, and rather than treating emotions as processes that are purely bod ily and non-cognitive, they have pursued the opposite path, equating emotions with cognitive processes like judgments, appraisals, and evaluations. The current paper re-examines William James’ original proposal and argues that it has been widely misunderstood by critics and Neo-Jamesian support ers alike. James’ account of emotions was not “Jamesian” in the sense of being ‘non-cognitive’, and this because his view questioned the cognitive/non-cognitive divide in the first place. This suggests that many of the objections and amend ments proposed in the literature over the years do not in fact apply to James’ account, which may have been closer to the mark than previously appreciated. 
The Cognitive/Non-Cognitive Divide in Emotion Theory and Research 
In his comprehensive overview of the psychological litera ture on emotions, Randolph Cornelius (1996) identifies four main research traditions. The first tradition Cornelius lists is the Darwinian approach following Charles Darwin’s (1872) evolutionary account of emotional expression, which seeks to understand human emotions biologically, as universal ex pressions that are continuous with the behaviors exhibited by non-human animals. The second tradition in Cornelius’ list is the Jamesian view, inspired by William James (1884), and de scribed as equating emotions with bodily responses, echoing “James’s insistence that the experience of emotion is primar ily the experience of bodily changes” (Cornelius 1996: 12). The third tradition is Cognitivism, which views emotions as necessarily cognitively-based, and arising from judgments or appraisals individuals make of what goes on in their environ ment. Lastly, the fourth tradition listed by Cornelius is Social Constructivism, according to which emotions are best under stood from a social level of analysis, as culturally-based and unique to particular social contexts rather than biological and, for that reason, universal. 
Cornelius discusses the possibility, suggested by Plutchik (1980), of considering neurological research as a tradition of its own. Yet, he decides against adding it as a fifth tradition because he sees this line of research on the neurophysiology of emotions as being more of a methodological approach that can inform and complement work in the other four traditions. But similar reasons would justify characterizing the psychol ogy of emotion as divided into fewer than four categories. The four traditions Cornelius lists can reasonably collapse into only two general approaches. One such division would be between biological and cultural approaches: the Jame sian view coincides with the Darwinian view in understand ing emotions in functional terms, as biological adaptations of organisms to their environments; on the opposite camp, the Cognitivist and Social Constructivist views of emotion can coincide insofar as the cognitive judgments giving rise to an individual’s emotional experience is shaped by that individ ual’s cultural context. At the same time, however, it seems equally valid to divide the four different traditions according to the question each asks: in this perspective, the Darwinian and Social Constructivist approaches fall in the same camp as they deal most centrally with the question of how universal, if at all, emotions are, whereas the Jamesian and Cognitive approaches fall on a distinct side as they are primarily con cerned with determining, more basically, what emotions are. So while I recognize at the outset the plausibility of view 
1020
ing contributions to the psychological literature in terms of a biological/cultural divide, this article’s focus on the Jame sian view motivates adopting a distinct characterization and focusing instead on the contrast between cognitive and non cognitive approaches as competing answers to the question of what an emotion is. 
Characterizing the Divide 
Briefly considering examples of work in the cognitive/non cognitive divide will help make clearer what the disagreement is about—it will also make explicit the typical understanding of William James’ view of emotions that is assumed by critics and Neo-Jamesians alike. 
Robert Solomon’s influential article “A Subjective Theory of the Passions” (1976) gives a good illustration of the cogni tivist approach. Solomon’s account of emotions as judgments is based on (1) a distinction between emotions and feelings, and (2) a distinction between emotions and other kinds of judgments. First, Solomon acknowledges that feelings and sensations may be intimately associated with emotions, but he argues that this association is not straightforward: feel ings are not all there is to an emotion, and, at the same time, not all feelings are accompanied by an emotion. In contrast with both feelings and moods, Solomon claims that emotions are about something, that is, they have an intentional object: feelings are about nothing at all, moods are about nothing in particular, yet one is never simply angry, but rather “angry at someone for something” (Solomon 1976/2003: 57). Second, even though he takes the intentionality of emotions to be what differentiates them from feelings and moods, Solomon recog nizes that not every intentional state is emotionally valenced. In his view, emotions are evaluative judgments, but “not all evaluative judgments are emotions” (p. 69): when one adju dicates between the competing claims of two friends who are having an argument, one’s judgment can be as detached and “cold” as the conclusion that one fruit at the grocery store is riper than another. Emotions, by contrast, are judgments about objects that matter, objects we are deeply and person ally invested in: “The objects of an emotion are objects of great personal importance to us” (p. 61). Solomon further adds: “An emotion is a basic judgment about our Selves and our place in our world, the projection of the values and ide als, structures and mythologies, according to which we live and through which we experience our lives” (p. 68). In this sense, the judgment that one friend is right and the other is wrong can be emotional if their disagreement matters to us on a personal level, if it connects to our sense of identity and meaning more generally; but the judgment that one banana is ripe and the other isn’t typically does not matter to us in the same way and, for this reason, the judgment does not typi cally amount to an emotion. In short, while for Solomon not all judgments will be emotionally valenced, all emotions are judgments. 
This and other cognitivist views of emotions (as judgments, appraisals, or evaluations) were proposed as alternatives to the opposite side of the divide, where we find the James 
Lange Theory, as the Jamesian view is also known. As al ready suggested, the canonical understanding of James’ the ory is that it postulates that emotions are just feelings of bod ily changes, or sensations of physiological processes, and that “intellectual” processes are not part of the emotion it self. Taking this to be James’ view, both cognitivists and self declared neo-Jamesians criticize his theory for the obvious reason that it results in emotional experiences becoming ex periences of bodily processes rather than experiences of the world. Among the critics, Solomon summarizes James view as follows: 
in “What Is an Emotion?” James answered his question with his theory: an emotion is the perception of a vis ceral disturbance brought about by a traumatic percep tion, for example, seeing a bear leap out in front of you or coming across a bucket filled with blood. The theory (developed simultaneously by C. G. Lange in Europe) is now appropriately called the “Jamesian (James-Lange) theory of emotion.” It is, I shall argue, as misleading as it is pervasive. (Solomon 1984/2003: 76) 
On the opposite side of the divide, Antonio Damasio’s work provides a good example of the neo-Jamesian view. Damasio recognizes the importance of bringing the body in as an essential component of emotional experience, but, like others, he complains that James seems to take this claim too far: “The main problem some have had with James’s view is not so much his stripping emotion down to a process that in volved the body, [...] but rather that he gave little or no weight to the process of evaluating mentally the situation that causes the emotion” (Damasio 1994: 129-130). And Damasio com plements, summarizing James’ view in the typical fashion: 
“James postulated a basic mechanism in which partic ular stimuli in the environment excite, by means of an innately set and inflexible mechanism, a specific pattern of body reaction. There was no need to evaluate the sig nificance of the stimuli in order for the reaction to occur” (Damasio 1994: 130). 
This understanding of James’ view, shared by cognitivists and (neo-Jamesian) non-cognitivists alike, is mistaken. This traditional rendering of James’ theory of emotion misses a distinction, central to James’ scientific approach to psychol ogy, between sensation and perception. Re-examining James’ thought in light of the rival psychological theory of structural ism, and with a better grasp of the richer sense of percep tion at play in James’ theory, reveals James’ account not to fit neatly on either side of the cognitivist/non-cognitivist divide. This fresh perspective motivates the conclusion that James did not endorse the James-Lange Theory as it is commonly described in the literature. Moreover, this re-evaluation of James’ account in its context reveals that the view for which James has been criticized by cogntivists and praised by Neo Jamesians is in fact closer to the perspective James meant to reject than to the one he actually proposed. 
1021
Contextualizing James’ Psychology 
The past couple of decades has seen a few attempts to re evaluate James’ thought, particularly his theory of emotion. Phoebe Ellsworth (1994), for example, has provided an in teresting, if controversial, interpretation of James as spous ing a “labeling” view of the Shachterian style (Schachter and Singer 1962, Schachter 1964): “The bodily processes com bine with the perception of the object to produce the emo tion. In this respect, James’s theory resembles Schachter and Singer’s (1962) idea that emotion is a combination of cognitive and physiological responses” (Ellsworth 1994: 223). More recently, Matthew Ratcliffe (2005) has used James’ later philosophical writings to shed light on his earlier work on emotions, emphasizing how the pragmatist and phe nomenological aspects of James’ thought incorporate affect into intentionality and turn emotion into the kind of “world making” process that cognitivists take it to be. I agree with these and others insofar as I share the feeling that James has been misunderstood. But rather than anachronistically bring ing in later ideas (whether James’ own or others’), I believe that we can find already in James’ early scientific work the tools to better understand his view of emotion. 
The key aspect that most cognitivists and neo-Jamesians alike miss in James’ thought is the distinction between sen sation and perception, which was at the center of the clash between functionalist and structuralist psychology. Although James never explicitly accepted the label “functionalist,” his scientific work was largely framed in opposition to the struc turalist approach of figures like German physiologist Wilhelm Wundt and his American pupil Edward Titchener. One way to frame the distinction is as between, on the one hand, a passive process in which stimuli impinge upon our sense or gans (this is sensation), and, on the other hand, an active pro cess in which an organism engages in exploratory behavior as it attends to its environment (this is perception). Structural ist experimental psychology was predicated on the view that all psychological phenomena, including perception, are built through the addition or combination of simple stimulations or sensations. In contrast, James took “pure sensation” to never occur in the ordinary experience of adult humans. 
The view of perception I have alluded to above, as a form of active exploratory engagement with the environment, res onates with the perspective put forward by J. J. Gibson, the James-inspired functionalist founder of Ecological Psychol ogy. Gibson proposed that the senses are not “channels of sensation” but “perceptual systems” that pick up information for action: “Sensation is not a prerequisite of perception, and sense impressions not the ‘raw data’ of perception—that is, they are not all that is given for perception” (Gibson 1966: 48). Gibson further distinguishes perception and sensation in terms of being active and passive: “perceiving is an act, not a response, an act of attention, not a triggered impression, an achievement, not a reflex” (p. 149), and further, “Perceiv ing is an achievement of the individual, not an appearance in the theater of his consciousness. It is a keeping-in-touch 
with the world, an experiencing of things rather than a hav ing of experiences” (p. 239). Although there is no room for doubt about the influence of William James’ work in Gibson’s thought (see, e.g., Heft 2001 and Chemero 2009), it is open to question the extent to which James would have agreed with Gibson. Still, at least when it comes to this distinction be tween sensation and perception, textual evidence from James supports the idea that Gibson was on the right track. Notice how James himself draws the distinction between sensation and perception: 
The nearer the object cognized comes to being a sim ple quality like ‘hot,’ ‘cold,’ ‘red,’ ‘noise,’ ‘pain,’ ap prehended irrelatively to other things, the more the state of mind approaches pure sensation. The fuller of rela tions the object is, on the contrary; the more it is some thing classed, located, measured, compared, assigned to a function, etc., etc.; the more unreservedly do we call the state of mind a perception, and the relatively smaller is the part in it which sensation plays. (James 1890: 1) 
But, James says, in ordinary life there is no pure apprehension of sense stimuli, no pure sensation—our engagement with the world always involves more than meets the eye: “Pure sensa tions can only be realized in the earliest days of life. They are all but impossible to adults with memories and stores of associations acquired” (James 1890: 7). And further: 
A PURE sensation we saw above (...) to be an abstrac tion never realized in adult life. Any quality of a thing which affects our sense-organs does also more than that: it arouses processes in the hemispheres which are due to the organization of that organ by past experiences, and the result of which in consciousness are commonly de scribed as ideas which the sensation suggests. (James 1890: 76) 
Structuralists like Wundt and Titchener held the opposite view, assuming that pure or simple sensations are not only possible, but are actually required for perception. They took a reductionist approach to psychology, and viewed the mind as involving additive or associative processes, with basic or atomic sensory “elements” (pure sensations) combining to form complex “psychical compounds” (such as perception). The following quote illustrates this view: 
All the contents of psychical experience are of a com posite character. (...) The elements of the objective con tents we call sensational elements, or simply sensations: such are a tone, or a particular sensation of hot, cold, or light, when we neglect for the moment all the con nections of these sensations with others, and all their’ spacial and temporal relations. (...) The actual contents of psychical experience always consist of various com binations of sensational and affective elements, so that the specific character of the simple psychical processes depends for the most part not on the nature of these ele ments so much as on their union into composite psychi cal compounds. (Wundt 1897: 29, emphasis original) 
1022
The structuralists’ view of the mind as operating through the combination of basic “sensational elements” or “sensa tions” informed their approach to experimental psychology, particularly motivating the development of reaction-time ex periments. The idea was that if the mind operates by com bining basic elements, then we can measure the complexity of various mental operations by checking how long they take: the more basic, the faster; the more complex, the more el ements need to be combined and the longer it takes. Both the conceptual framework and the experimental approach of structuralism remain very popular in cognitive science—even if we now complement reaction-time experiments with brain imaging techniques to see what parts of the brain activate when we impose a given sensory stimulus on the subject. But it is precisely the assumption of this structuralist view of per ception as sensation-based that, I suggest, led to the current misunderstanding of James’ theory by cognitivists and neo Jamesians alike. 
Distinguishing James’ View of Emotion from the “Jamesian” View of Emotion 
As seen in the previous section, James and Wundt had very different views of the nature of psychological phenomena, in cluding the nature of perception as distinct from sensations (in the case of James) or as built upon combinations of pure elementary sensations (in the case of Wundt). This section will discuss in more detail how this conflation of sensation and perception has shaped the common misunderstanding of James’ view. The section then concludes with a sketch of what, in light of the theoretical background discussed here, we can more adequately interpret James to have meant. 
The “Jamesian” View: Emotion as Proprioception 
The fuller version James’ thesis that is usually quoted in the literature is: 
the bodily changes follow directly the PERCEPTION of the exciting fact, and (...) our feeling of the same changes as they occur IS the emotion 
(James 1884: 189-190, emphasis original). 
Equating perception with sensation (or taking perception to be the building up from, or combination of, pure sensations), as was proposed by structuralists and is still the mainstream view in cognitive science today, leads to a misunderstanding of the two parts of James’ claim. The first part is misunder stood as saying something like bodily changes follow directly from pure sensation—for example the sensations involved in seeing a bear, that is, having discrete visual impressions or sensations of certain color patterns, appearance of fur, size, etc, and adding up all those elements to inform the recogni tion of a bear. In turn, the second claim is misinterpreted as stating that the pure sensation of such bodily changes is the emotion: in other words, proprioception is the emotion. 
As already noted, in assuming that perception is a kind of passive pure sensation of bodily disturbances, Solomon 
seems to think that James views emotions as devoid of content and meaning. Prinz (a self-avowed neo-Jamesian) misrepre sents James in a very similar way, as viewing emotions as “perceptions of the body”: “I present evidence in support of William James’s conjecture that emotions are perceptions of patterned changes in the body” (Prinz 2005: 9). Prinz claims further: 
James (...) tried to reduce emotions to a class of feel ings that everyone is already committed to: feelings of changes in the body. When emotions occur, our bodies undergo various perturbations. These changes include alterations in our circulatory, respiratory, and muscu loskeletal systems. Our hearts race or slow. Our breath ing relaxes or becomes strained, blood vessels constrict or dilate, our facial expressions transform, and so on. Most people assume that these changes are the effects of our emotions, but James argues that this is backwards. Our bodies change, and an emotion ‘just is’ the feeling of that change. (Prinz 2005: 12) 
Both the cognitivist and the neo-Jamesian, then, seem to think that James took emotions to be sensations of bodily changes, or internal sensory inputs, as a result of misunder standing what he meant by “perception”—i.e., as a result of assuming the structuralist view that perception is pure sen sation, rather than the functionalist view of perception as an active engagement of the organism with the environment that is shaped by past experiences, learning, habituation, etc. 
James’ View: Emotion as a Form of Perception 
Beyond mistaking James’ and the structuralists’ views of ‘perception’, an additional linguistic misunderstanding leads to the error of taking James’ view as defining ‘emotions’ as our sensing our own physiological changes. This error can be observed in the common claim that, in James’ theory, emo tions are “feelings of bodily changes”: “The James-Lange theory identifies emotions with feelings of bodily changes” (Prinz 2004: 224); and “On the concept James defined (...) the feelings an emotion consists in [are] nothing over and above the feelings of bodily changes” (Deigh 2010: 25). No tice, however, that James did not speak of emotions as “feel ings” (in the plural) that are “of bodily changes” (that is, feel ings whose object was the body and its changes). James’ claim, instead, was that “our feeling of [bodily changes] as they occur is the emotion” (1884: 189-190). There is a fine but important distinction in the grammatical function of ‘of’ in these two uses, mirrored in the following constructions: 
1. The mayor of Cincinnati 
2. The city of Cincinnati 
In [1], ‘of’ indicates a relation between two distinct entities (one is a person, the other a city), while in [2] ‘of’ connects two nouns that refer to a single thing (i.e., the city). The difference between these two constructions is similar to that 
1023
between “feelings of bodily changes” (the usual description of the Jamesian view) and “our feeling of bodily changes” (James’ actual claim). The former (the “Jamesian” view) equates emotions with feelings and then it specifies the dis tinct entities which are the object of those feelings (namely, bodily changes). James’ claim, in contrast, parallels con struction [2] above, equating emotion with a single entity: “our feeling of bodily changes” just means “our having bod ily changes” or “our undergoing bodily changes”. The “Jame sian” view as described in parallel with construction [1] treats emotion as a psychological experience the object of which is the body: to have an emotion is to feel changes in one’s body (e.g., to be sad is to sense our eyes producing tears). James’ claim, in contrast, describes emotions as an experi ence of the world rather than of our bodies: in this view, to have an emotion is to experience the world body-changingly or while undergoing bodily changes (e.g., to be sad is to expe rience the world tearfully). James’ description of an emotion as “our feeling of bodily changes” suggests that an emotion is our having bodily changes, not our having feelings/sensations that are of bodily changes. In this light, instead of describ ing emotions (in the plural) as “feelings of bodily changes,” James might make his claim in the plural form by saying sim ply that emotions are our feeling (of) bodily changes. 
The James-Lange Theory (the “Jamesian” view) has come to be understood as stating that emotions are feel ings/sensations of bodily changes (which in turn result from sensations of discrete external stimuli). Yet, there is good reason to understand James as claiming that our having bod ily changes informs our perception of objects in the envi ronment—e.g. enabling our adaptation to it by detecting good and danger—and that this bodily process is the emo tion. Given James’ richer sense of perception (in contrast with “pure sensations” or their combination) and in light of the scientific alternatives James’ theory was intended to op pose, a reevaluation of the Jamesian view of emotion is called for. From what I have explored in this paper, we can con clude that not only did James not hold a “Jamesian” view of emotion as it is traditionally framed in the literature, but also that the view usually associated with the James-Lange theory by both cogntivists and Neo-Jamesians is actually closer to a structuralist perspective than to the views James actually held. Rather than equating emotion with proprioception—i.e., sen sations of bodily changes—the scientific framework put for ward by James motivates seeing emotion as a form of per ception of the world—a way in which our body informs and constitutes our engagement with objects and events in the en vironment. In this view, emotions are forms of perception, not in the sense of being “perceptions of bodily changes” (where “perception” would mean the same as “sensation”), but rather in the richer sense of perception, as necessarily intentional and challenging the very divide between the cognitive and the non-cognitive. The reinterpretation proposed here provides a more accurate understanding of William James’ work and, by extension, of the historical foundations and progression of 
psychological science. This reinterpretation is also of con temporary interest insofar as it makes James’ view directly relevant to current debates about embodied cognition, percep tion, and affectivity (e.g., Chemero 2009, Gallagher 2017). 
References 
Chemero, A. (2009). Radical embodied cognitive science. MIT press. 
Cornelius, R. R. (1996). The science of emotion: Research and tradition in the psychology of emotions. Prentice-Hall. Damasio, A. (1994). ´ Descartes’ error: Emotion, reason, and the human brain. Avon Books. 
Darwin, C. (1872). The expression of emotion in animals and man. John Murray. 
Deigh, J. (2010). Concepts of emotions in modern philosophy and psychology. In P. Goldie (Ed.), The oxford handbook of philosophy of emotion. Oxford University Press. 
Ellsworth, P. C. (1994). William james and emotion: is a century of fame worth a century of misunderstanding? Psy chological review, 101(2), 222. 
Gallagher, S. (2017). Enactivist interventions: Rethinking the mind. Oxford University Press. 
Gibson, J. J. (1966). The senses considered as perceptual systems. Houghton Mifflin. 
Heft, H. (2001). Ecological psychology in context: James gibson, roger barker, and the legacy of william james’s rad ical empiricism. Lawrence Erlbaum Associates Publishers. 
James, W. (1884). What is an emotion? Mind, 9(34), 188– 205. 
James, W. (1890). The principles of psychology (Vol. 2). Henry Holt and Company. 
Plutchik, R. (1980). Emotion: A psychoevolutionary synthe sis. Harper and Row. 
Prinz, J. (2005). Are emotions feelings? Journal of Con sciousness Studies, 12(8-9), 9–25. 
Prinz, J. J. (2004). Gut reactions: A perceptual theory of emotion. Oxford University Press. 
Ratcliffe, M. (2005). William james on emotion and inten tionality. International Journal of Philosophical Studies, 13(2), 179–202. 
Schachter, S. (1964). The interaction of cognitive and phys iological determinants of emotional state1. In Advances in experimental social psychology (Vol. 1, pp. 49–80). Else vier. 
Schachter, S., & Singer, J. (1962). Cognitive, social, and physiological determinants of emotional state. Psychologi cal review, 69(5), 379. 
Solomon, R. C. (1976/2003). A subjective theory of the pas sions. In S. Leighton (Ed.), Philosophy and the emotions: A reader. Broadview Press. (Originally published in Robert Solomon (1976) The Passions. Doubleday and Company.) 
Solomon, R. C. (1984/2003). Getting angry: The jamesian theory of emotion in anthropology. In R. C. Solomon (Ed.), Not passion’s slave: Emotions and choice. Oxford Univer sity Press. 
1024
Using Deep-Learning Representations of Complex Natural Stimuli as Input to  Psychological Models of Classification 
Craig A. Sanders (craasand@indiana.edu) 
Robert M. Nosofsky (nosofsky@indiana.edu) 
Department of Psychological and Brain Sciences, Indiana University 
1101 E. Tenth Street, Bloomington, IN., 47405 USA 
Abstract 
Tests of formal models of human categorization have  traditionally been restricted to artificial categories because  deriving psychological representations for large numbers of  natural stimuli has been an intractable task. We show that deep  learning may be used to solve this problem. We train an  ensemble of convolutional neural networks (CNNs) to produce  the multidimensional scaling (MDS) coordinates of images of rocks. We then show that not only are the CNNs able to predict  the MDS coordinates of a held-out test set of rocks, but that the  CNN-derived representations can be used in combination with a formal psychological model to predict human categorization  behavior on a completely new set of rocks. 
Keywords: deep learning; multidimensional scaling;  categorization; psychological representations 
Introduction 
Numerous sophisticated formal models of human category  learning and representation have been proposed in the field  of cognitive science (for a comprehensive review, see Pothos  and Wills, 2011). However, almost all rigorous quantitative  tests of such models have been in highly simplified domains  involving artificial category structures tested in laboratory experiments. In recent work, Nosofsky, Sanders and  McDaniel (2018; see also Nosofsky, et al., 2017a) scaled up  the application of such models by testing their ability to  account for learning and generalization of rock classifications  in the geologic sciences. Rock categories provide good  examples of complex, high-dimensional category structures  found in the natural world, so provide an intriguing and  challenging test of the candidate models in the field. 
 Nosofsky et al.’s (2018) study focused on a well-known  exemplar model of classification known as the generalized  context model (GCM; Nosofsky, 1986). According to the  GCM, people represent categories by storing individual  exemplars of the categories in memory, and classify objects  based on their similarity to the stored exemplars. 
 To apply the GCM, one needs to specify the  multidimensional feature space in which the to-be-classified  objects are embedded. In numerous past tests of the model,  the derivation of the feature space was straightforward,  because the objects used in the artificial category-learning  experiments were simple stimuli composed of a small  number of highly salient dimensions (e.g., geometric forms  varying in shape, color, angle, and so forth). In a real-world  category domain such as rocks, however, the derivation of the  feature space becomes a highly ambitious task. The stimuli  that compose such categories vary along a very large number  of dimensions, many of which may be difficult to discern. 
 Thus, as a prerequisite to testing the exemplar model in the  rock-classification domain, Nosofsky et al. (2017a) and  Nosofsky, Sanders, Meagher and Douglas (2017b) engaged  in extensive similarity-scaling studies of the rock stimuli. In  these studies, observers provided similarity judgments  among pairs of items drawn from a set composed of 360 rock  pictures (10 categories of each of the broad divisions of  igneous, metamorphic and sedimentary rocks, with 12  samples of each of the categories). Multidimensional scaling  (MDS) (Shepard, 1980) was then used to model the similarity  judgments to derive the rock feature space. In brief, in MDS,  each object is represented as a point in a multidimensional  space, with similarity presumed to be a decreasing function  of distance in the space. A virtue of the MDS technique is that  beyond summarizing large sets of similarity-judgment data,  one can inspect the derived space to determine the  psychological dimensions that compose the objects.  
 In the case of the MDS analysis of the rocks, the results  were remarkably straightforward: An 8-dimensional solution  provided a good account of the similarity structure of the 360  rock tokens that composed the 30 rock categories, and the  derived dimensions could be interpreted in terms of:  lightness/darkness of color, average grain size, shininess,  roughness/smoothness, organization, chromaticity, hue, and  shape-related components. Displays of the derived MDS  solution are provided in the website (https://osf.io/w64fv/)  associated with Nosofsky et al.’s (2017b) study. Perhaps  most important, when used in combination with the MDS  solution, the GCM was able to achieve good first-order  quantitative predictions of rock-classification learning and  generalization across a variety of conditions in which the  nature of the training exemplars was manipulated (for details,  see Nosofsky et al., 2018; for related work in the domain of  semantic classification, see, e.g., Storms et al., 2000).  
 Despite its virtues, the MDS approach also has some limitations. One limitation is a practical one: In situations  involving the scaling of large numbers of stimuli, deriving  MDS solutions from similarity-judgment data requires the  collection of a prohibitive amount of empirical data—for  example, there are over 100,000 cells in the 360x360  similarity-judgment matrix used in Nosofsky et al.’s (2017b)  study. If the goal is to position even larger numbers of stimuli  in the high-dimensional feature space using these techniques,  then the traditional approach becomes intractable. 
 Thus, in the present work our goal was to begin to test  automated methods for deriving the natural-category feature  space. Our key idea involves a novel integration in which  MDS methods are combined with the use of deep learning  
1025
convolutional neural networks (CNNs; e.g., Lecun et al.,  2015). As is well known, CNNs have been used successfully  to predict the classification of natural images from large data  bases. In a typical CNN architecture, elementary visual inputs  are converted to higher-order features via connections to a  series of hidden convolutional layers and pooling layers, which then feed into fully connected layers and a final output  layer that generates the classification responses. Recent  research has shown that unlike classic computer vision  algorithms, CNNs can be used to predict human category and  typicality judgments regarding visual stimuli (e.g., Lake et  al., 2015). Other work has advanced the idea that the deep  features extracted after training the networks to predict visual  categories can serve as candidates for the psychological  feature-representations of the stimuli. Those deep-level  features can then be used to predict human similarity  judgments (Peterson et al., 2017; see also Rumelhart & Todd,  1993) or used as input to psychological models of  classification (Battleday, Peterson, & Griffiths, 2017). 
 Despite these preliminary successes, the extent to which  CNNs truly capture the detailed nature of human  classification learning remains unknown. Thus, in the present  work, we adopt an approach that is complementary to the past  applications. Rather than training CNNs to classify objects  into categories, we instead train them to predict the  dimension values of individual exemplars derived from  traditional MDS methods. Once the CNN is trained in this  manner, new stimuli can be presented to the CNN and it can  be used to automatically produce the coordinate values of the  stimuli in the multidimensional psychological feature space.  Thus, an unlimited number of stimuli from complex  naturalistic domains can be scaled in this manner. The  derived coordinate values can then be used in combination  with formal models such as the GCM to predict  categorization. In the remainder of this article, we explain the  proposed procedure in depth, and present preliminary tests of  the approach in the domain of rock classification.  
Deep Learning Procedure 
The basic plan of action for our deep learning procedure was  to train CNNs to take images of rocks as input and yield their  psychological representations as output. In this section we  describe the specific data set, CNN architecture, and training  procedure that we used. All procedures described in this  section were implemented using the Keras Python package  and Tensorflow (Abadi et al., 2016).  
Data Set  
We used Nosofsky et al.’s (2017b) data set to train our CNNs.  To reiterate, this data set consists of 360 images of rocks  belonging to 30 different categories along with each rock’s 8- dimensionsal MDS coordinates. While the naïve approach  would be to train and evaluate each network using all 360  images, CNNs may have millions of trainable parameters,  and thus are prone to overfitting to noise and failing to  generalize to new data. Therefore, we needed a means to  compare the CNNs’ generalization performance and not just  
their training performance. To this end, we split the data into  three separate sets: a training set, a validation set, and a test  set. CNNs were trained to minimize error on the training set,  and each network’s error on the validation set was computed  to find the CNNs with the best generalization performance. 
Finally, these networks’ error on the test set was computed to avoid overfitting to the validation set and to gain an unbiased  estimate of their ability to generalize to completely new data.  The training set was formed by randomly sampling 6 of the  12 rock tokens in each category, and the remaining tokens  were evenly split between the validation and test sets.  Therefore, there were 180 images in the training set, and 90  images in both the validation and test sets. 
CNN Architecture 
Our rocks data set is quite small for a deep-learning data set.  By comparison, deep CNNs are often trained to perform  image classification on the ILSVRC data set, which consists  of over one-million images belonging to 1000 different  categories (Russakovsky et al., 2015). Networks trained on  such large data sets are able to learn much more robust and  complex features than those trained on smaller data sets.  Therefore, instead of training our CNNs from scratch, we  used pre-trained networks as a starting point, a procedure  known as transfer learning (Yosinski, et al., 2014).  
 We downloaded an implementation of ResNet50 (He,  Zhang, Ren, & Sun, 2016) that was pre-trained to perform  image classification on the ILSVRC data set (other popular  network architectures were also considered but were found to  not perform as well). To adapt this network for our own  purposes, we removed its topmost layers and replaced them  with a new set of untrained layers so that we could take  advantage of the low-level features trained on big data, while  still being able to learn high-level features relevant to our  specific task. More specifically, we kept each layer up to the  final pooling layer, and then used global average pooling to  convert the activation of the pooling layer into a vector that  could be used as input into a series of fully-connected layers.  For each of these layers, dropout (Srivastava, et al., 2014) and  batch normalization (Ioffe & Szegedy, 2015) were used to  improve generalization and accelerate learning. The dropout  rate was set to 0.5, and the batch normalization parameters  were left at their default values. Rectified linear units (ReLU; Nair & Hinton, 2010) were used as the activation functions.  These layers fed into a final output layer consisting of 8 linear  units corresponding to the 8 MDS dimensions. 
Training Procedure 
The objective function we sought to minimize was the mean  squared error (MSE) between the network’s output and the  MDS coordinates of the rocks in the training set. To  artificially increase the size of the training set we performed  data augmentation: training images were randomly flipped,  rotated, cropped, and stretched/shrunk every time they were  presented to the network. 
 Training took place in two steps. During the first step we  kept the parameters of the pre-trained CNN fixed and only  
1026