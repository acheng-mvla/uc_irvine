affect interpersonal coordination, as in Marmelat &  Delignières (2012), and the strength of response coupling  between individuals and dyads influenced measures of  complexity matching. 
A more complete examination of the link between  coupling and complexity matching during bimanual  coordination will require further analysis and  experimentation. First, continuing to analysis the data using  methods of non-linear statistics will help to clarify the way  in which multiple limbs coordinate in space and time.  Examining the relative phase relationship between the  actions produced by individuals and dyads may reveal the  underlying structure leading to the differing degrees of  complexity matching observed in this task.  
Additionally, another coupling condition could further our  understanding of the dependent nature of coupling in  coordinated behaviors. Variability in target locations was  more predictable with dependent drift compared with  random drift. Therefore, it is unclear whether the observed  effects of dependent drift were due to the interactions  between hands that created predictable target locations, or  the predictability itself. We can test these competing  hypotheses by testing a condition in which participants  respond to targets whose locations are “played back” from a  previously recorded block of dependent drift responses. If  predictability is the underlying factor at play, then the  playback condition should yield a similar pattern of results  as the dependent drift condition. Alternatively, if  collaborative interaction is the underlying factor, then the  playback condition should be similar to the random drift  condition. 
Finally, further advances may come from further  investigation into the conditions that manifest  complementary coordination instead of simpler forms of  coordination like synchrony and alignment. Other studies  have found performance benefits from synchrony and  alignment (van der Wel, Knoblich, & Sebanz, 2011), and understanding the principles and factors underlying these  differing forms of coordination will help us know when it is  time to swing to the beat together, or march to the beat of  your own drum. 
References 
Abney, D. H., Paxton, A., Dale, R., & Kello, C. T. (2014).  Complexity matching in dyadic conversation. Journal of  Experimental Psychology: General, 143(6), 2304. 
Amazeen, E.L., DaSilva, F., Amazeen, P. G. (2008). Visual spatial and anatomical constraints interact in a bimanual  coordination task with transformed visual feedback.  Experimental Brain Research, 191(1), 13–24.  
Coey, C., Varlet, M., Schmidt, R. C., & Richardson, M. J.  (2011). Effects of movement stability and congruency on  the emergence of spontaneous interpersonal  coordination. Experimental brain research, 211(3-4),  483-493. 
Haken, H., Kelso, J. S., & Bunz, H. (1985). A theoretical  model of phase transitions in human hand  movements. Biological cybernetics, 51(5), 347-356. 
Jordan, J. S., Schloesser, D. S., Bai, J., & Abney, D. (2017).  Multi‐Scale Contingencies During Individual and Joint  Action. Topics in cognitive science. 
Kloos, H., & Van Orden, G. C. (2009). Soft-assembled  mechanisms for the unified theory. Toward a unified  theory of development: Connectionism and dynamic  systems theory re-considered, 253-267. 
Knoblich, G., & Jordan, J. S. (2003). Action coordination in  groups and individuals: learning anticipatory  control. Journal of Experimental Psychology: Learning,  Memory, and Cognition, 29(5), 1006. 
Marmelat, V., & Delignières, D. (2012). Strong  anticipation: complexity matching in interpersonal coordination. Experimental Brain Research, 222(1-2),  137-148.  
Mechsner, F., Kerzel, D., Knoblich, G., Prinz, W. (2001).  Perceptual basis of bimanual coordination. Nature, 414, 69–73. 
Rosenbaum, D. A., Dawson, A. M., & Challis, J. H. (2006).  Haptic tracking permits bimanual independence. Journal  of Experimental Psychology: Human Perception and  Performance, 32(5), 1266. 
Schmidt, R. C., Morr, S., Fitzpatrick, P., & Richardson, M.  J. (2012). Measuring the dynamics of interactional  synchrony. Journal of Nonverbal Behavior, 36(4), 263- 279. 
Stephen, D. G., Stepp, N., Dixon, J. A., & Turvey, M. T.  (2008). Strong anticipation: Sensitivity to long-range  correlations in synchronization behavior. Physica A:  Statistical Mechanics and its Applications, 387(21), 5271- 
5278. 
van der Wel, R. P., Knoblich, G., & Sebanz, N. (2011). Let  the force be with us: dyads exploit haptic coupling for  coordination. Journal of Experimental Psychology:  Human Perception and Performance, 37(5), 1420. 
Van Orden, G. C., Kello, C. T., & Holden, J. G. (2010).  Situated behavior and the place of measurement in  psychological theory. Ecological Psychology, 22(1), 24- 43. 
West, B. J., Geneston, E. L., & Grigolini, P. (2008).  Maximizing information exchange between complex  networks. Physics Reports, 468(1-3), 1-99. 
Acknowledgements 
Thank you to Vivien Marmelat at the University of  Nebraska Omaha for his thoughtful input and contributions  to this project. Also, thanks to the National Science  Foundation, Research Traineeship-DESE Intelligent  Adaptive Systems: Training computational and data 
analytic skills for academia and industry (#1633722), for  their support. 
2447
Complexity Reduction in the Negotiation of New Lexical Conventions William Schueller (william.schueller@inria.fr)1, 2, Vittorio Loreto3, 4, 5, and Pierre-Yves Oudeyer2 
1University of Bordeaux, Bordeaux, France 
2INRIA Bordeaux Sud-Ouest/ Ensta ParisTech : Flowers Project-team, Bordeaux, France 3SONY Computer Science Lab, Paris, France 
4Physics Dpt., Sapienza University of Rome, Rome, Italy 
5Complexity Science Hub Vienna (CSHV), Vienna, Austria 
Abstract 
In the process of collectively inventing new words for new con cepts in a population, conflicts can quickly become numerous, in the form of synonymy and homonymy. Remembering all of them could cost too much memory, and remembering too few may slow down the overall process. Is there an efficient be havior that could help balance the two? The Naming Game is a multi-agent computational model for the emergence of lan guage, focusing on the negotiation of new lexical conventions, where a common lexicon self-organizes but going through a phase of high complexity. Previous work has been done on the control of complexity growth in this particular model, by allowing agents to actively choose what they talk about. How ever, those strategies were relying on ad hoc heuristics highly dependent on fine-tuning of parameters. We define here a new principled measure and a new strategy, based on the beliefs of each agent on the global state of the population. The mea sure does not rely on heavy computation, and is cognitively plausible. The new strategy yields an efficient control of com plexity growth, along with a faster agreement process. Also, we show that short-term memory is enough to build relevant beliefs about the global lexicon. 
Keywords: language emergence, active learning, multi-agent model, control of complexity growth 
Motivations 
Lexical conventions constitute an important element of social interactions. They can emerge, evolve, or be learnt within a population, without necessarily having a centralized control. In other words, they can be negotiated through local inter actions between individuals. In practice, this happens con tinuously in human societies, being the spread of new words and conventions, the acquisition of those conventions by in fants or other learners, or even the emergence of new forms of communication. Despite the high complexity of the processes involved, humans deal with these issues quite efficiently. 
Learning of high complexity tasks in individuals can in general be facilitated by an active control of the complexity of learning situations , often driven by intrinsic motivation, like for example maximization of the learning progress (Gottlieb, Oudeyer, Lopes, & Baranes, 2013; Baldassarre & Mirolli, 2013; Barto, 2013; Oudeyer, Kaplan, & Hafner, 2007). This type of mechanism is also argued to be an evolutionary ad vantage for cognitive abilities (Oudeyer & Smith, 2014), and can also be found in lexicon acquisition at the individual level (Partridge, McGovern, Yung, & Kidd, 2015). But does it have a significant impact on population-wide learning and conven tions negotiation dynamics? 
The Naming Game (Steels & Kaplan, 1998; Wellens, 2012; Loreto, Baronchelli, Mukherjee, Puglisi, & Tria, 2011; Ke, 
Minett, Au, & Wang, 2002) is an adapted framework to test this hypothesis. It is a class of multi-agent models of lan guage emergence and evolution, where pairs of randomly se lected individuals try to communicate by referring to some pre-defined meanings using words. At the beginning, they do not share any convention about word-meaning associations. Through repeated decentralized interactions, a common lex icon self-organizes. However, the process can be slow and pass through a high-complexity phase where agents memo rize a lot of conflictual information, in the form of synonyms and homonyms. 
It has already been shown that active learning mecha nisms can increase convergence speed towards a shared lex icon in different language emergence models (Cornudella, Van Eecke, & Van Trijp, 2015; Schueller & Oudeyer, 2016). The main idea behind those mechanisms is to allow agents to actively choose the topic of their communication, based on information collected during their past interactions and driven by control of complexity growth. However, the algo rithms used so far are based on ad hoc heuristics, constrained interaction scenarios and can depend heavily on fine-tuning of parameters themselves depending on population size and number of words and meanings. 
In previous work, an approximation of the global state is built by each agent using the information of past interac tions, in the form of an average vocabulary of the population (Oliphant & Batali, 1997; De Vylder, 2007). Is it possible to design a new principled algorithm for an active topic choice based on such a representation? Could decisions be driven by both the compatibility of an agent’s own lexicon with this av erage vocabulary, and a reduction of both their complexities? Such an algorithm should rely on a time scale for the mem ory of past interactions: Indeed, in the case of uncentralized negotiation of a lexicon, conflictual conventions will neces sarily appear and have to be forgotten in order to converge to a functional global vocabulary. Remembering them could slow down the self-organization process. 
In this work, we define a principled measure of correlation between an agent’s lexicon and a local approximation of the average lexicon of the population. We build a strategy driven by the maximization of this value without being computation ally hard, to be cognitively plausible. We study and discuss the impact of this strategy on convergence time and complex ity growth, depending on a time scale used for memory. 
2448
Methods 
The Naming Game 
We define here precisely the Naming Game model that we used (see fig.1 for an overview). We need to explicit: - The interaction scenario itself 
- How agents represent their lexicon 
- How they update their lexicon at the end of each interaction It is a simple modification of the standard Naming Game sce nario (Loreto et al., 2011; Wellens, 2012). 
  

Figure 1: Illustration of the Naming Game model. Out of a popu lation of simulated agents, two are picked and try to communicate, using/inventing words to refer to meanings. After repeated such in teractions, a common lexicon self-organizes. In this example, there are M=2 possible meanings, W=4 possible words and N=12 agents. 
  

Figure 2: Interaction process: Beforehand, 2 individuals have been randomly selected among a population, an designated as speaker (S) and hearer (H). 1. S chooses a topic, 2. S checks its vocabulary to find or invent an associated word, 3. S utters the word, 4. H guesses the intended meaning, 5. S indicates the intended meaning. 
probabilities of usage, and a decoding or interpretation part, mapping a word to a set of meanings that can be interpretated from this word, also weighted by probabilities. 
We represent the vocabulary of an agent A as a matrix V(A) of size M ×W, with values of 1 for each word-meaning asso ciation used by the agent. Each agent starts with an empty vo cabulary, a matrix filled with zeros. The coding matrix Vc(A) and decoding matrix Vd(A) are derived from V(A) by nor malizing respectively over rows and columns: 
Vc(A)mw =V(A)mw 
V(A)mw0Vd(A)mw =V(A)mw 
∑ 
∑ 
w0 
m0 
Interaction process We re-use a previously defined in 
V(A)m0w(1) 
teraction process called Speaker’s Choice (Schueller & Oudeyer, 2016). It allows one of the interacting agents, called the speaker, choose actively the topic of the interaction. Each interaction involves two agents, that are picked ran 
Normalization factors are used only if V(A)mw 6= 0. In prac tice, when coding a meaning m, a word wiis sampled using the distribution (Vc(A)mw)w∈W . When decoding a word w, a meaning mjis interpreted, sampled from the distribution 
domly from the population. One of them is assigned the role  
Vd(A)mw m∈M. In our case, these distributions are uniform 
speaker, and the other the role hearer. The speaker chooses a topic and picks up a word for this topic. If it does not have a word associated so far to the meaning used as topic, it just invents a new meaning-word association. It utters this word, which is interpreted by the hearer as a meaning, if it knows this word. If the interpreted meaning is the same as the topic, i.e. the meaning intended by the speaker, the communication is considered successful. Otherwise, it is considered a failure. See fig.2 for a detailed illustration of the interaction process. 
Vocabulary Representation Vocabularies, or lexicons, are a set of associations between meanings and words. In this work, we consider only a finite set of meanings M and a finite set of words W. In this context, vocabularies can be repre sented as associations matrices, where each row corresponds to a meaning, and each column to a word. This representa tion has been extensively used in related work (Oliphant & Batali, 1997; Steels & Kaplan, 1998; Ke et al., 2002). Two parts of the lexicon are distinguished, the coding or produc tion part, which maps a meaning to a set of words weighted by 
either on the set of words associated to m for coding, or on the set of meanings associated to w for decoding. Those 2 sets change over time, during the vocabulary update. 
Vocabulary Update Policy At the end of each interaction, each agent takes into account the result of the interaction by modifying its lexicon. There exists various policies that have been described and studied in previous work (Wellens, 2012). We are using the one called Minimal Naming Game. 
In this policy, updates work this way: when the communi cation fails, both agents add the used word-meaning associa tion (meaning used as a topic by the speaker, and word uttered by the speaker) to their lexicon, and do nothing if they already had it. If the communication is successful, not only do they add this association to their respective lexicons, they also re move any conflicting synonyms and homonyms. See fig.3 for an illustration of the update policy in both cases. 
Typically, among existing policies, Minimal NG and an other one called Basic Lateral Inhibition are used: they are more realistic as they allow synonymy/homonymy and yield 
2449
faster agreement. Moreover, Minimal NG has been shown to yield similar dynamics as Basic Lateral Inhibition, yet being simple and not depending on any parameter, while the latter depends on 3. This is the reason why we are using the Mini mal NG as vocabulary update policy. 
  

Figure 3: Vocabulary update (Minimal NG). Failure (when the hearer interpreted the word as another meaning than the topic): the word-meaning association used by the speaker is added to the hearer’s vocabulary. The speaker adds it as well if it was just in vented. Success (when the hearer interpreted correctly the word as the topic): both hearer and speaker remove synonyms/homonyms in conflict with the word-meaning association used during the interac tion. In both examples the topic is the apple, and the word rimi. 
Measures 
The self-organization process happening while simulating the Naming Game has complex dynamics, and goes through various states before reaching global consensus. We talk about those dynamics as a convergence process, towards the state where all agents share the exact same lexicon, with exactly one word for each meaning without synonymy and homonymy. This state is stable, lexicons will not change any more whatever are the modalities of the interaction – which agent is the speaker, which is the hearer, and which mean ings and words are used. Convergence and stability for dif ferent types of Naming Games has been proved analytically (De Vylder, 2007). In this paper, we do not focus on whether the model converges or not, but on the speed and complex ity properties of the dynamics before convergence. Measures for each of those aspects, used to describe the system while in this intermediate state, were defined in previous work (Loreto et al., 2011). We distinguish local measures –accessible to each agent– from global measures, computed on the whole population. 
TCS: Theoretical Communicative Success The Theoret ical Communicative Success is a measure of distance to the fully converged state. First, for each meaning, we can con sider the probability of having a successful communication when using this meaning as a topic, given a state of the pop ulation. The TCS is the average of those probabilities, over all possible meanings. In the case of Random Topic Choice, this measure coincides with the general probability of having a successful interaction. By definition, it is a global measure, not accessible to individual agents. To retrieve its value, we 
can either estimate it using a snapshot of the population and a Monte Carlo method with random topic choice, or compute it. To detail the exact computation formula, we need to first define the probability of success between two given vocabu laries of agents A and B. As detailed in the previous section, a vocabulary has 2 components: a coding part, used to find words associated to a meaning, and a decoding part, used to find meanings associated to a word. For vocabulary V(A), we would then have the 2 matrices Vc(A) and Vd(A). If A is the speaker and B the hearer, A is coding and B decoding, hence the formula of the probability of success in this case, averaged over all possible meanings: 
TCSs(A,B) = 1M ∑m∑wVc(A)m,w ·Vd(B)m,w (2) 
Because before an interaction we do not necessarily know which agent will be the speaker and which will be the hearer, the 2 situations (A speaker and B hearer / B speaker and A hearer) are to be considered, as equiprobable. The final value TCS(A,B) is the mean of TCSs(A,B) and TCSs(B,A). 
To scale up to population level, one can compute an aver age vocabulary for the whole population V(P), and then the probability of success for an interaction between this lexicon and itself. For a large enough population, this value is indeed a good approximation of the probability of success. V(P) is an element-wise average of the lexicon matrices of all agents. 
When using random topic choice, this value abruptly goes from 0 to 1 after a certain number of interactions. These dy namics can be seen on fig.4, where the random topic choice is represented – among active strategies that are explained in a following section. In practice, we use Monte Carlo estima tion for the values at population level over time, and the exact computation for the active topic choice strategy (see follow ing section), as it requires more precision and the population vocabulary is already built. 
Local Complexity The starting state of an agent’s vocabu lary is empty (all-zero matrices), and the end state is identical coding and decoding matrices, with exactly one distinct word per meaning. But between those 2 situations, through which states goes the vocabulary? How much conflictual informa tion (synonymy and homonymy) has to be considered? 
For each agent, we can define a local complexity measure, by counting the number of distinct associations present in the vocabulary. In our case, this is exactly the sum of all ele ments of the matrix V(A). At the beginning of a simulation, while the vocabulary is empty, this measure equals 0. At the end, its value is the number of meanings M. When using ran dom topic choice, there is a fast growth to a maximum, before a slow decrease to the final value M (can be seen in fig.4). This measure is nearly proportional to the minimal memory needed to represent the lexicon (as a sparse matrix or a list of word-meaning associations), and therefore should remain low in a cognitively plausible situation. 
2450
Active Topic Choice Strategy 
The main contribution of this work is the definition of an ac tive strategy for the choice of the topic in each interaction, by comparison to the usual choice of picking meanings ran domly (with a uniform distribution over the space of mean ings). The strategy has to be local, i.e. use only information available to the agent, namely its own vocabulary and results of past interactions it was involved in. 
To both converge quickly and control complexity, behav ior should be driven by maximization at each interaction of the Theoretical Communicative Success. However, this value is a global measure, therefore not accessible at agent level. Agents only sample information about the global state of the population, or the average vocabulary V(P), through their in teractions as hearer or speaker. 
The strategies for active topic choice found in previous work are separated in two levels of decision (Schueller & Oudeyer, 2016). First, a decision between exploring a new meaning (that is associated to no words in the vocabulary so far) and choosing (exploiting) a meaning among those al ready used before. Then, if exploiting, deciding which known meaning to use depending on past interaction results. 
The strategy introduced in this work keeps those two levels, while basing both decisions on a new measure called Local Approximated Probability of Success (LAPS), using a local representation of V(P). 
LAPS: Local Approximated Probability of Success Here, we define an approximation of V(P), Ve(P), using in formation sampled by agents during their interactions. We construct independently the coding and decoding parts Vec(P) and Ved(P). For every meaning m (and every word w), we use a sliding window over the recent past interactions – of maxi mal length τ, the time scale parameter– and count the number of times it is associated to each word w0(or meaning m0). This value divided by τ is the local estimation of the probability of an other agent coding m using w0(or decoding w as m0). With this, we retrieve the values of both matrices Vec(P) and Ved(P). 
Let Mc(m) be the memory of the past interactions where m was the topic, if there has been Tm such interactions. wt denotes the word used during the tth interaction of the agent using the meaning m. We can now build Vec(P): 
Tm 
maining probability weight is assumed to be associated with failure. If we would normalize to 1, with a single interaction an agent would already estimate as 100% sure that the same word-meaning association would be used again with the same topic for example. Without the normalization, this happens only after τ interactions. In other words, this reflects lack of information due to small sample size. We define a Local Ap proximated Probability of Success, or a local equivalent of the Theoretical Communicative Success for an agent A with vocabulary V(A): 
LAPSA = TCS(V(A),Ve(P)A) (5) 
For some vocabulary update policies called lateral inhibition, similar matrices are computed, but used directly as an agent’s own representation of the lexicon. This usage does not pre vent the complexity burst (Wellens, 2012). 
Exploration vs. Exploitation The first choice of our new strategy is between exploring new meanings or exploiting al ready known ones. Exploration should happen when agents are confident enough about their agreement with the rest of the population over their known meanings (Schueller & Oudeyer, 2016). The LAPS measure in itself is a measure of confidence, and the simplest way to take this into account is to only explore when reaching the maximum value KM where K is the number of known meanings and M the total number of meanings in the world. This value can actually be reached, thanks to the sliding window of parameter τ. 
Multi-Armed Bandit The second decision process con cerns the exploitation part, when picking the topic among the known meanings. We designed a behavior driven by the in crease of the LAPS measure. In other words, agents seek the meaning that would yield the greatest increase of LAPS. However, computing the expectancy of this value ∆LAPS is hard computationally speaking, and therefore not suitable for a model of a cognitive process. We can only consider the pro cess a black box, where following a decision between a finite set of options, a reward value is obtained. This is exactly the definition of the Multi-Armed Bandit problem, associated to a class of reinforcement learning algorithms that have been extensively studied (Bubeck, Cesa-Bianchi, et al., 2012). The name comes from an analogy with a person trying to maxi 
Mc(m) = (wt)1≤t≤TmVec(P)mw = 
∑ 
t=Tm−τ+1 
δw,wt 
mize their gain while facing a set of slot-machines (also called one armed bandit), and being able to use only one at a time. 
τ(3) 
Similarly, by defining Md(w) be the memory of the past interactions where w was the topic, with Tw such interactions, we can build Ved(P): 
The probability distribution of the reward of each machine is unknown, and the player has to both collect information by playing and exploit the highest rewarding machine – with limited knowledge of its reward distribution – hence keep bal ance between exploration and exploitation. In our problem, 
Md(w) = (mt)1≤t≤TwVed(P)mw = 
Tw 
∑ 
t=Tw−τ+1 
δm,mt 
we can see known meanings as the possible arms, and the re ward ∆LAPS. Our case is quite specific, as: 1) distributions 
τ(4) 
Until τ interactions have been done with a given meaning or word, ∑wVec(P)mw and ∑mVed(P)mw do not sum to 1. The re 
are non stationary, 2) they depend on past choices, 3) and the number of arms grows over time (and starts at 0). This spe cific situation led us to choose an algorithm, where weights associated to each arm undergo a decay over time, which let 
2451
them stay at the same order of magnitude of the initial weights of new arms (Clement, Roy, Oudeyer, & Lopes, 2015). Our algorithm depends on 2 parameters: integrated balance be tween reward-driven exploitation and random exploration be tween arms through the parameter γ, and time scale n for the decay of weights. As a reward, we consider the increase of LAPS yielded by the interaction, ∆LAPS, or 0 if the latter is negative in order to avoid negative weights. See algorithm 1. 
Algorithm 1 LAPSmax Bandit Multi-Armed Bandit algo rithm used as a topic choice strategy maximizing the LAPS measure. New arms are created with weights wa equal to the reward ri obtained at the end of an interaction with a new meaning. 
Require: γ rate of exploration for bandit 
Require: n time scale for weights decay 
Require: vocabularies V and Ve, #meanings M K ← |V.known meanings()| 
if LAPSA =KMthen 
m ← random(V.unknown meanings()) 
else 
for a ∈ Arms do 
w˜a =wa 
∑j wj 
pa = (1−γ)·w˜a +γK 
end for 
Sample m ∈ Arms using distribution (pa)a∈Arms end if 
return m 
{Interact using topic m and compute reward r} if m ∈ Arms then 
wm ← n 
n+1·wm +r 
else 
Add m to Arms with wm = r 
end if 
Results 
For all simulations, we set N=M=W=40, compute up to 80,000 interactions and take the mean over 8 trials. The situ ation M=W is the most constrained and complex to solve, as synonymy and homonymy are more probable. We ran simu lations for 1 ≤ τ ≤ 50, and set n=τ. For the exploration rate, if the condition 0 < γ   1 is respected, the actual value of γ does not matter much, as its only function is to avoid rare cases where some weights reach a value of 0 and cannot be selected anymore. We set γ=0.01. However, we also ran sim ulations with pure random choices at the bandit level, to be able to study the influence of each level of our algorithm. This case identifies as γ=1. 
The evolution of the TCS and complexity over time is rep resented on fig.4, for several values of the time scale τ. They are compared on the same plots with Random Topic Choice. We can see that convergence is faster for low values of τ, the fastest being for τ=2, which is 4 times faster than Random Topic Choice. As for complexity, for all configurations ex 
  
  

Figure 4: Theoretical success rate over time and Local Com plexity for Random Topic Choice and Active Topic Choice with several values of the time scale τ used in the LAPS mea sure. N=M=W=40, γ=0.01, mean over 8 trials. 
cepted τ=1 values stay below the final level 40. After reach ing a first threshold, they increase linearly with time, the slope being smaller for higher values of τ. For τ=1, the maximum value is only half of the maximum reached by Random Topic Choice. It is understandable that τ=1 is an outlier: in this case LAPS is an autocorrelation with the current interaction, by definition older interactions are not taken into account. 
On fig.5, we can see the dependency of convergence time on the parameter τ, plotted for configurations γ=0.01, γ=1 and the value for Random Topic Choice as a reference. Both have dynamics consistently faster than Random Topic Choice for low values of τ, however γ=0.01 performs better. Excepted for τ=1, convergence time increases linearly with τ for both, with a minimum at τ=2, and a smaller slope for γ=0.01. 
Discussion 
Results show that the new strategy presented in this paper 1) allows fast convergence, 2) controls efficiently complexity growth, 3) its dynamics are consistent and highly correlated with parameter change, 4) the 2 levels of the algorithm each contribute to the increased performance. 
2452
  

Figure 5: Convergence time depending on time scale τ used in LAPS measure, for both γ=0.01 and γ=1, compared with Random Topic Choice. N=M=W=40, mean over 8 trials. 
With τ=2, each agent on average only speaks 15 times about each meaning before convergence (i.e. less than half the population), and information has already been both con veyed between all agents and disambiguated. The linearity of the evolution of TCS and complexity lets think that this algo rithm may as well scale efficiently to other values of N, M and W. Compared to previous work, this topic choice algorithm is more robust, and optimal parameters are easier to find. It generalized well to Minimal Naming Game and can be used for all other Naming Game models. 
LAPS is coherent from a cognitive point of view, and cor responds to an actual internal confidence about quality of communication with the rest of the population. As stated in the results section, the case τ=1 is an outlier, being a sim ple autocorrelation with the current interaction. The optimal value τ=2 is then the lowest possible value taking into account past interactions, i.e. Ve(P) takes the lowest possible memory, which is therefore credible for humans. Further work will be needed to determine for which values of N, M and W τ=2 stays the optimal value. 
Acknowledgments 
The IdEx program (Univ. de Bordeaux) allowed W. Schueller to visit V. Loreto. We thank Miguel Ibanez Berganza and ˜ Benjamin Clement for the fruitful discussions. ´ 
Source code The Python code used for the simula tions of this paper is available as open source software: https://github.com/wschuell/notebooks cogsci2018 
References 
Baldassarre, G., & Mirolli, M. (2013). Intrinsically moti vated learning systems: an overview. In Intrinsically moti vated learning in natural and artificial systems (pp. 1–14). Springer. 
Barto, A. G. (2013). Intrinsic motivation and reinforcement learning. In Intrinsically motivated learning in natural and artificial systems (pp. 17–47). Springer. 
Bubeck, S., Cesa-Bianchi, N., et al. (2012). Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and TrendsR in Machine Learning, 5(1), 1– 122. 
Clement, B., Roy, D., Oudeyer, P.-Y., & Lopes, M. (2015). Multi-Armed Bandits for Intelligent Tutoring Systems. Journal of Educational Data Mining (JEDM), 7(2), 20–48. 
Cornudella, M., Van Eecke, P., & Van Trijp, R. (2015). How intrinsic motivation can speed up language emergence. In Proceedings of the european conference on artificial life (pp. 571–578). 
De Vylder, B. (2007). The evolution of conventions in multi agent systems. Unpublished doctoral dissertation, Vrije Universiteit Brussel, Brussels. 
Gottlieb, J., Oudeyer, P.-Y., Lopes, M., & Baranes, A. (2013). Information-seeking, curiosity, and attention: computa tional and neural mechanisms. Trends in cognitive sciences, 17(11), 585–593. 
Ke, J., Minett, J. W., Au, C.-P., & Wang, W. S.-Y. (2002). Self-organization and selection in the emergence of vocab ulary. Complexity, 7(3), 41–54. 
Loreto, V., Baronchelli, A., Mukherjee, A., Puglisi, A., & Tria, F. (2011). Statistical physics of language dynamics (Vol. 2011) (No. 04). 
Oliphant, M., & Batali, J. (1997). Learning and the emer gence of coordinated communication. Center for research on language newsletter, 11(1), 1–46. 
Oudeyer, P.-Y., Kaplan, F., & Hafner, V. V. (2007). Intrinsic motivation systems for autonomous mental development. Evolutionary Computation, IEEE Transactions on, 11(2), 265–286. 
Oudeyer, P.-Y., & Smith, L. (2014). How evolution may work through curiosity-driven developmental process. Top ics Cogn. Sci. 
Partridge, E., McGovern, M., Yung, A., & Kidd, C. (2015). Young Childrens Self-Directed Information Gathering on Touchscreens. In Proceedings of the 37th annual meeting of the cognitive science society. 
Schueller, W., & Oudeyer, P.-Y. (2016). Active control of complexity growth in naming games: Hearer’s choice. In The evolution of language: Proceedings of the 11th inter national conference (evolangx11). 
Steels, L., & Kaplan, F. (1998). Stochasticity as a source of innovation in language games. In Proceedings of artificial life vi (pp. 368–376). 
Wellens, P. (2012). Adaptive Strategies in the Emergence of Lexical Systems. Unpublished doctoral dissertation, Vrije Universiteit Brussel, Brussels. 
2453
Evidence for an Intuitive Physics Engine in the Human Brain 
Sarah Schwettmann 
Massachusetts Institute of Technology, Cambridge, Massachusetts, United States 
Jason Fischer 
Johns Hopkins University, Baltimore, Maryland, United States 
Josh Tenenbaum 
MIT, Cambridge, Massachusetts, United States 
Nancy Kanwisher 
Massachusetts Institute of Technology, Cambridge, Massachusetts, United States 
Abstract 
Humans demonstrate a remarkable ability to infer physical properties of objects and predict physical events in dynamic scenes. These abilities have been modeled as probabilistic simulations of a mental physics engine akin to 3D physics engines used in computer simulations and video games (Battaglia, Hamrick & Tenenbaum 2013; Sanborn, Mansinghka & Griffiths 2013), but it is unknown if and how such a physics engine is implemented in the brain. Does the brain represent quantities corresponding to the key latent variables of physical objects that contribute to their dynamics? To find out, we used multivariate pattern classification analyses of fMRI data from subjects viewing videos of dynamic objects. The mass of depicted objects could be decoded, across physical scenarios and object materials, from brain regions previously implicated in intuitive physics. This invariant representation of mass may serve as a key variable in a generalized engine for intuitive physics. 
2454
Cross-Domain Influences on Creative Processes and Products 
Victoria Scotney (v.scotney@alumni.ubc.ca), 
Sarah Weissmeyer (sarah.weissmeyer@alumni.ubc.ca),  
and Liane Gabora (liane.gabora@ubc.ca) 
Department of Psychology, University of British Columbia  
Okanagan Campus, Fipke Centre for Innovative Research, 3247 University Way  Kelowna BC, Canada V1V 1V7 
Abstract 
According to the honing theory of creativity, the iterative  process culminating in a creative work is made possible by the  self-organizing nature of a conceptual network, or worldview,  and its innate holistic tendency to minimize inconsistency. As  such, the creative process is not limited to the problem domain,  and influences on creativity from domains other than that of the  final product are predicted to be widespread. We conducted a  study in which participants with varying levels of creative  experience listed their creative outputs, as well as influences  (sources of inspiration) on these outputs. Of the 758 creative  influences, 13% were within-domain narrow, 13% within domain broad, 67% cross-domain, and 6% unclear. These findings support the hypothesis that to trace the inspirational  sources or ‘conceptual parents’ of a creative output, and thus  track its cultural lineage, one must look beyond the problem  domain to the creators’ self-organizing, inconsistency 
minimizing worldview at large. 
Keywords: art; creativity; cross-domain influence; domain general; domain-specific; innovation; inspiration; music 
Introduction 
Creativity is thought to involve the restructuring of  information in a creative domain, sometimes referred to as  the problem domain (Runco, 2014), or simply, the domain. Domain-specific theories of creativity emphasize the non transferability of expertise from one creative domain to  another (Baer, 2015). They appear to be supported by  findings that creative individuals are rarely creative in more  than a few domains, i.e., someone known for their creativity  in physics is rarely also known for their creativity as a dancer  (Baer, 2012; Kaufman & Baer, 2004a). Support also comes  from studies in which individuals created products for  different domains, such as poems and mathematical  equations, which found a low correlation in the ratings of  
individuals’ creativity across domains (Baer, 1991). Domain-general theories emphasize the generalizability of  creative thinking across different domains (Hong & Milgram,  2010). The domain general view is supported by personality  studies, which suggest that there is something to the notion  of a creative personality type (Batey & Furnham, 2006;  Eysenck, 1993; Feist, 1998; Martindale & Daily, 1996), and by evidence that when people express themselves in different  creative domains these outputs bear a recognizable style or  ‘voice’ (Gabora, O’Connor, & Ranjan, 2012; Ranjan, 2014). Such findings suggest that the creative mind seeks to explore  
2455
and express its distinctive structure and dynamics using  whatever means available. 
Currently, many scholars espouse a less dichotomous view  of creativity that incorporates both domain-specific and  domain-general elements (Gabora, 2017; Plucker &  Beghetto, 2004; Kaufman & Baer, 2004c). Nevertheless, we  believe that the domain-generality of creativity is still under 
appreciated due to emphasis on the final product or output of  the creative process. Even if creative individuals tend to  express themselves in one domain this does not necessarily  mean that prior phases of their creative process are domain 
specific. This paper describes a study designed to test the  hypothesis that cross-domain influences play a normal and  natural role in creativity and constitute a ubiquitous part of the creative process, and that the prominence of cross-domain  influences on creativity is not exclusive to expert creators. 
Honing Theory 
Central Aim and Core Concepts. While the central aim of  most theories of creativity is to account for the existence of  creative products, the honing theory of creativity (HT) arose to account for the cumulative, open-ended nature of cultural  evolution. HT grew out of the view that humans possess two  levels of complex, adaptive, self-organizing, evolving  structure: an organismic level, and a psychological level  (Barton, 1994; Combs, 1996; Freeman, 1991; Gabora, 1998,  2017; Pribram, 1994; Varela, Thompson, & Rosch, 1991).  We refer to this psychological level as a worldview: an  individual’s unique dynamic web of understanding that  provides a way of both seeing the world and being in the  world, i.e., a mind as it is experienced from the inside. In  short, HT posits that the worldview is the hub of a second  evolutionary process—cultural evolution—that rides  piggyback on the first—biological evolution—and that  creative thinking fuels this second evolutionary process (Gabora, 1998, 2004, 2008, 2013, 2017). 
Honing an idea entails reiteratively looking at it from the  different angles proffered by one’s particular worldview, ‘putting ones’ own spin on it’, and make sense of it in one’s  own terms, followed by expressing it outwardly (Gabora,  2017). Honing may involve the restructuring of  representations by re-encoding the problem such that new  elements are perceived to be relevant, or relaxing goal  constraints (Weisberg, 1995), and self-organized criticality,  wherein small perturbations can have large effects (Gabora,  1998). As the creator’s understanding of the task shifts, the  
creative idea may find a form that fits better with the  worldview as a whole, such that the worldview achieves a  more coherent state, as formalized by the notion of  conceptual closure (Gabora, 1998; Gabora & Steel, 2017).  Creative acts and products render such cognitive  transformation culturally transmissible. Thus, it is suggested  that what evolves through culture is not creative contributions  but worldviews, and cultural contributions give hints about  the worldviews that generate them. 
Predictions of HT Concerning Cross-Domain Influences.  HT posits that creative output reflects the idiosyncratic,  transformative process by which a worldview restructures  itself in response to perturbations such as the detection of  threats, inconsistencies, ambiguity, or potentiality. Such  perturbations cause arousal-provoking uncertainty (Gabora,  2017), which Hirsh, Mar, and Peterson (2012) refer to as  psychological entropy, and which sets self-organized  iterative honing into motion. HT posits that since the contents  of the mind collectively self-organize, none are a priori excluded from the creative task, and it is possible for the 
domain-specific aspects of an idea to be stripped away such  that it is amenable to re-expression in another form.  Because a worldview can continuously renew its overall  structure, there are no limits on the possible influences or  ‘conceptual parents’ of a creative work such as a song or  journal article. For example, consider the situation in which  a book inspires a movie, which inspires an invention. To see  the thread of continuity across this ‘line of descent’ it is  necessary to consider how their creators navigate through  webs of beliefs, attitudes, procedural and declarative  knowledge, and habitual patterns of thought and action that  emerge through the interaction between personality and  experience. In short, HT predicts that cross-domain  influences play a role in the creative processes that fuel the  self-organized transformation of worldviews, and that this in  turn is the driving force of cultural evolution. 
Previous Research on Creative Influences 
There have been efforts to corroborate anecdotal reports of  creative influences (see Feinstein, 2006) with machine  learning techniques designed to resolve lines of influence  (Saleh, Abe, & Elgammal, 2014). However, these techniques  are not yet able to discern cross-domain influences, wherein  a creator in one domain (e.g., artist) is influenced by another  domain (e.g., music).  
Chan, Dow, and Schunn (2015) examined the conceptual  distance of inspirational sources on the quality of design ideas, and found that conceptually closer sources (which were  defined as sharing a ‘topic’ of closely associated words) were  associated with higher quality solutions. However, as the  authors note, this finding is inconsistent with the relatively  robust finding that problem solvers from outside a given 
problem domain often produce the most creative solutions (Franke, Poetz, & Schreier , 2014; Hargadon & Sutton, 1997;  Jeppesen & Lakhani, 2010). Moreover, since the designers  were not asked to provide all elements that inspired their  work, the scope of study was limited to the kinds of  
2456
influences that one might logically expect to have a direct  bearing on the result. Thus, for example, they listed things  like previously generated solutions or design ideas, but not  things like a particular piece of music, or ‘a conversation with  a friend’.  
Studies of cross-domain inspiration showed that it is  possible to re-interpret a creative work in one medium into  another medium (Ranjan, Gabora, & O’Connor, 2013;  Ranjan, 2014). When painters were instructed to paint what a  particular piece of music would ‘look like’ if it were a  painting, naïve participants were able to correctly identify at  significantly above chance which piece of music inspired  which painting. Although the medium of expression was  different, something of its essence remained sufficiently  intact for people to detect a resemblance between the new  creative output and its inspirational source. This suggested  that, at their core, creative ideas are less domain-dependent  than is widely assumed. The study supported our intuitive  conviction that when the creative output is not a blend but lies  squarely in one domain, the creative process giving rise to it may be rooted in different domains. However, due to the  artificial nature of this study it did not provide evidence that  cross-domain plays a role in real-world creative endeavors. 
In a precedent to the current study, 66 individuals with  demonstrable accomplishments in a fine arts domain (e.g.,  music, painting, or fiction writing) were asked to list, for each  of their most significant creative works, all influences on the  creative process of generating these works (Gabora &  Carbert, 2015). Of the 65 creative influences provided by the  66 participants, 47% were cross-domain influences (e.g., a  painting influenced by music), 27% were narrow within domain (e.g., a painting influenced by another painting), 8%  broad within-domain (e.g., a painting influenced by  sculpture), and 18% unclassifiable. Thus, the cross-domain  influences were more widespread than within-domain  influences, even when broad within-domain influences (e.g.,  technology influenced by music) as well as narrow within 
domain influences (e.g., music influenced by other music)  were taken into account. This result was surprising, for we  had just been looking to see if cross-domain influence exists  at all; we were not expecting it to predominate. 
A limitation of this previous study was that the sample size  was small, and because it included only expert level creative  individuals it did not enable us to make conclusions about  creative processes beyond this exclusive group. The goal of  the current study was to replicate the above study on a  participant population that is not characterized by expertise  in a creative domain. 
Method 
Participants 
The participants were 463 undergraduate students (114  males, 347 females, and two who selected ‘no or different  gender’) from the University of British Columbia. They were  recruited through SONA, an online participant pool approved  by the UBC Research Ethics Board. 
Procedure 
The SONA website provided a link to an online questionnaire  hosted by FluidSurvey. After formally consenting to the  study, participants were asked to provide their age, gender,  and occupation. The questionnaire then asked the  respondents to answer the following questions: 
1. What is the general category for the creative work for  which you are most known (e.g., art, music, drama,  science)? 
2. What is the subcategory for the creative work for which  you are most known (e.g., painting, piano composition,  biochemistry)? 
3. Please describe your creative outputs. 
4. Please describe as best you can your creative process. 
5. Describe all elements that have inspired your work  (natural or artificial, or it may be a particular event or  situation, or something not in the concrete environment,  that is, something abstract that you have been thinking  about), and with each item, if possible, put as much  identifying information as you can about the item it  inspired (e.g., my Sunlight Sonata in B Flat composed in  2012 was inspired by going skiing in the alps with my  sister who had just recovered from pneumonia). Do this for as many of your creative works as you can, itemizing  them as (a), (b), (c), and so forth. Provide as much detail  as possible. 
The first three questions were used to determine the  domains of creative outputs for each participant. Question  five was used to assess the domain of the inspirational source  associated with each creative output. Question four was not  used in this study, as it did not provide additional clarification  regarding either creative outputs or their inspirational  sources. The questions were worded in an open-ended way  so as not to constrain participants’ answers in any way. The  study was designed as an online survey, rather than a personal  interview, so that we could maximize the time we had to collect as much data as possible.  
Analysis 
Of the 463 participants, 111 were excluded because they left  one or more of questions one, two, three, or five blank. (They  were able to receive partial course credit whether or not they  completed the questionnaire.) An additional 90 
questionnaires were excluded because the participants did not  provide classifiable answers. Some of the questionnaires  were unclassifiable because participants either provided a  description of their creative process, or answered with what  motivated a creative output, rather than providing an  inspiration; e.g., an answer was excluded if the only reason  for engaging in the creative activity was that someone else,  such as a parent, obliged them to participate. The second category of unclassifiable questionnaires were those in which  no creative outputs were provided in conjunction with a  
creative influence. The last category of unclassifiable questionnaires were those for which both raters independently found them incomprehensible and impossible  to evaluate. This left 262 completed questionnaires for  analysis, and these questionnaires provided a total of 758  influences. 
By comparing the answers to questions one and two with  those for question five, the provided influences were  organized into four categories: within-domain narrow,  within-domain broad, cross-domain, and uncertain. A  response was classified as within-domain narrow (WN) if the  domain of inspiration and the domain of the creative output  fell within the same subcategory, e.g., a painting inspired by another painting. An example of a within-domain broad 
(WB) influence is a photograph inspired by a painting. A  photograph and a painting belong to the same domain of  visual art, but not to the same subdomain. Cross-domain (C)  influences were those for which the domain of the influence  was different from the domain of creative expression. For  example, a song (domain: music) that inspired a software  program (domain: technology) was rated as a cross-domain  influence. An answer was categorized as unclear (U) when  insufficient information was provided to categorize the  influence as WN, WB, or C. 
Two raters independently categorized these responses as  either WN, WB, C, or U. Inter-rater reliability between the  raters, calculated using both Cohen’s kappa (κ = .77) and  Krippendorff’s alpha (α = .87) was well beyond what would  be expected by chance (see Davey, Gugiu & Coryn, 2010).  Where there were any inconsistencies between the ratings of  the two raters, they reached a final decision through  discussion. 
Results 
The total number of influences in each domain category, as  well as the upper and lower limits for the 95% confidence  interval for each domain category, are provided in Table 1. 
Table 1: Frequency and Percentage of Domain  Influences on Creative Output and Lower Limit and  Upper Limit for a 95% Confidence Interval. 
  

2457
The participants’ creative outputs came from a variety of  domains, including drawing, architecture, photography,  scientific experiments, song writing, furniture design,  biochemistry, and athletic performance. They also gave a  wide variety of inspirational sources, ranging from people in  their lives such as family, friends, and strangers, to African  safaris and The Book of Kells. Each participant listed an  average of 2.89 creative influences (SD = 1.92, Mdn = 3,  range: 1-15).  
Of the 758 influences provided, 101 (13.32%) were WN,  101 (13.32%) were WB, 508 (67.02%) were C, and 48  (6.33%) were U. Thus, cross-domain influences constituted  more than double the number of within-domain and unclear  influences, even when broad as well as narrow within-domain  influences were included.  
Since the participants were encouraged to list all the  influences they could think of that inspired their creative  outputs, there was variation in the number of influences that  each participant provided. A possible explanation for the low  frequency of WN influences could be that there is only one  NW influence that can match a given creative output, but  there is a larger number of WB influences, and a potentially  infinite number of C influences. Thus, once someone has  provided an influence that matches the domain of the creative  output, any subsequent influences they provide will  necessarily be either cross-domain or within-domain broad.  To explore the possibility that our results give more weight  to participants who gave multiple influences, we re-analyzed  the data according to the number of influences provided by  each participant, as shown in Table 2.  
Table 2: Percentage and Frequency (in brackets) of  Within-Domain Narrow (WN), Within-Domain Broad  (WB), Cross-Domain (C) and Unclear (U) Influences by  Total Number of Influences (N-Infl) Provided by  Participant. N-Partic is the number of participants who  provided that number of influences. 
  
2458
This re-analysis shows that there may be some merit to this  explanation, for participants who gave only one influence did  indeed have a higher frequency of WN influences than any  other group (26.47% versus between 8.89 – 14.41%) and a  lower frequency of C influences (57.35% versus between  66.08 – 75.56%). However, this does not alter the overall  pattern of the findings that even when only one influence was  given, that influence was more often than not (i.e., 57.35% of  the time) a cross-domain influence. 
Discussion 
The results of this study concur with previous finding (Gabora & Carbert, 2015) that the majority of creative  outputs were inspired by cross-domain influences. However,  the current results show that this is not just the case for  individuals with proven success or expertise in a creative  domain; it holds true for non-experts as well. This result has  implications for our understanding of the creative process,  because it demonstrates that it is substantially less domain 
specific than it is widely presumed to be. Even if individuals  primarily express their creativity in a single domain, they are  often employing cross-domain thinking when they create.  Although domain-specific knowledge may ensure that tools  of the trade are appropriately applied, and one’s creative  works may consistently be in one particular domain, the  sources that initially triggered these creative processes may  be diverse in nature. To the extent that this is the case,  creativity may involve synthesizing information from  different arenas of one’s life. 
Implications for a Theoretical Framework for  Creativity 
The finding that cross-domain influences are widespread is  consistent with HT, according to which it is not just one’s  conception of the creative task (or ‘problem domain’) but  one’s worldview as an integrated whole that transforms— 
becoming less fragmented and/or more robust—through  immersion in a creative task. Honing entails iteratively  viewing the creative task from a new context, which may  restructure the internal conception of it, and this restructuring  may be amenable to external expression. This external  change may in turn suggest a new context, and so forth  recursively, until the task is complete. The view that creative  honing can bring about sweeping changes to an individual’s  second (psychological) level of complex, adaptive structure is consistent with findings that creativity is potentially  therapeutic (Barron, 1963; Forgeard, 2013), and that through  immersion in a creative task, a more stable image of the  world, and one’s own relation to it, can emerge (Pelaprat &  Cole, 2011). Thus, it is through the interaction and cross 
fertilization of knowledge and ideas that conceptual closure  is achieved, and psychological entropy kept to an acceptable  minimum. Although the phenomenon cross-domain  influence in creativity—and by implication, the abstraction  and re-expression of abstract forms—may seem obvious to  artists, it plays no role in the bulk of psychology and AI  
research, in which creativity is portrayed as heuristically  guided search or selection amongst discrete, well-defined  states, guided by domain-specific expertise (e.g., Simonton,  2010; Weisberg, 1995). 
Implications for Cultural Evolution 
At first glance it might seem that the basic units of cultural  evolution—i.e., the cultural equivalent of the organism in  biological evolution—are such things as catchy songs or  rituals or tools. However, the above evidence for the cross 
fertilization of different domains suggests that the only way  to delineate the cultural lineage of a given idea is to look to  the creator’s entire loosely-integrated web of knowledge and  understandings, i.e., the creative process transforms—not just  the problem domain—but the worldview as a whole. In this  way, the inspirational sources—or ‘conceptual parents’—of  a sad ballad could include everything from other musicians,  to the patter of rain, to the death of a loved one. Thus, creative  products don’t just serve practical purposes or provide  aesthetic pleasure; they provide tangible external markers of  the evolutionary states of the worldviews that generated  them. This is consistent with the theory that what evolves  through culture is, not creative outputs like songs or tools, but worldviews, with creative outputs as the externally visible  ‘excrement’ of this transformation process (Gabora, 2004,  2008, 2013). In short, research into cross-domain influences  has implications for not just how the creative process works  but for how culture evolves. 
As discussed elsewhere, a worldview not only self organizes in response to perturbations but it is imperfectly  reconstituted and passed down through culture (Gabora,  2013). This is because it is not just self-organizing but self regenerating: people share experiences, ideas, and attitudes  with each other, thereby influencing the process by which  other worldviews form and transform. Children expose  elements of what was originally an adult’s worldview to  different experiences, different bodily constraints, and  thereby forge unique internal models of the relationship  between self and world. In short, worldviews transform by  interleaving (1) internal interactions amongst their parts, and  (2) external interactions with others. It is through these social  interactions that novelty accumulates, and culture evolves. 
Limitations and Future Directions 
We attribute the large fraction of respondents who did not  complete the questionnaire to the anonymous nature of the  study, and the fact that they could receive course credit even  if they did not complete it. In future studies, it would be  helpful to consider ways of further incentivizing participants  to complete the questionnaire. Although the open-ended questionnaire was necessary to enable participants to give  anything as an inspirational source, it may have been less  inviting for those who prefer a structured format. Changing  the format from an online questionnaire to an in-person  interview may elicit a higher response rate. In addition, the  instructions should actively discourage participants from  providing motives (e.g., a desire to be creative) instead of  
2459
inspirational sources, and examples of each should be given  so that the distinction is clear. Also, reformatting the  questionnaire so that it is always clear which creative  influence is associated with which creative output would help  clarify the interpretation of the responses. 
Another study is planned to examine the hypothesis that  scientists make less use of cross-domain influences than  artists. Further research might also investigate developmental  differences in the ability to employ cross-domain influences. 
Future research could investigate the factors that predispose  individuals to employ cross-domain influences, such as their  implicit conception of how the creative process works.  Another direction for future research is to investigate the  extent to which the application of cross-domain influences is  associated with personality traits correlated with creativity,  such as norm-doubting, high aspiration levels, tolerance of  ambiguity, and openness to experience (Batey & Furnham,  2006; Eysenck, 1993; Helson, 1996; Martindale & Daily,  1996). If so, this would suggest that propensity toward cross domain influence plays a mediating role between personality  and creativity. 
Practical Implications 
The finding that the majority of creative outputs were  inspired by cross-domain influences has implications for the  development of practices that promote creativity in  education, the workplace, and personal life. It suggests that  creativity may be cultivated by interdisciplinary courses, as  well as activities and cultural objects such as murals of  ecological food chains or poetry about science that foster  connections between different domains. 
Acknowledgements 
We acknowledge and are grateful for funding from grant  62R06523 from the Natural Sciences and Engineering  Research Council of Canada. 
References 
Baer, J. (1991). Generality of creativity across performance  domains. Creativity Research Journal, 4, 23-39. Baer, J. (2012). Domain specificity and the limits of  creativity theory. Journal of Creative Behavior, 46, 16-29. Baer, J. (2015). The importance of domain-specific expertise  in creativity. Roeper Review, 37, 165-178. 
Barron, F. (1963). Creativity and psychological health. Princeton, NJ: Van Nostrand. 
Barton, S. (1994). Chaos, self-organization, and psychology.  American Psychologist, 49, 5-14. 
Batey, M., & Furnham, A. (2006). Creativity, intelligence,  and personality: A critical review of the scattered  literature. Genetic, Social, and General Psychology Monographs, 132, 355-429. 
Chan, J., Dow, S. P., & Schunn, C. D. (2015). Do the best  design ideas (really) come from conceptually distant  sources of inspiration? Design Studies, 36, 31-58. 
Combs, A. (1996). The radiance of being: Complexity, chaos  and the evolution of consciousness. St. Paul, MN: Paragon House. 
Davey, J., Gugiu, P., & Coryn, C. (2010). Quantitative  methods for estimating the reliability of qualitative data.  Journal of Multidisciplinary Evaluation, 6, 140-162. 
Eysenck, H. (1993). Creativity and personality: Suggestions  for a theory. Psychological Inquiry, 4, 147–178. 
Feinstein, J. S. (2006). The nature of creative development. Stanford: Stanford University Press. 
Feist, G. J. (1998). A meta-analysis of personality in  scientific and artistic creativity. Personality and Social Psychology Review, 2, 290-309. 
Forgeard, M. (2013). Perceiving benefits after adversity: the  relationship between self-reported posttraumatic growth  and creativity. Psychology of Aesthetics, Creativity, Arts 7,  245–264. 
Franke, N., Poetz, M. K., & Schreier, M. (2014). Integrating  problem solvers from analogous markets in new product  ideation. Management Science, 60(4), 1063-1081. 
Freeman W. J. (1991). The physiology of perception.  Scientific American, 264, 78-85. 
Gabora, L. (1998). Autocatalytic closure in a cognitive  system: A tentative scenario for the origin of culture.  Psycholoquy, 9. 
Gabora, L. (2004). Ideas are not replicators but minds are. Biology & Philosophy, 19(1), 127-143. 
Gabora, L. (2008). The cultural evolution of socially situated  cognition. Cognitive Systems Research, 9(1-2), 104-113. Gabora, L. (2013). An evolutionary framework for culture:  
Selectionism versus communal exchange. Physics of Life  Reviews, 10, 117-167. 
Gabora, L., (2017). Honing theory: A complex systems  framework for creativity. Nonlinear dynamics, Psychology, and Life Sciences, 21, 35-88. 
Gabora, L., & Carbert, N. (2015). A study and preliminary  model of cross-domain influences on creativity. In R. Dale,  et al. (Eds.), Proceedings of the 37th annual meeting of the  Cognitive Science Society (pp. 758-763). Austin TX:  Cognitive Science Society. 
Gabora, L., O’Connor, B., & Ranjan, A. (2012). The  recognizability of individual creative styles within and  across domains. Psychology of Aesthetics, Creativity, and  the Arts, 6, 351-360. 
Gabora, L., & Steel, M. (2017). Autocatalytic networks in  cognition and the origin of culture. Journal of Theoretical  Biology, 431, 87-95. 
Hargadon, A., & Sutton, R. I. (1997). Technology brokering  and innovation in a product development firm.  Administrative Science Quarterly, 42, 716. 
Helson, R. (1996). In search of the creative personality. Creativity Research Journal, 9(4), 295-306. 
Hirsh, J., Mar, R., & Peterson, J. (2012). Psychological  entropy: A framework for understanding uncertainty related anxiety. Psychological Review, 119, 304-320. 
2460
Hong, E., & Milgram, R. M. (2010). Creative thinking  ability: Domain generality and specificity. Creativity Research Journal, 2, 272-287. 
Jeppesen, L. B., & Lakhani, K. R. (2010). Marginality and  problem-solving effectiveness in broadcast search.  Organization Science, 21(5), 1016-1033. 
Kauffman, S. (1993). Origins of order. New York: Oxford  University Press. 
Kaufman, J., & Baer, J. (2004a). Hawking's haiku,  Madonna's math: Why it is hard to be creative in every  room of the house. In R. J. Sternberg, E. L. Grigorenko, &  J. Singer (Eds.), Creativity: From potential to realization.  Washington, DC: American Psychological Association. 
Kaufman, J. C., & Baer, J. (2004b). Sure, I'm creative—but  not in mathematics!: Self-reported creativity in diverse  domains. Empirical studies of the Arts, 22, 143-155. 
Kaufman, J. C., & Baer, J. (2004c). The amusement park  theoretical (APT) model of creativity. The International Journal of Creativity & Problem Solving, 14, 15-25. 
Martindale, C., & Daily, A. (1996). Creativity, primary  process cognition and personality. Personality and Individual Differences, 20, 409–414. 
Pelaprat, E., & Cole, M. (2011). “Minding the gap”:  Imagination, creativity and human cognition. Integrative  Psychological and Behavioral Science, 45(4), 397-418.  
Plucker, J. A., & Beghetto, R. A. (2004). Why creativity is  domain general, why it looks domain specific, and why the  distinction does not matter. In R. J. Sternberg, E. L.  Grigorenko, & J. L. Singer (Eds.), Creativity: From 
potential to realization. Washington, DC: APA. Pribram K.H. (1994). Origins: brain and self-organization.  Hillsdale NJ: Lawrence Erlbaum. 
Ranjan, A. (2014). Understanding the creative process:  Personal signatures and cross-domain interpretations of  ideas. Ph.D. Thesis, University of British Columbia. 
Ranjan, A., Gabora, L., & O'Connor, B. (2013). The cross domain re-interpretation of artistic ideas. Proceedings of  the 35th annual meeting of the Cognitive Science Society (pp. 3251-3256). Houston TX: Cognitive Science Society. 
Runco, M. A. (2014). Creativity: Theories and themes: Research, development, and practice. Elsevier. Saleh, B., Abe, K., & Elgammal, A. M. (2014). Knowledge  discovery of artistic influences: A metric learning  approach. Proceedings of the Fifth International Conference on Computational Creativity. Paulo Alto: Association for the Advancement of Artificial Intelligence. Simonton, D. K. (2010). Creative thought as blind-variation  and selective-retention: Combinatorial models of  exceptional creativity. Physics of life reviews, 7, 156-179. Varela, F., Thompson, E. and Rosch, E. (1991). The  embodied mind. Cambridge MA: MIT Press. 
Weisberg, R. W. (1995). Prolegomena to theories of insight  in problem solving: Definition of terms and a taxonomy of  problems. In R. Sternberg & J. Davidson (Eds.) The nature  of insight (pp. 157-196). Cambridge MA: MIT Press. 
Coupling Dynamical and Connectionist Models: Representation of Spatial Attention via Learned Deictic Gestures in Human-Robot Interaction 
Barıs¸ Serhan (baris.serhan@plymouth.ac.uk) 
Centre for Robotics and Neural Systems (CRNS), Plymouth University 
B110, PSQ, Drake Circus, Plymouth, PL4 8AA, UK 
John Spencer (j.spencer@uea.ac.uk) 
School of Psychology, University of East Anglia 
Norwich Research Park, Norwich, Norfolk, NR4 7TJ, UK 
Angelo Cangelosi (a.cangelosi@plymouth.ac.uk) 
Centre for Robotics and Neural Systems (CRNS), Plymouth University 
A316, PSQ, Drake Circus, Plymouth, Devon, PL4 8AA, UK 
Abstract 
A proper representation of space and a joint attention mecha nism are indispensable for an effective deictic communication with embodied agents. Taking inspiration from developmen tal psychology may help us to tackle computational challenges for robots. Although some developmental joint attention mod els for robots have already been proposed, to the best of our knowledge, there is no such model that can stand for the ef fects of pointing gestures on covert attention in infants. Thus we have designed and implemented a developmental robotics model for joint spatial attention combining connectionist and dynamical approaches. The hybrid architecture was struc tured over two existing computational models: a connectionist model of gesture comprehension and a Dynamic Field (DF) model of spatial attention in infants. These models were ex tended with various perceptual modules and dynamical neu ral fields, and implemented on the state-of-art iCub humanoid robot. In this paper, the computational architecture is intro duced with some preliminary results that show the model’s ca pability of representing deixis and perceived objects, and their effects on attention over space and time. 
Keywords: cognitive modelling; cognitive robotics; artificial neural networks; dynamic field theory; joint attention; pointing gestures; spatial attention; deixis; grounded cognition 
Introduction 
Inherently simple tasks, such as jointly attending to a particu lar object or an event in the scene, might be very challenging for artificial cognitive agents. Human infants acquire joint attentional skills very early in infancy, starting from gaze fol lowing, later comprehension and production of deictic ges tures such as pointing (Tomasello, Carpenter, & Liszkowski, 2007). These abilities are essential for human communica tion. On the other hand, the ability to accomplish proper de ictic communication with humanoid robots, key processing mechanisms, such as attention synchronisation, object recog nition and object indication, are needed (Sugiyama, Kanda, Imai, Ishiguro, & Hagita, 2007). 
Pointing gestures are observed prior to verbal communi cation and they are universal social tools to direct attention (Bates, Camaioni, & Volterra, 1975). In attentional cue ing tasks, it has been shown that comprehension of point ing gestures occurs several months before their production (Gredeback, Melinder, & Daum, 2010) and if the pointing ¨ 
hand provides also motion information, then the attentional sensivity in congruent cases can be observed even in 4.5- month-old infants (Rohlfing, Longo, & Bertenthal, 2012). 
Developmental (or epigenetic) Robotics is a multidisci plinary field where insights from developmental psychology guides the implemention of adaptive intelligent embodied agents (Cangelosi & Schlesinger, 2015). In developmental robotics, Artificial Neural Networks (ANNs) have been used to map some of the developmental changes of joint attention (Nagai, Hosoda, Morita, & Asada, 2003). ANNs were also used to model pointing gesture comprehension using edge features in robot-robot interaction (Hafner & Kaplan, 2005), as well as using the motion and edge information in human robot interaction (Nagai, 2005). However, time is not an in herent property of these feed-forward networks. Even if the number of learning steps can be used to denote the time, once the network is trained, the network’s output reaction for a given input is immediate in terms of computation steps. On the other hand, time is a built-in feature in dynamical systems approaches, as well as in certain hybrid approaches such as Nengo, which integrates time dynamics into its framework using LIF spiking neurons (Eliasmith, 2013). 
The Dynamic Field Theory (DFT) is a dynamical approach to model cognition at the neural population level (Schoner, ¨ Spencer, & the DFT Research Group, 2015). The theory has been used to model wide variety of cognitive processes, as well as the developmental aspects of cognition. The DFT is notably robust to simulate reaction times of the underlying processes of spatial cognition (Spencer, Simmering, Schutte, & Schoner, 2007). The DF model of the proposed architec- ¨ ture of this paper was constructed over the existing IOWA model that can capture the developmental changes in spatial attention and saccade planning (Ross-Sheehy, Schneegans, & Spencer, 2015). 
It has been proposed that, on the theoretical basis, connec tionism and dynamical systems accounts do not have compet ing positions in child development (Thelen & Bates, 2003). In this paper, we introduced a computational architecture that integrates and extends the conceptual link between connec 
2461
tionism and dynamical modelling approaches. The proposed developmental robotics model is able to represent the overt and the covert spatial attention over time and space by ex tending a connectionist model of deictic gesture comprehen sion (Nagai, 2005) with the DFT approach. 
In the next section, the architecture of the model is ex plained in detail considering, respectively, the robot and its related modules, the connectionist parts of the model, and the integration of the DFT modules. The model is then evaluated in three case scenarios in the results section. Finally, the paper is concluded with the discussions and the future directions. 
The Computational Architecture 
The cognitive robotics model was designed to interpret the contribution of the low level features of pointing gestures such as movement and edge information, to a higher under standing of deixis. To learn the association between the point ing hands and the indicated locations in the space through the low level features, a variation of a gesture comprehen sion neural network model was implemented (Nagai, 2005). This model can learn autonomously the intended direction of a pointing gesture. However, once the network is trained, it immediately produces outputs for any given input sequences. This makes it impossible to model developmental psychology studies based on reaction time. We extended this model us ing the Dynamic Field Theory so that the new architecture is able to represent some parts of the high level cognition such as spatial attention and spatial working memory. The overall structure of the model can be seen in Figure 1. Its constitu tive modules and their functions are explained in detail in the following subsections. 
The Embodied Agent 
The iCub robot was used as an embodied agent of the compu tational model in this study. This section briefly explains the robot and associated modules. 
iCub Humanoid Robotic Platform The iCub humanoid robotic platform is an open source robotic platform developed at the Italian Institute of Technology with the contribution of more than 20 laboratories. The iCub robot was designed as a 3 to 4 year-old child (Figure 1) and equipped with binoc ular vision, binaural audition, haptic and inertial sensors to perceive the surrounding environment, as well as its bodily states. It has also 53 degrees of freedom that enables it to perform wide variety of actions to interact with its environ ment. The main purpose of the iCub is to provide an inter disciplinary platform for cognitive development research via HRI and autonomous learning studies (Metta et al., 2010). 
YARP Modules Yet Another Robot Platform (YARP) is an open source robotics middleware that is designed to ease communication between different hardware and software sys tems (Metta, Fitzpatrick, & Natale, 2006). In our study, YARP was used to ensure the link between all physical ma chines such as server and client PCs, and the iCub’s boards. The communication of the modules that work on different 
platforms (e.g. Matlab for DFT modules and Python for neu ral network modules) were also accomplished by implement ing modules using YARP’s functionalities. 
Motor Control Module This module was implemented to create an actual saccade on the particular location where the saccade motor field of the DFT module was indicated. It takes one dimensional input, turns into a point on a semicircle on 2D plane and sets the motor decoders of the robot’s eyes to fixate that point. 
Learning Pointing Direction via Low Level Features 
The modules that are responsible to get raw data from the robot’s camera and process them to understand pointed loca tion, are illustrated in the upper half of Figure 1. Pointing gestures are first captured by the iCub’s left camera and im ages are transferred to the main computer using YARP proto cols. Then, the images are passed separately through pre processing steps in three modules before they are fed into neural networks and dynamical neural fields. 
Perception Module This module detects the object in the current scene according to its colour using basic openCV masking methods and forms the object location into an an gle value. This angle value is later sent to the DFT module and represented as the location of the object on the perception dynamic neural field. 
Feature Detection Modules The Edge Detection (ED) and the Optic Flow Detection (OFD) modules were implemented very similarly to Nagai’s model (Nagai, 2005). The centre of the image (168x168) was considered as foveal area. The ED detects the edges of the hand image in this area with an ori entation selective filter so that each edge pixel has a 4 dimen sional vector for 4 different orientations ( ↔,.%,l,-& ). The foveal region was split into 49 small regions (24x24) called receptive fields. A cumulative orientation vector was calcu lated for each receptive fields. 
The displacement of the receptive fields between consecu tive frames was calculated by the OFD module using a tem plate matching algorithm. For each field, an 8 dimensional vector is constructed to keep the displacement amounts on 8 different directions (←,.,↓,&,→,%,↑,-). 
Learning Modules Two separate feed-forward neural net works were implemented in PyBrain (Schaul et al., 2010) to learn the association between pointing gestures and the pointed location. The edge neural network (edge-NN) has three layers. The input layer has 196 neurons which receive the orientation vectors of the receptive fields as inputs (49x4) from the ED. The edge-NN also has a fully connected hid den layer consisting of 49 neurons and an output layer of 8 neurons. The output neurons represent the magnitude of the 8 different direction vectors of the indicated location. 
The optic flow neural network (flow-NN) has one input (392 neurons) and one output layer (8 neurons). It receives displacement information of the receptive fields in 8 direc 
2462
  
Figure 1: Architecture of the model 
tions (49x8) and outputs an 8 dimensional vector as edge-NN. 
The learning of pointing gestures with these networks was done offline by using 104 labelled videos from the same par 
τu˙ = −u(x,t) +h(x) +s(x,t) +
Z 
g(u(x0,t))k(x−x0)dx (1) 
ticipant. These videos had 37 different object locations that were congruent to the pointing hand. Around 2500 image frames were extracted from these videos to train the networks for 10000 epochs with a learning rate σ = 0.05. 
Dimension Reduction Once the pointed location is deter mined by neural networks with 8 dimensional vectors, these vectors are first projected onto 2D plane by taking the means of horizontal and vertical components of the 8 directions as in (Nagai, 2005). After that, their dimension is again re duced by using a multi-valued inverse tangent function (i.e. numpy.arctan2) to an angle in radian ( ] − π; 0[ ). The two angle predictions of two networks are sent separately to the DFT module through YARP. 
High Level Representation of Pointed Location 
To extend the sensorimotor understanding of our connection ist network with spatial attention and spatial working memory mechanisms, we took advantage of the dynamic field theory (Schoner et al., 2015). In the DFT, the activation of the neural ¨ populations are represented with dynamic neural fields that are defined by the following differential equation: 
where u(x,t) is the activation level of the related neural field over the predefined metric dimension x such as space, τ is the time constant, h(x) is the resting level of the activation, s(x,t) is the external input to the field, and the integral term stands for the convolution of the interaction kernel k (e.g. a Gaussian function) with the output sigmoid function g(u). 
The DFT is a powerful approach to model neural dynam ics of high level cognitive processes at the population level. The DF model of this study has been built by extending the existing IOWA model (Ross-Sheehy et al., 2015) using the COSIVINA framework in Matlab. The IOWA model is an in fant saccade planning model that can capture developmental changes in spatial attention and memory. The IOWA model was extended by adding two other dynamic neural fields, namely perception field and reference (pointing) field (the DFT module in Figure 1). 
The continuous metric dimension (x) of all the neural fields is defined as the angles on a semicircle (]−π; 0[) that is cen tred at the mid horizontal line of the image plane (the dimen sion reduction in Figure 1). 
Visual Perception Field This neural field is used to repre sent the perceived object location as a peak of activation of a 
2463
neural population. This can be thought as a sort of retinotopic representation of the object in the current scene by a popula tion of neurons in early visual areas such as V1. The visual perception field has excitatory projections onto the attention field so that if the visually salient object remains a sufficient amount of time on a particular location, that might cause a peak of activation in the spatial attention for that location. The field has also lateral interactions so that when a detected object gives rise to a peak of activation, this peak may became an attractor state with the local excitation around that location and the global inhibition over the space dimension. 
Pointing (Reference) Field The purpose of the neural pop ulation of the pointing field is to stand for the referential re lation between the observed space and the pointed location. The angle values received from two neural nets are projected onto the pointing field as the summation of two Gaussian stimuli (i.e. s(x,t) in eq. 2 ) where their centres were char acterised by these angles on the field’s metric dimension (x). The reference field has self excitatory-inhibitory lateral inter actions and an excitatory projection onto the attention field (just as the visual perception field). The field equation of the pointing field is the following: 
τu˙r =−ur(x,t) +hur(x) +s(x,t) 
sion which is the same metric dimension as the others. Our contributions to its dynamical equation were two excitatory projections coming from the visual perception (bottom-up) and the pointing field (top-down) which are defined by the convolutions of those fields’ outputs with Gaussian kernels. 
Once the activation passes the resting level on a particular location, the strong global inhibition suppresses all the other rival spots over the feature dimension. Together with the local excitation, one single attractor state that represents the spot light of the attention emerges on this field. 
If there is a conflicted situation, for example, if a hand points in the opposite direction while there is a visually salient object on the other side, the competition increases the time needed to create an attractor on an attentional locus. This process is also non-deterministic in terms of who the winner will be. 
Saccade Motor Field This field represents motor areas re sponsible of saccadic eye movements. It receives excitatory input from the spatial attention field and this interaction is done by convolving the sigmoid output function of the atten tion field with an inverse Gaussian kernel so that foveal areas are more inhibited while approaching to the center. With this mechanism, if the spotlight of attention is already at the fovea, the motor responses are suppressed, on the other hand, if the 
Z 
+ 
kurur(x−x0)g(ur(x0,t))dx+qξ(x,t)(2) 
attention is on another locus, an attractor state emerges at that location to saccade and fixate there. Once the resting level 
where uris the activation variable of the pointing (reference) field, τ is the time coefficient, g is the output sigmoid func tion, ξ is the random noise function and kururis a Mexican hat shaped function for the lateral interaction in the form of: 
is exceeded, attention field is inhibited to reset the system by discrete nodes (Ross-Sheehy et al., 2015). 
Results 
kurur(x−x0) = cexc √2πσexcexp −(x−x0)2 
  
2σ2exc 
The model was tested with three different videos that were not in the training dataset for the learning experiments. Each (3) 
−cinhib 
√2πσinhibexp
  
−(x−x0)2 2σ2inhib 
  
−cglob 
video had a different scenario. A blue plastic ball was located in the same place on the table in all cases. No pointing gesture appears in the scene in the first scenario while a congruent or 
where c is the strength of the interaction (cexc for excitatory, cinhib for inhibitory interactions), σ parameters are the width of the Gaussians and cglob is used for the global inhibition over the metric feature dimension of the pointing field. 
Basically, when the distance between the referential loca tions related to motion and edge information is small, then the amplitude of the attractor that appears on that location be comes higher, which then causes an increase in the attention on that location with its excitatory projection onto the spatial attention field. 
Spatial Attention Field The spatial attention and the sac cade motor fields are constructed based on the existing IOWA model (Ross-Sheehy et al., 2015). The strength of a localised activation on the spatial attention field represents the amount of attention on that particular location. The lateral inter actions permits the emergence of a rivalry mechanism be tween different localised activations over its feature dimen 
an incongruent pointing gesture appears, respectively, in case II and case III. 
The behaviour of the model was illustrated in these sce narios in three columns in Figure 2. Each panel of a column simultaneously represents the activation patterns on the re spective neural field during the associated experimental sce nario. In each panel, x-axis stands for the continuous metric feature dimension that is linked to locations on a spatial map of the environment. Y-axis represents the computational time steps whereas z-axis shows the activation levels of the field over time and space. Except for the saccade motor field, the surface areas were covered by connected red lines where the output of the sigmoid activation functions were higher than 0.5. In the saccade motor fields, only the first attractor was covered in red, since once threshold passed, the location is sent immediately to the motor control module to direct the iCub’s eye gaze to that fixation point. 
2464
  
Figure 2: Behaviours of the dynamical neural fields in 3 different conditions 
Case Scenario I - Object Perception 
In the first case, the stationary object located at −2π/3 can be seen on the visual perception field as a continuous peak of activation over time. Random fluctuations at the resting level (h = −5) on the pointing field demonstrate that there was no pointing gesture observed during this scenario. It can be seen in the attention field that the persistent activation of the per ception field triggered an increase in the attention at the same location and the field’s output function passed its threshold (i.e. g(ua(x0,t)) > 0.5) after around 300 computation cycles. The projection of this activation then caused a rise on the sac cade motor field and created a saccade signal at t = 551. 
Case Scenario II - Congruent Pointing 
In this case, the stationary object was again located in the same spot, however this time a moving pointing gesture di rected at the object was also included in the scene. Thus, the peaks of activation can be observed around the object loca tion (−2π/3) on the attention field in this occasion, whilst the behaviour of the perception field was very similar to that of the case I. Since the combination of both field activations left a trace together onto the spatial attention field, in this scenario the attractor states in the attention field had more strength than the previous case and more importantly, attrac tors were formed faster starting after around 200 time steps. This effect was then reflected also to the motor field and the saccade reaction time decreased to t = 284. 
Case Scenario III - Incongruent Pointing In the final scenario, the object was positioned in the same location, and a pointing gesture was presented. However 
this time the pointing hand was indicating another spatial re gion (−π/6) which was incongruent to the object location (−2π/3) (see the first and the second panels from the top). In this example, when the activations of the perception and the pointing fields were forwarded onto the spatial attention field, the incongruity of the locations initiated a rivalry be tween two conflicting regions. The localised peaks on the two sides of the attention field were trying to suppress the other because of the strong global inhibition defined through the lateral interaction kernel. Similarly, the strong local ex citation was helping these peaks to self-sustain whilst being under inhibition of the other. Therefore, this attentional ri valry mechanism elicited an increase in reaction time of the motor field (t = 807). 
The pattern of results described here reflect the typical dy namics of the system with the three visual stimulus configura tions. Future explorations of the control of the object location and the pointing hand will help to clarify the full dynamics of the model. 
Conclusion and Future Directions 
The proposed cognitive architecture is able to learn and rep resent the joint attentional intention underlying pointing ges tures while also taking into consideration its time dynam ics and its deictic nature. The implementation of our com putational model is consistent with the formal account of grounded cognition (Barsalou, 2008). Connectionism was taken into our hybrid model as a bottom-up understand ing mechanism of pointing gestures so that its learning can be seen similar to ‘sensorimotor toil’ method in the Sym 
2465
bolic Theft Hypothesis (Cangelosi, Greco, & Harnad, 2002). Grounding symbols over the pointing neural field might be possible in future, as, for example, demonstratives are ac companied by pointing gestures in early infancy and the ex ophoric use of demonstratives is to create a joint attentional frame (Diessel, 1999). In addition, the model may provide practical advantages for the design of robots that have more natural interaction and communication skills. 
In this paper, we introduced a cognitive robotics model and validated its key mechanisms. The next step is to design experiments to compare the iCub’s behaviours with infants’ reactions to the pointing gestures in attentional cueing tasks (e.g. Rohlfing et al. (2012)). Moreover, replicating develop mental psychology studies with robots may improve our un derstanding of the underlying mechanisms of cognitive pro cesses. Furthermore, this line of research might also provide new directions of investigations for developmental psycholo gists (Cangelosi & Schlesinger, 2015). 
Since speech is an essential modality for human communi cation, it can be an obvious extension for the model in future. The DFT is again an option as it has been already used for modelling spatial language (Richter, Lins, Schneegans, San damirskaya, & Schoner, 2014), as well as in word learning tasks (Samuelson, Spencer, & Jenkins, 2013). Another op tion might be using a deep neural network (DNN) to classify the speech and gesture couplings. 
Acknowledgements 
This study was conducted as a part of Deictic Communica tion (DComm) project and has received funding from the Eu ropean Union’s Horizon 2020 research and innovation pro gramme under the Marie Skodowska-Curie Actions (Grant agreement No 676063). We would also like to thank Prof. Dr. Gregor Schoner and the DFT Research Group at Ruhr ¨ University Bochum, as well as the researchers at the iCub fa cility at the Italian Institute of Technology (IIT, Genoa). 
References 
Barsalou, L. W. (2008). Grounded cognition. Annu. Rev. Psychol., 59, 617–645. 
Bates, E., Camaioni, L., & Volterra, V. (1975). The acquisi tion of performatives prior to speech. Merrill-Palmer Quar terly of Behavior and Development, 21(3), 205–226. 
Cangelosi, A., Greco, A., & Harnad, S. (2002). Symbol grounding and the symbolic theft hypothesis. Simulating the evolution of language, 191–210. 
Cangelosi, A., & Schlesinger, M. (2015). Developmental robotics: From babies to robots. 
Diessel, H. (1999). Demonstratives: Form, function and grammaticalization (Vol. 42). John Benjamins Publishing. Eliasmith, C. (2013). How to build a brain: A neural archi tecture for biological cognition. Oxford University Press. Gredeback, G., Melinder, A., & Daum, M. (2010). The devel- ¨ opment and neural basis of pointing comprehension. Social Neuroscience, 5(5-6), 441–450. 
Hafner, V. V., & Kaplan, F. (2005). Learning to inter pret pointing gestures: experiments with four-legged au tonomous robots. In Biomimetic neural learning for intel ligent robots (pp. 225–234). Springer. 
Metta, G., Fitzpatrick, P., & Natale, L. (2006). Yarp: yet another robot platform. International Journal of Advanced Robotic Systems, 3(1), 8. 
Metta, G., Natale, L., Nori, F., Sandini, G., Vernon, D., Fadiga, L., . . . others (2010). The icub humanoid robot: An open-systems platform for research in cognitive devel opment. Neural Networks, 23(8), 1125–1134. 
Nagai, Y. (2005). Learning to comprehend deictic gestures in robots and human infants. In Robot and human interac tive communication, 2005. roman 2005. ieee international workshop on (pp. 217–222). 
Nagai, Y., Hosoda, K., Morita, A., & Asada, M. (2003). A constructive model for the development of joint attention. Connection Science, 15(4), 211–229. 
Richter, M., Lins, J., Schneegans, S., Sandamirskaya, Y., & Schoner, G. (2014). Autonomous neural dynamics to test hypotheses in a model of spatial language. In Proceedings of the 36th annual meeting of the cognitive science society. 
Rohlfing, K. J., Longo, M. R., & Bertenthal, B. I. (2012). Dy namic pointing triggers shifts of visual attention in young infants. Developmental Science, 15(3), 426–435. 
Ross-Sheehy, S., Schneegans, S., & Spencer, J. P. (2015). The infant orienting with attention task: Assessing the neural basis of spatial attention in infancy. Infancy, 20(5), 467– 506. 
Rumelhart, D. E., & McClelland, J. L. (1986). Parallel dis tributed processing: explorations in the microstructure of cognition. 
Samuelson, L. K., Spencer, J. P., & Jenkins, G. W. (2013). A dynamic neural field model of word learning. Theoreti cal and computational models of word learning: Trends in psychology and artificial intelligence, 1–27. 
Schaul, T., Bayer, J., Wierstra, D., Sun, Y., Felder, M., Sehnke, F., . . . Schmidhuber, J. (2010). Pybrain. Jour nal of Machine Learning Research, 11(Feb), 743–746. 
Schoner, G., Spencer, J. P., & the DFT Research Group. ¨ (2015). Dynamic thinking: A primer on dynamic field the ory. Oxford University Press. 
Spencer, J. P., Simmering, V. R., Schutte, A. R., & Schoner, ¨ G. (2007). Insights from a dynamic field theory of spatial cognition. The emerging spatial mind, 320. 
Sugiyama, O., Kanda, T., Imai, M., Ishiguro, H., & Hagita, N. (2007). Natural deictic communication with humanoid robots. In Intelligent robots and systems, 2007. iros 2007. ieee/rsj international conference on (pp. 1441–1448). 
Thelen, E., & Bates, E. (2003). Connectionism and dynamic systems: Are they really different? Developmental Sci ence, 6(4), 378–391. 
Tomasello, M., Carpenter, M., & Liszkowski, U. (2007). A new look at infant pointing. Child development, 78(3), 705–722. 
2466
Early warning signals in improvised music 1 
Creative leaps in musical ecosystems: early warning signals of critical transitions in  professional jazz 
Matt Setzler*1 
msetzler@indiana.edu
	Tyler Marghetis*1,2,3 
tmarghet@indiana.edu
	Minje Kim4 
minje@indiana.edu
	



* lead authors contributed equally 1 Cognitive Science 2 Psychological & Brain Sciences  
3 School of Public & Environmental Affairs 4 Intelligent Systems Engineering 
Indiana University, Bloomington, Indiana, USA 
Abstract 
High-level cognition is often accomplished not by  individuals working in isolation, but by distributed, complex  cognitive systems. Examples include teams of scientists or  collaboratively improvising musicians. These distributed  systems can undergo critical transitions, suddenly moving  from one stable pattern of activity to another. For instance,  in ‘free jazz,’ where musicians improvise without a  predetermined plan or a central leader, the performance will  often settle into a particular texture or style before  transitioning to something entirely new, often quite  suddenly. When do these transitions occur? Are they  foreseeable? Inspired by suggestions that cognitive systems  are, in some sense, a kind of ‘ecosystem,’ we draw on recent  work in quantitative ecology that has begun to describe  generic early warning signals of impending critical  transitions in ecosystems. We apply these techniques to a  corpus of audio recordings of professional jazz quartets  playing improvised music. We find that the same generic  measures that have been used successfully to predict critical  transitions in natural ecosystems describe the complex  dynamics of improvised musical performance in the lead-up  to transitions. By taking seriously the metaphor that  cognition occurs in ‘ecosystems,’ we gain new insights into  how stable patterns of thought can emerge suddenly in  complex cognitive systems.  
  
Keywords: Early Warning Signals; Music; Improvisation; Complex  Adaptive Systems; Distributed Cognition 
Introduction 
A massive team of scientists, entangled with highly advanced  instruments, make a breakthrough discovery in particle physics.  Sailors on a navy vessel creatively reconfigure the way they track  the ship’s location (Hutchins, 1995). Improvising musicians  explore one particular musical texture before suddenly  transitioning to a new style or sound. In each of these examples,  expert reasoning is accomplished not by individuals working in  isolation, but by the whole distributed, complex system. Such  distributed cognitive systems can undergo critical transitions — 
sudden transformations from one stable pattern of activity to  another. But when? Are these transitions foreseeable? Consider two examples. First, Hutchins (1995) describes how  sailors on a large navy ship were forced to improvise when the  ship suddenly experienced a catastrophic loss of power. The  typical procedure for tracking the ship’s location relied on  instruments that were no longer operational. The entire distributed  system of sailors and instruments first stabilized around one  procedure for locating the ship on a map; after it became apparent  that this procedure was incorrect, the entire system reconfigured  quite suddenly into a new distributed procedure.  
As a second example, consider ‘free jazz’ musicians who  create new improvised music without a score, a central leader,  or explicit advance planning. Free jazz often exhibits  unexpected transitions between qualitatively different musical  textures characterized by stable rhythmic, melodic, or sonic  frameworks — which we will call ‘soundworlds.’ After  exploring a soundworld for some time, a jazz ensemble may  transition to an entirely new soundworld, often quite suddenly,  without apparent warning. These critical transitions between  soundworlds appear to reflect the emergence of a new stable  regime within the distributed system of musicians.  
Both these examples illustrate how distributed cognitive  systems can suddenly transition from one stable regime to  another — resulting in entirely novel cognitive procedures or  products. While the existence of these critical transitions is well  known, we know little about why and when these transitions  occur.  
An ecosystems perspective 
Distributed cognitive systems often involve a heterogeneous  mix of agents that interact across space and time. Inspired by  this, a number of authors have proposed that we adopt an  ‘ecological’ perspective on distributed cognitive systems  (Bateson, 1972; Gibson, 1986; Hutchins, 2010). This analogy  between cognitive systems and ecosystems has largely  remained at the level of an evocative image. Over the last  decade, however, ecologists have begun to develop  mathematical tools for analyzing, and perhaps even predicting,  critical transitions in natural ecosystems.  
2467
While many natural ecosystems exhibit considerable  resilience, maintaining a stable regime of activity in the face of  outside perturbations, they can sometimes transition suddenly  to an entirely different regime. A fish population may collapse  suddenly, or a lush ecosystem may experience sudden  desertification. These ‘tipping points’ can seem to appear from  nowhere, but ecologists have recently begun to develop early  warning signals (EWS) of impending critical transitions  (Sheffer et al, 2009; van Belzen et al 2017; Dakos et al, 2012;  Wang et al, 2012).  
In particular, many critical transitions are preceded by a  period in which the ecosystem becomes increasingly sensitive  to perturbations. In response to some outside ‘push,’ a resilient  ecosystem will eventually return to a stable state — but in  systems that are susceptible to a critical transition, this process  of restabilization will take longer and longer. This decrease in  the rate-of-return is known as critical slowing down (Fig 1B).  Ecologists have identified a number of indices that an  ecosystem is undergoing critical slowing, including two that we  will deploy here: increased variability, and increased lagged  autocorrelation (Fig 1B).  
From forest ecosystems to cognitive ecosystems Can we gain traction on critical transitions in distributed  cognitive systems by taking seriously the metaphor that  distributed cognitive systems are a kind of ‘ecosystem’? There  are reasons to hesitate. The complex systems that accomplish  human cognition often differ in critical ways from the  ecological systems for which these generic early warning  signals were first developed. Distributed cognitive systems  often involve a large number of distinct roles — think of the  proliferation of precise roles on a navy battleship, or dozen or  more musical parts in a piece of modern orchestra music.  Cognitive systems can also be highly heterogeneous,  combining highly specialized humans with a variety of  technologies, tools, and practices. And cognitive systems  operate on multiple timescales, some of which on multiple  timescales that are of less importance in natural ecosystems; in  addition to evolution and moment-to-moment interaction,  cognitive systems often have a cultural history. Jazz musicians,  for instance, spend years acquiring a set of shared intuitions and  practices. 
To investigate whether early warning signals of critical  transitions in natural ecosystems might also predict transitions  in expert cognitive systems, we focused on a system that  exemplifies many of the most rarified and unusual features of  human cognitive activity: ensemble free jazz performance. Free  jazz performance involves multiple humans in hyper 
specialized roles, using a range of technologies (i.e.,  instruments), with skills honed over a lifetime, to create new  music without an organizing score. The collective activity of  this distributed system creates entirely novel musical products.  
2468
Early warning signals in improvised music 2 
In the current study, using a corpus of audio recordings of  professional jazz musicians, we quantify the amount of critical  slowing down in the periods leading up to improvised  transitions. If this class of distributed cognitive systems  behaves similarly to natural ecosystems, then critical slowing  down should increase systematically in the lead-up to a critical  transition. 
Methods 
Corpus of free jazz recordings 
The corpus consisted of single-track audio recordings of  improvised free jazz music (~ 20 minutes), taken from two  recording sessions in a professional recording studio. Both  sessions featured a professional jazz quartet consisting of  saxophone, guitar, bass and drums. Although the tracks were  recorded on separate occasions, they feature the same  musicians except for the saxophonist. 
The first piece (length: 16m12s) was entirely ‘free’  improvised, making no use of pre-composed material and with  no explicitly stated preconceptions about what was supposed to  happen.  
The second piece (length: 2m54s) included some composed  material, interleaved with periods of free improvisation.  Transitions between improvised and composed sections were  determined collectively in the moment, so we consider these to  be improvised. The timing of transitions between composed  and improvised material were determined explicitly by the  score, so we consider these to be composed. 
Identifying critical transitions 
From the audio recording, a professional musician coded the  onset of transitions between soundworlds. Two critieria were  used to identify critical musical transitions: (1) transitions  needed to demarcate qualitatively different musical textures or  styles, and (2) transitions needed to involve a coordinated  change in playing from two or more individuals. The coder  identified twelve transitions: 8 improvised and 4 composed.  Only improvised transitions were included in our analysis.  
Analysis 
The audio recordings were transformed into a multi dimensional time series using Mel-Frequency Cepstrum  Coefficients (MFCC), which have been widely used in speech  recognition and music classification (Rabiner et al, 1993;  Tzanetakis et al, 2002). The typical procedure to calculate  MFCCs is to (a) apply a sliding window to a short period of the  signal, (b) transform the windowed signal to the frequency  domain by using Discrete Fourier Transform, (c) take the log of  the power of the spectrum, (d) convert the linearly spaced  frequencies into the mel scale, (e) apply Discrete Cosine  Transform, (f) move on to the next frame. MFCCs provide a  
Early warning signals in improvised music 3 
spectral analysis whose small number of coefficients (usually  
13) contains a compressed version of the full Fourier spectral  analysis results. On top of that, this compact representation is  more suitable than the original time domain signal with  redundantly high temporal resolution. To further reduce the  dimensionality of our data, each dimension of the MFCC time  series was normalized before performing Principal Component  Analysis. For simplicity, we used only the first four PCA  components (Fig1, top).  
From this four-dimensional time series representation of the  musical performance, we computed two indices of critical  slowing down: variability and lag-1 autocorrelation. Each was  computed in a sliding window (17.5s), with a stepsize between  windows of 0.02 seconds. Variability was computed as the  distance between all points in a given window, and  autocorrelation was computed as the mean lag-1 autocorrelation  for each of the 4 components. This produced two time series of  potential early warning signals; one for variability, and one for  autocorrelation (Fig2, bottom).  
Figure 1. Audio recordings were transformed into a  multidimensional feature representation, which was used to  calculate putative early warning signals of critical transitions.  (Top) Each single-track audio recording was transformed into  a multidimensional feature representation (MFCC), then  reduced to the first four principal components (colored lines).  When performers transition from one soundworld to another  (vertical rectangle), the performance should move to a new  region of this 4-dimensional state space. (Bottom) From this 4- d representation of the audio, we calculated two putative early  signals: variability and lagged autocorrelation. These were  computed within a sliding window (length = 17.5 seconds),  illustrated by the horizontal arrow in the top panel. In this toy  example, both variability and lagged autocorrelation increase  monotonically in the lead up to the critical transition. 
2469
Critical slowing down is indexed by a systematic increase in  variability and lagged autocorrelation. We thus examined the  rate of change in these early warning signals over the course of  the entire performance, in a sliding window of length 35s and  stepsize 0.02s. To quantify the rate of change within these  windows we used Kendall’s tau to measure the correlation  between the early warning signal and time. More positive  values of tau indicate greater monotonic increase. A system  undergoing critical slowing down during a particular time  period (e.g., leading up to a musical transition) should thus  have a positive value of tau for this period. 
Results 
Soundworlds: sub-regions of musical state space? We first verified that the multidimensional feature  representation of the audio allowed us to distinguish between  listener-perceived soundworlds. We thus investigated whether  distinct soundworlds inhabited distinct (though perhaps  overlapping) regions of the multidimensional feature space. A  soundworld that consists of entirely the same sound played over  and over should exist within a small region of the  multidimensional feature space; conversely, moments from two  very different soundworlds should be far apart in the feature  space. Following this logic, for each soundworld, we found the  subset of points that fully enclosed all points in the entire  soundworld (i.e., the convex hull) and calculated the volume of  this region. We then compared the size of each soundworld region to the size of equally-sized random samples from the  entire performance (n = 100 random samples per soundworld).  Each improvised soundworld inhabited smaller regions than  expected by chance (every p < .01). Thus, our multi dimensional feature space captured the subjective judgments of  the listener, correctly placing moments from within a  soundworld closer together than to other moments from the  performance.  
Critical slowing down before musical transitions?  We next turned to our critical question: Whether critical  musical transitions were preceded by critical slowing down. As  predicted, both indices of critical slowing down — variability  and lagged autocorrelation — increased systematically and  selectively in the period leading up to a critical transition.  These warning signals were increasing monotonically, as  measured by Kendall’s tau, at most critical transitions between  soundworlds, for both variability (75% of transitions; M = 0.24  ± 0.19 SEM) and for lagged autocorrelation (75% of transitions; M = 0.28 ± 0.17 SEM). By comparison, for  instance, these early warning signals were largely flat during  the rest of the second half of the soundworlds (variability: M =  0.05 ± 0.14 SEM; autocorrelation: M = 0.05 ± 0.17 SEM). The  complex systems generating these soundworlds, therefore,  
appeared to undergo critical slowing down in the lead-up to  transitioning between soundworlds.  
To account for non-stationarity, we compared these results to  surrogate time series with the same linear trend but scrambled  noise structure. We fit a linear model to the original  multidimensional feature representation of the audio and  randomly scrambled the residuals across time, creating a  surrogate time series that controlled for drift in the data while  randomizing the temporal spread of the noise structure.  Comparing the early warning signals in the original time series  to equivalent times in the surrogate time series allows us to rule  out the possibility that increases in early warning signals are  driven entirely by non-stationarity. 
We analyzed the timecourse and specificity of critical  slowing down with a linear mixed effects model of the tau  values across time. This model had fixed effects of  soundworld-normalized time (start = 0, end = 1), the time series  (actual = 0, surrogate = 1), and their interaction, along with  random by-soundworld intercepts and effects of time series  (actual vs. surrogate).  
This model confirmed that both variability and lagged  autocorrelation increased monotonically in the lead-up to a  critical transition (variability: b = 0.43 ± 0.08 SEM, p < 0.001;  autocorrelation: b = 0.30 ± 0.09 SEM, p = 0.02). This increase  was damped significantly in the surrogate time series  (variability: b = 0.32 ± 0.14 SEM, p = 0.047; autocorrelation: b  = -0.32 ± 0.12 SEM, p = 0.04). Finally, critical slowing down  increased significantly over the course of the soundworlds  (variability: b = 0.77 ± 0.15 SEM, p < 0.001; autocorrelation: b  = -0.47 ± 0.18 SEM, p < 0.001) — but this occurred primarily  in the actual time series rather than the surrogate time series  (variability: b = -0.56 ± 0.02 SEM, p < 0.001; autocorrelation: b  = -0.40 ± 0.02 SEM, p < 0.001). In summary, these distributed  systems underwent critical slowing down in the period leading  up to a critical transition. 
  
Figure 2. Early warning signals increased systematically  before critical transitions. The first three plots (blue) show  soundworlds where the early warning signal (vertical axis)  increased systematically leading up to a musical transition  (dashed lines). For comparison, the fourth plot (red) shows a  soundworld where the performance did not exhibit critical  
2470
Early warning signals in improvised music 4 
slowing down before transitioning (i.e., variability decreased,  rather than increased). The predicted increase in the early  warning signals before a transition is captured by the  correlation between the early warning signal and time (i.e.,  Kendall’s tau), plotted in Figure 3.  
  
Figure 3. Mean critical slowing down in the period  immediately before a musical transition (dashed line). The  vertical axis indicates the direction and rate of change (i.e.,  Kendall’s tau) for each early warning signal in a 35-sec.  sliding window ending at that moment. Positive values indicate  monotonic increase. Time (x-axis) is normalized to go from 0 to  1 within each soundworld. Error ribbon = standard error of the  mean. 
Discussion 
We asked whether adopting an ‘ecosystem’ perspective  might give us empirical traction on an outstanding problem:  understanding when and why critical transitions occur in  distributed cognitive activity. As our case study, we chose the  sudden musical transitions that occur in improvised free jazz  performance. Building on theoretical and empirical  investigations of critical transitions in natural ecosystems, we  calculated generic early warning signals that are thought to  index critical slowing down, a kind of loss-of-resilience that  can precede critical transitions. As predicted, we found that  improvised transitions between musical ‘soundworlds’ were  preceded by a monotonic increase in two measures of critical  slowing down: variability and lagged autocorrelation. In free  jazz ensembles, sudden transitions from one distributed  cognitive regime to another appear to follow the same general  patterns that characterize transitions in natural ecosystems.  
Improvised music as a cognitive ecosystem  Some of the most sophisticated and intricate formal systems  invented by humans have arisen in the domain of music: tonal  
harmony of Western classical music, the polyrhythms of  African drumming, melodic counterpoint of the Bach  inventions. In composed music, musical structures (i.e. the  surface realizations of these formal systems) are formulated  ahead of time by an individual composer and dictated to  performers in the form of a written score. But in improvised  music, abstract musical structures emerge spontaneously out of  the distributed activity of the ensemble. Interaction is key in  improvised music. Each individual is continuously adapting to  and influencing the other members of the ensemble (Walton et  al, 2015). Musical meaning is less ascribable to individual  intentions as it is to the ongoing interplay between the various  voices of the ensemble (Borgo, 2005). Improvised music thus  provides us a testbed to study how high-level cognition (in the  form of abstract musical structures) emerges out of distributed  action of embodied, highly specialized agents. 
There are many genres of improvised music across the globe.  Each musical tradition can be characterized by distinct  conceptual structures, functional norms and roles aesthetic  guidelines. For example, the raga in Indian classical music  provides a framework for improvising coherent melodies over  long song forms. Jazz musicians master a shared repertoire of  "standard" tunes – melodies with corresponding harmonic  structures, that serve as improvisational templates. Musical  genres also determine functional roles assigned to particular  instruments. In straight ahead jazz for instance, the bassist  typically "walks" (i.e. plays quarter notes to mark time and  passing harmonic structure) while the saxophonist improvises a  melodic solo over the underlying harmony. These culturally  construed functional roles and formal structures are learned in  intimate detail by improvisers ahead of time, whose shared  knowledge facilitates the spontaneous generation of  sophisticated, compelling musical pieces. The existence of  these culturally produced constraints, and of learning on the  part of individual musicians constitutes an interesting departure  of cognitive ecosystems from natural ecosystems.  
 In this paper we analyzed recordings of free jazz. In free jazz,  musicians with strong training in straight-ahead jazz come  together to improvise without reference to any preconceived  "tune" or template. The musicians have a shared mastery of the  formal structures of straight-ahead jazz, but they are not  confined by them. Functional roles can be challenged, new  systems of harmony and rhythm can be explored. In the course  of this exploration, groups often settle into stable regimes,  which can be characterized by distinct harmonic structures,  rhythmic patterns, or sets functional roles. For example, in the  quartets analyzed in this paper, there might be a cacophonous  section in which everyone is playing as loud and fast as  possible with little to no group coherence. This section may  then yield to an intimate duo with saxophone and guitar  carefully co-constructing melodic and harmonic material. 
 Most of the periods leading up to transitions between  different stable regimes showed evidence of critical slowing  down. This is due to the collective, decentralized manner in  
2471
Early warning signals in improvised music 5 
which those transitions are executed. Within a given stable  regime, one performer within the ensemble may hint at a new  musical area to explore. This hint might be reinforced by  another musician playing a supporting motif, which might be  further reinforced by a third musician catching onto the  developing theme. In this manner, an ensemble can quickly  transition between qualitatively different stable regimes without  any central locus of control. While this may be the norm, it is  important to note that improvising ensembles also have the  capacity to make centralized transitions. In some cases, an  individual may simply decide to start playing something  different and force the ensemble along an alternate path. An  improvising ensemble's capability to support both decentralized  and centralized dynamics constitutes an interesting distinction  with natural ecosystems. 
Future work 
In future iterations, we would like to use a more sophisticated  modeling technique in our surrogate analysis. Here drift was  modeled with a linear regression spanning the entire range of  the recording, but it is possible that shorter-spanned nonlinear  trends present in our dataset were not captured by this  approach. Following the example of past works, it may be  beneficial to fit an ARIMA model to the music timeseries  (Wang et al, 2012). 
Another extension of this work will be to add more  recordings to the corpus. Doing so will enable increased  statistical confidence in the results, as well as an opportunity to  analyze the behavior of different musical ensembles. Moreover,  adding composed music to our dataset would enable  comparison between improvised versus composed transitions.  If it is true that the CSD observed in the free jazz transitions  owes to the distributed nature of improvised performance, we  should expect to not observe CSD in composed transitions as  they are issued by an a priori script (i.e. the written score). 
Conclusion 
Much high-level cognition is accomplished by systems that are  complex, distributed, and adaptive. Political consensus requires  multiple individuals bringing their beliefs into alignment.  Scientific activity is almost always a community endeavor.  Great musical improvisation often requires each performer to  cede some autonomy to the emergent will of the group. Each of  these systems can stay in a particular regime for a prolonged  period of time — before suddenly transitioning to a new  cognitive state. One political consensus might break down,  replaced by another. Scientists have eureka moments.  Musicians shock their audiences — and themselves — by  playing something that has never been played before.  Describing when these critical transitions occur is a first step  towards understanding why.  
Early warning signals in improvised music 6 
Acknowledgments 
We thank members of the GeoLab for comments.  
References 
Bateson, G. (1972). Steps to an ecology of mind. New York:  
Balentine Books. 
Borgo, D. (2005). Sync or Swarm: Improvising Music in a  
Complex Age. Bloomsbury Academic. 
Belzen, J. V., et al. (2017). Vegetation Recovery in Tidal  
Marshes Reveals Critical Slowing down under Increased  
Inundation. Nature Communications, vol. 8. 
Dakos, V., et al. (2012). Methods for Detecting Early Warnings  
of Critical Transitions in Time Series Illustrated Using  
Simulated Ecological Data. PLoS ONE, vol. 7, no. 7. 
Gibson, J. J. (1986). The ecological approach to visual  
perception. Hillsdale, NJ: Lawrence Erlbaum. 
Hutchins, E. (1995). Cognition in the Wild. MIT Press. 
Hutchins, E. (2010). Cognitive Ecology. Topics in Cognitive  
Science, vol. 2, no. 4, 705–715. 
Rabiner, L. R., & Juang, B.-H. (1993). Fundamentals of speech  
recognition. Englewood Cliffs: PTR Prentice Hall. 
Sheffer et al. (2009). Early-warning signals for critical  
transitions. Nature, vol. 461. 
Tzanetakis, G., and Cook, P. (2002). "Musical genre  
classification of audio signals." IEEE Transactions on  
speech and audio processing. 293-302 
Walton, A., et al. (2015. Improvisation and the Self 
Organization of Multiple Musical Bodies. Frontiers in  
Psychology, vol. 06. 
2472
Social information can undermine individual performance in exploration-exploitation tasks 
Kyanoush Seyed Yahosseini (yahosseini@mpib-berlin.mpg.de)1, Samuli Reijula (samuli.reijula@helsinki.fi)2, Lucas Molleman (molleman@mpib-berlin.mpg.de)1and Mehdi Moussa¨ıd (moussaid@mpib-berlin.mpg.de)1 
1 Center for Adaptive Rationality, Max Planck Institute for Human Development, Berlin, Germany 2 TINT / Social and Moral Philosophy, University of Helsinki, Finland 
Abstract 
In many daily life situations, people face decisions involving a trade-off between exploring new options and exploiting known ones. In these situations, observing the decisions of others can influence people’s decisions. Whereas social information often helps making better decisions, research has suggested that under certain conditions it can be detrimental. How precisely social information influences decision strategies and impacts perfor mance is, however, disputed. Here we study how social informa tion influences individuals’ exploration-exploitation trade-off and show that this adaptation can undermine their performance. Using a minimal experimental paradigm, we find that partici pants tend to copy the solution of other individuals too rapidly, thus decreasing the likelihood of discovering a better solution. Approximating this behavior with a simple model suggests, that individuals’ willingness to explore only depends on the value of known existing solutions. Our results allow for a better under standing of the interplay between social and individual factors in individual decision-making. 
Keywords: Exploration-exploitation trade-off, social learning, decision-making 
Introduction 
Social information is crucial to help individuals and groups adapt to novel circumstances. Through social interaction and observation, people can collect up-to-date information about their environment and efficiently deal with its uncertainty (Hills et al., 2015). For example, by selectively copying suc cessful others, individuals can readily improve their decisions, while avoiding the costs of trial-and-error learning (Mesoudi, 2011; Rendell et al., 2010; Wisdom, Song, & Goldstone, 2013). Moreover, the transmission of known solutions in populations can lead to the accumulation of knowledge, which can be built upon and refined over time (Boyd, Richerson, & Henrich, 2011; Derex & Boyd, 2015; Tomasello, 1999; Moussa¨ıd & Seyed Yahosseini, 2016). 
Yet, theoretical models from a range of disciplines suggest that social information can also be detrimental for the effi ciency of decision-making (March, 1991; Mehlhorn et al., 2015). Several mechanisms can underlie this counter-intuitive effect. First, it might be due to the structure of the environment. When exploration has an opportunity cost, the availability of social information can motivate people to free-ride and wait for others to discover a profitable solution, thus reducing the group’s exploration range (Bolton & Harris, 1999). This is particularly critical in dynamic environments that change in time and space, and where social information might be out dated or ill-fitted to one’s own situation (Henrich & Boyd, 1998; Rogers, 1988). Second, the detrimental effects of social information can be caused by social factors: One example 
of such an effect are information cascades, where mutual re inforcement can lead groups to converge upon sub-optimal solutions, while leaving potentially superior solutions unex plored (Bala & Goyal, 1998; Giraldeau, Valone, & Templeton, 2002; Salganik & Watts, 2008). Finally, individual factors may impact how social information affects decision-making. Social influence is often modulated by individuals’ perceived skill, experience and knowledge about the environment, which are not always accurately evaluated (Laland, 2004; Moussa¨ıd et al., 2017; Rendell et al., 2010). Additionally, individuals’ aspiration levels may change when observing the rewards of very successful or unsuccessful others (March, 2006). 
Recently, empirical studies have delineated how environ mental and social factors impact collective performance in decision problems. It has been shown that reducing the flow of social information among individuals – e.g., through sparsely connected social networks – can enhance performance at the group level (Fang, Lee, & Schilling, 2009; Derex & Boyd, 2016; Mason, Jones, & Goldstone, 2008). However, other studies suggest the opposite: they show that networks that facilitate the exchange of information between individuals tend to enhance group performance (Derex & Boyd, 2015; Mason & Watts, 2012). These conflicting conclusions suggest that a clear picture of the processes at play and their interac tion between each other are currently not available. As most simulation studies assume simplified decision rules, while ex perimental approaches often involve a combined manipulation of environmental and social factors, making it difficult to un derstand the contributions of the different factors (Mehlhorn et al., 2015). How do people respond to social information when searching for a problem solution? How do they adapt their exploration and exploitation decisions when exposed to the behavior of a peer? Addressing these questions helps disen tangle the complex interactions between these processes and facilitates understanding the resulting dynamics in its entirety. 
In this paper we show that social information directly affect individuals’ decision to explore or exploit, that is the used decision strategy, and as a result hamper performance. We examine how social information affects individuals’ tendency to exploit their own best solution, to copy the solution of a peer, and to explore their environment in search for superior alternatives. To this end, we designed a experiment in which we tightly control the value of social information. We aim to eliminate several common confounding factors stemming from temporal and spatial heterogeneity in the environment, 
2473
A 
New  
endogeneity of information propagation in the network, and pre-existing individual variation of knowledge and skills (e.g., Mason and Watts (2012); Jayles et al. (2017); Jonsson, Hahn, ¨ and Olsson (2015). This approach allows us to draw a clear 
? 
and simple picture of the isolated effects of social information on how individuals solve an exploration-exploitation task. 
Season 2 of 30 Best so far  
6 
Confirm 
Other's best  46 
B 
) 
f 
f
o
y
a
p
≤ 
X 
( 
P 
1.00 0.75 0.50 0.25 0.00 
≤ 
0 25 50 75 100 Payoff 
Methods 
We designed a sequential decision-making task with unidi rectional information flow in which participants played the role of farmers trying to maximize their cumulative payoff over 30 rounds. In every round, each participant could choose between three options: (1) plant a new unknown crop (i.e. explore a new solution), (2) plant the best crop he or she found so far (i.e. exploit the best known solution), and (3) plant the crop with the highest value that one other participant had discovered while taking the same task before (i.e. copy social information). Figure 1A shows the experimental interface of the experiment. 
Each crop was associated with a fixed payoff ranging from 1 to 100 points. The crop payoffs were randomly drawn from an exponential distribution with λ = 0.05, capped at 100. That is, many crops were associated with a low payoff, and a few of them had a high payoff, with a maximal possible value of 100 (Figure 1B). 
Each round, participants could either (1) draw a new value from the exponential distribution and receive the associated payoff (explore), (2) receive the payoff Xe associated to the highest value that was drawn so far (exploit), or (3) receive the highest payoff Xc that another participant had discovered (copy). In each round, participants could see the payoffs Xe and Xc while the payoff for explore was hidden. 
Experimental treatment. To systematically examine the ef fect of social information on individual decision strategies and performance, we implemented seven experimental treatments and a control condition in a between-subjects design. In the control condition, no social information was available, and participants could only choose to explore or exploit. We gath ered the highest payoff found by each participant in the control condition, that is Xe after 30 rounds of independent search. To systematically assess the effect of these values on decision strategies, we selected a subset of them to display as social information Xc in the experimental treatments. We selected the following values: 16, 21, 26, 31, 36, 46, and 56. This setup allows the participants in the experimental conditions to observe actual social information generated by other partici pants, and it ensures a uniform sample size over a wide range of different values of social information. For each participant, the value Xc was constant over the 30 farming rounds. 
Procedure and participants. We ran two sessions of the experiment on Amazon Mechanical Turk. In the first session all participants were assigned to the control condition. In the second session participants were randomly assigned to one of the seven experimental treatments, where a specific Xc was 
Figure 1: Experimental design. (A) The experimental inter face as shown to the participants. In every round (season), participants could choose to plant a new unknown crop (left button), to collect the payoff associated to their best discov ered crop (middle button) or to collect the payoff associated to the best crop found by another participant (right button). (B) The cumulative distribution function of the exponential random variable used to generate the payoffs every time a participant decided to plant a new crop. The values of social information used in our experimental conditions are marked by red triangles. 
selected from the first session. 
Participant were informed that the payoffs could range from 1 to 100 and that most crops were associated to a low number of points. They where also briefed about how the social infor mation was acquired. Participants were instructed to maximize their cumulative payoff over 30 rounds and informed that at the end of the experiment, their cumulative payoff would be converted into real money (2,000 points = US$1). Before start ing the experiment, participants completed a short interactive tutorial and had to pass a comprehension check. At the end of each round, participants were informed about their payoff from that round and their cumulative payoff. 
In total 322 participants (145 Female, mean age = 36.9 years, SD = 10.9 years) completed the experiment with an average of 40.2 participants (SD = 4.7) per experimental con dition. Participants were rewarded by US$0.75 plus a mone tary bonus based on their final score in the experiment (mean bonus=US$0.62, SD=US$0.24). The average completion time was 8 minutes. The self-reported understanding of the experi mental task was very high, as 97% of the participants reported ≥ 6 points on a 7 point Likert scale. 
Models 
To gain a deeper understanding of how social information shapes individual decisions in our experiment, we first intro duce two simple models involving different decision strategies: the benchmark model and the threshold model. In both models, agents make a decision between (1) explore, (2) exploit, and (3) copy at any given round t. The payoff ρ(t) that the agent receives at round t depends on the chosen option as follows: 
1. If the agent decides to explore, ρ(t) = x, where x is a randomly drawn value from the exponential distribution shown in figure 1B. 
2. If the agent decides to exploit, ρ(t) = Xe, where Xe is the highest value that has been drawn by the agent since the beginning of the task. 
2474
A 
) 
e
r
o
l
p
x
e
(
P
1 
p0 0 
B 
y 
c
n
e
u
q
e
r
F


	



0 x0 100 Xmax 
0.3 
0.2 
0.1 
0.0 
0 25 50 75 100 Satisfaction level x0 
C 
y 
c
n
e
u
q
e
r
F
0.3 
0.2 
0.1 
0.0 
0.0 0.2 0.4 
Base exploration rate p0 
We fit the step function to the behavioral data of each participant individually. For that we use the step func tion with p0 = 0 as a binary classifier to predict if a par ticipant explores. We define exploration as a positive and exploitation as a negative outcome. We then calculate x0 such that the predictive accuracy of the classifier is maxi 
Figure 2: The building blocks of the threshold model. (A) Graphical representation of the step function used for the threshold model. The probability P(explore) equals 1 as long as the payoff of the best known solution Xmax is lower than the satisfaction level x0. Above that level, some exploration is maintained with a probability p0, the base exploration rate. (B) Distribution of the estimated threshold values x0 for all participants. The the red curve indicates the best log-normal fit (meanlog = 3.13, sdlog = .78, McFadden’s r2 = .58). (C) Dis tribution of the estimated values of p0 for all the participants. The median value p0 = .17 is indicated by the red line. 
3. If the agent decides to copy, ρ(t) = Xc, where Xc is the pay off associated with the crop provided by social information. 
For both models we measure performance as the average payoff that an agent achieves across the 30 rounds. We ran 610,000 repetitions of each model while systematically vary ing Xc between 0 and 60. 
Benchmark Model. In the benchmark model, we assume that the agents explore their environment during the first τ rounds (i.e. the exploration phase) of the experiment, and then choose the most rewarding option between exploit and copy, during all the remaining rounds (i.e. the capitalization phase) (Rapoport & Tversky, 1970; March, 1991). The unique parameter of this normative model is the time τ at which the agents switch from exploration to capitalization. We call the optimal switching point τ∗the value of τ that yields the best mean performance for a given value of Xc. We estimate τ∗ by systematically varying τ between 0 and 30 and pick the value that yielded the best mean performance. 
Threshold Model. For the threshold model, we assume a simple decision strategy to facilitate the comparison with the experimental results. The threshold model assumes that the probability to choose the explore option P(explore) in a given round is solely dependent on the maximum payoff Xmax = max(Xe,Xc) that the agent can get by exploiting or copying. Thus, in each round the agent will either explore with a probability P(explore) or choose the exploit or copy option that will yield the higher payoff with a probability 1−P(explore). 
The probability P(explore) is specified by a simple step func 
mized. Accuracy is defined as the (number of true positives+ number of true negatives)/30. For the most accurate x0 we set p0 to the number of false negatives/30. That is, p0 is the probability that exploration was wrongly classified as exploita tion or copy. This procedure provides an estimation of the parameters x0 and p0 for each participant. The distributions of the two parameters are shown in figure 2B-C. For the simu lations, we generate agents by picking x0 from the log-normal distribution fitted to the estimated values of the participants and p0 by the median of those. 
Results 
We now look at our experimental results and compare them to the predictions from the two models. 
Performance. The presence of social information has a strong and non-monotonic influence on the participants’ per formance (Figure 3). We observe a decay in performance in the conditions where participants received social information of low value, specifically when Xc ranges between 21 and 31, but not in case of Xc = 16. Overall, participants who received no social information performed equally well or better than those who received social information of value Xc lower than 46. For higher values of Xc social information was beneficial and allowed participants to improve their performances as compared to the control condition. 
Furthermore, our simulations show that the threshold model predicts a similar decay in performance around Xc = 26, whereas the benchmark model – which was not calibrated on the data but for maximizing performance – suggests that participants could have reached a much better score with a different decision strategy, such as exploring early to be able to assess the relative value of Xc. 
Decision strategies. To explain the decrease in performance observed in our experimental results for values of Xc surround ing 26, and predicted by the threshold model, we analyzed the underlying decision strategy of the participants. Specifically, we looked at how frequently participants chose to explore, to exploit and to copy in each treatment (figure 3B). We antici pated that participants would explore less in the presence of social information, and indeed participants explored on av erage 10 rounds (SD = 5.5) in the control condition, while exploring 8.1 (SD = 5.2) rounds when social information was 
tion: 
P(explore) = 
( 
1, if Xmax < x0 p0, otherwise 
available (W = 6761.5, p = .04). Also we predicted that the frequency of exploration would depend on the value of social information. Surprisingly the data shows that the exploration rate changes only marginally between the experimental condi 
Where x0 is a threshold aspiration level based on Xmax, and p0 is the base exploration rate (see figure 2A). 
tions. For Xc = 16 participants explored on average 7.8 rounds (SD = 4), very close to the 7.5 rounds (SD = 5.4) of exploration 
2475
A 
60 
B 
0.6 
Beha vioral 
e c
n
n o
data 
explore 
a
m
r
o
fr
e
P
50 
40 
no social information 
16 26 36 46 56 
it
r
o
p
o
r
P
0.4 
0.2 
0.0 
no social information 
16 26 36 46 56 
Benchmark model 
Threshold model 
copy 
exploit 
Social information Xc 
Social information Xc 
Figure 3: Experimental results and model predictions. (A) Average individual performance as a function of social information Xc as measured in the experiment and predicted by the two models. Average individual performance is calculated as the average payoff per round, ∑(ρ(t))/30. Error bars indicate the standard error. (B) Proportion of explore, copy, and exploit decisions as a function of the social information Xc. 
for Xc = 56. That is, a reduction of exploration cannot explain 
the decay in performance. However, as expected, the overall 
tendency to copy increases with larger values of Xc, while the amount of exploitation decreases at the same time. 
1.0 
Because the average performance of individuals in the con 
Behavioral data Threshold model 
s
n
trol condition – where no social information was available – is 
o
0.5 
o
c
n 
i
a
l 
approximately 40 points, copying a crop of value Xc lower than 
0.0 
40 would necessarily be counter-productive. This is indeed 
1.0 
confirmed by the prescriptive simulations of our benchmark 
model (blank green and blue circles in figure 3B). Yet, our 
0.5 
results show that for values Xc ≤ 36, people unknowingly copy too frequently – thus capitalizing on a sub-optimal option. Our 
0.0 
1.0 
threshold model predicts a similar trend. 
y 
c
n
0.5 
e
u
Temporal changes. To draw a more accurate picture of the 
q
e
r
F
decision strategies, we looked at the temporal changes of 
0.0 
1.0 
behavior across the 30 rounds (figure 4). One striking ob servation is that the normative assumption that people would 0.5 
explore first and copy or exploit later, as implemented in the benchmark model and suggested by optimal stopping theory 
0.0 
(Rapoport & Tversky, 1970), clearly does not capture the 
1.0 
participants’ decisions. On the contrary, copying is the pre dominant behavior during the first few rounds independent of 
0.5 
the value of Xc. Only later on, if a better Xe is found, copying 0.0 
rates diminish. 
Participants tend to alternate between explore and copy at 
1
6 
2
6 
3
6 
4
6 
0 10 20 30 0 10 20 30 Round 
explore copy exploit 
the beginning of the experiment and, unsurprisingly, disre gard Xc, if Xc is not sufficiently good compared to what has been sampled in the meantime. This dynamic is captured by the threshold model. Thus the reduced performance around Xc = 26, as shown in figure 3, can be explained by the fact that participants tend to copy social information too frequently during the first few rounds without being able to assess the relative value of Xc. Whenever the value of social information is lower than what they would have sampled independently (i.e. Xc < 40), individual performance is undermined. Due to 
Figure 4: Proportions of explore, copy, and exploit as a func tion of the round in our experimental data (left column) and as predicted by the threshold model (right column). Each row refers to a different value of social information Xc (as indicated in the gray rectangles on the right). 
2476
the non-zero base exploration rate of the participants (mod eled by p0 > 0) a better solution is eventually discovered and exploited. But this discovery is delayed as compared to the control condition, decreasing the number of rounds when Xe can be exploited, and hence reducing overall individual performance. For Xc = 16 a better solution for Xe can be dis covered very easily and thus the overall performance is not undermined. 
Discussion 
In this paper we investigated how the presence of social in formation can influence individual strategy and performance. We studied this question by means of a simple exploration exploitation task. In contrast to existing research, we only im plemented the most basic parts of the exploration-exploitation paradigm, thus focusing on how social information affects de cisions. On that account, we ignored the structure of commu nication networks and considered unidirectional information flow between two individuals only (Mason & Watts, 2012; Toyokawa, Kim, & Kameda, 2014; Wisdom et al., 2013). Fur thermore, we fixed the social information to one static value that does not change over time (in contrast to Mason and Watts (2012); Mesoudi (2011); Toyokawa et al. (2014)), and we elim inated the spatial correlations between the payoffs (in contrast to Mason et al. (2008); Wu, Schulz, Speekenbrink, Nelson, and Meder (2017) 
With this design, we discovered that social information can undermine not only the collective, but also the individual per formance (cf. Wisdom et al. (2013)). In line with a recent simulation study conducted by Barkoczi and Galesic (2016), our results show that the detrimental impact of social informa tion can depend on the decision strategies employed and not exclusively on the network structure connecting people or the structure of the environment. 
The rationale of early copying. The harmful effect of so cial information is caused by the participants’ tendency to copy social information too early in the experiment, without knowing its relative value compared to what can be discovered by individual exploration. One common assumption is that people start exploring their environment and with the help of the gathered data evaluate the relative value of the social information, and only then capitalize on the best solution (cf. our benchmark model and also March (1991)). An alternative strategy, assuming an already exhaustive search by the pre vious participant, could be to rely completely on the social information provided and copy it all the time. Such a strat egy would minimize the cost for exploration. However our results show that participants do not follow either of those strategies, but rather prefer to copy in the very early phases of the experiment and only then start to explore. But copying does not provide any information about the environment, so why do people adopt this seemingly irrational strategy? Early copying can actually be reasonable if the payoff of the copied solution is sufficiently good. In fact, the best crop found by participants in the control condition had an average payoff of 
56.2, which is above the average of the payoff distribution. Thus, copying early could possibly have been beneficial if the social information given to the participants was representa tive of the performance in the absence of social information, which was not the case in our experiment. It is reasonable to assume that participants expected the social information to be representative of the underlying distribution of payoffs, which could have then justified their early copying. 
Sequential versus simultaneous treatment. Compared to other studies, one specificity of our design is that the par ticipants completed the experiment sequentially rather than simultaneously (Mason & Watts, 2012; Toyokawa et al., 2014). Each participant in the experimental condition was exposed to the best value found by another participant in the control con dition during independent search. Other experimental designs implemented simultaneous interactions, in which participants could see what others have found at the end of every round. In this case, the dynamics might be different, as participants could not reasonably assume that their peer had extensively explored the environment beforehand. In this context, the rationale of the early copying strategy would vanish, and we would expect people to copy only later in the experiment. In agreement with this interpretation, late copying has been reported in experiments involving simultaneous interactions (Mason & Watts, 2012). 
Accuracy of the threshold model. Despite its simplicity, the threshold model reproduces our experimental observations quite closely, suggesting that it has captured key aspects of the decision strategy. The model assumes that the probability to search for a new solution only depends on the payoff of the best available solution. The model therefore ignores most of the available information, such as the payoff distribution of previously explored solutions and the remaining number of rounds. The fact that the model captures key dynamics in the experiment without explicitly accounting for temporal dimen sion is surprising, since intuitively, people are likely to explore less as the end of the experiment approaches. Nevertheless, given the current quality of the model’s predictions, adding a temporal component might only yield a marginal improve ment of the predictions. Hence, time appears as a cue that has – if anything – a minor role on the decision strategy. Finally, whereas the model currently implements a fixed threshold value, it is also possible to consider an adaptive threshold that would vary with the observed sample of payoffs. 
Future research directions To examine basic aspects of how social information affects decision strategies of explo ration and exploitation, we deliberately started from a simple task. In future research we will gradually increase the com plexity of the decision-making setting – up to the point where a complete, realistic situation can be described. This will con sist of implementing simultaneous interactions, varying group size, manipulating the communication network, changing the payoff distribution and injecting private information. These ad ditions would also allow us to determine the predictive power 
2477
of the model, by testing it in different environments. Acknowledgments 
We thank the ARC research group and especially Wouter van den Bos for fruitful discussions. Samuli Reijula’s research is supported by the Academy of Finland. 
References 
Bala, V., & Goyal, S. (1998). Learning from Neighbours. The Review of Economic Studies, 65(3), 595–621. 
Barkoczi, D., & Galesic, M. (2016). Social learning strate gies modify the effect of network structure on group perfor mance. Nature Communications, 7, 13109. 
Bolton, P., & Harris, C. (1999). Strategic Experimentation. Econometrica, 67(2), 349–374. 
Boyd, R., Richerson, P. J., & Henrich, J. (2011). The cultural niche: Why social learning is essential for human adapta tion. Proceedings of the National Academy of Sciences, 108(Supplement 2), 10918. 
Derex, M., & Boyd, R. (2015). The foundations of the human cultural niche. Nature Communications, 6, 8398. Derex, M., & Boyd, R. (2016). Partial connectivity increases cultural accumulation within groups. Proceedings of the National Academy of Sciences, 113(11), 2982. Fang, C., Lee, J., & Schilling, M. A. (2009). Balancing Exploration and Exploitation Through Structural Design: The Isolation of Subgroups and Organizational Learning. Organization Science, 21(3), 625–642. 
Giraldeau, L., Valone, T. J., & Templeton, J. J. (2002). Po tential disadvantages of using socially acquired information. Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 357(1427), 1559. 
Henrich, J., & Boyd, R. (1998). The Evolution of Conformist Transmission and the Emergence of Between-Group Differ ences. Evolution and Human Behavior, 19(4), 215–241. 
Hills, T. T., Todd, P. M., Lazer, D., Redish, A. D., & Couzin, I. D. (2015). Exploration versus exploitation in space, mind, and society. Trends in Cognitive Sciences, 19(1), 46–54. 
Jayles, B., Kim, H.-r., Escobedo, R., Cezera, S., Blanchet, A., Kameda, T., . . . Theraulaz, G. (2017). How social infor mation can improve estimation accuracy in human groups. Proceedings of the National Academy of Sciences. 
Jonsson, M. L., Hahn, U., & Olsson, E. J. (2015). The kind of ¨ group you want to belong to: Effects of group structure on group accuracy. Cognition, 142, 191–204. 
Laland, K. N. (2004). Social learning strategies. Animal Learning & Behavior, 32(1), 4–14. 
Lazer, D., & Friedman, A. (2007). The Network Structure of Exploration and Exploitation. Administrative Science Quarterly, 52(4), 667–694. 
March, J. G. (1991). Exploration and Exploitation in Organi zational Learning. Organization Science, 2(1), 71–87. March, J. G. (2006). Rationality, foolishness, and adaptive intelligence. Strategic Management Journal, 27(3), 201– 214. 
Mason, W. A., Jones, A., & Goldstone, R. L. (2008). Prop agation of innovations in networked groups. Journal of Experimental Psychology: General, 137(3), 422–433. 
Mason, W. A., & Watts, D. J. (2012). Collaborative learning in networks. Proceedings of the National Academy of Sciences, 109(3), 764. 
Mehlhorn, K., Newell, B. R., Todd, P. M., Lee, M. D., Morgan, K., Braithwaite, V. A., . . . Gonzalez, C. (2015). Unpacking the exploration–exploitation tradeoff: A synthesis of human and animal literatures. Decision, 2(3), 191–215. 
Mesoudi, A. (2011). An experimental comparison of human social learning strategies: Payoff-biased social learning is adaptive but underused. Evolution and Human Behavior, 32(5), 334–342. 
Moussa¨ıd, M., Herzog, S. M., Kammer, J. E., & Hertwig, ¨ R. (2017). Reach and speed of judgment propagation in the laboratory. Proceedings of the National Academy of Sciences. 
Moussa¨ıd, M., & Seyed Yahosseini, K. (2016). Can Sim ple Transmission Chains Foster Collective Intelligence in Binary-Choice Tasks? PloS one, 11(11), e0167223. 
Rapoport, A., & Tversky, A. (1970). Choice behavior in an optional stopping task. Organizational Behavior and Human Performance, 5(2), 105-120. 
Rendell, L., Boyd, R., Cownden, D., Enquist, M., Eriksson, K., Feldman, M. W., . . . Laland, K. N. (2010). Why Copy Others? Insights from the Social Learning Strategies Tour nament. Science, 328(5975), 208. 
Rendell, L., Fogarty, L., Hoppitt, W. J., Morgan, T. J., Webster, M. M., & Laland, K. N. (2011). Cognitive culture: Theo retical and empirical insights into social learning strategies. Trends in Cognitive Sciences, 15(2), 68–76. 
Rogers, A. R. (1988). Does Biology Constrain Culture? American Anthropologist, 90(4), 819–831. 
Salganik, M. J., & Watts, D. J. (2008). Leading the Herd Astray: An Experimental Study of Self-fulfilling Prophe cies in an Artificial Cultural Market. Social Psychology Quarterly, 71(4), 338-355. 
Tomasello, M. (1999). The Human Adaptation for Culture. Annual Review of Anthropology, 28(1), 509–529. Toyokawa, W., Kim, H.-r., & Kameda, T. (2014). Human Collective Intelligence under Dual Exploration-Exploitation Dilemmas. PLOS ONE, 9(4), e95789. 
Wisdom, T. N., Song, X., & Goldstone, R. L. (2013). So cial Learning Strategies in Networked Groups. Cognitive Science, 37(8), 1383–1425. 
Wu, C. M., Schulz, E., Speekenbrink, M., Nelson, J. D., & Meder, B. (2017). Mapping the unknown: The spatially correlated multi-armed bandit. bioRxiv. 
2478
Predicting the Optimal Time for Interruption  using Pupillary Data and Classification 
Hagit Shaposhnik (h.shaposhnik@rug.nl) 
Jelmer P. Borst (j.p.borst@rug.nl)  
 Niels A. Taatgen (n.a.taatgen@rug.nl) 
Department of Artificial Intelligence, University of Groningen  Nijenborgh 9, 9747 AG, Groningen, the Netherlands 
Abstract 
In the current study we present an air traffic control (ATC)  task in which we measured pupil dilation to automatically  determine high and low workload periods. We manipulated  working memory (WM) requirements across three conditions:  a no WM condition, a passive WM condition in which  information was accumulated, and an active WM condition in  which information had to be added to and removed from WM.  Results showed that no WM resulted in the least dilation, but  that passive WM and active WM did not differ. Next, we used the pupil data to train a range of classifiers to differentiate  between high and low workload periods with the ultimate  goal to create an online task-independent interruption  management system (IMS). The best predicting features were  the median and a second-order polynomial fit, going back 12  seconds from the to-be-predicted moment. Using these  features, our classifier was able to predict workload at high  accuracy (77%). We conclude that pupil dilation can be used  to create a reliable IMS. 
Keywords: Working memory; Interruptions; Multitasking;  Pupil dilation; Machine learning. 
Introduction 
Nowadays, we are interrupted continuously throughout the  day. Especially interruptions in the middle of a task are  known to have considerable costs. For example, during office work people are often interrupted by notifications on  their smartphone, which disrupts their focus and can lead to  large resumption costs. In certain work environments,  interruptions are part of the normal work flow and cannot be  avoided. For instance, air traffic controllers (ATC) follow  aircraft traffic while at the same time instructing pilots and  communicating with other controllers on the ground. In this  case, mistakes due to interruptions may lead to fatal  accidents. To reduce these potentially high costs of  interruptions, the main goal of the current study is to  develop a robust algorithm to automatically determine the  best moment for interruptions. To this end, we employ  pupillary data and machine learning techniques. 
Previous studies have shown that the extent to which  performance on a primary task is affected by an interrupting  task depends on the degree of cognitive load in the primary  task (Iqbal & Bailey, 2005). Moreover, interruptions during  high workload increase the duration of the resumption 
process to return to the primary task (Altmann & Trafton,  2007; Altmann, Trafton, & Hambrick, 2014; Mark,  Gonzalez & Harris, 2005). Multiple studies have shown that  the less disruptive moment to present an interrupting task is  
2479
between tasks rather than in the middle of a task and more  specifically in low workload periods (Borst, Taatgen & van  Rijn, 2015; Iqbal & Bailey, 2005, 2006; Katidioti &  Taatgen, 2014; Monk, Boehm-Davis & Trafton, 2004; 
Salvucci & Bogunovich, 2010). Thus, interruptions during  low workload moments have limited costs compared to high  workload moments. Therefore, if we had an automatic way  of determining workload, we could schedule interruptions at  less disruptive moments. 
One way of determining workload is by measuring pupil  size. It has long been known that cognitive workload, and  especially working memory load (WM), causes the pupil to  dilate. For example, Kahneman and Beatty (1966) asked  participants to report from a string of a memorized list of  different digits. Results showed that pupil dilation increased  for each additional digit, and after the last digit decreased  again (for a similar recent study, see Karatekin, 2004).  
As these results suggest, a number of studies have shown  that interruptions during moments of high pupil dilation – and thus high workload – are more disruptive than  interruptions when pupil size was small (Iqbal, Adamczyk,  Zheng & Bailey, 2005; Katidioti, Borst, Bierens de Haan, et  al., 2016). Based on these results, Katidioti, Borst, van Vugt  & Taatgen (2016) designed a rudimentary interruption  management system (IMS), and demonstrated that 
interruptions based on pupillary data resulted in better  overall performance than self-interruptions. 
Given that interruption can be disruptive and affects one’s  performance, Züger and Fritz (2015) were interested to  measure the interruptibility of programmers. In their study,  they did not use pupil dilation data, but other physiological  sensors such as EEG, eye blinks, heart rate, BVP, EDA 
(measuring the activity of heart), and body temperature. In  addition, they used machine-learning techniques to identify  the programmer’s interruptibility state. They found that  based on these measurements their classifier identified the  programmers’ state of interruptability with high accuracy,  which implies that this kind of classifier might be in used to  automatically schedule interruptions during low workload  periods. While this is promising, it seems infeasible to  measure EEG and heart rate variability in a real  environment, which is why we decided to concentrate on  pupil dilation measurements. 
Current Study 
The main goal of the current study was to classify high and  low workload periods based on pupillary data and improve  the simple threshold technique of Katidioti and colleagues (2016). To this end, we designed an experiment that  simulated a simplified ATC environment. We aimed to  compare three conditions with different levels of workload:  a condition with no WM requirements, one with a passive  WM load, and one with an active WM load. In the no-WM  condition no memorization was required and decisions wer  based on a given rule. In the passive WM task information  was accumulated and decision-making had to be based on  previous information. In the active WM task information  had to be updated several times throughout the task. 
Our goal was to determine whether we can differentiate  between periods in which participants had to make active  decisions versus periods in which they had to wait for the  next series of queries. To this end, we trained a classifier to  make an online assessment of workload. 
Method 
Subjects 
Twenty-five students from the University of Groningen  participated in the experiment for monetary compensation of  14 euros. Data of one participant was not analyzed because  of recording problems. Data of three other participants were  excluded due to an error in the experimental code. Finally,  one participant was excluded due to excessive eye blinks.  This leaves 20 participants (12 females and 8 males, mean  
age 24.5 (range 20-30), SD = 2.7). All were right-handed,  and had normal vision. 
Design 
In the experiment participants interacted with a simple air  traffic control simulator (Figure 1). Each trial lasted 100 sec and was split into two on-task phases and one off-task  phase. The trials started with a fixation cross in the middle  of a centered circle (10 cm diameter) for 2 sec, which was  followed by the appearance of aircraft entering the screen (i.e., airspace). Aircraft that were entering into the airspace  flew at a constant speed. Some of the aircraft flew into the  circle and others continued to fly outside of the circle, which  represent the airspace the controller is responsible for.  Aircraft that entered into the circle presented a request. The requests were either an altitude or a speed change, each  which a specific new speed or altitude. Altitude requests consisted of 4 digits and speed requests of 2 digits. Requests were presented for 1.5 sec. The time between the offset of  one request and the onset of the next request was 2.5 sec.  The first on-task phase ended when aircraft started to leave  the airspace, after which no aircraft entered for 26 sec (the  off-task phase). After the off-task phase, a new on-task  phase started in which aircraft entered the airspace again.  
After the second on-task phase the trial ended. The experiment consisted of three conditions: no WM, passive WM, and active WM. In the no-WM condition, six aircraft entered into the circle one by one, and each aircraft  presented a speed request. If the requested value was  smaller than 35 it should be rejected, otherwise it should be 
  
Figure 1: The ATC experiment. Participants had to respond to airplanes inside the circle. Here, the altitude change request  should be allowed if none of the other 5 planes is at altitude 5433 – information participants had to maintain in their WM.   
2480
accepted. Thus, memorization of the requests was not  required. 
In the passive WM condition, six aircraft entered the  airspace circle and presented altitude requests one at the  time. Participants were required to compare each request to  the previous requests by the other aircraft in the circle. If a  requested altitude was already occupied by another aircraft, 
it should be rejected, otherwise it should be accepted. Thus,  previous requests should be maintained in WM. 
In the active WM condition 4 aircraft entered into the  airspace circle and presented altitude requests one at the  time, similar to the passive WM condition. After that, two  aircraft would leave the airspace and two additional aircraft  would enter the airspace circle, and present their request.  Similar to the passive WM condition, no aircraft within the  airspace could fly at the same altitude. However, altitudes  can become available again if the aircraft at a particular altitude left the airspace. This meant that participants needed  to actively update their WM when aircraft were leaving.  
Participants had to press ‘Z’ to reject request and ‘/’ to  accept. Participants were required to respond while the  request was still presented on the screen (1.5 sec).  Following the response feedback was given for 1 sec. If the 
response was correct, the aircraft was colored by a green  square, if it was incorrect the aircraft was colored by a red  square. The study consisted of 36 trials grouped in 6 blocks.  Within a block, two trials in each of the three conditions  were administered in random order. 
Procedure 
Participants were tested individually in a windowless room  containing a desk on which a monitor, eye-tracker camera  and chinrest were placed. The seating distance from the 20- inch LCD monitor (1600×1200, 60 Hz) to the chinrest with  forehead support was 59 cm. 
The room was illuminated using a ceiling lamp, resulting  in ambient light that provided a comfortable level of  luminance to participants. Eye position and pupil dilation of  either left or right eye, depending on each participant’s  dominant eye, was measured at the sampling rate of 500 Hz  using an SR Eyelink 1000 eye tracker. Calibration and drift  correction were performed before the experiment and after  each break, using a randomized target order with 9 points.  
Before staring the experiment, participants gave informed  consent. After reading the experimental instruction a verbal  instruction was provided to ensure that they understood the  task. Participants started with a practice block that contained  all three conditions. If, after three practice trials, participants  did not understand the task, they were required to repeat it.  Afterwards, the experiment started. 
Analysis and Classifier 
To create the optimal predictor for a potential IMS, we  trained a classifier with pupillary data to identify different  workload periods. Before implementing the classifier, the  pupillary data were preprocessed. First, in order to reduce  artifacts, saccades and blinks were detected and replaced by  
2481
quadratic-interpolation after extending the rejection area  with 50 msec before and after the saccades and 100 msec  before and after the blinks. Further, pupil dilation was  down-sampled from 500 Hz to 50 Hz, and normalized by a  moving-average baseline of the last 20 seconds1. 
To analyze the data, we used linear mixed effects models;  models were compared using chi-squared likelihood tests.  Contrast testing was performed with Tukey Post-Hoc tests. Participants and phase were submitted as random effects. 
To classify high and low workload moments, we used  binomial logistic regression. Classifiers were trained and  tested with 10-fold cross-validation within-subject. To  predict workload, we used features from the pupillary data.  Features were created by splitting the data into windows of  2, 3, or 4 seconds. From these windows, we calculated the  median, SD, and a second order polynomial fit. We first  thought to examine the slope of each curve but since our  pupillary data is not linear, we decided that polynomial will  fit better to our data. For the second order polynomial fit we  used the following function: � � = �1�& + �2� ,the  fitting method attempt to fit the best possible coefficients (p1, p2) to the given curve at each window using the least  squares polynomial fitting algorithm. Thus, for each  window we had four features: the median, the SD, and the  two coefficients of the polynomial fit. 
Results 
Behavioral Data 
Figure 2 shows the average accuracy and average RTs for  each condition. The results show that participants performed  well on 3 conditions with a mean proportion of correct  responses of 0.93 (SD = 0.1). RTs were measured from the  moment of the request to the moment of response. Results  show that mean RTs were 0.65 (SD = 0.07) for the 3  conditions  
  

Figure 2: Average Accuracy and Average Response Time  (RT) per condition. 
 
1 We used a moving-average baseline because the final goal is to  design an IMS that does online interruption management. 
r 
e
t
e
m
a
i
d
 
l
i
p
u
P
 
e
g
n
a
h
C
 
%
Pupillary Data 
Average Pupillary Size Active WM 
10 
No WM 
Passive WM 
5 
0 


	

	

	

	

	

	

	

	

	

	

	

	



-5 
-10 
0 20 40 60 80 100 Time (sec) 
Figure 3: Percentage change in pupil size measured for each  
condition across time. 
testing indicated a different pupil response to requests in the 
Figure 3 shows percentage change in pupil size measured  for each condition across time. Each vertical line represents  a request (1 to 6) in each phase, the white gap represents the  off-task interval period between the two on-task phases. The  red line represents the active WM task, the green line  represents the no-WM task, and the blue line represents the  passive WM task. The initial dilation of the pupil started  after each request and reached a peak after 1.5 sec to 2 sec  and reduced again afterwards. In both WM conditions, pupil  response increased gradually as a function of time. A more  pronounced increase followed the 5th and the 6th request,  after which it decrease below the baseline during the off task period. In the control task (no-WM) the pupil response  was initially higher than in both other conditions until the 
3rd request, but then reduced almost below the baseline. To analyze the pupillary data, we calculated the average  pupillary peak response for each condition across the two  response phases (Figure 4; there was no difference in  pupillary response between phases; � = 0.5 , �& 1 = 0, p=1). First we found a main effect of condition on pupillary  response that showed a significant difference between both  WM tasks and the no-WM task (� = −0.170 , �& 1 = 35.3, p<0.001). There was no difference between the active  WM and passive WM tasks (� = −0.185, �& 1 = 0.586, p=0.443). The effect of Request was found to be significant  ( � = −0.471 , �& 1 = 34.15, p<0.001). Tukey post-hoc  
2482
active WM conditions and the no-WM condition (β = 0.342,  SE = 0.626; z = -8.297, padjusted < 0.001; β = 0.342, SE =  0.626; z = -9.93, padjusted < 0.001).  
Figure 4: Average pupillary peak response for each condition as a function of request. 
Classification 
The classifier was trained to distinguish between two  periods; the on-task period, which included the requests, and  the off-task period in which participants did not perform a  task for a period of approximately 26 sec. As explained  above, 10-fold cross validation was performed for each  subject. 
Table 1. Results of the classifier (average accuracy + range) for four different feature combinations, for windows sizes of  2, 3, and 4 seconds. 
Median Median + SD Polynomial Median + Polynomial Condition 4 s 3 s 2 s 4 s 3 s 2 s 4 s 3 s 2 s 4 s 3 s 2 s 
Active WM 73% (49-90) 
Passive WM 74% (54-92) 
No WM 69% (47-83) 
All 70% (49-84) 
71% 
(50-86) 72% 
(52-88) 66% 
(43-81) 69% 
(50-84) 
72% 
(50-87) 72% 
(52-89) 67% 
(52-84) 69% 
(50-84) 
73% 
(50-90) 70% 
(48-84) 73% 
(50-90) 70% 
(48-84) 
72% 
(47-86) 67% 
(47-82) 72% 
(47-86) 67% 
(47-82) 
73% 
(49-88) 68% 
(52-83) 73% 
(49-88) 68% 
(52-83) 
77% 
(52-91) 76% 
(53-91) 77% 
(52-91) 76% 
(53-91) 
72% 
(47-87) 68% 
(54-83) 72% 
(47-87) 68% 
(54-83) 
73% 
(55-88) 70% 
(54-83) 73% 
(55-88) 70% 
(54-83) 
77% 
(50-90) 76% 
(55-91) 77% 
(50-90) 77% 
(55-91) 
72% 
(49-85) 72% 
(51-83) 72% 
(49-85) 72% 
(51-83) 
73% 
(56-88) 72% 
(53-83) 73% 
(56-88) 72% 
(53-83) 
We explored which features yield the best classification  results. Table 1 shows the overall mean and min-max rates  for different features and window combinations. The first  observation we can make is that larger windows on average  gave the best predictions, that is, it was more effective to go  12 second back in time than less. Second, using the  polynomial fit in each window improved performance over  using either the median, or the median and the SD. Thus,  not only average dilation and its variance are informative,  but also the pattern of dilation inside each window. Third,  the hardest condition to classify was the no-WM condition,  presumably because the difference between on- and off-task  phases was the smallest in this condition (Fig. 3). 
The best feature combination were three four-second  windows, for each of which we used the median and a two coefficient polynomial fit. On average, this resulted in 77%  correct classifications. Figure 5 shows that for a majority of  
different levels of workload. Based on previous studies we  hypothesized that pupillary size would increase with  increasing memory load and decrease with decreasing load.  The results confirmed the hypotheses; dilation increased  with increased WM load and was smaller when WM load  decreased. Figure 3 clearly shows the change in pupil  dilation during the period of on-task and off-task. 
Additionally, it can be observed that during the on-task  pupil size increase proximally 1.5 to 2 seconds after each  request and decrees afterward. 
Based on these results, we developed a classifier. In order  to identify high and low workload periods, we applied binominal logistic regression to the pupillary data. Table 1  shows that it is possible to classify high and low workload  periods based on pupillary data. Using large windows, going  back 12 seconds in time, including the median value and a  polynomial fit per window, gave the best predictions for our  model. This indicates that not only the level of pupil dilation  
s 
t
c
e
jbu
S 
f
o
 
r
e
b
m
u
N
K-Fold (K=10) Cross Validation 
10 
9 
7 
2 
1 1
	



8 
6 
4 
2 
0 
50-60 60-70 70-80 80-90 90-100 
Precentage of Accuracy 
(median) is relevant to determine workload, but also the  direction of the change in pupil dilation. We hypothesize  that decreasing dilation indicates the start of a low-workload  period, whereas increasing dilation signal the start of a high 
workload period. 
Figure 5 shows the accuracy of the model for each  participant. These results show that the classifier could  classify above chance for all subjects, and with a high  accuracy for the large majority. Different from our study in  which we focused only on pupillary data, Züger and Fritz 
(2015) used several physiological sensors. On the one hand,  this provided more features for the classifier, but it also  
Figure 5: Distribution of classifier accuracy over  subjects. 
the participants’ classification was even over 80% in this  case, and only one participant scored below 60%. 
Discussion 
The main goal of the present study was to develop a  classifier that will predict and differentiate between low and  high workload periods using machine learning techniques  based on pupillary data. In order to do so we designed a  ATC task that simulated a real world scenario and included  
2483
makes the classifier less practical to use in a real work  environment, while pupil dilation might be measured with  high-end webcams (Rafiqi, Wangwiwattana, Fernandez,  Nair, & Larson, 2015). Performance of the two classifiers 
was comparable, where we reached 77% accuracy on  average, Züger and Fritz (2015) classifier reached 75%. A notable feature of the pupillary pattern observed in this  study was the way pupil size was affected by the number of  requests. Figure 4 indicates the difference in peak size  between the no-WM condition and both WM conditions as a  function of request. At the first 3 requests, the average peak  size was larger during in the no-WM condition, but it then  decreased sharply compared to both WM conditions. In  
contrast, in the WM conditions the average peak response  increased gradually as a function of the number of requests.  This implies that the amount of information that is stored in  memory evoked changes in pupillary size. 
We might assume that the average of peak was larger in  the no-WM condition during the first 3 requests because  participants had to decide if a presented value was higher or  lower than the given threshold. This may be confusing at the  beginning but once participants got used to the drill it  becomes an easy task. On the contrary, in the WM  conditions the answer to the first request was automatically  ‘YES’, since participants were not required to compare it to  any previous value and no storage or decision-making was  required. Yet, as the task continued more information was  stored in WM and more decision-making was required,  which affected cognitive workload and pupil size.  
To conclude, in this study we have shown that it is  possible to use pupil dilation to determine high and low  workload periods. These results will form the basis an  online task-independent IMS. As our next step, we aim to fit  our model across participants. Additionally, we would like  to identify the high and low load periods during the on-task  phase, to enable more fine-grained interruption  management. 
Acknowledgements 
This research was supported by AFOSR grant FA9550-17- 1-0309 awarded to Niels Taatgen and Jelmer Borst. 
References 
Altmann, E.M., & Trafton, J.G. (2007). Timecourse of  recovery from task interruption: data and a model.  Psychonomic Bulletin & Review 14 , 6, 1079–84. 
Altmann, E.M., Trafton, J.G., & Hambrick, D.Z. (2014). Momentary interruptions can derail the train of thought. JEP: General 143, 1, 215–226. 
Borst, J. P., Taatgen, N. A., & Van Rijn, H. (2015). What  Makes Interruptions Disruptive ? A Process-Model  Account of the Effects of the Problem State Bottleneck on  Task Interruption and Resumption. In Proceedings of the  SIGCHI Conference on Human Factors in Computing  Systems: CHI 2015. New York: ACM. 
Hess, E. H., & Polt, J. M. (1960). Pupil size as related to  interest value of visual stimuli. Science, 132, 349–350. Iqbal, S. T., & Bailey, B. P. (2005). Investigating the  effectiveness of mental workload as a predictor of  opportune moments for interruption. In Proceedings of  the SIGCHI Conference on Human Factors in Computing  Systems: CHI 2005 (pp. 1489–1492). 
Iqbal, S.T. and Bailey, B.P. (2006). Leveraging  characteristics of task structure to predict the cost of  interruption. In Proceedings of CHI 2006 (pp.741–750). 
Iqbal, S.T., Adamczyk, P., Zheng, X., and Bailey, B.P.  (2005). Towards an index of opportunity: understanding changes in mental workload during task execution. In  Proceedings of the SIGCHI. 2005, 311–320. 
Kahneman, D., & Beatty, J. (1966). Pupil diameter and load  2484
of memory. Science, 154 (3756), 1583–1585. doi:10.1126/  science.154.3756.1583.  
Karatekin, C. (2004). Development of attentional allocation in the dual task paradigm. International Journal of  Psychophysiology 52, 7–21. 
Katidioti, I., Borst, J.P., Bierens de Haan, D.J., Pepping, T.,  Van Vugt, M.K., & Taatgen, N.A. (2016). Interrupted by  your Pupil: An Interruption Management System based  on Pupil Dilation. International Journal of Human 
Computer Interaction 32(10), 791-801. 
Katidioti, I., Borst, J. P., & Taatgen, N. A. (2014). What  happens when we switch tasks: Pupil dilation in  multitasking. Journal of Experimental Psychology:  Applied, 20(4), 380–396.  
Katidioti, I., Borst, J. P., Van Vugt, M. K., & Taatgen, N. A.  (2016). Interrupt me: External interruptions are less  disruptive than self-interruptions. Computers in Human  Behavior, 63, 906–915.  
Mark, G., Gonzalez, V., & Harris, J. (2005). No task left  behind? Examining the nature of fragmented work. In  CHI 2005 Proceedings (pp. 321–330), ACM Press. 
Monk, C. A., Boehm-Davis, D. A., & Trafton, J. G. (2004).  Recovering from interruptions: Implications for driver  distraction research. Human Factors, 46, 650–663. 
Rafiqi, S., Wangwiwattana, C., Fernandez, E., Nair, S., &  Larson, E. C. (2015). Work-in-progress, PupilWare-M:  Cognitive Load Estimation Using Unmodified  Smartphone Cameras. MASS 2015, SocialSens 2015. 
Salvucci, D. D., & Bogunovich, P. (2010). Multitasking and  monotasking: The effects of mental workload on deferred  task interruptions. In Proceedings of the SIGCHI  Conference on Human Factors in Computing Systems. 
Züger, M., & Fritz, T. (2015). Interruptibility of software  developers and its prediction using psycho-physiological  sensors. In Proceedings of the SIGCHI Conference on  Human Factors in Computing Systems (CHI ‘15), Seoul,  South Korea. 
A Conceptual Ladder from Spikes to Behavior: 
Toward the Neural Basis of Dynamic Choices at Multiple Scales 
Timothy M. Shea (tshea2@ucmerced.edu) 
David C. Noelle (dnoelle@ucmerced.edu) 
Cognitive and Information Sciences, University of California, Merced 
5200 Lake Road, Merced, CA 95343 USA 
Abstract 
Reducing cognitive phenomena to neural activity is seen by  many as lacking in scientific utility. The conceptual chasm  between electrochemical activity and the act of making a  choice is too broad to span in a single step. Instead, we adopt  a multi-scale approach to cognitive neuroscience by  constructing a conceptual ladder that incrementally climbs  from neuronal spikes to cognitive processes with each step  offering theoretic reductions. Here we propose a sequence of  intermediate neurocomputational processes that are promising  for understanding an array of cognitive phenomena. We  illustrate this approach in the context of the dynamics of  choice. These dynamics emerge from serial evaluation  mediated by systems in frontal cortex and the basal ganglia.  The effect is to promote neural oscillations that provide a  substrate for communication through coherence. Both  empirical and simulation studies are described to support this  view of emergent behavior. 
Keywords: spiking neural networks; synchrony; coherence Introduction 
In this paper, we construct a conceptual ladder upon which  we climb from the foundations of neuroscience -- spiking  neurons -- to the dynamical patterns of brain activity and  behavior that arise during decision making. In spite of broad  acceptance of the general idea that, in some way, high level  cognitive processes are grounded in the electrical and  chemical processes of neurons, there are relatively few  instances in which cognition has been clearly mapped onto  cellular actions. In part, this may be due to the tremendous  difference in scale: the human hand is a thousand times  larger than a neuron. Pushing a button takes hundreds of  times longer than sending an electrical impulse down an  axon. Nevertheless, we describe here an account which  ascends these spatial and temporal scales, one rung at a  time, by drawing on emerging perspectives at various levels  of computational and empirical neuroscience, as well as  modern behavioral research. We review some literature  related to each of these levels of analysis and discuss our  own computational simulations of relevant phenomena.  
While this conceptual ladder may be a generally useful  framing for a broad array of cognitive processes, we focus  on a category of behavioral experimental paradigms which  target value-based decision making. A simple example is a  two-armed bandit task, in which a participant selects one of  two actions on each trial, guided by the predicted reward for  each action. These kinds of choices can be made reflexively  
and can be learned by non-human primates and rodents.  They arguably offer a clear and simple model of the broader  problem of action selection. There is also extensive research  on the contributions of brain waves, brain regions, cell  types, neurotransmitters, and various other biological factors 
to these types decision tasks. This large body of research  provides multi-scale perspectives on the neural basis of  value-based decision making and provides constraints on  any proposed account of choice. 
Our conceptual ladder starts with spiking neural networks.  We explain how synchronization in spiking neural networks  offers a general mechanism to understand the emergence of  oscillations. We discuss how oscillations modulate regional  processing in the brain. We argue that the interaction of  oscillations provides a useful active substrate for neural  communication. Lastly, we describe how these properties  can give rise to characteristic patterns of brain activity and  behavior observed in decision making. 
Spiking Neural Networks Synchronize One of the first lessons learned by every scientist who  attempts to build a spiking neural network model is that  spiking networks synchronize (Brunel, 2000). Synchronous  spiking is the generation of a large fraction of spikes during  narrow, semi-regular temporal bands, separated by relative  silence. This fact often goes unmentioned in the literature,  perhaps because it is so basic and pervasive to the approach,  but it is virtually assured that every successful spiking  neural network model has undergone a period of tuning to  avoid excessive synchrony (c.f. Hahn, et al., 2014).  Excessive synchrony is undesirable, as it reduces the  representational capacity of a spiking network and impairs spike timing dependent plasticity (STDP). It also leads to  visibly artificial spike raster plots that fail to capture  observed biological spiking patterns. 
A common cause of synchronous spiking is recurrent  synaptic connectivity associated with a “reservoir” (Maass,  Natschläger, & Markram, 2002) or cortical layers (Tiesinga  & Sejnowski, 2009). In these cases, feedback loops from  recurrent connectivity drive excitatory spiking interspersed  with inhibitory silencing. Without careful tuning, this  feedback-induced synchrony can overpower activity related  to meaningful stimuli in the network. Nevertheless, recurrent connections in biological neuronal networks are  ubiquitous. 
One of the longest running debates in computational  neuroscience involves the role of spike timing in neuronal  
2485
information processing. Although it is widely agreed that information is conveyed by neural spikes in aggregate, there  is disagreement over whether that information is encoded in  the precise timing of spikes or only in the rate at which  spikes are generated. In some specific cases, highly  temporally precise sensory information that can be decoded  from spike times (e.g. in binaural spatial cues, Chase &  Young, 2006) beyond that which can be extracted from  firing rates. We suggest that emerging theories that  emphasize the role of spike synchrony in robust neuronal  communication offer a potential route to resolving these  tensions. 
Spike Synchrony Links Spikes to Oscillations 
The excitability of neurons in a brain region is correlated  with the phase of ongoing neural oscillations in that region  (Fries, 2005). Local field potentials (LFP) are generated by  fluctuations in membrane potential across many thousands  of neurons in a region (Gold et al., 2006). These fluctuations  are the result of various processes that occur at different  timescales. While spike generation is a distinct feature of  individual neurons, LFPs deemphasize high-frequency  fluctuations, at the timescale of spikes, so that only very  dense concentrations of spikes affect the LFP amplitude.  For this reason, synchronous spiking across a neural  population will give rise to an ongoing LFP oscillation,  while irregular spiking activity will not. Alternative  oscillatory mechanisms are certainly plausible (e.g.  endogenously generated oscillatory currents, Brunel, Hakim, & Richardson, 2003), but synchronous spiking  offers a parsimonious account for the emergence of  oscillations while simultaneously explaining why LFP  oscillation phase is correlated with neuronal excitability.  The patterns of connectivity which give rise to synchrony  result in periods of inhibition (low excitability) and  disinhibition (high excitability) and these periods will  necessarily be phase-locked to resulting oscillations. Thus,  spike synchrony provides a functional link from the activity  of individual neurons to neural oscillations. 
An important consideration in the emergence of  oscillations from synchronous spiking is the role of neuronal  and network parameters in shaping the oscillations which  emerge. Properties such as neuron leak conductance and  excitatory-inhibitory ratio of the network directly affect the  gain in recurrent synaptic pathways. Both the mean and  variance in spike transmission delays alter the length of  feedback loops. These and other structural properties  determine the frequency, phase, and amplitude of intrinsic  neural oscillations (Figure 1). 
Figure 1: This spike raster plot demonstrates synchrony in a  simulated spiking neural network as a result of inhibitory  recurrence. Each row represents a neuron and each dot  represents a spike at a given time. The blue line indicates  the average firing rate of the population in time. 
Neural Oscillations Provide an Active  Substrate for Communication 
As described previously, the phase of neural oscillations is  correlated with neuronal excitability. These findings have  led to an emerging consensus concerning the functional role  of neural oscillations. This consensus holds that the  effectiveness of communication between brain regions is  modulated by the coherence of oscillations in the regions.  This hypothesis is called communication-through-coherence  (CTC) (Fries, 2005).  
The CTC hypothesis makes clear predictions concerning  neuronal communication in the context of a single dominant  frequency of oscillation (Figure 2). However, biological  neural oscillations typically exhibit power in many distinct  frequency bands. In this case, it is unclear which frequency  might have a dominant effect on neuronal excitability. One  potential solution to this problem involves a mechanism  through which multiple oscillations are entrained, such that  the phase relations between regions are consistent across  multiple frequency bands. Indeed, just such entrainment has  been observed. Cross-frequency-coupling (CFC) describes  the phenomena where ongoing neural oscillations in one  frequency are coupled to oscillations in a different  frequency. CFC is particularly strong between alpha-band  (8-12 Hz) phase and gamma-band (>30 Hz) amplitude  (phase-amplitude coupling). This means that the strength of  the high frequency component of neural oscillations in a  region is modulated by the phase of the low frequency  component. The degree of phase-amplitude coupling in a  region has been linked to the strength of intra-regional  communication versus inter-regional communication. Other  
forms of CFC include phase-phase coupling and amplitude amplitude coupling (Canolty & Knight, 2010). 
2486
Figure 2: Communication-through-coherence between two  regions with the same dominant frequency. In this scenario,  the effectiveness of communication (likelihood of a  transmitted spike to induce a spike at the receiving neuron)  is predominantly affected by the relative phase and spike  transmission delays. The sending population (blue) exhibits  a strong influence on neurons in the receiving population  (orange) with a compatible phase and has minimal impact  on neurons in the inhibitory period of an oscillation.  Receiving neurons are shown with staggered phase to  illustrate the effect of CTC. 
Another important clue in deciphering the functional role  of oscillations comes from the spatial scales over which  neural communication occurs. Over long neurophysiological  distances, spike transmission delays and variability both  increase. These increases correspond to a wider temporal  window in which postsynaptic potentials might arrive. To  accommodate this, the frequency of neural oscillation must  be lower, producing increased durations of the periods of  neuronal excitability. In contrast, oscillations at a high  frequency (e.g. gamma-band), with more brief periods of neuronal excitability, provide a substrate for communication  over short neurophysiological distances. These predictions  are consistent with the behavioral correlates of neural  oscillations (Table 1). 
Table 1: Behavioral correlates of neural oscillations (Canolty & Knight, 2010). 
Frequency Correlates 
Gamma > 30 Hz Local network processing Beta 20 - 25 Hz Motor planning, rhythm Alpha 8 - 12 Hz Visual attention 
Theta 4 - 8 Hz Conflict detection 
Delta < 4 Hz Multisensory integration 
Together, CTC and CFC suggest a framework in which  communication across neuronal networks is modulated by a  broad range of interacting oscillations at various spatial  scales. These interacting oscillations provide an active  substrate for communication: a constantly shifting network  
of channels vying for the available bandwidth. Rather than a  central coordinator allocating influence to streams of neural  processing, the streams dynamically entrain and diverge  from one another according to learned task demands and  new inputs. As the relative power of oscillation components  fluctuate, and as they shift in and out of relative phase, the  effectiveness of particular channels of communication  increase and decrease. Because the oscillations emerge from  spiking activity, neural spikes drive these shifts in phase and  power. The detailed relationship between spikes and waves  is highly complex, however, making oscillation coherence a  useful intermediate level of analysis.  
This framework of activity-driven modulation of neural  communication offers a plausible mechanism for variation  in functional connectivity between larger neural regions  (Akam & Kullman, 2012; Salinas & Sejnowski, 2001). A  vast literature based on fMRI, EEG, and other imaging  methodologies has demonstrated that functional changes in  coupling between regions can occur rapidly in response to  task and context cues (Bullmore & Sporns, 2009). While  functional connectivity between regions can reflect common  inputs, it is often taken to imply selective communication.  These observations have been made without knowledge of  the mechanism by which neural activity might be selectively  processed or ignored. Given that the coherence of  oscillations among regions is rapidly altered by interacting  neuronal activity, CTC and CFC could underlie task- and  context-dependent changes in functional connectivity  throughout the brain. 
Dynamics of Choice Arise from Properties of  the Communication Substrate 
Perhaps counterintuitively, coherent oscillations supporting  communication between regions do not necessarily improve  information processing between those regions and produce  associated facility in behavior. It is natural to expect greater  amplitudes in task-linked oscillations to be associated with  better communication and, thus, better task performance.  Almost paradoxically, though, high amplitude oscillations  are regularly associated with a lack of strong information  processing. For example, alpha amplitude increases in  visual areas when the eyes are closed and there is  (apparently) no visual attention. Also, conflict-related high  amplitude theta waves in medial frontal and subcortical  regions is linked to slow responses and poor performance  (Zavala, Zaghloul, & Brown, 2015).  
In a computational model of the role of thalamocortical  loops in signal selection (Shea, Rodny, Warlaumont, &  Noelle, 2017), we found that this inverse relationship can  emerge from a trade-off between cognitive stability and  sensory signal integration. During periods of low conflict,  such as when a sensory stimulus is clearly distinguished  from its background, the strong stimulus input suppressed  background noise, leading to a stable selection of the signal.  During periods of high conflict, such as when the stimulus  was not clearly distinct from background noise, competition  caused increased oscillations, promoting greater  
2487
communication. However, if the increased oscillations led  to conflict being quickly resolved, the oscillations then  rapidly faded. If conflict persisted, the oscillations remained  strong as the network failed to pull the signal from the  noise. Thus, in our model, the strength of oscillations is  inversely related to the neuronal network’s performance. 
Figure 3: Architecture of a spiking neural network model of  thalamocortical signal selection. The network is based on  recurrent synaptic circuits which connect the thalamus,  cortex, and basal ganglia. Arrow-heads denote excitatory  pathways, circles denote inhibitory pathways. STIM =  
stimulus, THL = thalamus, CTX = cortex, DA1 = Striatum  (Da1-Receptors), DA2 = Striatum (Da2-Receptors), STN =  Subthalamic Nucleus, GPI = Globus Pallidus Internal, GPE  
= Globus Pallidus External (Shea, Rodny, Warlaumont, &  Noelle, 2017). 
The model contained seven populations of leaky  integrate-and-fire spiking neurons and eleven synaptic  pathways comprising a recurrent thalamo-cortico-basal  ganglia circuit (Figure 3). Shaped input currents were  injected at the model thalamus to simulate a stimulus, and  these signal inputs were overlaid with random background  noise. Thalamic activity propagated forward through the  cortex and basal ganglia, where an off-center on-surround  inhibitory dynamic gave rise to neuronal competition. For  weak stimuli, the resulting competition was unstable, and  the excitatory-inhibitory recurrence of the network caused  neurons in every region to synchronize. For stronger stimuli,  suppression of background noise kept recurrent feedback  under control, allowing a stable representation of the signal  to emerge in the cortex (Figure 4). 
The task performed by our model is simple: a signal,  represented as increased thalamic activity in a region of an  abstract neural map, is obscured by noise. The network  attempts to amplify the signal by suppressing the noise. This  reflects a single choice task: a Go task as opposed to a  Go/No-Go task. Although this task seems simpler than  many animal behaviors, very complex decisions can be  mapped onto such a signal selection mechanism through a  combination of affordance competition and serial  evaluation. 
Many neural network models of two-alternative forced  choice tasks represent relevant features of the alternatives  simultaneously in two different populations of neurons, with  
Figure 4: During each trial, the model is presented with a noisy bump-attractor stimulus for 2s. In trials with high  stimulus signal-to-noise ratio (SnR) (4 - 10 s above), the network selects the stimulus and inhibits background noise,  yielding a high evoked SnR. In trials with low stimulus SnR (0 - 4 s above), competition between signal and noise leads  to the emergence of oscillations. The local field potential (LFP) is modeled as the leak, excitatory, and inhibitory currents  of all neurons in a population inversely scaled by the distance to a fixed point in the population. 
2488
choices also represented separately and in parallel. The  neurons representing the alternatives then compete through  recurrent projections, producing some form of a “winner  take all” dynamic (Usher & McClelland, 2001). This  approach is problematic when considering how it might  scale up to situations in which there are many more than  two options. It is unlikely that the brain is equipped with  parallel neural pathways for each possible choice in a large  and novel set, with inhibition appropriately configured to  cause the alternatives to compete when a choice is  presented. 
A different account of choice involves serial evaluation.  Alternatives are represented and entertained one at a time,  with relative value information represented, and there is a  process of shifting from one alternative to the next, with  potentially many repeated considerations of a given choice.  Rather than making a parallel forced-choice, there is only an  “accept-reject” decision for the currently represented choice,  with acceptance resulting in the selection of that alternative  and rejection entailing continued serial consideration. This  account scales to multiple alternatives and is consistent with  the proposal that decision making capabilities of this kind  initially evolved in the context of foraging, where potential  choices (e.g. bushes that might contain good berries) are  considered serially, resulting in repeated “accept-reject”  decisions (Hayden, 2018).  
There is increasing evidence that serial evaluation is used  in the brain. For example, Rich & Wallis (2016) recorded  ensemble spiking activity and local field potentials from the  orbitofrontal cortex, finding neurons representing the value  of options in a 2-alternative forced choice task, alternatively  encoding the value of one choice and then the other.  
If input signals in our computational model are seen as  encoding value, perhaps with noise capturing a background  value standard arising from previously considered options,  then successful signal selection can be an “accept” choice,  while continued strong oscillations could drive a “reject”,  prompting input of another potential choice.  
Our computational model of choice is incomplete. Any  form of attentional switching -- triggered by oscillations or  other factors -- is exogenous to the network. The model  illustrates how recurrent communication between cortical  and midbrain decision structures can support both signal  selection, and can promote oscillations necessary for  neuronal communication. Thus, prolonged “deliberation” in  such a circuit will give rise to more effective spike  propagation across a broader region of neural tissue. 
Discussion 
The problem of grounding cognitive processes in the  activity of the brain is at the core of cognitive science, yet  the mechanisms of brain function which are well understood  operate at a finer scale than what is relevant to behavior. In  investigating the neural mechanisms of serial decision 
making, we have identified important abstractions, at  different scales, with which we can climb from spikes to  choices. We have proposed that synchrony is a fundamental  
property of neuronal networks and argued that synchrony is  the primary mechanism of neural oscillation. There are  counter-arguments to this proposal, yet there is no  alternative which enjoys as much empirical support or as  robustly explains the bidirectional interactions of spikes and  brain waves. We also reviewed evidence that neural  oscillations which emerge from spike synchrony provide a  flexible, dynamic mechanism for selective communication  across spatial and temporal scales: an active substrate. We  then explored how this communication across recurrently  connected brain regions may underlie some of the cognitive  processes of choice. 
Mental and behavioral phenomena occurring at the level  of human experience find their causes not only in brain  states, but in the interactions of brains, bodies, and  environments. Specific mental states, it might be argued,  emerge from these interactions. Much of the modern  understanding of neuronal activity has been developed at the  scale of individual cells, whereas it is likely that  qualitatively different properties emerge from brain-scale  collections of neurons. These possibilities invite criticism of  a pure reductionist account of cognition. Nevertheless, we  propose that our conceptual ladder, providing a multi-scale  perspective on neural phenomena, can help bridge the gulf  of understanding between brain and behavior. In our model  of signal selection, we have demonstrated that such a  reductive approach can provide insight. 
Finally, we recognize that the precise mechanisms of any  decision task will certainly involve processes beyond those  discussed here. Nevertheless, much cognitive neuroscience  research operates solely at one scale, and we hope that this  limited exploration of choice highlights the benefits of work  at multiple scales. By tying the mechanisms of neuronal  activity to those of oscillatory interactions to those of large scale functional activity, we can begin to offer neural  accounts of behavior which extend beyond a single level of  abstraction. In ongoing work, we plan to explore these  possibilities. 
Acknowledgments 
We gratefully acknowledge the advice and support of the  Cognitive & Information Sciences Graduate Group at UC  Merced. 
References 
Akam, T. E., & Kullmann, D. M. (2012). Efficient  “communication through coherence” requires oscillations  structured to minimize interference between signals. PLoS  Computational Biology, 8(11), e1002760.  
Brunel, N. (2000). Dynamics of sparsely connected  networks of excitatory and inhibitory spiking neurons.  Journal of Computational Neuroscience, 8(3), 183-208.  
Brunel, N., Hakim, V., & Richardson, M. J. (2003). Firing rate resonance in a generalized integrate-and-fire neuron  with subthreshold resonance. Physical Review E, 67(5),  051916.  
2489
Bullmore, E., & Sporns, O. (2009). Complex brain  networks: graph theoretical analysis of structural and functional systems. Nature Reviews Neuroscience, 10(3),  186.  
Canolty, R. T., & Knight, R. T. (2010). The functional role  of cross-frequency coupling. Trends in Cognitive  Sciences, 14(11), 506-515.  
Chase, S. M., & Young, E. D. (2006). Spike-timing codes  enhance the representation of multiple simultaneous  sound-localization cues in the inferior colliculus. Journal  of Neuroscience, 26(15), 3889-3898.  
Fries, P. (2005). A mechanism for cognitive dynamics:  neuronal communication through neuronal coherence. Trends in Cognitive Sciences, 9(10), 474-480.  
Gold, C., Henze, D. A., Koch, C., & Buzsaki, G. (2006). On  the origin of the extracellular action potential waveform: a  modeling study. Journal of Neurophysiology, 95(5),  3113-3128.  
Hahn, G., Bujan, A. F., Frégnac, Y., Aertsen, A., & Kumar,  A. (2014). Communication through resonance in spiking  neuronal networks. PLoS Computational Biology, 10(8),  e1003811.  
Hayden, B. Y. (2018). Economic choice: the foraging  perspective. Current Opinion in Behavioral Sciences, 24,  1-6.  
Maass, W., Natschläger, T., & Markram, H. (2002). Real time computing without stable states: A new framework  for neural computation based on perturbations. Neural  Computation, 14(11), 2531-2560.  
Rich, E. L., & Wallis, J. D. (2016). Decoding subjective  decisions from orbitofrontal cortex. Nature Neuroscience,  19(7), 973.  
Salinas, E., & Sejnowski, T. J. (2001). Correlated neuronal  activity and the flow of neural information. Nature  Reviews Neuroscience, 2(8), 539.  
Shea, T. S., Rodny, J. J., Warlaumont, A. S., & Noelle, D.  C. (2017). Emergent oscillations in the subthalamic  nucleus of simulated basal ganglia. Neuroscience 2017.  Poster.  
Tiesinga, P., & Sejnowski, T. J. (2009). Cortical  
enlightenment: are attentional gamma oscillations driven  by ING or PING?. Neuron, 63(6), 727-732.  
Usher, M., & McClelland, J. L. (2001). The time course of  perceptual choice: the leaky, competing accumulator  model. Psychological Review, 108(3), 550.  
Zavala, B., Zaghloul, K., & Brown, P. (2015). The  subthalamic nucleus, oscillations, and conflict. Movement  Disorders, 30(3), 328-338. 
2490
Qualifying Causes as Pertinent 
Giovanni Sileno1(giovanni.sileno@telecom-paristech.fr) 
Jean-Louis Dessalles1(dessalles@telecom-paristech.fr) 
1LTCI, Tel´ ecom ParisTech, Universit ´ e Paris-Saclay, 46 rue Barrault, 75013 Paris, France ´ 
Abstract 
Several computational methods have been proposed to evaluate the relevance of an instantiated cause to an observed consequence. The paper reports on an ex periment to investigate the adequacy of some of these methods as descriptors of human judgments about causal relevance. 
Keywords: Actual Causation, Relevant Cause, Coun terfactuals, Bayesian Inference, Relevance Theory, Simplicity Theory. 
Introduction 
Causes play a central role in the way we conceptualize the world. Seeking explanations of events, or, stated differently, attributing responsibility for their occurrence, is common in practically all human activities. Despite such widespread use, however, there is yet no established model about how peo ple qualify a cause as pertinent (literally, holding together) to a specific event. As observed by (Glymour et al., 2010), most psychological literature focuses on judgments of gen eral causation (about causal regularities), or, when investigat ing actual causation (about situational interpretation), it fo cuses on specific applications like the perception of causation and animacy in minimal “mechanical” settings—see e.g. the overview in (Rips, 2011)—or on higher-level tasks, like the attribution of moral responsibility. The logic-philosophical literature, for its part, focuses for the most on finding and incrementally resolving paradoxes on existing models, with little concerns about practical settings. A similar situation holds on the computational side, where several approaches compete—with mixed results—for producing human-like in ferences about causation. In this context, this paper aims to assess the gap existing between theoretical models and em pirical observations: it considers a short selection of methods that offer means to compute the relevance of causes and it investigates if these methods can produce outputs similar to people’s responses collected in a dedicated experiment. For better decomposition, the study bypasses the natural language processing problem, and exploits a domain model for each 
in law: “but-for” the event A, would the event B have oc curred? If not (or if it did), A did (or did not) cause B. In this form, it is well known that the method suffers from captur ing all necessary elements for the generation to occur (with out discriminating their relevance), and not the sufficient ones (cf. the fire squad case: if the sniper who killed hadn’t shot, the victim would have died anyway). Despite this practical limitation, many formalizations of counterfactuals have been proposed in the last fifty years, attempting to find an unified account satisfying known and newly found paradoxes—see e.g. the famous work of (Lewis, 1973), based on modal logic, and the more recent account by (Hitchcock, 2001), based on structural equations. The interest of these methods resides in inferring, given a system of counterfactuals, other valid coun terfactuals (except some paradoxical cases). 
Bayesian inference Intuitively, part of the problem of the lack of sensitivity of counterfactuals may be due to deter minism. Turning to probabilistic methods, and in particular Bayesian probability, a full research track investigates how to explain why certain variables are observed in certain states; see e.g. (Yuan, Lim, & Lu, 2011) for a reasoned overview. 
Let us suppose to we are able to encode the domain model in a Bayesian network (BN). Amongst the proposed choices for computing the relevance of the occurrence of the event C to the occurrence of event E, the most commonly used are the likelihood p(E|C), as in maximum likelihood (ML) estima tion, or the product p(E|C)· p(C) as in maximum a posteriori (MAP) estimation. Alternatively, observing that the occur rence of a cause increases the possibility of occurrence of the effect, we could capture the raise of probability by comput ing differences as p(E|C) − p(E) or p(E|C) − p(E|¬C), or ratios of these terms. By dealing with co-occurrences, these approaches can be seen as conflating causes to evidential sup ports. Interestingly, an experimental study on measures of evidential supports by (Tentori, Crupi, Bonini, & Osherson, 2007) finds empirical alignment of human responses with re spect to two measures:1 
p(E|¬C)(1)p(E|C)− p(E|¬C) 
task, expressed in forms that can be automatically processed 
log p(E|C) 
p(E|C) + p(E|¬C)(2) 
by the methods to be evaluated. 
The document consists of five sections: a brief overview of the frameworks used as a basis for the study, presentation of experiment, model, computation, and evaluation of results. 
On causation and relevance 
Counterfactuals The primary approach to actual causa tion, rooted in philosophy and logic, builds upon counter factuals, a construct corresponding to the but-for test used 
Returning to the causal domain, to avoid undesired effects— like consequences that “cause” causes—additional machinery is required, e.g. introducing time-related constraints in the inferences—see e.g. (Williamson, 2009). 
Alternatively, (Pearl, 2000) proves that there is strict con nection between structural equations and Bayesian networks, 
1From a theoretical point of view, however, the authors argue that (2) is the only one to satisfy desirable mathematical properties. 
2491
and proposes an unifying notation—causal Bayesian net works (CBNs)—introducing an explicit do notation to dis tinguish interventions from standard probabilistic events. An acknowledged problem with this method is that variables rel evant to the computation may be unobservable (Zhang, 2008). 
At a more fundamental level, however, the problem of model adequacy, i.e. of which variables to include in the model, concerns all these computational methods. Intuitively, a cognitive basis might offer a more robust solution. 
Relevance Theory Relevance Theory (RT) identifies gen eral principles that are supposed to govern successful commu nication. A statement is said to be relevant if the addressee is able to draw inferences from it. Since inferences may always be produced from any statement, RT prioritizes those which can be produced “effortlessly” (Sperber & Wilson, 1986). This principle is supposed to guide listeners in determining causal relations, as in the two following examples (Wilson & Sperber, 1998): 
(i) John dropped the glass. It broke. 
(ii) I got caught. My best friend betrayed me. 
According to RT, causality is inferred because it enriches the context. In (i), the first statement is understood as a cause of the second one, because such a material relation is easy to ac cess from experience. In (ii), the friend’s betrayal could be the consequence of the speaker’s having been caught. However, the converse causality is preferred because it is more “acces sible” (and the speaker would have expressed things differ ently to mean otherwise). It has been observed that notions such as “effort” or “accessibility” are crucial for RT to make predictions and yet remain external to the theory (Levinson, 1989): there is a risk that RT’s principles be bent to justify any intuitively correct interpretation ex post facto. 
Simplicity Theory Simplicity Theory (ST) has been intro duced to account for interestingness, and offers an alterna tive definition of relevance (Dessalles, 2013). Relevant events must be unexpected, which means that they can be presented as more complex to generate than to describe. Cognitive com plexities of generation and of description are measured as minimum description lengths (MDL) (Chater, 1999). In par ticular, generation or world complexity (denoted with CW ), generalizes the classical notion of (im)probability, as it com putes odds without using set extensions. Considering two events e1 and e2, the complexity of their sequential compo sition (denoted by ‘∗’) is (chain rule): 
CW (e1 ∗ e2) = CW (e1) +CW (e2|e1) (3) 
where CW (e2|e1) is the conditional complexity of generating e2 considering e1 already realized. 
Neglecting effects due to description complexity, a rele vant (tentative) explanation, according to ST, is any piece of knowledge that diminishes generation complexity. The po tential causal contribution of c on e is captured by CW (e) − CW (e ∗ c). When dealing with actual causation, c is realized, 
so CW (c) = 0. Thus, c is a relevant actual cause for e if the generation complexity CW of e is smaller conditionally to c, i.e. CW (e|c)  CW (e). A measure of relevance could then be: 
CW (e)−CW (e|c) (4) 
Consider again example (ii). “I got caught” is relevant as far as it can be perceived as unexpected: a complex set of circumstances was supposed necessary for this outcome to occur. The second statement “My best friend betrayed me” appears as a relevant cause as far as it makes the minimal causal path to being caught significantly shorter. Note that (4) is more constraining than RT’s principles. It states both that CW (e) is large and that c provokes complexity drop once taken into account. When several causes are offered, the most rele vant one should be the cause that provokes the largest drop. 
Experimental test 
Participants are asked to read five passages of a short story and to rank the pertinence of answers to simple why questions according to the scale NR: irrelevant, 1: low relevance, 5: high relevance (same ranking allowed).2 They are instructed to approach each answer as if it were the only answer pro duced by another locutor. 
Passage 1 Johnny is 7 years old. In recent months his mother has been worried because he developed a craving for sweet things. She bought some pots of strawberry jam and put them into the larder (a small room near the kitchen). Then one afternoon she finds that Johnny has gone into the larder and has eaten half a pot of strawberry jam. 
Q1. Why is ”half a pot of jam gone”? 
Q2. Why did ”Johnny eat the jam”? 
Q3. Why did ”Johnny go into the larder”? 
Each question had the same candidate answers: 
a. because of Johnny’s gluttony 
b. because Johnny ate it 
c. because mother has put the pot in the larder save the second answer of Q3: 
b’. because johnny wanted to eat a pot of jam being there 
Passage 2 The mother says: ”That’s naughty. In the future you are never to enter the larder without my permission.” Sev eral incidents then follow. First, Johnny gets a broom, hooks the pot of jam from above the shelf without entering into the larder and helps himself. 
Q4. Why did ”Johnny use the broom to hook the pot”? a. because Johnny wanted to take the pot 
b. because of Johnny’s gluttony 
c. because mother has put the pot in the larder d. because mother forbade Johnny to enter the larder e. because the broom was in the house 
f. because of gravity 
2The story (the “legalistic child” case) is adapted from (Rissland & Skalak, 1989), in turn revisiting (Twining & Miers, 1982) . 
2492
Passage 3 Mother finds Johnny eating the jam, but he says to her: ”I didn’t enter the larder”. Then another day, the cat enters the larder and attacks the salmon which mother has bought for a special occasion. 
Q5. Why did ”the cat enter the larder and eat the salmon”? a. because the cat was hungry 
b. because mother has put the salmon in the larder 
M 
T I F 
H 
A 
Q 
c. because the salmon was in the larder 
Passage 4 Mother, upstairs, hears Johnny laughing. She comes down to see Johnny standing outside the larder door watching the cat eating the fish. ’I may not go into the larder’ he says. 
Q6. Why did ”the cat enter the larder and eat the salmon”? a. because the cat was hungry 
b. because mother has put the salmon in the larder c. because the salmon was in the larder 
d. because mother forbade Johnny to enter the larder e. because Johnny made fun of mother 
Passage 5 Finally, Johnny’s parents were out and Johnny was watched by his usually iron-willed babysitter, Maggie. Johnny’s parents forgot to tell Maggie anything about dinner. Supper was late and Johnny was hungry. Johnny asked per mission from the babysitter to enter the larder. She said OK. Johnny feasted on jam. The questions were: 
Q7. Why did ”Johnny enter the larder”? 
Q8. Why did ”Johnny feast on jam”? 
The candidate answers were for both: 
a. because he was hungry 
b. because of Johnny’s gluttony 
c. because Maggie granted him permission 
d. because his parents forgot to tell Maggie about dinner e. because supper was late 
Domain model 
Referring to the traditional terminology, each question speci fies an explanandum (something which has to be explained), each answer proposes an explanans or explanation for the ex planandum. The test implicitly builds upon three roles: X, the (virtual) person who asks the why question; Y, the (virtual) person who gives the answer; and Z, the (actual) respondent, who evaluates the response given by Y. In order to produce an answer or to evaluate its relevance, Z requires a model of the world in which the story has occurred. Such representation is not required to be isomorphic with the input in all details, but just to be an adequate synthesis. 
General action-scheme All questions are about events— for the most, actions performed by an agent. Analyzing verbal reports of legal cases, (Pennington & Hastie, 1993) found that explanations of human behaviour in legal decision making converge to the following action-scheme—here in the version proposed by (Bex & Verheij, 2011): 
Motive ⇒ Intent ⇒ Action ⇒ Consequences 
Figure 1: Action-scheme as general model of action 
To cover further cases, we considered additional elements (Sileno, 2016, Ch. 7); motive is interpreted as a situation per ceived by the agent, triggering a preexisting motivation and producing an intent (here in the sense of specific desire); the intent develops into a certain action (or a course of actions) if coupled with perceiving the associated affordance and no inhibition is put in place by other motivational components; the action brings about a certain consequence depending on the actual environmental disposition. The following model components are then considered: 
M motivation T motive 
I intent F affordance of I via A A action H inhibition of A 
Q consequences 
For instance, for a boy craving for sweets (M), the fact that there is a jam pot (T) “generates” a desire to eat that jam (I). If he is already able to eat it (F), he just does it (A). As a side effect, there will be less jam in the pot (Q). The relative dependencies of the model components are illustrated in the graph in Fig.1 (for simplicity perceptual with actual affordance are aligned). Inhibition, specified using an empty circle arrow, is a negative dependence: the absence of the parent element enables the child element to occur. 
Actions usually have consequences relevant to other ac tions. For instance the agent might need an additional action A0to bring about F (e.g. to go near the pot); in this case the new action should be added in in A’s action model as a new element •F, parent of F. Note however that the generation of the affordance might be independent from the agent; when the action is intentionally preparatory (i.e. part of a plan to perform A), •F depends on I as well. Small case letters will be used in case of ambiguities. 
Passage 1 (Fig. 2) The central event for passage 1 is “Johnny eating the jam”. Reading the propositional content provided in questions and answers through an action-scheme centered around this action, the following associations hold: 
Q1 “half a pot of jam is gone” is a consequence (Q) Q2, b “Johnny eats the jam” is the core action (A) Q3 “Johnny goes into the larder” is a preparatory action to perform the core action (•F) 
a “Johnny is gluttonous” identifies the motivation (M) c “mother has put the pot in the larder” is an event gen erating the motive starting the course of action (•T) b’ “Johnny wanted to eat the jam” is the intent (I) 
2493
•T T 
M I 
a 
b’ 
•He 
b 
c 
•T 
a 
T 
M I 
c 
Q2, b 
Q5, Q6 
f n s 
•F 
Q3 
F 
A 
Q 
Q1 
e 
He 
d 
•F   F 
A 
Q 
Figure 2: Model of passage 1 
b 
M 
c 
Figure 4: Model of passage 4 (without the inhibitors, 3) 
b 
M 
•T T d 
I 
•T T I 
He 
Q4 
t A a Ih 
p He •F Q7 c 
A Q8 
  Q F 
f 
d 
l 
e 
h 
a 
F 
Q 
b u e 
h 
g 
f 
Figure 5: Model of passage 5 
Figure 3: Model of passage 2 
Passage 2 (Fig. 3) The easiest way to eat the jam would be to take it directly (t), however, the prohibition of the mother to enter (He) is inhibiting this easier action. Hooking the pot (h) is an alternative plan. Then, using the broom (u) to hook the pot (to eat the jam) is a nested preparatory action. The presence of broom (b) is a necessary condition to perform it, while gravity (g) is a necessary condition to hook the pot. Q4 (“use the broom to hook the pot”) cannot be modeled simply as u, a possible option is the composite action u ∗ h. 
Passages 3 and 4 (Fig. 4) The core action is the cat eat ing the salmon. Passage 4 brings to the foreground the non intervention of Johnny. The boy is normally (n) expected to stop the cat (s), overriding the prohibition issued by his mother (•He). Making fun of her (f) is a possible motivation behind the anomaly. Q5 and Q6 are modeled as •F ∗A. 
Passage 5 (Fig. 5) The action is centered again around Johnny eating jam. A new motivational state is added: hunger (h)—caused by the supper being late (l), in turn a conse quence of the lack of instructions by the parents (f). Hunger does not enter directly in the action scheme, but only behind the scenes, as the reason why Maggie gives permission (p) to enter the larder (e), thus overriding the prohibition. 
Computing relevance 
The models in the previous section serve as a common ground for a direct operationalization of the methods presented in the introduction (except for RT, as it does not specify the notion of “effort”; its comparative evaluation is then left as an open question). 
Counterfactuals Applying informally the but-for test on the model of passage 1, all answers qualify as causes. Fol lowing the formalization given by (Hitchcock, 2001), each el 
ement of our example is modeled as a binary variable associ ated to the occurrence or the non-occurrence of the event. The associated set of deterministic structural equations would be: 
I := M ∧T A := I ∧F Q := A∧F 
F := •F T := •T •F := I 
Each equation can be seen as encoding counterfactual infor mation related to a causal dependence. Also in this case, applying Hitchcock’s definition of active route for the deter mination of actual causes, we qualify positively all answers. Same results are obtained with the other passages. 
Bayesian inference The application of Bayesian inference requires the domain model to be encoded in a Bayesian net work. In principle, these graphs should be diagrammatically very similar to e.g. Fig. 2. A practical problem arises for deciding the parameters of the conditional probability tables. Even acknowledging subjective probability (i.e. capturing de gree or strength of belief), it is not evident to provide solid backup for these numbers. Nevertheless, this is a required step to proceed with this method. With subjective estimations as parameters, we have extracted the relevance measures de fined in the introduction, obtaining the results on Table 1. 
Simplicity theory The chain rule formula (3) enables us to run through the models in search of the shortest path from cause to effect. Path lengths are measured by the sum of conditional complexities associated to the transitions and the complexity of nodes with no parents required to proceed in the path. Let us assume that all the dependencies belonging to the general action-scheme (Fig. 1) carry similar complexity of transition C0. The graph implies: 
CW (I) = CW (M) +CW (T) +C0 
CW (A) = CW (F) +CW (I) +CW (¬H) +C0 
CW (Q) = CW (F) +CW (A|F) +C0 = CW (A) +C0 
2494
a b c d e f a b c d e f 
p(E|C) p(E|C)· p(C) 
Q1 0.15 0.53 0.11 0.03 0.05 0.05 
Q2 0.16 1 0.11 0.03 0.1 0.05 
Q3 0.18 0.9 0.12 0.04 0.06 0.06 
Q4 0.67 0.13 0.11 0.12 0.11 0.11 0.06 0.03 0.05 0.07 0.1 0.11 Q5 0.33 0.18 0.19 0.07 0.09 0.09 
Q6 0.94 0.4 0.47 0.16 0.66 0.31 0.14 0.16 0.06 0.22 Q7 0.14 0.15 0.14 0.12 0.13 0.04 0.03 0.04 0.04 0.04 Q8 0.13 0.16 0.12 0.11 0.12 0.04 0.03 0.04 0.03 0.04 (1) (2) 
Q1 0.83 3.42 0.23 0.28 0.83 0.08 
Q2 0.9 ∞ 0.26 0.3 1.0 0.09 
Q3 0.98 4.17 0.28 0.33 0.89 0.1 
Q4 3.69 0.42 0.11 0.54 1.01 nan 0.86 0.15 0.04 0.18 0.34 nan Q5 2.01 1.01 1.18 0.6 0.34 0.39 
Q6 0.11 0.08 0.08 0.07 0.1 0.02 0.04 0.04 0.06 0.01 Q7 1.49 1.28 1.47 1.08 1.27 0.48 0.42 0.47 0.36 0.41 Q8 1.06 1.34 1.04 0.78 0.91 0.35 0.43 0.35 0.26 0.3 
Table 1: Relevance measures computed using Bayesian net works, with parameters: for passages 1, 2, 5, p(•T) = 0.5, p(M) = 0.2, p(•|PT) = 0.2; for passage 2, p(He) = 0.6, p(b) = 0.9, p(g) = 1; for passages 3 and 4, p(M) = 0.2, p(•T) = 0.5; for passage 4, p(f) = 0.1, p(He) = 0.8; for passage 5, p(f) = 0.3. 
a b c 
Q1 CW (M) CW (M) +CW (•T ∗T) +CW (F| •F) +3C0 CW (•T) Q2 CW (M) 0 CW (•T) Q3 CW (M) CW (M) +CW (•T ∗T) +C0 ≡ CW (I) CW (•T) a b c d e f 
Q4 CW (I) +CW (He) +C0 CW (M) CW (•T) CW (He) CW (b) CW (g) a b c d e Q5 CW (M) CW (•T) CW (•T ∗T) 
Q6 CW (M) CW (•T) CW (•T ∗T) CW (f) +CW (•He) +5C0 CW (f) a b c d e 
Q7 CW (f ∗ l ∗ h) CW (M) CW (f ∗ l ∗ h ∗ p) CW (f) CW (f ∗ l) Q8 CW (f ∗ l ∗ h) CW (M) CW (f ∗ l ∗ h ∗ p) CW (f) CW (f ∗ l) 
Table 2: Relevance strengths computed as drops of generation complexity (C0 is the transition complexity of action-scheme dependencies). 
and then constraints as: CW (I) > CW (M) and CW (I) > CW (T), etc. Turning upon the passage models3, by applying (4) we obtain the expressions reported on Table 2, from which we can extract similar constraints. Note how this analytical form does not require to decide the parameters upfront. 
Results 
Empirical results The participants to our experiment were 102 individuals (54% female, 71% age 31-50), mostly Eu ropean researchers, recruited via social networks. The test was conducted online. Analyzing the responses, we initially quantified the ranking of answers from 0 (irrelevant, NR) up to 5 (highly relevant), as in the test. The average and standard deviation of rankings are reported on Table 3. These mea sures are however not necessarily the most illustrative for our study, as the resulting histograms have various shapes. We then considered ordering decreasingly the participants’ rank ings and reading the (minimal) ranking value attained by 51% 
3In a context in which A would occur if not inhibited by H: CW (A|¬H) = C0, the double inhibition B ( H ( A translates into CW (¬H|B) = C0 +CW (B) and so CW (A) = 2C0 +CW (B). 
a b c d e f Q1 3.5 ± 1.3 4.5 ± 1.1 0.7 ± 1.1 
Q2 4.5 ± 1.0 1.1 ± 1.8 1.1 ± 1.3 
Q3 3.1 ± 1.6 3.8 ± 1.7 3.7 ± 1.5 
Q4 4.4 ± 1.1 3.1 ± 1.6 2.1 ± 1.7 4.4 ± 1.2 0.9 ± 1.2 0.7 ± 1.0 Q5 4.1 ± 1.4 2.4 ± 1.8 3.5 ± 1.8 
Q6 4.0 ± 1.5 2.8 ± 1.7 3.6 ± 1.7 0.6 ± 1.1 0.5 ± 1.0 Q7 3.8 ± 1.6 2.9 ± 1.8 4.2 ± 1.3 2.3 ± 1.5 2.5 ± 1.6 Q8 3.6 ± 1.7 4.2 ± 1.3 1.8 ± 1.7 1.9 ± 1.6 2.1 ± 1.7 
Table 3: Ranking attributed to answers: mean ± st.dev. a b c d e f 
Q1 4 (3) 5 (5) 0 (0) 
Q2 5 (4) 0 (0) 0 (0) 
Q3 3 (2) 5 (3) 4 (3) 
Q4 5 (4) 3 (2) 2 (1) 5 (4) 0 (0) 0 (0) 
Q5 5 (4) 2 (1) 4 (2) 
Q6 5 (3) 3 (1) 4 (3) 0 (0) 0 (0) 
Q7 5 (3) 3 (1) 5 (4) 2 (1) 3 (1) 
Q8 4 (3) 5 (4) 1 (0) 2 (0) 2 (0) 
Table 4: Minimal rankings for simple (qualified) majorities. 
or 75% of the population. This method enables us to associate to the selected value a majority (simple or qualified) for which that answer has at least that ranking of pertinence. Table 4 il lustrates that the relative ordering of such minimal rankings is consistent passing from 51% to 75% of the population. 
We have also extracted the relative ordering of the rank ings given by individual respondents for each question, in case there were cross-relations between answers that were lost by the previous analysis. Even if respondents were in structed to consider options as independent, one can indeed reasonably expect some repositioning effects due to the avail able choices. These relative orderings, reported on Table 5 (1 means ranked as most relevant by participants), are consis tent with the previous results, although they lose information about the relative gap of pertinence between answers. 
Comparative evaluation As we can see on the tables, no measure of Bayesian inference is fully consistent with our experiments; likelihood and (1) are more aligned, followed by (2). In all cases, we observe a pathological response for Q2b (tautological answer). In many cases, even if the most pertinent cause is correctly identified, the relative order be tween the answers does not follow the empirical results. This may be due to a wrong choice of parameters or even to wrong dependencies in the model. Unfortunately, the framework is quite opaque to model correction tasks. 
In contrast, the relevance measure computed via ST are quite aligned to the empirical results, with fewer (constraints on) parameters and at inferior computational cost. The ir relevance of Q2b is correctly captured. The relative ranking of Q1 and Q2, in the plausible hypothesis that CW (M)   CW (•T) (the child being gluttonous vs putting jam in the larder), is correct. Q4 is also aligned: a is necessarily the most pertinent cause; d the second one, at the condition that CW (He) is sufficiently high (e.g. by considering a plausible dependency of He w.r.t. M); b and c are consistent with the previous ranking; e and f have low pertinence, because their complexity is very low. For Q4 and Q5, consistency holds if 
2495
a b c d e f Q1 1.7 ± 0.5 1.2 ± 0.5 2.8 ± 0.5 
Q2 1.1 ± 0.4 2.1 ± 0.7 2.2 ± 0.5 
Q3 2.0 ± 0.8 1.4 ± 0.7 1.6 ± 0.8 
Q4 1.4 ± 0.6 2.6 ± 1.2 3.3 ± 1.3 1.5 ± 1.0 4.4 ± 1.1 4.6 ± 1.1 Q5 1.3 ± 0.6 2.1 ± 0.8 1.5 ± 0.6 
Q6 1.4 ± 0.7 2.1 ± 0.9 1.6 ± 0.8 3.5 ± 0.9 3.6 ± 1.1 Q7 1.9 ± 1.2 2.7 ± 1.5 1.5 ± 0.9 3.3 ± 1.3 3.1 ± 1.3 Q8 1.8 ± 1.0 1.5 ± 1.1 3.1 ± 1.2 3.1 ± 1.0 3.0 ± 1.1 
Table 5: Relative ordering per question, mean ± st.dev. 
CW (M) > CW (•T) (the cat being hungry vs holding salmon in the larder). The relative gap between Q5b and Q5c is con firmed in all cases. In Q6, respondents do not consider rele vant the conditions related to the prohibition (d, e). Seeing the graph, because of the conjunction in the question, we need to generate all the rest to obtain the target, while the inhibition branch is independent and therefore less complex. Similar considerations hold for Q7 and Q8: the decreasing order of c, a, e, d is respected (but for Q8c); Q7b is aligned with the experiment if CW (M) < CW (f ∗ l ∗ h), Q8b for the opposite condition. 
Perspective In perspective, ST offers two additional advan tages. First, taking into account description complexity, ne glected in this study, ST can provide explanations for the ob served misalignments. Informally, by framing the vocabu lary of the question around the larder (Q3), a jam pot has an higher associative strength (and then less description com plexity) than gluttony. The effect is inverted when questions are framed around eating jam. Q5a, rather than generation complexity, might be influenced by description complexity: “eating” strongly associates with “hungry”; consider for in stance the alternative question: “why did the cat enter the larder?”. Similar considerations apply for the different em pirical results of Q7 and Q8, identical w.r.t. CW . 
Second, in our modeling exercise, we haven’t specified a method for choosing the core action (e.g. “eating the jam”) around which the action model given by the story may be con structed. ST considers relevance to be a matter not only of un expectedness, but also of emotional interest. For instance, in passage 1, the “worrying” of the mother presents an “ought” that, if contradicted, would raise emotional interest. This is what occurs with “eating the jam”. 
Conclusion 
The paper presents an early assessment of the gap between theoretical models and empirical observations with respect to the task of qualifying relevant causes. Our experiment sug gests that simplicity theory (ST) might offer a better opera tional framework for the computation of pertinence of causes. Probabilistic methods, like Bayesian inference or causal Bayesian networks, implicitly assume a set-extensional se mantics (classes of events), but such holistic approach to modeling implies a closure which is not cognitively plausi ble, and difficult to be maintained, even in simple stories like the ones studied here. Furthermore, these methods put aside 
the fundamental problem of contextualizing interpretation by deciding the set of variables under study upfront. This study was necessarily limited to models made by hand to test the adequacy of methods; however, the positive confirmation of good judgment prediction of ST theory is a strong motivation towards automatizing the model construction process, by in verting the problem: an action-scheme is nothing more than pertinent answers to a sequence of why questions. 
References 
Bex, F., & Verheij, B. (2011). Solving a Murder Case by Ask ing Critical Questions. Argumentation, 26(3), 325–353. Chater, N. (1999). The search for Simplicity: a fundamental 
Cognitive Principle? The Quarterly Journal of Experimen tal Psychology, 52A(2), 273–302. 
Dessalles, J. L. (2013). Algorithmic simplicity and relevance. Algorithmic probability and friends, 7070 LNAI, 119–130. Glymour, C., Danks, D., Glymour, B., Eberhardt, F., Ramsey, J., Scheines, R., . . . Zhang, J. (2010). Actual causation: A stone soup essay. Synthese, 175(2), 169–192. 
Hitchcock, C. (2001). The Intransitivity of Causation Re vealed in Equations and Graphs. The Journal of Philoso phy, 98(6), 273–299. 
Levinson, S. C. (1989). A review of relevance. Journal of Linguistics, 25(2), 455–472. 
Lewis, D. K. (1973). Causation. Journal of Philosophy, 70(17), 556–567. 
Pearl, J. (2000). Causality. Cambridge University Press. Pennington, N., & Hastie, R. (1993). Reasoning in explanation-based decision making. Cognition, 49, 123– 163. 
Rips, L. J. (2011). Causation From Perception. Perspectives on Psychological Science, 6, 77–97. 
Rissland, E. L., & Skalak, D. B. (1989). Combining case based and rule-based reasoning: A heuristic approach. In Proceedings of the 11th IJCAI (pp. 524–530). 
Sileno, G. (2016). Aligning Law and Action. Doctoral dis sertation, University of Amsterdam. 
Sperber, D., & Wilson, D. (1986). Relevance: Communica tion and Cognition. Wiley. 
Tentori, K., Crupi, V., Bonini, N., & Osherson, D. (2007). Comparison of confirmation measures. Cognition, 103(1), 107–119. 
Twining, W., & Miers, D. (1982). How to Do Things with Rules (2nd ed.). Cambridge University Press. 
Williamson, J. (2009). Probabilistic Theories of Causality. In The oxford handbook of causation. OUP. 
Wilson, D., & Sperber, D. (1998). Pragmatics and time. In Relevance theory: Applications and implications (pp. 1– 22). John Benjamins Publishing. 
Yuan, C., Lim, H., & Lu, T. C. (2011). Most relevant explana tion in bayesian networks. Journal of Artificial Intelligence Research, 42, 309–352. 
Zhang, J. (2008). Causal Reasoning with Ancestral Graphs. Journal of Machine Learning Research, 9, 1437–1474. 
2496
Do Pitch and Space Share Common Code?: Role of feedback on SPARC effect 
Pulkit Singhal (pulkit.singhal@research.iiit.ac.in) 
Cognitive Science Lab, International Institute of Information Technology 
Hyderabad, India 
Aditya Agarwala (m2017apclp002@tiss.edu) 
Tata Institute of Social Sciences 
Mumbai, India 
Priyanka Srivastava (priyanka.srivastava@iiit.ac.in) 
Cognitive Science Lab, International Institute of Information Technology 
Hyderabad, India 
Abstract 
Previous research shows that performance is better when a high pitch is responded with up or right responses and a low pitch is responded with down or left responses, called the spatial-pitch association of response codes (SPARC) effect. Despite the in tuitive coupling of perception-action, studies investigating the SPARC effect have, however, used feedback to manipulate the stimulus-response mapping. Feedback contradicts the purpose of intuitive stimulus-response mapping by enabling short-term learning. This study primarily investigates the role of feedback on SPARC effect. We believe that feedback can facilitate in congruent mapping and can, therefore, reduce the cost between incongruent and congruent mapping resulting in a diminished SPARC effect. Our results, however, show that feedback has no influence on the SPARC effect indicating that long-term associations can not be overcome by short-term learning due to robust perception-action coupling. Further, unlike previous studies, we observed a strong horizontal SPARC effect in non musicians as well. Keywords: response selection, stimulus-response compat ibility, cross-modal correspondence, pitch-space mapping, SPARC effect, feedback, dimensional overlap, automaticity, dual-route model 
Introduction 
Stimulus-Response Mapping is essential for an effective re sponse selection which is important in the course of inter action between perception and action (Fitts & Deininger, 1954; Fitts & Seeger, 1953; Kornblum, Hasbroucq, & Os man, 1990). Research has widely referred to such map pings or correspondences between stimulus and response as stimulus-response compatibility (SRC) effects. Such stimulus-response mappings exist in stimuli, ranging from non-spatial attributes such as color i.e. Simon effect (Simon, 1990), to spatial correspondence i.e. stimulus and response sharing spatial coding such as pitch and number e.g spatial pitch or music association of response codes (SMARC or SPARC) (Lidji, Kolinsky, Lochy, & Morais, 2007; Rusconi, Kwan, Giordano, Umilta, & Butterworth, 2006) and spatial numerical association of response codes (SNARC) respec tively (Dehaene, Bossini, & Giraux, 1993). Research shows that performance is better when stimulus and response share a common coding than when they do not. 
This study primarily addresses the cross-modal correspon dence between pitch and space. Pitch-Space mapping was first investigated by Pratt (1930) who showed that higher 
pitches are perceived to originate from a higher position in space and lower pitches from a lower position. Pitch is also generally categorically referred to as “high” and “low” in many languages. Such ubiquity of linguistic association be tween pitch and space across languages led Stumpf (2013) to argue that pitch has no spatial characteristics and instead effective linguistic cross-modal associations occur between pitch and space. This has led to the argument that the cross modal correspondence between pitch and space might be en tirely due to language. Following Pratt (1930), other studies (Mudd, 1963; Roffler & Butler, 1968; Trimble, 1934), em ploying explicit linguistic responses such as high, low, as cending, descending (also called pitch metaphors) also failed to establish any intrinsic pitch-space mapping because of the aforementioned arguments. However, studies such as (Wagner, Winner, Cicchetti, & Gardner, 1981; Walker et al., 2010) showed supporting results by employing the head-turn paradigm indicating early development of pitch-space map ping and its automaticity in response. Such contradictory ob servations have led to subsequent investigations which aimed to filter out spatial pitch metaphors. 
Studies (Beecham, Reeve, & Wilson, 2009; Lidji et al., 2007; Rusconi et al., 2006) have attempted to investigate the spatial representation of pitch by employing SRC paradigm. It seeks to remove the pitch metaphors by pairing pitch to discrete response locations i.e. by looking into spatial associ ation between stimuli (pitches) and response locations (up vs. down & left vs. right). Hence, the task becomes a simple key press task which does not require participants to use explicit pitch-metaphors or visuo-spatial imagery in order to give re sponses. Their findings support the spatial mapping between pitch and the associated response locations by showing better accuracy and faster response times (RTs) when a high pitch is responded with up or right response and a low pitch is re sponded with down or left response than vice-versa. 
One of the cognitive foundations for SRC comes from the seminal study by Kornblum et al. (1990). They proposed a dimensional overlap model which refers to the fact that SRC effect is caused by an overlap of dimensions or cat egories between stimulus and response. This dimensional overlap can be caused not just by a similarity in physical cat 
2497
egories between stimulus and response but also when they refer to the same coding. In the context of this study, we assume that pitch and response location refer to the same spatial coding that gives rise to SRC effects - referred gener ally as spatial pitch association of response codes (SPARC). The model proposes that when stimulus and response in SRC tasks share categories, then “elements in the stimulus set au tomatically activate corresponding elements in the response set” (Kornblum et al., 1990). When the activated and in structed response coincide, it is called congruent or compat ible mapping. When they do not, it is called incongruent or incompatible mapping. 
Traditionally, SRC has also often been explained by dual route models (De Jong, Liang, & Lauber, 1994; Gevers, Caessens, & Fias, 2005) which call for two parallel routes: unconditional or automatic route and conditional or inten tional route. According to the model, both routes are activated on stimulus presentation. The unconditional route automati cally activates the corresponding or the compatible response whereas the conditional route is driven by task instructions. If the automatically activated response matches the response generated by the conditional route, the response is executed relatively fast. On the other hand, if the automatically acti vated response is in conflict with the intended response, the former is aborted and the program for intended response is initiated and executed thereby resulting in increased latency and decreased accuracy. This implies that there is a degree of automaticity that is involved in such stimulus-response map pings. Moreover, it is also important to note here that these categories or dimensions are learned over time and therefore give rise to such automaticity and subsequently the SRC ef fects. 
Due to the automaticity caused by long-term learning, it becomes reasonable to assume that such SRC effects can be intuitively expected and investigated without any explicit ma nipulation of training and feedback. Why is it expected that feedback should not have been employed in SRC paradigm? Feedback has been considered as an essential factor in learn ing and training for effective and efficient decision making and knowledge and skill acquisition (Astwood, Van Buskirk, Cornejo, & Dalton, 2008; de Groot, de Winter, Garc´ıa, Mul der, & Wieringa, 2011; Hattie & Timperley, 2007). Studies have shown that feedback enables conscious or unconscious error corrections to change the course of any task perfor mance. Positive feedback facilitates, whereas negative feed back inhibits the given task performance (Hattie & Timper ley, 2007). Furthermore, it has been discussed, which of the two: a positive or negative feedback is an effective feedback? A study on lane-keeping driving simulation (de Groot et al., 2011), investigating on-target compared to the off-target feed back, shows a different impact on an immediate lane-keeping performance and a retention phase. No difference has been observed between the on-target and off-target feedback on lane-keeping performance. However, the off-target feedback showed an advantage over the on-target feedback during re 
tention phase, indicating low sensory overload due to the con stant feedback on every action. Previous findings show a re lationship between learning and the nature of the feedbacks, whether it is extrinsic (augmented) or intrinsic feedback, i.e. embedded into the task itself (Anderson, 1994), its temporal placement, i.e. appearing immediately or delayed by vary ing number of trials (Anderson, 1994; de Groot et al., 2011; van Leeuwen, de Groot, Happee, & de Winter, 2011), and the kind of modality, i.e. visual and audio or combination of the two or proprioceptive feedback (Anderson, 1994; Goldberg & Cannon-Bowers, 2015). The aforementioned studies indi cate the importance of feedback in a novel task situation for better learning and training. Therefore, it seems pointless to employ feedback in case of skilled task performances, which involve intuitive or automatic information processing such as SRC effect. 
Despite automaticity in pitch-space mapping, studies in vestigating SPARC effect (Beecham et al., 2009; Rusconi et al., 2006) have used feedback to manipulate the stimulus response mapping. Based on previous findings, it can be argued that feedback contradicts the purpose of intuitive stimulus-response mapping. It enables short-term learning and can, therefore, act as a strong confound. One could pre dict that this can cause short-term learning in the incongru ent mapping. As elements in stimulus automatically activate the corresponding elements in response, feedback might not facilitate the congruent mapping as much as it might facil itate the incongruent mapping. Feedback might, therefore, strengthen the conditional route and could subsequently lead to a reduction of cost incurred between the incongruent and the congruent mapping resulting in a diminished SPARC ef fect. 
Considering the aforementioned factor, we found it piv otal to investigate the role of feedback on SPARC effect. We hypothesize that if feedback enables learning then we will observe a reduced SPARC effect in the feedback condition. Both vertical and horizontal spatial representation of pitch is tested. 
Methodology 
Participants 
We recruited 28 (14 males) participants from International Institute of Information Technology, Hyderabad for the ex periment. All of them were non-musicians, right-handed and reported normal hearing. The average age was 23.9 years ranging from 18 to 29. The first language of the participants was collected. As per the informal consultation with Speech and Linguistic researchers, we found that unlike Mandarin or Cantonese, Indian languages are not tonal. Hence we did not expect any plausible effect of language. The mode of instruc tion in experiment was English. 
Apparatus and Stimuli 
Pure tones were used for the experiment and all tones corre sponded to musical notes. The tones were generated in Au 
2498
dacity software (Mazzoni & Dannenberg, 2000). We had C4 
(261.63 Hz) as the reference tone with target tones E3 (164.81 
+ 
Hz), F3# (185.00 Hz), G3# (207.65 Hz), A3# (233.08 Hz) 
as “lower” tones and D4 (293.66 Hz), E4 (329.63 Hz), F4# 
(369.99 Hz), G4# (415.30 Hz) as “higher” tones. All tones 
Fixation = 300ms 
Reference Tone = 1000ms  Target Tone + Response 
had a presentation time of 1000ms including 25ms rise and fall times, shared a constant amplitude and were presented via headphones (Sennheiser HD 202) at a comfortable listen ing level. 
 + 
 Response 
Visual  
Feedback 
 = 1000 + 1300 ms ISI = 300ms  
Feedback Window = 750ms 
(Absent in NoFeedback  
condition) 
Design and Procedure 
+ 
We employed a 5 factorial mixed group design with 2 (Feed back: feedback vs. nofeedback) as between group × 2 (Pitch height: low vs. high) × 4 (Distance from the reference tone: 1, 2, 3, 4) × 2 (Response Location: up vs. down or left vs. right) × 2 (Arm position: arm vs. cross-arm) as within group factors. The design was used for both vertical and horizontal 
ITI = 1000ms 
Figure 1: Schema of a single trial 
alignments. Participants were randomly assigned to the feed back and the nofeedback conditions. The experiment was di vided into two sessions corresponding to two alignments with half the participants starting with the vertical alighment while the other half starting with the horizontal alignment. The or der of arm position and mappings were also counterbalanced across participants. Mappings, here, refer to the congruent and incongruent conditions. Congruent condition is the re sult of compatible mapping of pitch height and response lo cation i.e. higher pitch is paired with up or right response while lower pitch is paired with down or left response. While incongruent condition is the result of incompatible mapping of pitch height and response locations i.e. higher pitch with down or left response while lower pitch with up or right re sponse. 
The task was to compare the pitch of target tones with that of the reference tone. Participants had to respond whether the target tone was higher or lower in pitch than the reference and they reported their judgment by pressing the following keys: P or Q for the horizontal alignment; 6 or B for the vertical alignment. Each trial had a fixation of 300ms which was suc ceeded by the presentation of the reference tone and target tone one after the other. The inter-stimulus interval (time be tween the offset of reference and onset of target) was 300ms. Response window began at the onset of target tone itself and had an extra 1300ms, so that the participant had a total of 2300ms to respond. Feedback condition had an extra feed back window of 750ms which displayed the visual feedback: 
colotto, 2002). 
Results 
Similar to Rusconi et al. (Rusconi et al., 2006), both accuracy and mean correct RTs were analyzed using a 2×2×4×2×2 mixed ANOVA on the factors mentioned in design section. RTs faster than 100ms were excluded on the assumption that no motor habituation should be considered as a response. Only correct trials RTs were included for the analysis. Both the alignments (horizontal and vertical) were separately ana lyzed. 
Vertical 
Accuracy Analysis Overall accuracy was 90.1% (Feedback 88.7% and NoFeedback- 91.6% ). The effect of distance was significant showing higher accuracy [F(3,78) = 62.475, p < 0.001] for larger distances; accuracy being significantly less for distance “1” tone (1: 78.3%, 2: 93.7%, 3: 96.5%, 4: 95.7%). Figure.2 shows the dip in accuracy for close target tones. 
Feedback Congruent Feedback Incongruent 
NoFeedback Congruent NoFeedback Incongruent 
1 
0.9 
0.8 
Y 
C
A
R
U
C
C
“correct” or “incorrect”. The inter-trial interval was set at A
1000ms. There were a total of 80 trials (10 presentations of each target tone) in a block. Hence, there were a total of 320 trials in a session corresponding to the 4 blocks (2 arm posi tion × 2 mappings). Both accuracy and speed were empha 
0.7 
0.6 
0.5 
- 4 - 3 - 2 - 1 1 2 3 4 TARGET - REFERENCE (TONES) 
sized and participants were urged to take breaks between the blocks. They performed the succeeding alignment after 24 hrs. Figure 1 shows schema of a single trial. Accuracy and response time (RT) were the performance measures. The ex periment was conducted in a soundproof room. It was run on E-Prime psychology software (Schneider, Eschman, & Zuc- 
Figure 2: Accuracy as function of target tones in vertical alignment 
RT Analysis Overall mean correct RT was 618 ms (Feed back - 596 ms and NoFeedback condition- 641 ms). The ef 
2499
100 
) 
T
R
(
Feedback Congruent Feedback Incongruent NoFeedback Congruent NoFeedback Incongruent 
 
T
N
E
U
R
G
N
O
C
-   
T
N
E
U
R
G
N
O
C
N
I
80 
60 
40 
20 
0 
-4 -3 -2 -1 1 2 3 4 TARGET - REFERENCE (TONES) 
Feedback NoFeedback 
1 
0.9 
0.8 
Y 
C
A
R
0.7 
U
C
C
A
0.6 
0.5 
- 4 - 3 - 2 - 1 1 2 3 4 TARGET - REFERENCE (TONES) 
Figure 3: Mean RT difference between incongruent and con gruent conditions as a function of target tones in vertical alignment 
Figure 4: Accuracy as function of target tones in horizontal alignment 
100 
) 
90 
T
R
(
80 
fect of distance was significant showing faster RTs [F(3,78) = 
 
T
70 
N
E
80.1, p < 0.001] for larger distances. Also, pitch height × re 
U
60 
R
G
sponse location interaction was significant [F(1,26) = 13.642, 
50 
N
O
40 
C
p = 0.001] with congruent faster than incongruent by 51ms 
- 
  
30 
T
N
indicating SPARC effect. 
20 
E
U
R
10 
G
In both the analyses, feedback had no significant main ef 
N
0 
O
C
fect. No main effects or interactions involving arm position 
N
I
were found. Pitch height × response location interaction was not significant in accuracy analysis. 
Horizontal 
-4 -3 -2 -1 1 2 3 4 TARGET - REFERENCE (TONES) 
Feedback NoFeedback 
Accuracy Analysis Overall accuracy was 90.6% (Feedback: 89%, NoFeedback: 92%) The effect of distance was signifi cant showing higher accuracy [F(3,78) = 64.433, p < 0.001] for larger distances; accuracy being significantly less for dis tance “1” tone (1: 77.8%, 2: 92.3%, 3: 96.2%, 4: 96%). Feedback × pitch height was significant [F(1,36) = 4.579, p = 0.042]. Further post hoc analysis revealed that lower pitches are significantly more accurate in NoFeedback than Feedback condition (5.7% advantage over higher pitches, p = 0.009). Figure. 4 shows that particularly at “-1” target tone, NoFeedback is more accurate (11.5% advantage over Feed back) independent of congruent conditions. 
RT Analysis Overall mean correct RT was 605 ms (Feed back: 574ms, NoFeedback: 636ms). The effect of distance was significant with faster RTs [F(3,78) = 72.199, p< 0.001] for larger distances. Pitch height × response location inter action was also significant [F(1,26) = 9.442, p = 0.005] with congruent faster than incongruent by 44ms indicating SPARC effect. A significant main effect of arm position was found [F(1,26) = 8.43, p = 0.007] with arm faster than cross-arm by 42ms. Feedback × distance × pitch height × response lo cation approached significance [F(3,78) = 2.604, p = 0.058]. Further post hoc analysis showed that in Feedback condition, only extreme target tones showed significant SPARC effect (+4: 53ms, p = 0.05; +3: 70ms, p = 0.008; -3: 75ms, p = 0.013; -4: 75ms, p = 0.026) whereas NoFeedback showed SPARC effect only at “-2” target tone (90ms, p = 0.001). This 
Figure 5: Mean RT difference between incongruent and con gruent conditions as a function of target tones in horizontal alignment 
can be easily seen in fig. 5. Feedback × arm position × pitch height × response location was significant [F(1,26) = 7.414, p = 0.011]. Post hoc revealed that in Feedback, arm condition (uncross) shows SPARC effect for both high pitches (98ms, p = 0.01) and low pitches (91ms, p = 0.004. In NoFeedback, however, cross-arm condition showed SPARC effect only for lower pitches (66ms, p = 0.015). Distance × arm position × pitch height × response location was also significant [F(3,78) = 6.635, p < 0.001]. Further post hoc interestingly revealed significant SPARC effect only for arm condition (uncross) al beit at extreme target tones (+4: 74ms, p = 0.026; +3: 66ms, p = 0.016; -3: 101ms, p = 0.002; -4: 66ms, p = 0.031). Feed back had no significant main effect. 
In both the analyses, feedback had no significant main ef fect. Pitch height × response location interaction was not significant in accuracy analysis. 
Discussion 
SPARC Effect 
Results show SPARC effect for both horizontal (44ms) and vertical (51ms) alignments unlike Rusconi et al. (2006) which showed (a) no SPARC effect in horizontal alignment and (b) 
2500
vertical SPARC effect not just in RT but also in error anal ysis. The vertical SPARC effect has been consistently ob tained across studies irrespective of musical training (Lidji et al., 2007; Rusconi et al., 2006). However, many studies including Rusconi et al. (2006) have found significant hori zontal SPARC effect in musicians only and have attributed it to their familiarity with the piano structure which has lower pitches on the left side and higher pitches on the right side. Our study, however, shows strong horizontal SPARC effect for non-musicians as well. Lidji et al. (2007) suggest that even non-musicians can have the piano as a referent or the ef fect could be biased by the writing direction. However, in line with some other studies (Cho, Bae, & Proctor, 2012; Nishimura & Yokosawa, 2009), we believe that the hori zontal SPARC effect might be due to the orthogonal SRC effect (Cho & Proctor, 2003). An orthogonal (vertical-to horizontal) SRC effect is obtained when a vertically aligned stimuli is coupled with a horizontally aligned response and an advantage for the up-right and down-left pairing is observed relative to the opposite pairing. The main effect of arm posi tion in horizontal alignment resulting in higher RTs for cross arm condition was expected after the participants consistently reported the uncomfortability of cross-arm position. More over, the significant interaction of distance × arm position × pitch height × response location showed that arm condition (uncross) only contributed to the significance in SPARC ef fect. 
There is no particular fixed pattern of SPARC effect across the target tones in both the alignments unlike Rusconi et al. (2006) which showed larger mean RT differences be tween incongruent and congruent for distant tones. In Fig ure 3, nofeedback seems to show vertical SPARC effect to be increasing with the distance of target tones but not feed back. However, the effect was more pronounced with higher pitched tones than lower-pitched tones. In Figure 5, how ever, exactly the opposite seems to be true - in which hori zontal SPARC effect is clearly stronger for the distant tones than the closer ones in the feedback condition while nofeed back condition shows no such trend. In addition, the hori zontal SPARC effect in feedback shows symmetrical pattern w.r.t. the distance across pitches. The contradictory patterns suggest that it is difficult to establish a clear-cut pattern of SPARC effect w.r.t. distance of target tones. This, however, is not expected in the purview of dimensional overlap model. As suggested by Kornblum et al. (1990), dimensional overlap varies in degree depending on the extent of overlap between the shared attributes. It can therefore be assumed that dimen sional overlap between pitch and response location will be more in the distant target tones than close tones. Our results, however, do not show this quite adequately. We, therefore, argue in favor of categorical / propositional spatial represen tation (Kosslyn, 1994) compared to analog / coordinate spa tial representation (Kosslyn, 1994). In addition, the current results are consistent with Proctor and Cho (2006) finding, which suggests that pitches are encoded as binary polarities - 
(+) polarity for high pitches and (-) polarity for low pitches, independent of their relative positions on the pitch spectrum. In other words, if we consider pitch-response coupling as co ordinate / analogous representation, i.e. mental pitch line as suggested by Rusconi et al. (2006), then larger SPARC ef fect would be expected with distant compared to closer tones with respect to the reference tone. However, we did not ob serve any significant difference in SPARC effect for distant and closer tones. Therefore, it can be concluded that the current result supports the categorical representation of pitch response coupling than analogous representation. This, how ever, also opens a new line of inquiry in the SPARC research. Many studies (Cho et al., 2012; Lidji et al., 2007) have only employed distant tones to investigate the pitch-space mapping which fail to capture the varying degree of overlap spreading across the pitch spectrum. 
Feedback 
Feedback, importantly, had no influence on SPARC effect. Feedback could not influence the SPARC effect in vertical alignment indicating towards a more intuitive spatial repre sentation of pitch. This also reinforces the fact that perfor mance in SRC tasks is largely influenced by the uncondi tional route due to automaticity. The automatic activation of responses due to long-term learning can not be overcome by short-term training. Dutta and Proctor (1992) demonstrated the persistence of SRC effects with extended practice. This leads us to question whether feedback is required in SRC tasks such as SPARC effect. As feedback has no role in modulating the SPARC effect, it might only result in sen sory overload. We, therefore, propose that feedback should not be employed in vertical SPARC effect because of strong perception-action coupling between pitch and space. 
In the horizontal alignment, Feedback × distance × pitch height × response approached significance. Post hoc revealed that significant SPARC effect came from the extreme tones and only in the feedback condition. We do not have any ro bust explanation for this result as of now. 
NoFeedback also showed a trend of better accuracy partic ularly at “-1” distance tone in both the alignments. We believe that feedback resulted in sharing of confusion between closer tones “+1” and “-1” which was absent in nofeedback as par ticipants consistently underestimated the “+1” tone. One pos sible explanation is that the tones were not loudness equalized which resulted in loudness acting as a confound to pure pitch perception. This is to be investigated in our future work. 
Conclusion 
This study provides interesting results in the domain of pitch space mapping literature. The novel findings are: a) no influence of feedback on vertical SPARC effect indicating strong pitch-space association due to long-term learning, and b) dominant horizontal SPARC effect in non-musicians sug gesting possible orthogonality effect (Cho & Proctor, 2003); however the effect was limited to the feedback condition only. Vertical SPARC effect, however, was expected as has been 
2501
shown in previous research (Lidji et al., 2007; Rusconi et al., 2006). Moreover, the asymmetric SPARC effect across tones suggest for categorical spatial representation of pitch instead of a coordinate representation. 
References 
Anderson, D. I. (1994). The relationship between intrinsic and augmented feedback in motor skill learning. Astwood, R. S., Van Buskirk, W. L., Cornejo, J. M., & Dalton, J. (2008). The impact of different feedback types on decision-making in simulation based training en vironments. In Proceedings of the human factors and ergonomics society annual meeting (Vol. 52, pp. 2062– 2066). 
Beecham, R., Reeve, R. A., & Wilson, S. J. (2009). Spatial representations are specific to different domains of knowl edge. PLos One, 4(5), e5543. 
Cho, Y. S., Bae, G. Y., & Proctor, R. W. (2012). Referential coding contributes to the horizontal smarc effect. Journal of Experimental Psychology: Human Perception and Per formance, 38(3), 726. 
Cho, Y. S., & Proctor, R. W. (2003). Stimulus and response representations underlying orthogonal stimulus-response compatibility effects. Psychonomic Bulletin & Review, 10(1), 45–73. 
de Groot, S., de Winter, J. C., Garc´ıa, J. M. L., Mulder, M., & Wieringa, P. A. (2011). The effect of concurrent bandwidth feedback on learning the lane-keeping task in a driving sim ulator. Human factors, 53(1), 50–62. 
Dehaene, S., Bossini, S., & Giraux, P. (1993). The mental representation of parity and number magnitude. Journal of Experimental Psychology: General, 122(3), 371. 
De Jong, R., Liang, C.-C., & Lauber, E. (1994). Conditional and unconditional automaticity: a dual-process model of effects of spatial stimulus-response correspondence. Jour nal of Experimental Psychology: Human Perception and Performance, 20(4), 731. 
Dutta, A., & Proctor, R. W. (1992). Persistence of stimulus response compatibility effects with extended practice. Journal of Experimental Psychology: Learning, Memory, and Cognition, 18(4), 801. 
Fitts, P. M., & Deininger, R. L. (1954). Sr compatibility: cor respondence among paired elements within stimulus and response codes. Journal of experimental psychology, 48(6), 483. 
Fitts, P. M., & Seeger, C. M. (1953). Sr compatibility: spatial characteristics of stimulus and response codes. Journal of experimental psychology, 46(3), 199. 
Gevers, W., Caessens, B., & Fias, W. (2005). Towards a com mon processing architecture underlying simon and snarc effects. European Journal of Cognitive Psychology, 17(5), 659–673. 
Goldberg, B., & Cannon-Bowers, J. (2015). Feedback source modality effects on training outcomes in a serious game: 
Pedagogical agents make a difference. Computers in Hu man Behavior, 52, 1–11. 
Hattie, J., & Timperley, H. (2007). The power of feedback. Review of educational research, 77(1), 81–112. Kornblum, S., Hasbroucq, T., & Osman, A. (1990). Di mensional overlap: cognitive basis for stimulus-response compatibility–a model and taxonomy. Psychological re view, 97(2), 253. 
Kosslyn, S. M. (1994). Image and brain. 
Lidji, P., Kolinsky, R., Lochy, A., & Morais, J. (2007). Spa tial associations for musical stimuli: A piano in the head? Journal of Experimental Psychology: human perception and performance, 33(5), 1189. 
Mazzoni, D., & Dannenberg, R. (2000). Audacity [software]. pittsburg. PA: Carnegie Mellon University. 
Mudd, S. (1963). Spatial stereotypes of four dimensions of pure tone. Journal of experimental psychology, 66(4), 347. Nishimura, A., & Yokosawa, K. (2009). Effects of laterality and pitch height of an auditory accessory stimulus on hor izontal response selection: The simon effect and the smarc 
effect. Psychonomic Bulletin & Review, 16(4), 666–670. Pratt, C. C. (1930). The spatial character of high and low tones. Journal of Experimental Psychology, 13(3), 278. Proctor, R. W., & Cho, Y. S. (2006). Polarity correspondence: 
a general principle for performance of speeded binary clas sification tasks. Psychological bulletin, 132(3), 416. Roffler, S. K., & Butler, R. A. (1968). Localization of tonal stimuli in the vertical plane. The Journal of the Acoustical Society of America, 43(6), 1260–1266. 
Rusconi, E., Kwan, B., Giordano, B. L., Umilta, C., & But terworth, B. (2006). Spatial representation of pitch height: the smarc effect. Cognition, 99(2), 113–129. 
Schneider, W., Eschman, A., & Zuccolotto, A. (2002). E prime computer software and manual. Pittsburgh, PA: Psy chology Software Tools Inc. 
Simon, J. R. (1990). The effects of an irrelevant directional cue on human information processing. In Advances in psy chology (Vol. 65, pp. 31–86). Elsevier. 
Stumpf, C. (2013). Tonpsychologie (Vol. 2). Cambridge University Press. 
Trimble, O. C. (1934). Localization of sound in the anterior posterior and vertical dimensions of auditory space. British Journal of Psychology, 24(3), 320–334. 
van Leeuwen, P., de Groot, S., Happee, R., & de Winter, J. (2011). Effects of concurrent continuous visual feedback on learning the lane keeping task. 
Wagner, S., Winner, E., Cicchetti, D., & Gardner, H. (1981). ” metaphorical” mapping in human infants. Child Devel opment, 728–731. 
Walker, P., Bremner, J. G., Mason, U., Spring, J., Mattock, K., Slater, A., & Johnson, S. P. (2010). Preverbal infants sensitivity to synaesthetic cross-modality correspondences. Psychological Science, 21(1), 21–25. 
2502
An Embodied Intelligent Tutor for Literal Concepts Recognition Marietta Sionti 
Thomas Schack 
Bielefeld University, Bielefeld, NRW, Germany 
Yiannis Aloimonos 
University of Maryland, College Park, Maryland, United States 
Abstract 
We combine motion captured data with linguistic notions in a game-like intelligent tutoring system, in order to help elementary school students to better differentiate literal from metaphorical uses of motion verbs, based on embodied in formation. In addition to the thematic goal, we intend to improve young students attention and spatiotemporal memory, by presenting sensorimotor data experimentally collected in our motion capturing labs. Furthermore, we examine the accom plishment of games goals and compare it to curriculums approach. Sixty nine elementary school students were randomly divided in two experimental groups (game and traditional) and one control group. Two way analysis of variance suggests that the experimental groups showed progress in posttests, with game group showing remarkable progress especially in the verbs/actions presented during the intervention. This finding was considered as a first indication of attentional and spatiotemporal memorys improvement, while the games assistance features cultivated students metacognitive perception. 
2503
The Development of a Generative Lexicon: Evidence from Instrument Verbs 
Barbora Skarabela 
University of Edinburgh, Edinburgh, United Kingdom 
Hugh Rabagliati 
University of Edinburgh, Edinburgh, United Kingdom 
Mahesh Srinivasan 
UC Berkeley, Berkeley, California, United States 
Abstract 
Many words have multiple yet predictably related meanings. For example, in English and in other languages, the same root morphemes can be used flexibly, to label an action and the instrument used to perform the action (e.g., we hammer with a hammer and mix with a mixer). Previous findings indicate that four- and five-year-olds have formed abstract generalizations about these patterns and use them to infer new word meanings, such that they expect a word that has labeled an action to also label its instrument. But how do these generalizations develop? Across five experiments with a large sample of English-speaking children, we show that in the third year of life, children begin to generalize words between actions and instruments: e.g., they expect that if an action involving an instrument and patient has been called pabbing, then a pab (or a pabber) will refer to the instrument. Additionally, we find that children of the same age also spontaneously extend words between actions and instruments: e.g., if an action has been called pabbing, children indicate that the instrument cannot be a neefoo, presumably because they think it should instead be called a pab or a pabber. Critically, we show that these results do not depend on whether the new word labels an event for which children know a word (e.g., hammering) or instead labels a novel event involving a novel instrument. These findings suggest that by age three, children’s knowledge of lexical flexibility is generative and abstract, and may not be constructed through item specific learning. 
2504
Robot-Based Gestural Intervention Prevents Delay in the Production of Intransitive Gestures in Preschoolers with Autism Spectrum Disorder 
Wing Chee So 
The Chinese University of Hong Kong, Hong Kong, Hong Kong 
Miranda Kit-Yi Wong 
The Chinese University of Hong Kong, Hong Kong, Hong Kong 
Wan Yi Lam 
The Chinese University of Hong Kong, Hong Kong, Hong Kong 
Chun Ho Cheng 
The Chinese University of Hong Kong, Hong Kong, Hong Kong 
Melvin Ng 
The Chinese University of Hong Kong, Shatin, Hong Kong 
Abstract 
Children with autism have impairments in communication and social interactions. Past studies have shown that robotbased interventions are effective in improving their gestural use. The present study asked whether or not children with autism could meet the level of gestural production found in age-matched children with typical development after intervention. Four- to six-year-old children with autism in the intervention group (N = 15) took four training sessions in which they imitated the gestures demonstrated by a social robot in various narratives. Age-matched children with autism in the wait list control group (N = 15) and children with typical development (N = 15) received the training after the completion of the research. Children with autism in the intervention condition produced gestures more accurately in the training and novel stories than those in the wait-list control group in the posttests. Even more promising, the level of gestural production accuracy in children with autism in the delayed posttest of novel stories was comparable to that in children with typical development, suggesting that children with autism could catch up to the level of gestural production found in children with typical development. 
2505
Motivated Manipulators?  
A NLP Analysis of Psychopathic Speech 
Mikhail Sokolov (MishaSokolov@cmail.carleton.ca) John Logan (JohnLogan@cunet.carleton.ca) Department of Psychology, Carleton University  1125 Colonel By Drive Ottawa, ON K1S5B6 Canada 
Abstract 
Psychopaths have long been associated with a unique ability to manipulate others (Hare, 1999). According to the “bottleneck” hypothesis of psychopathy (Newman & Baskin Sommers, 2012), psychopaths’ cognitive abilities are directly related to goal-directed behavior. To shed more light on language production in psychopathy, two language production studies were completed contrasting content and fluency under different motivational and difficulty conditions. Individuals high in psychopathy (HP) were less fluent but maintained a more complex lexicon than their low psychopathy (LP) counterparts when under high cognitive load and low motivation. Yet when HP individuals were under low cognitive load and high motivation, they were more fluent, but used a less complex lexicon. Furthermore, the HP group produced more emotional language in both conditions. The results suggest that HP individuals’ language production is inherently related to motivation and they attempt to balance fluency and complexity when cognitive load is increased. 
Keywords: psycholinguistics, psychopathy, speech production, NLP 
Introduction 
Psychopathy is a personality trait characterized by emotional callousness, manipulative behaviours, parasitic lifestyle, and antisocial behaviours. Psychopathic individuals are also argued to be charming and manipulative (Hare, 1999), allowing them to perpetuate their lifestyle. Among other factors, the form, such as fluency, and content, such as emotionality, of speech is a crucial component of persuasion and manipulation. 
Dual-process models of speech production suggest that the creation of the abstract message to be conveyed, the encoding of the message, and subsequent production, are all discrete processes (Levelt, 2001). Due to its resource intensive nature, the conceptual message formation stage is affected to a greater extent by cognitive load than language encoding. When message formation rate decreases due to higher cognitive load, the production system begins to compensate by producing disfluencies (silent and filled), using simpler, easy to retrieve, words, and reducing the complexity of the message by, for example, using shorter sentences to convey each thought. Even though speech production is a mature area of psycholinguistics, it has not been studied in the context of psychopathy. This knowledge gap hinders our understanding of what aspects of a psychopaths’ speech is “charming and manipulative” and, by extension, how their use of language differs from individuals with few psychopathic characteristics. 
In previous research on the semantic content of speech produced by psychopaths, Hancock, Woodworth, and Porter (2013) transcribed interviews with individuals incarcerated for murder in which they described the murder they committed. They found that psychopaths used a greater number of cause-and-effect descriptors, had a greater focus on physical needs (food, drink, sex, etc.), used distancing language, and had a greater number of disfluencies. Furthermore, Hancock et al. concluded that psychopaths’ speech was less emotional and less pleasant than their non psychopathic peers. Recently, similar findings were obtained through the analysis of PCL-R interviews (Le, Woodworth, Gillman, Hutton, & Hare, 2017). 
However, two studies by Gawda examining individuals diagnosed with antisocial personality disorder (ASPD) found a different pattern of results. ASPD is a disorder that overlaps with the anti-social component of psychopathy. Participants, were asked to write stories based on pictures that displayed emotional scenes (Gawda, 2010). Contrary to Hancock et al. (2013), Gawda found that the ASPD individuals used more repetitions, pauses, and negations. In a follow-up study, Gawda (2013) showed that individuals with ASPD used a greater number of emotional words, and words of a greater emotional intensity, than a control group. Intriguingly, she also found that the antisocial individuals used emotional words of an inappropriate valence for the situation they were describing. Gawda argues that these linguistic techniques are tools for persuading the listener. According to Gawda, the use of repetitions, pauses, negations, and intense emotional lexicon is a way emphasizing certain statements, similar to an experienced orator using these tactics for impact. 
Several explanations are possible for why one group of researchers found results that would seemingly contradict the view that psychopaths are charming and manipulative, while others found evidence that confirms the charming view (albeit sampled from a population that did not have identical characteristics; i.e., psychopathy versus ASPD). One starting point for reconciling this discrepancy is to consider how psychopathy is conceptualized in terms of cognitive functioning. According to the bottleneck hypothesis of psychopathy (Newman & Baskin-Sommers, 2012), the behaviours that are commonly associated with psychopathy (e.g., impulsiveness, risk-taking, emotional callousness, etc.) are predominantly the result of goal oriented behaviour supressing bottom-up processing. The result of this response modulation error is that if a cognitive 
2506
process is not directly related to the ongoing attainment of a rewarding goal, it is inhibited. 
Another possibility for the divergent results is variation in the amount of cognitive load individuals are subjected to in the experimental tasks. In Gawda’s (2010, 2013) studies the use of written responses may have relieved much of the cognitive load associated with the task. In contrast, the requirement for a spoken response in the Hancock et al. (2013) and Le et al. (2017) studies arguably imposed a higher cognitive load. 
Present Studies 
For the present studies we introduced the variables of cognitive load and level of motivation. Our goal was to see if we could reproduce the previous findings of Hancock et al. (2013) and Gawda (2010, 2013). 
In Study 1, a sample of undergraduate participants produced spoken stories under very low motivation conditions. We asked participants to a) provide a truthful recollection of their own choosing; and b) provide us with fictional stories based on each of Ekman (2003) basic emotions. Participants dictated their stories into a microphone with no observers present. In Study 1, the dependent variables of interest were emotional content and linguistic complexity. Following Gawda’s (2013) findings, we hypothesized that the high psychopathy (HP) group would produce speech content with more emotion words than the low psychopathy group (LP), but that the valence would be inappropriate for the emotion they were supposed to portray. For switching from recall (low cognitive load) to fictional stories (high cognitive load) we expected the HP individuals would show a significant deterioration in the fluency of their speech. However, we did not have a specific hypothesis about the emotional content. 
In Study 2, we analyzed recordings of PCL:YV (Forth, Kosson, & Hare, 2003) interviews with incarcerated male youths (Flight, 2004). We predicted that due to the higher incentive for impression management in a forensic setting, and reduced cognitive load due to the question-answer style of the interview, the HP individuals would produce more fluent language, that is not reduced in complexity, and that it would have more emotional content. 
Study 1 
Method 
Participants 
41 undergraduate students volunteered to participate in exchange for course credit. From this original group, 7 participants were removed due to not following instructions, leaving 34 participants (20 female) with a mean age of 20.9 (SD= 7.4) years. Of the remaining participants a large subset (N=30) had the stories they produced transcribed verbatim. Four participants were excluded based on the reduced quality of their recordings. All participants self-identified English as their primary language. 
Measures 
Among other measures as part of a larger study, participants completed the Self-Report Psychopathy Scale III (SRP-III) (Williams, Paulhus, & Hare, 2007) short version. A median split was used to divide participants into LP (mean SRP = 36.75, SD = 5.66) and HP (mean SRP = 64.70, SD = 15.57) groups. 
Stimuli 
Visual stimuli consisted of six public domain images depicting the emotional categories of anger, happiness, fear, disgust, surprise, and sadness. 
Procedure 
Participants were tested individually in a sound attenuated booth. Instructions, stimuli, and questionnaires were presented on a PC using PsychoPy software (Peirce, 2007). Participants’ speech was recorded using a headset microphone and Audacity software (Audacity-Team, 2016). Each recording session was preceded and succeeded by a one-second tone denoting the onset and completion of the recording session. The study required approximately 75 minutes to complete. 
Analysis 
Speech Data 
Speech recordings were manually segmented using  Audacity software to separate the recordings into different  emotional categories. Audio segments were trimmed to two  minutes in length to allow for inclusion of participants who  produced stories that were less than 4 minutes in length, and  to be able to compare the fictional stories with the  recollected stories. A total of 476 minutes of audio recording  was analyzed. The recordings were subjected to high-pass  and low-pass band filters of 500 Hz and 1 kHz, respectively,  to remove non-speech artifacts. Praat software (Boersma &  Weenink, 2016) was used to analyze the speech for silent  disfluencies. Silences were measured by a modified version  of a Praat script, originally created by Lennes (2017), set to  detect silences with duration greater than 200 ms and  intensity lower than 45 db. The 200 ms criterion for silent  disfluencies was based on work by Jameson et al. (2010).  Speech samples with less than 60 seconds of speech or fewer  than 50 pauses detected were manually reviewed. A decision  was then made to accept the results, or to reconfigure the  intensity threshold of silence. Typically, the results were  accepted, but some soft-spoken participants’ recordings  were reanalyzed with a threshold of 30 db. Syllables were  counted using the Syllable Nuclei Praat script (de Jong &  Wempe, 2009). 
Semantic Content 
Speech from 30 participants was transcribed verbatim,  including the filled disfluencies “um”, “uh” and “so”. The  number of words produced and the number of polysyllabic  words produced were also counted. For each word a rating  of emotionality, frequency and rank were assigned using  
2507
custom Visual Basic scripts. The emotional valence of  words was obtained from the NRC Emotion Lexicon (National Research Council Canada, 2011). Frequency and  rank values for all the words were assigned according to the  Frequency Words list for the 2016 OpenSubtitles dataset 
(David, 2017). The truncated version containing the fifty  thousand most frequent words was used in the present analysis. The OpenSubtitles dataset was chosen over more  traditional frequency lists because it is based on television  transcripts, which provide a much closer approximation to spoken language than frequency lists based solely on written  texts. Furthermore, the words were not stemmed to allow for  the inherent complexity contributed by affixes.  
Results 
Participants were divided into HP and LP groups using a median split based on SRP scores. A series of mixed 2 (LP vs HP; between) x 2 (truthful recall vs fiction; within) ANOVAs were performed to test the hypotheses that the HP group’s fluency and/or linguistic complexity would be reduced when producing fictional storiesrelative to recalling an actual, true event, but a similar trend would not appear in the LP group. Specifically, we expected to observe in the HP group: a reduction in the number words produced, a reduction of polysyllabic words (3 or more syllables) produced as a function of all words, an increase in silent pauses, and an increase in verbalized disfluencies; we predicted that LP individuals’ fluency and complexity would not significantly change from recall to fiction. As per Rubin (2017), who argues that family-wise error adjustments in exploratory research is only needed when multiple tests of the same hypothesis are performed, each specific hypothesis was treated as a separate test with follow-up pairwise comparisons’ significance criteria Bonferroni adjusted to .0125 (.05/4). All reported alpha values are unadjusted. 
Gender 
Male participants, on average, had higher SRP scores (M = 56.1, SD = 15.7), compared to females (M = 47, SD = 19.4). However, this difference was not statistically significant (F(1, 33) = 2.10, p = .16, d = 0.52), suggesting that gender differences in psychopathy did not significantly affect this study. 
Words Produced 
No significant main effect was observed for the number of words produced across all story types (F(1, 28) = 2.62, p = .12, ηp2 = .09), nor between HP and LP participants (F(1, 28) = .36, p = .55, ηp2 = .01). However, a significant interaction between psychopathy level and story type was observed (F(1, 28) = 4.97, p = .034, ηp2 = .15). Consistent with our hypothesis, pairwise comparisons showed that the HP group had a significant decrease in the number of words produced between true (M = 311.7, SD = 76.9) and fictional stories (M = 274.5, SD = 75); F(1, 16) = 7.95, p = .007, d = .49. No significant change was observed when the LP individuals were switching from truthful recall to fictional 
stories, nor were significant differences observed between the HP and LP individuals in the recall or the fictional story conditions. 
Polysyllabic Words 
No significant main effect was observed for the number of polysyllabic words produced as a function of all words within participants (F(1, 28) = 0.15, p = .70, ηp2 = .01), nor between participants (F(1, 28) = .50, p = .49, ηp2 = .02). However, a significant interaction between psychopathy level and the number of polysyllabic words produced as a function of all words was observed (F(1, 28) = 4.57, p = .041, ηp2 = .14). Follow-up pairwise comparisons showed no significant within group differences when switching from truthful recall to fictional stories in the number of polysyllabic words produced for the LP individuals. Furthermore, no significant group differences were observed in the recall condition. However, as predicted, the HP group (M = 0.066, SD = 0.009) produced significantly fewer polysyllabic words as a function of all words produced in the fictional story condition compared to the LP group (M = 0.077, SD = 0.0095); F(1, 28) = 10.99, p = .003, d = 1.21. 
Silent Disfluencies 
A significant main effect was observed for the sum of silent intervals within participants (F(1, 32) = 8.33, p = .007, d = 0.49), with the recall condition containing significantly fewer silences (M = 35.43, SD = 13.20) than the fictional story condition (M = 41.49, SD = 11.47), but no between participants (F(1, 32) = 1.20, p = .28, ηp2 = .04) main effect was observed. Furthermore, a significant interaction between psychopathy level and total silence was observed (F(1, 32) = 4.48, p = .042, ηp2 = .12). Follow-up pairwise comparisons showed no significant group difference in the recall condition nor were significant differences observed within the LP group when switching from recall to fictional stories. A non-significant between-groups difference was observed in the fictional story condition with the HP (M = 45.68, SD = 11.12) individuals producing more silent pauses than the LP (M = 37.29, SD = 10.50); p = .031, d = 0.78. Finally, as predicted, it was observed that HP individuals had a significant increase in the total duration of silence when switching from recall (M = 35.59, SD = 11.79) to fictional stories (M = 45.68, SD = 11.12); F(1, 16) = 18.04, p = .001, d = 0.48.  
Verbalized Disfluencies 
For verbalized disfluencies, contrary to our hypothesis, the omnibus test did not reveal any significant differences as a function of psychopathy [F(1, 28) = 0.12, p = 0.79, ηp2 = .04] or story type [F(1, 28) = 1.10, p = 0.30, ηp2 = .04], nor was there a significant interaction [F(1, 28) = 1.04, p = 0.32, ηp2 = .04].  
Zipf’s Law 
To further explore the finding that the HP group’s fluency suffered due to the added cognitive load of creating 
2508
a fictional story, we modeled the rank and frequency of all the words produced by the HP and the LP groups in both conditions (Zipf, 1950). For this analysis, articles and disfluencies were removed from the corpus. The recall condition showed virtually no distinction between the regression slopes of the HP (β = -1.008) and the LP (β = - 0.995) groups. However, contrary to our prediction, a model of the fictional stories showed that the HP group had a smaller deviation (β = -1.208) from the ideal of -1 than the LP group (β = -1.243), suggesting that the set of words they produced are a more optimal conveyer of information (Zipf, 1950). 
Emotional Lexicon 
Based on the work of Gawda (2010, 2013), we hypothesized that the HP group would produce stories of a greater emotional intensity, but the emotional valence would be less appropriate for the stimuli (e.g., being happy at a funeral). 
Congruent with our hypothesis, HP individuals produced a significantly greater number (M = 32.5, SD = 5.7) of emotional tokens in the truthful recollection condition compared to the LP group (M = 24.2, SD = 4.9); t(28) = 1.86, p = 0.037, d = 1.57 (See Figure 1). 
A one-way ANOVA was used to determine if the HP group produced more inappropriate emotions than the LP group. Emotional appropriateness was operationally defined as the ratio of target emotional tokens and the sum of the other five emotional tokens. However, contrary to our hypothesis, no significant group or individual differences were present in the intensity or the appropriateness of the emotions produced between the HP and the LP groups for any of the emotional categories. 
60 
d 
e
For further analysis, we submitted the emotional lexicons to a log-linear model to test if the HP group used a cognitive trade-off between complexity and appropriateness of emotional words, similarly to the trade-off they made between fluency and complexity of words. Once again, contrary to our hypothesis, the HP group (β = -1.337) and the LP group (β = -1.350) had virtually no difference in the slope of their regression lines. This finding suggests that the emotional lexicon of the two groups does not differ in complexity. 
Conclusion 
Study 1 findings provide mixed evidence for our hypotheses. We found evidence that HP individuals are affected to a greater extent by increased cognitive demands in a low-motivation task relative to their LP peers. This hypothesis was supported by the observed reductions in the HP individuals’ use of polysyllabic words, and an increase in silent disfluencies, as well as an overall reduction in the number of words produced. However, we also observed that, contrary to our hypothesis, HP individuals produce a more optimal set of words in their fictional stories than did LP individuals. Finally, we found that HP individuals produce more emotional words, but we did not find that the emotions they were expressing were “inappropriate”. 
Study 2 
Participants 
Transcripts used in this study were derived from interviews of individuals recruited in a previous study by Flight (2004). Flight’s participants were sixty incarcerated adolescent males who ranged from 16 to 20 years old (M= 17, SD=0.9) when interviewed. These individuals were incarcerated in Ontario, Canada. From this original group of 60 participants, a subset of 31 was selected for inclusion in the present study based on the audio quality of the 
c
u
d
o
r
P 
s
n
e
ko
T
 
l
a
n
o
it
o
m
E 
f
o
 
r
e
b
m
u
N
HP LP 
50 
40 
30 
20 
10 
0 
DisgustedFearfulSadSurprisedTR 
AngeryHappy 
Story Type 
recordings. 
Materials 
The data in the present study were derived from 60-90 minute semi-structured interviews that were part of an evaluation for psychopathy using the Psychopathy Checklist: Youth Version (PCL:YV) (Forth, Kosson, & Hare, 2003; Neumann, Kosson, Forth, & Hare, 2006). 
Analysis 
Speech data from 31 participants were transcribed verbatim by a team of volunteers. For each interview the filled disfluencies “um” and “uh” were counted. Furthermore, the number of words produced, and the number of polysyllabic words (3 syllables or more) 
Figure 1. Total emotional tokens produced during each story condition. Error bars indicate 95% confidence intervals. TR = True Recall. 
2509
produced was also counted. For each word, a rating of emotionality, frequency and rank was assigned using custom Visual Basic scripts. The emotional valence of words was obtained from the NRC Emotion Lexicon (National Research Council Canada, 2011). Frequency and rank values for all the words were assigned according to the 
Frequency Words list for 2016 OpenSubtitles dataset (David, 2017). 
Results 
Fluency 
Because the data were not normally distributed, we used Spearman’s rho. 
Congruent with our hypothesis, a negative relationship was observed between psychopathy scores and the number of verbalized disfluencies produced (rs = -.45, p = .019), with the strength of the relationship increasing when disfluencies were counted as a function of all words produced (rs = -.52, p = .006). No significant relationship was observed between psychopathy and the number of words produced. 
However, findingsfrom analysis of the complexity of the words used by the HP and the LP groups were contrary to our hypothesis. First, it was observed that the polysyllabic words, as a function of all words produced, were negatively correlated with psychopathy scores (rs = -.42, p = .029). Furthermore, when the rank and frequency of the words were subjected to a log-linear model, the LP group had a much smaller deviation of β = -1.338 from the ideal of -1, compared to the HP group, with a regression slope of β = - 1.432, suggesting that the HP group’s lexicon is less complex. 
Emotional Lexicon 
Congruent with our hypothesis, a significant positive correlation was observed between the total number of emotional tokens produced and psychopathy scores(rs= .43, p = .026); this relationship was also observed when the emotional tokens were taken as a function of all words produced (rs = .43, p = .026). Furthermore, a significant positive correlation was observed for the specific categories of anger (rs = .49, p = .009), disgust (rs = .38, p = .048), and fear (rs = .42, p = .030). Overall, words with a negative emotional valence were positively correlated with psychopathy scores (rs = .43, p = .027). 
0.14 
0.12 
An incidental finding showed a significant positive correlation between emotional words produced as a function of all words produced, and psychopathy scores for Facet 1, interpersonal manipulation, (rs = .46, p = .015) and Facet 4, antisocial behaviors, (rs= .40, p =.040). When the emotional lexicons for the HP and the LP groups were subjected to the log-linear model, no difference was observed, with LP group’s regression slope being β = -1.276 and the HP group’s slope being β = -1.275 
Conclusion 
We found mixed evidence for the hypothesis that HP individuals, presumably under high impression management pressure, would not experience speech production deficits while producing more emotionally charged content. Supporting this hypothesis, we found that HP individuals produced fewer verbalized disfluencies. However, they were observed to produce less complex content than their peers. Finally, we observed that, congruent with our hypothesis, the HP individuals produced a greater number of emotional tokens. 
Discussion 
We conducted two studies to evaluate psychopathic language under different conditions of cognitive load and motivation. In Study 1, we sampled from an undergraduate population and manipulated their cognitive load during speech production under low motivation. In Study 2, we sampled from an incarcerated population under high impression management pressure. We hypothesized that under all conditions the high psychopathy (HP) individuals would produce more emotional content, but the fluency and complexity of their speech would fluctuate as a result of changing motivation and cognitive load. 
In Study 1, we found evidence that the HP group’s fluency deteriorates due to increased cognitive demands. However, we found mixed evidence with regard to complexity, with a significant reduction in polysyllabic words supporting our hypothesis, but the results of log-linear model contradict our hypothesis. Finally, we did find that the HP individuals produced significantly more emotional speech in the low cognitive load conditions, but this 
0.1 
0.08 0.06 0.04 0.02 0 
HP LP 
difference disappeared when cognitive load was increased. Study 2 replicated the finding that HP individuals produce more emotional words. Similar to other studies (Hancock et al., 2013; Le et al., 2017), we found that psychopathy is positively related to the production of angry, and generally negative emotional words. However, we also found that the HP individuals produce more words related to disgust and fear. Furthermore, we also replicated, contrary to our 
PositiveNegativeJoyFearSadnessAngerDisgustSurpriseAverage Figure 2. Proportion of emotional tokens produced as a function of all words produced during PCL-YV interviews. Error bars indicate 95% confidence intervals. 
2510
hypothesis, the finding that psychopathy is negatively related to linguistic complexity. Finally, we did find support for our hypothesis that motivation makes HP individuals’ speech more fluent. We interpret this pattern of results as suggesting that individuals high in psychopathy traits, when motivated, produce more fluent and emotional language as a 
manipulation technique, but are more vulnerable to cognitive load than their low psychopathy peers. We believe that one reason for the divergence between our findings and those of Le and colleagues (2017), as well as Hancock and colleagues (2013), is the use of varying operational definitions. For example, Le and colleagues considered a disfluency filler statements (e.g., “you know”, “like”, etc.), whereas in our study we counted simple statements towards reduced linguistic complexity. Another possible source of divergence is the use of analytical tools. For example, in the current study we used an emotional dictionary that contained all 6 basic emotional categories, whereas the dictionaries used in other studies primarily focus on the distinction of positive and negative valence, as well as other categories such as “anxiety”. Another source of variance is that the analysis, and emotional dictionary, used in our study did not stem words, so that “happy” and “unhappy” would be rated as polar opposites. Other studies did not include this information in their methods. Limitations of this study include the absence of a high motivation condition with high cognitive load. In the absence of a manipulation of motivation in the HP group it is difficult to infer the exact effect that motivation plays in this group’s speech production. In addition, the range of psychopathy in Study 1 was limited due to using a sample of university students. Finally, studies of language use as a function of personality characteristics are constrained by small sample sizes that may cause undue sampling error, which, in turn, may cause different studies to yield different patterns of results. 
Overall, we obtained results that are partially consistent with previous work and with the theoretical mechanisms proposed to account for the cognitive processes underlying psychopathy (i.e., Response Modulation Theory and capacity limitations in working memory). Clearly, additional studies are required to resolve differences in results across studies. Future work must focus on employing consistent methods (types of participants, stimuli, and tasks, as well as methods of speech content analysis) to clarify the relationship between psychopathy and language use. 
References 
David, H. (2017). Frequencywords. 2016, from https://github.com/hermitdave/FrequencyWords/ de Jong, N.H., & Wempe, T. (2009). Praat script to detect syllable nuclei and measure speech rate automatically. Behavior Research Methods, 41(2), 385-390. doi: 10.3758/brm.41.2.385 
Ekman, P. (2003). Emotions revealed (2 ed.). New York: St. Martin's Press. 
Flight, J.I. (2004). The association between motivations for violence, the victim-offender relationship, and psychopathic traits in violent youth. (Masters Thesis), Carleton University, Ottawa. Retrieved from 
http://catalogue.library.carleton.ca/record=b20642 13  
Forth, A.E., Kosson, D., & Hare, R. (2003). The Hare PCL: Youth Version. Toronto, ON: Multi-Health Systems. 
Gawda, B. (2010). Syntax of emotional narratives of persons diagnosed with antisocial personality. Journal of PsycholinguisticRresearch, 39(4), 273-283. doi: 10.1007/s10936-009-9140-4 
Gawda, B. (2013). The emotional lexicon of individuals diagnosed with antisocial personality disorder. Journal of Psycholinguistic Research, 42(6), 571- 580. doi: 10.1007/s10936-012-9237-z 
Hancock, J.T., Woodworth, M.T., & Porter, S. (2013). Hungry like the wolf: A word-pattern analysis of the language of psychopaths. Legal And Criminological Psychology, 18(1), 102-114. doi: 10.1111/j.2044-8333.2011.02025.x 
Hare, R.D. (1999). Without conscience: The disturbing world of the psychopaths among us. New York: Guilford Press. 
Jameson, A., Kiefer, J., Muller, C., Großmann-Hutter, B., Wittig, F., & Rummer, R. (2010). Assessment of a user’s time pressure and cognitive load on the basis of features of speech. In H. C. Siekmann, Matthew W (Eds.), Resource-adaptive cognitive processes (pp. 171-204). Berlin; London: Springer. 
Le, M.T., Woodworth, M., Gillman, L., Hutton, E., & Hare, R.D. (2017). The linguistic output of psychopathic offenders during a PCL-R interview. Criminal Justice and Behavior, 44(4), 551-565. doi: 10.1177/0093854816683423 
Lennes, M. (2017). Spect - speech corpus toolkit for Praat (Version 1.0.0). Retrieved from https://github.com/lennes/spect/releases 
Levelt, W.J.M. (2001). Spoken word production: A theory of lexical access. Proceedings of the National Academy of Sciences of the United States of America, 98(23), 13464-13471. doi: 
10.1073/pnas.231459498 
National Research Council Canada. (2011). NRC emotion lexicon. 
Neumann, C.S., Kosson, D.S., Forth, A.E., & Hare, R.D. (2006). Factor structure of the hare psychopathy checklist: Youth version (PCL: YV) in incarcerated adolescents. Psychological Assessment, 18(2), 142- 154. doi: 10.1037/1040-3590.18.2.142 
Newman, J.P., & Baskin-Sommers, A.R. (2012). Early selective attention abnormalities in psychopathy. Cognitive Neuroscience of Attention, 421-440. 
Rubin, M. (2017). Do p values lose their meaning in exploratory analyses? It depends how you define the familywise error rate. Review Of General Psychology, 21(3), 269-275. doi: 10.1037/gpr0000123 
Zipf, G., K. (1950). Human behavior and the principle of least effort. Hoboken, NJ: John Wiley & Sons 
2511
Automatic Identification of Texts Written by Authors with Alzheimer’s Disease 
Juan Soler-Company (juan.soler@upf.edu) 
NLP Group, Universitat Pompeu Fabra, C/ Roc Boronat 138, 08018 Barcelona, Spain 
Leo Wanner (leo.wanner@upf.edu) 
NLP Group, Universitat Pompeu Fabra and ICREA, C/ Roc Boronat 138, 08018 Barcelona, Spain 
Abstract 
As demonstrated in previous studies, Alzheimer’s disease leads to a degradation of vocabulary and communication skills. Novels by writers who are known to have suffered from this disease were compared with respect to their lexical richness and syntactic complexity. Those written after the break-out of the disease have shown to use a considerably smaller lex icon and a reduced syntactic complexity of the sentences. This makes us assume that writings of individual authors can be classified automatically into “pre-Alzheimer’s period” and “Alzheimer’s period”. But the writing style of an author is highly individual. Can we still detect whether any given novel is written by an author who suffers from Alzheimer’s? To as sess this, we use a corpus of novels by three well-known writ ers who were diagnosed with Alzheimer’s: Iris Murdoch, Terry Pratchett and Agatha Christie. Using a mostly stylistic set of features we are able to distinguish between novels written un der the influence of the disease and novels written by healthy writers with more than 82% accuracy. The classification of the novels of a given author into “pre-Alzheimer’s period” and “Alzheimer’s period” is accomplished with more than 86% ac curacy. We also prove that our feature set is versatile enough to be able to distinguish between authors in general and books with high precision. 
Keywords: Alzheimer’s Detection; Text Classification; Au thor Identification; Author Profiling 
Introduction 
Alzheimer’s disease is a degenerative brain disease and the most common cause of dementia. It is the 6th leading cause of death in the United States and kills more than breast and prostate cancer combined. 1 out of 10 people aged 65 and older suffers from Alzheimer’s, so it is quite clear that the impact of the disease in today’s society is huge.1 
The characteristic symptoms of Alzheimer’s are difficulties with memory, language, problem solving and other cognitive skills that affect a person’s ability to perform everyday activi ties. People with the disease have trouble following conversa tions, choosing the right vocabulary and articularing precisely their ideas. 
From the natural language processing point of view, the ef fects of Alzheimer’s can be assessed through the analysis of the writing style of an author before and after the break-out of the disease. Several studies in the past carried out such an analysis on novels of well-known authors; cf., e.g., (Garrard et al., 2004; Le et al., 2011; Hirst & Wei Feng, 2012), with the conclusion that a clear decline in vocabulary richness and syntactic complexity and an increase of repetitions after the break-out of the disease can be detected in works during the Alzheimer’s period. As a consequence, it can be expected that supervised machine learning techniques will be able to 
1https://www.alz.org/facts/ 
distinguish between the works of an author written before and after the break-out of the disease. However, a more intrigu ing research question is whether the language patterns of the Alzheimer’s disease are generalizable, i.e., whether we can identify if a novel (or text in general) has been written by an author with Alzheimer’s or not. 
In what follows, we show that indeed the individual works of an author can be classified as belonging to their “pre Alzheimer’s” or “Alzheimer’s” period and that a novel can be also identified as being written by an author with Alzheimer’s or by an author who does not suffer from the disease. In order to explore further to what extent Alzheimer’s leads to a change of style and (possibly also) to a thematic disper sion, we carry out another experiment, in which we automat ically assign fragments of different novels to the correspond ing novel and author. Furthermore, we analyze the distinc tiveness of each feature, to get insight about how the disease affects the style of the authors. Such analysis could be very useful for the implementation of tests that analyze how the writing style of a user changes with time and to warn users when a decline is detected with the goal to detect the disease early and to treat it as effectively as possible. 
For our experiments, we retrieved novels from three well-known authors, Iris Murdoch, Agatha Christie and Terry Pratchett, who were extremely productive while being healthy and also wrote some novels under the influence of the disease. 
The rest of the paper is structured as follows. The next section reviews the related work. Then, we present the exper imental setup, introduce the dataset, the selected features and the results of the implemented experiments. The results are discussed in a separate section. The last section draws some conclusions and outlines our future work. 
Related Work 
Several works have studied how the Alzheimer’s disease af fects language. Boye et al. (2014) study the language of ´ Alzheimer’s patients in conversation contexts with known in terlocutors. Conversations of five Alzheimer’s patients and five control people are analyzed. The conversations are tran scribed and lexical, syntactic and spoken features are ex tracted. The authors study how these features vary depend ing on whether the subject is a patient, or a control person. The outcome shows that people affected by the disease use fewer words, use more ‘yes’/‘no’ utterances and shorter utter ances in general. Paulino and Sierra (2017) looked at inter views conducted with 7 Spanish Alzheimer’s disease patients. 
2512
Rhetorical Structure Theory is used to analyze each dialog turn. The results indicate that there are significant differences in the number of rhetoric relations used by Alzheimer’s pa tients when compared to healthy individuals. 
Luzzatti et al. (2003) study the results of a writing task given to 23 Italian patients. The study shows that the subjects presented impairment of surface dysgraphia (i.e., the patients cannot access lexical knowledge, but still use phonological to-orthographic conversion rules correctly, misspelling irreg ular words), phonological dysgraphia (i.e., patients spell cor rectly words that they have known how to spell, but cannot spell new words), and in some cases, agraphia (i.e., loss of the ability to write). For further works on the evolution of agraphia and language comprehension; see, e.g., (Cummings & Benson, 1992; Houghton & Zorzi, 2003; Neils-Strunjas, Shuren, Roeltgen, & Brown, 1998). 
As already mentioned in the Introduction, some of the stud ies also analyzed the writings of well-known authors who contracted the disease. See e.g., (Garrard et al., 2004) for an analysis of the works of Iris Murdoch. The authors an alyze the syntactic complexity, the lexical variety, the fre quency of repetition and the usage of nouns, verbs, descrip tors and function words in three novels: her first novel, a novel on her prime, and the novel written under the influ ence of the disease. Her last novel appears to use simpler syntactic structures and a more restricted vocabulary than the other two studied novels. Le et al. (2011) and (Hirst & Wei Feng, 2012) study lexical and syntactic changes in 26 novels by Iris Murdoch, 16 by Agatha Christie, and 15 by P.D. James (who aged healthily). In this case, several features are studied, namely how vocabulary size, repetition, word specificity, use of passive and use of auxiliary verbs evolve with the disease. The study also shows a clear decline of Iris Murdoch in her last novel, and a more gradual declining tendency in Christie’s last novels. (Fraser & Hirst, 2016) ana lyze the semantic changes in Alzheimer’s patients using vec tor space models. The authors train word representations us ing healthy control individuals and Alzheimer’s patients and analyze the contextual differences of specific words. In con clusion, there are several works that analyze the evolution of linguistic features, but there are none that actually try to au tomatically distinguish between texts written under the influ ence of Alzheimer’s and texts whose authors do not suffer from Alzheimer’s. See also (Chaski, 2012; Koppel, Schler, & Argamon, 2011; O’Brien, 2013) for more generic approaches to authorship attribution using stylometric techniques. 
Experimental Setup 
In this section, we present the setup of our experiments. We first introduce the corpus on which we carried out the experi ments and then the classification features that are used. In the last subsection, we present the experiments and their results. 
Dataset 
Our corpus is composed of fragments of books by three au thors who are assumed to have suffered from Alzheimer’s, 
namely Iris Murdoch, Agatha Christie and Terry Pratchett. For each author, the same number of books written while healthy and under the influence of Alzheimer’s have been selected. Each selected book is divided into 300 instances. Depending on the total length of the book, the instances may contain a variable amount of sentences. We ensure that each instance contains full sentences (we do not split sentences be tween instances). 
For Agatha Christie, the selected books are the follow ing: Curtain, Elephants can remember, and Sleeping Mur der (written while with Alzheimer’s) and Mysterious Affair at Styles, Murder on the Orient Express and The Burden (writ ten while healthy); for Iris Murdoch: Jackson’s Dilemma (written while with Alzheimer’s), and The Sea (written while healthy); for Terry Pratchett: Discworld’s 36-37-38-39 (writ ten while with Alzheimer’s) and Discworld 1-2-5-6(written while healthy). The main reason behind the prominence of Terry Pratchett in our corpus is that he was diagnosed ear lier and was able to write more books while suffering from Alzheimer’s. Iris Murdoch wrote only one book under the influence of the disease, and even if Agatha Christie has never been officially diagnosed with Alzheimer’s, there are clear signs that her last books were much simpler, which has been associated with the neurological decline caused by Alzheimer’s; see e.g., (Le et al., 2011; Hirst & Wei Feng, 2012). 
Our dataset is thus not completely balanced: 2400 in stances are texts by Terry Pratchett, 1800 by Agatha Christie and 600 by Iris Murdoch. However, as we will see later, this does not affect the performance of our classifier. 
Feature Set 
We implement our experiments as supervised machine learn ing problems in which a set of features is extracted to charac terize an instance with respect to its label. We use Weka’s im plementation of LibSVM (Hall et al., 2009) with a linear ker nel for classification and 10-fold cross validation in order not to be biased by the selection of a training respectively test data subset. The feature set is composed of six subgroups of fea tures introduced below; for their extraction, we use Python’s natural language toolkit and Bohnet and Nivre (2012)’s de pendency parser. Raw text is converted into multidimensional vectors, where each dimension is a feature. 
The feature set is composed of six subgroups of features introduced below. 
Character-based Features are composed of the ratios be tween upper cased characters, periods, commas, parentheses, exclamations, colons, number digits, semicolons, hyphens and quotation marks and the total number of characters in a text. 
Word-based Features are composed of the mean values of characters per word, vocabulary richness, acronyms, stop words, first person pronouns, usage of words composed by two or three characters, standard deviation of word length and the difference between the longest and shortest words. 
2513
Sentence-based Features are composed of the mean num ber of words per sentence, standard deviation of words per sentence and the difference between the maximum and mini mum number of words per sentence in a text. 
Dictionary-based Features consist of the ratios of dis course markers, interjections, abbreviations, curse words, po lar words (positive and negative words using the polarity dic tionaries described in (Hu & Liu, 2004)) and emotion words with respect to the total number of words in a text. The emo tion word features are computed using a publicly available re source called “Depeche Mood”, which provides dictionaries that contain words that evoke the following emotions: fear, amusement, anger, annoyance, indifference, happiness, inspi ration and sadness; for more information, refer to (Staiano & Guerini, 2014). For each one of these emotions, two features are computed: the mean number of words per text that cor respond to each specific emotion and the percentage of the emotion words that belong to that particular emotion. The mean ratio of emotion words per text in general is also com puted. 
Syntactic Features Three types of syntactic features are distinguished: 
1. Part-of-Speech Features are given by the relative fre quency of each PoS tag2in a text, the relative frequency of comparative/superlative adjectives and adverbs and the rel ative frequency of the present and past tenses. In addition to the fine-grained Penn Treebank tags, we introduce general grammatical categories (such as ‘verb’, ‘noun’, etc.) and cal culate their frequencies. 
2. Dependency Features reflect the occurrence of syntac tic dependency relations in the dependency trees of the text. The dependency tagset used by the parser is described in (Surdeanu, Johansson, Meyers, Marquez, & Nivre, 2008). ` We extract the frequency of each individual dependency re lation per sentence, the percentage of modifier relations used per tree, the frequency of adverbial dependencies (they give information on manner, direction, purpose, etc.), the ratio of modal verbs with respect to the total number of verbs, and the percentage of verbs that appear in complex tenses referred to as “verb chains” (VCs). 
3. Tree Features measure the tree width, the tree depth and the ramification factor of the tree. Tree depth is defined as the maximum number of nodes between the root and a leaf node, the width is the maximum number of siblings at any of levels of the tree, and the ramification factor is the mean number of children per level. In other words, the tree features characterize the complexity of the inner structure of the sen tences. These measures are also applied to subordinate and coordinate clauses. 
Analyzing how these metrics evolve with respect to the health status of an author can give us an idea on whether the complexity of the syntactic structures decreases as the disease 
2We use the Penn Treebank tagset http://www.ling.upenn.edu/courses/ 
Fall 2003/ling001/penn treebank pos.html 
progresses or not. 
Lexical Features (or content-dependent features) are used to complement our mainly structural/stylistic features. This group contains the frequencies of the 50 most frequent words of our corpus. 
Our full set of features consists thus of less than 200 features, which, compared with most of the state-of-the-art works on author identification/profiling and on text classifica tion in general, is rather low (and still obtains state-of-the-art performance). Earlier versions of the feature set have been successfully used in several tasks (see e.g., (Soler-Company & Wanner, 2017b, 2015, 2017a)), and we believe that the cur rent version is general enough to tackle different tasks effec tively, so it is an appropriate fit for the problem at hand. 
To contrast the performance of our feature set, two base lines are chosen. The first one is very simple, the majority class baseline, which classifies every instance as the class with more instances in the corpus, showing how challenging an experiment really is. The second one is a token bigram (se quences of two consecutive words) baseline, which uses the frequencies of the most frequent 100, 300, 500, 700 and 900 bigrams for classification. We also considered using trigrams and 4-grams, but their performance was worse than that of bigrams in all cases, so they were discarded. 
Experiments and Results 
We carried out several experiments. The first batch of exper iments aims to identify, given a text instance, the author, the book and whether the author of the text has Alzheimer’s or not. In these experiments, the full dataset is used. The second batch of experiments tries to distinguish between each author when healthy vs. the same author when ill. In each exper iment from the second batch, only instances of the specific author are used. For each experiment, we present the perfor mance of our full set of features, of each feature group by itself and of both baselines. 
The results of the first batch of experiments are shown in Table 1. 
Table 1: Results of the first set of experiments. 
Features Used 
	Author Id 
	Alzheimer’s Id 
	Book Id
	Full Set 
	96,39% 
	82,21% 
	73,02%
	Character-based 
	69,75% 
	64,91% 
	35,04%
	Word-based 
	83,44% 
	70,60% 
	42,65%
	Sentence-based 
	61,65% 
	60,85% 
	19,25%
	Dictionary-based 
	71,58% 
	65,56% 
	33,33%
	Syntactic 
	94,71% 
	73,83% 
	55,15%
	Lexical 
	57,45% 
	54,47% 
	19,98%
	Majority Class 
	50% 
	50% 
	6%
	Token 2-gram 100 
	80,23% 
	68,44% 
	33,27%
	Token 2-gram 300 
	84,15% 
	72,52% 
	40,39%
	Token 2-gram 500 
	85,87% 
	74,60% 
	48,06%
	Token 2-gram 700 
	89,47% 
	76,66% 
	52,94%
	Token 2-gram 900 
	90,87% 
	78,01% 
	57,35%
	



2514
The results of the second batch of experiments are pre sented in Table 2. 
Table 2: Results of the second set of experiments. 
Features Used 
	Iris Murdoch 
	Agatha Christie 
	Terry Pratchett
	Full Set 
	98,50% 
	86,00% 
	94,50%
	Character-based 
	82,33% 
	72,67% 
	76,63%
	Word-based 
	87,17% 
	68,51% 
	85,00%
	Sentence-based 
	68,67% 
	59,33% 
	69,29%
	Dictionary-based 
	74,50% 
	66,50% 
	76,50%
	Syntactic 
	89,51% 
	76,89% 
	86,21%
	Lexical 
	75,83% 
	71,61% 
	67,13%
	Majority Class 
	50% 
	50% 
	50%
	Token 2-gram 100 
	85,67% 
	64,50% 
	83,71%
	Token 2-gram 300 
	87,01% 
	65,17% 
	85,63%
	Token 2-gram 500 
	88,55% 
	65,94% 
	85,33%
	Token 2-gram 700 
	90,19% 
	65,39% 
	87,95%
	Token 2-gram 900 
	90,66% 
	69,17% 
	88,78%
	



Discussion 
Table 1 shows the performance in the first batch of experi ments. It can be observed that the performance of our full set of features is competitive, achieving more than 96% of accu racy in author identification, more than 82% in Alzheimer’s identification and finally, in the most challenging experiment, the book identification case (where the majority class base line is only 6%), 73,02%. In each case, the classifier with our features is able to outperform the baselines. The table also shows the performance of each individual set of features in each experiment. Some conclusions can be drawn from the performance of the individual feature groups. In all cases, the syntactic group of features performs best; it is also the largest group, and the one that best characterizes the writing style of the authors, without analyzing specific choices of words. We see that the baseline achieves good performances in au thor and Alzheimer’s identification, but has a harder time in the book classification case. It needs to be noted that the best performances of the baseline involve the use of 900 features, which is a much larger number of features compared to our feature set. We can also observe that the lexical features are not very effective by themselves and that word-based features obtain competitive performance in author and Alzheimer’s identification, which can be due to the fact that this group of features analyzes the characteristics of words and the vocab ulary richness of the authors, one of the characteristics that can directly be related to the cognitive degradation that the disease causes. 
Figure 1 shows the confusion matrix of the book identi fication experiment. In general, this matrix shows that the feature set captures effectively the style of an author and that books by the same author are often confused between each other, while books by different authors are confused very in frequently. More specifically, the matrix indicates that Disc world 36 and 37 and Discworld 38 and 39 are often confused between each other. It is also notable that even though Disc world 37 is often confused (in particular) with 36, 38-39 and 
6 (not as frequently), it is never confused with Discworld 1 and 2, and only once with Discworld 5. This shows a clear evolution of the writing style of Terry Pratchett during the de velopment of the saga. It also shows that books written under the influence of Alzheimer’s are stylistically similar enough to be confused with each other often. The case of Iris Mur doch shows that the book written with Alzheimer’s and the one written while healthy are confused only in two cases, which shows how different stylistically these two books are. The books by Agatha Christie are mostly confused between each other, which shows the consistency of the style of the au thor even with the disease. In other words, the style of some authors tends to change significantly or become less distinc tive from work to work during the period they suffered from Alzheimer, while the style of others remained stable. 
Table 2 shows the performance of the second batch of ex periments. This experiment aimed to distinguish between the writings of the same author when healthy and when ill. The table shows that the performance of our classification is rather competitive in this case as well, with more than 86% of ac curacy in all cases. In the Iris Murdoch case, we obtain an accuracy of 98,50%, which is almost perfect. This can be due to the fact that there are only 300 instances per class in this case and the two selected books are very different stylis tically. However, looking at the performance of the Terry Pratchett experiment, we can see that we obtain 94,50% of ac curacy while distinguishing books from the same author and saga, sharing themes, characters, and universe, which makes the classification task much more challenging. In all cases, we outperform the baselines by a large margin. 
One of the main advantages that our (mainly) stylistic fea tures have against other feature sets such as word embed dings, bag-of-words approaches or other content-based fea tures, is that we can analyze the values of many different lin guistic features in different settings. This analysis can provide very valuable information on the effects of the disease on the writing style of the analyzed authors. Computing the infor mation gain of the features in each one of the Alzheimer’s related experiments, we can see the features that were the most relevant for the classification. Table 3 shows the 10 most distinctive features in each of the Alzheimer’s-related exper iments. Features with ‘SYNPOS’ as prefix represent part-of speech frequencies, the ones with ‘SYNDEP’ are dependency relation frequencies and ‘SYNSHAPE’ are shape-based met rics of the dependency trees 
For convenience of the reader, we list the definitions of these features:3 
• SYNPOS POS: Word with possessive ending, • SYNDEP PRT: Particle (dependent on verb), • SYNPOS WP: Wh-pronoun, 
• SYNPOS RP: Particle, 
3For the definition of the full list of dependencies, see (Surdeanu et al., 2008). 
2515
Figure 1: Confusion matrix of the book identification experiment. 
Table 3: 10 features with more information gain in every Alzheimer’s-related experiment. 
Alzheimer’s Id 
	Iris Murdoch 
	Agatha Christie 
	Terry Pratchett
	SYNPOS POS 
	SYNDEP compVerbRatio 
	SYNPOS VBP 
	SYNDEP OPRD
	SYNDEP PRT 
	SYNDEP MNR 
	SYNDEP OPRD 
	SYNDEP IM
	SYNPOS WP 
	SYNDEP APPO 
	SYNDEP IM 
	SYNDEP SUB
	SYNPOS RP 
	SYNPOS RP 
	SYNDEP compVerbRatio 
	SYNPOS PRP$
	SYNDEP OPRD 
	SYNDEP PRT 
	SYNDEP MNR 
	SYNPOS MD
	SYNPOS MD 
	SYNDEP DIR 
	SYNPOS MD 
	SYNPOS POS
	SYNPOS VBP 
	SYNPOS WRB 
	SYNPOS VBD 
	SYNDEP APPO
	SYNDEP SUB 
	SYNPOS WP 
	SYNDEP LOC 
	SYNPOS VBP
	SYNDEP MNR 
	SYNPOS POS 
	SYNPOS VBG 
	SYNDEP MNR
	SYNPOS WRB 
	SYNDEP LOC 
	SYNDEP AMOD 
	SYNPOS WP
	



• SYNDEP OPRD: Predicative complement of rais ing/control verb, 
• SYNPOS MD: Modal verb, 
• SYNPOS VBP: Verb, non-3rd person singular present, • SYNDEP SUB: Subordinated clause, 
• SYNDEP MNR: Adverbial of manner, 
• SYNPOS WRB: Wh-adverb, 
• SYNDEP compVerbRatio: ratio of composed verbs vs. to tal number of verbs, 
• SYNDEP APPO: Apposition, 
• SYNDEP DIR: Adverbial of direction, 
• SYNDEP LOC: Locative adverbial, 
• SYNDEP IM: Infinitive verb (dependent on infinitive marker to), 
• SYNPOS VBD: Verb, past tense, 
• SYNPOS VBG: Verb, gerund or present participle • SYNDEP AMOD: Modifier of adjective or adverbial, • SYNPOS PRP$: Possessive pronoun. 
Note that the features that are displayed in Table 3 show the most distinctive features in each experiment considering 
the full set of features. As we see, all of these features are syntactic, showing that the analysis of the syntactic traits is a good way to measure the stylistic evolution of an author. The first non-syntactic feature that appears in this feature ranking is the vocabulary richness, which is also a good indicator of the lexical variety that an author shows throughout different moments of his/her career. If we analyze the specific syn tactic features that are distinctive, we see that for the general case (Alzheimer’s Id) and for the case of Terry Pratchett, the number of subordinate clauses is very distinctive. This could mean that complex structures such as subordinate clauses are found more scarcely in the texts written by authors with Alzheimer’s. Other features such as the ratio of composed verbs and the usage of adverbial dependencies (which indi cate manner, location, direction, etc.) are also very distinc tive. The ratio of composed verbs and the usage of adverbial dependencies are features that indicate that a text gives de tailed, precise explanations (specifying locations, manners, directions, purpose, or extent) and uses complex verb struc tures. A decline of these features could indicate a decline of the writing style of the author. 
Conclusions and Future Work 
This paper presents classification experiments on the distinc tion between the writings of authors with Alzheimer’s and 
2516
healthy authors. We show that it is possible to differentiate between the writings of the same author with and without the disease very effectively, and even more: that it is possible to identify whether a novel has been written by an author who suffers from Alzheimer’s or by an author who does not. Our book identification experiments, in which we assigned iso lated text instances to specific novels, have shown that the style of a writer may change with Alzheimer’s and become less distinctive from work to work or remain stable. Further, broader studies are needed to investigate this issue in more depth. 
From the perspective of feature engineering, we analyze the features that are most distinctive in all Alzheimer’s dis ease classification experiments, showing the relevance of syn tactic features in the experiments and relating them to the de velopment of the disease. We also analyze the confusions that emerge from the book identification experiment, which prove that with the chosen features we are effectively capturing the writing style of the authors. 
In the future, we plan to expand this work using data from patients to see whether these stylistic patterns also appear in non-literary texts. We also plan to explore different fea ture sets and approaches, using texts written in different lan guages. 
References 
Bohnet, B., & Nivre, J. (2012). A transition-based system for joint part-of-speech tagging and labeled non-projective de pendency parsing. In Proceedings of the 2012 joint confer ence on empirical methods in natural language processing and computational natural language learning (pp. 1455– 1465). 
Boye, M., Tran, T. M., & Grabar, N. (2014). Nlp-oriented ´ contrastive study of linguistic productions of alzheimers and control people. In International conference on natu ral language processing (pp. 412–424). 
Chaski, C. E. (2012). Best practices and admissibility of forensic author identification. JL & Pol’y, 21, 333. Cummings, J. L., & Benson, D. F. (1992). Dementia: A clinical approach. Butterworth-Heinemann Medical. Fraser, K. C., & Hirst, G. (2016). Detecting semantic changes in alzheimers disease with vector space models. In Pro ceedings of lrec 2016 workshop. resources and process ing of linguistic and extra-linguistic data from people with various forms of cognitive/psychiatric impairments (rapid 2016). 
Garrard, P., Maloney, L. M., Hodges, J. R., & Patterson, K. (2004). The effects of very early alzheimer’s disease on the characteristics of writing by a renowned author. Brain, 128(2), 250–260. 
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009). The WEKA data mining soft ware: an update. ACM SIGKDD explorations newsletter, 11(1), 10–18. 
Hirst, G., & Wei Feng, V. (2012). Changes in style in authors with alzheimer’s disease. English Studies, 93(3), 357–370. Houghton, G., & Zorzi, M. (2003). Normal and impaired spelling in a connectionist dual-route architecture. Cogni tive neuropsychology, 20(2), 115–162. 
Hu, M., & Liu, B. (2004). Mining and summarizing customer reviews. In Proceedings of the tenth acm sigkdd interna tional conference on knowledge discovery and data mining (pp. 168–177). New York, NY, USA: ACM. Retrieved from http://doi.acm.org/10.1145/1014052.1014073 doi: 10.1145/1014052.1014073 
Koppel, M., Schler, J., & Argamon, S. (2011). Authorship at tribution in the wild. Language Resources and Evaluation, 45(1), 83–94. 
Le, X., Lancashire, I., Hirst, G., & Jokel, R. (2011). Longi tudinal detection of dementia through lexical and syntactic changes in writing: a case study of three british novelists. Literary and Linguistic Computing, 26(4), 435–461. 
Luzzatti, C., Laiacona, M., & Agazzi, D. (2003). Multiple patterns of writing disorders in dementia of the alzheimer type and their evolution. Neuropsychologia, 41(7), 759– 772. 
Neils-Strunjas, J., Shuren, J., Roeltgen, D., & Brown, C. (1998). Perseverative writing errors in a patient with alzheimer’s disease. Brain and Language, 63(3), 303–320. 
O’Brien, S. (2013). The borrowers: Researching the cogni tive aspects of translation. Target. International Journal of Translation Studies, 25(1), 5–17. 
Paulino, A., & Sierra, G. (2017). Applying the rhetorical structure theory in alzheimer patients’ speech. In Proceed ings of the 6th workshop on recent advances in rst and re lated formalisms (pp. 34–38). Association for Computa tional Linguistics. 
Soler-Company, J., & Wanner, L. (2015). Multiple language gender identification for blog posts. In Proceedings of the 37th annual meeting of the cognitive science society (pp. 2248–2253). 
Soler-Company, J., & Wanner, L. (2017a). On the relevance of syntactic and discourse features for author profiling and identification. In European chapter of the association for computational linguistics, eacl 2017 (pp. 681–687). 
Soler-Company, J., & Wanner, L. (2017b). On the role of syntactic dependencies and discourse relations for author and gender identification. Pattern Recognition Letters. 
Staiano, J., & Guerini, M. (2014). Depechemood: a lexicon for emotion analysis from crowd-annotated news. CoRR, abs/1405.1605. 
Surdeanu, M., Johansson, R., Meyers, A., Marquez, L., & ` Nivre, J. (2008). The conll-2008 shared task on joing parsing of syntactic and semantic dependencies. In Pro ceedings of the twelfth conference on computational nat ural language learning (pp. 159–177). Stroudsburg, PA, USA: Association for Computational Linguistics. 
2517
Quantifying Conceptual Flexibility in a Compositional Network Model 
Sarah Solomon (sarahsol@sas.upenn.edu) 
Department of Psychology, University of Pennsylvania,  
425 S. University Ave., Philadelphia, PA 19104 USA 
John Medaglia (john.d.medaglia@drexel.edu) 
Department of Psychology, Drexel University 
Department of Neurology, University of Pennsylvania 
3201 Chestnut Street, Philadelphia, PA 19104 USA 
Sharon L. Thompson-Schill (schill@psych.upenn.edu) 
Department of Psychology, University of Pennsylvania 
425 S. University Ave., Philadelphia, PA 19104 USA 
Abstract 
A single concept can manifest in many varied forms,  depending on the context in which it is activated. That is,  concepts appear to be flexible rather than static. Here we implement a compositional model of conceptual knowledge in  which basic-level concepts are represented as graph  theoretical networks, with the specific goal of quantifying  conceptual flexibility. We collect within-concept statistics  using online participants, construct network models, and  validate these models in a classification analysis. We then 
extract network measures and find that network diversity and  core-periphery structure correspond to conceptual flexibility  and stability, respectively. These results suggest that a  compositional network model can be used to extract formal  measures that are interpretable and useful in the study of  conceptual knowledge. 
Keywords: conceptual knowledge, network science,  flexibility, semantics 
Introduction 
The APPLE information evoked by “apple pie” is  considerably different from that evoked by “apple picking”:  the former representation is soft, warm, and wedge-shaped,  whereas the latter is firm, cool, and spherical. Though APPLE 
is considered to be one basic-level concept, its information  content can be flexibly adjusted to reflect contextual  demands. This conceptual flexibility enables concepts to be  represented in varied and fluid ways, a central characteristic  of the semantic system that has not yet been captured in a  formal model of conceptual knowledge.  
Perhaps the most basic form of conceptual flexibility is  that a single concept has many distinct sub-ordinates that  differ from each other. The concept APPLE can be  instantiated as a Granny Smith or as a Macintosh, and either  one can easily be brought to mind. But even a representation  of a single token of APPLE can be flexibly adjusted:  activated properties might be RED and ROUND while  shopping, whereas they might be SWEET and CRISPY while  eating. A concept can also be represented in varied states,  each with their own distinct features: the representation of  an APPLE is FIRM versus SOFT before and after baking, and  SOLID versus LIQUID before and after juicing. Conceptual  
flexibility is further evidenced in the frequent non-literal use  of concepts: one should stay away from “bad apples” and  should not “compare apples with oranges;” and, one can use  concepts fluidly in novel analogies and metaphors. Though  conceptual flexibility is a pervasive phenomenon, it poses a  formidable challenge: what kind of conceptual structure  permits this flexibility to occur?  
In vector-based approaches, concepts are represented as  vectors of features. These features can span a range of  information-types (e.g., visual, functional, encyclopedic),  consistent with a distributed account of conceptual  knowledge (e.g., McRae et al., 1997; Tyler & Moss, 2001).  Models that represent basic-level concepts in terms of their  constituent features are valuable because they can be  implemented in computational architectures such as parallel  distributed processing models and attractor networks (e.g.  Cree et al., 1999). More generally, they provide an account  of concepts’ internal structure, which is arguably essential  for a theory of conceptual flexibility. However, the feature vectors that represent individual concepts are static and  unchanging — a clear limitation if one aims to incorporate  flexibility into conceptual structure.  
In current network-based approaches, individual concepts  are characterized in terms of their relation to other concepts  by virtue of their word-association strengths or text-based  co-occurrence statistics. In this framework, concepts are  represented as nodes in a network, and their relations are  encoded as the links, or edges, between them (e.g., Steyvers  & Tenenbaum, 2005; De Deyne et al, 2016). These models  are valuable because semantic structure can be analyzed  using a rich set of network science tools. However, current  network-based implementations do not provide the internal  conceptual structure that is necessary — we argue — to  model conceptual flexibility. In other words, it is hard to  provide a model of conceptual flexibility (in the sense  described above) when the features that are being flexibly  adjusted are not explicitly represented.  
Here we introduce a new model in which concepts are  represented as their own feature-based networks. We  believe that a feature-based conceptual framework paired  with network science techniques provides a platform on  
2518
which to model conceptual flexibility. In our concept specific networks, nodes represent individual features and  edges (i.e., the links between the nodes) represent the  statistical relationship between features within that concept.  That is, edges capture the extent to which certain properties  tend to covary with each other within a concept. The  creation of such networks thus requires the calculation of  within-concept statistics. These statistics provide the  scaffolding to build our networks, and also reveal how a  concept’s information may be appropriately adjusted to  form valid, yet varied, instances of that concept. Our  specific goals here are (1) to show that creation of such  networks is possible, (2) that these networks contain  concept-specific information, and (3) that they permit the  extraction of formal measures of conceptual flexibility.  
Another phenomenon relating to conceptual flexibility is  the distinction between context-independent and context dependent conceptual properties (here, we use this  synonymously with “features”; Barsalou, 1982). Context independent properties are those that are automatically  activated for a concept in all contexts, and are sometimes  referred to as “core” properties. Context-dependent  properties are those that are only activated when the context  renders them relevant. In the APPLE example, SWEET and  HAS SKIN may be context-independent and –dependent  properties, respectively. Concepts are composed of both  kinds of properties, such that some properties are stable and  occur across all instances, and some are more variable and only occur some of the time. Furthermore, some concepts  may have a stronger “core” than others, and this might relate  to the flexibility of those concepts. One of our additional  goals was thus to extract network-based measures that  characterize this element of conceptual structure in a formal  way.  
Many networks by their very nature permit flexibility,  because a single network can support different states, each  characterized by different patterns of activation across  nodes. This kind of network flexibility is determined by the  connections between nodes and how those connections give  rise to a larger network structure. Most natural systems  exhibit “small-world” network structure (Bassett &  Bullmore, 2006), which means that there are clusters of  nodes in a network with strong connections between them.  These are called “modules”, and nodes can interact with  these modules in different ways. Some nodes may have  links that are highly distributed across the modules in a  network, whereas other nodes may have links only in one  module. This tendency is captured in the diversity  coefficient, a version of the participation coefficient  calculated using normalized Shannon entropy. We  interpreted network diversity as a likely candidate for a  formal flexibility measure, and predicted that it would  correlate with a measure of “semantic diversity” calculated  separately using word co-occurrence statistics (SemD;  Hoffman et al., 2013).  
Network science also provides techniques for assessing  core-periphery structure (Borgatti & Everett, 2000). In  
network terms, a core is a set of nodes that are densely  interconnected and therefore often co-activated, whereas the  periphery consists of nodes with sparser connections. A  measure can be extracted that represents the extent to which  a given network has a core-periphery structure; some  networks might have more prominent cores than others. We  hypothesized that this construct of core-periphery structure  could provide a way to formally capture the notion of  context-dependent and context-independent conceptual  properties. More specifically, concepts characterized by  large sets of context-independent properties might  correspond with networks characterized by a strong core periphery structure. It also seems reasonable to suggest that  concepts with a stronger core might be less flexible in the  ways described above. If we interpret a core as a set of  properties whose activation patterns are stable across  contexts, then there is less room for variability in the  expression of these properties, and therefore less flexibility  overall. We therefore predicted a negative relationship  between our network measures of flexibility and core periphery structure.  
Methods 
General Methods 
Network Construction In order to create our networks we  first had to define our nodes. Since our nodes represent  individual conceptual properties, we compiled a list of  properties that applied to all of our target concepts.  Participants were recruited from Amazon Mechanical Turk  and were asked to list all of the properties that must be true  or can be true for each concept. It was emphasized that the  properties do not have to be true of all types of the concept.  Participants were required to report at least 10 properties per  concept, but there was no limit on the number of responses  they could provide. Once these data were collected, we  organized the data as follows. For each concept, we  collapsed across different forms of the same property (e.g.,  “sugar”, “sugary”, “tastes sugary”), and removed responses  that were too general (e.g., “taste”, “color”). For each  concept, we only included properties that were given by  more than one participant. We then combined properties  across all concepts to create our final list of N properties that  will be represented as nodes in our concept networks.  
The same participants also provided “sub-concepts”:  these included subordinate concepts and possible concept  states (e.g., chocolate chips, wine bottle). For each concept,  participants were asked to think about that object and all the  different kinds, forms, types, or states in which that object  can be found. For each concept, we removed responses that  we considered properties rather than types (e.g., “sweet  chocolate”), and responses that were non-generic  trademarks (e.g., “Chiquita banana”). We only included  responses that were given by more than one participant,  resulting in a set of K sub-concepts for each concept. It  should be noted that the classification of “concepts” and  “sub-concepts” is arbitrary: networks could theoretically be  
2519
constructed at any level of the conceptual hierarchy (e.g.,  FOOD, CHOCOLATE, DARK CHOCOLATE). We chose to model  basic-level concepts in the present work. 
A separate set of participants was presented with one sub concept of each of the target concepts in random order (e.g.,  “chocolate chips”, “frozen banana”), and were asked to  select the properties that are true of that specific sub concept. The full list of N properties was displayed in a  multiple-choice format. For each sub-concept, responses  were combined across participants and represented in a  binary fashion. To reduce noise, a property was only  considered “true” for a sub-concept if more than one  participant made that response. At this point, each concept’s  data include a set of K sub-concepts, each of which  corresponds to a N-length vector that indicates the presence  or absence of each property. Each sub-concept is weighted  equally. We can also view these data as a set of N conceptual properties, each of which corresponds to a K length vector that indicates its presence or absence in each  of the sub-concepts. 
For each concept, we excluded properties that were not  present in any of the sub-concepts, resulting in a smaller set  of M properties. We created a network by correlating the M binary property-vectors with each other to create a M x M symmetrical, weighted correlation matrix. These networks  were filtered using the triangulation filtering method in  order to remove spurious correlations (e.g., Massara et al.,  2016). This filtering approach generates a simpler subgraph  that maximizes information content while reducing the  influence of noise, and is appropriate for graphs where  edges are defined as correlations between nodes, as is the  case here. No parameter fitting is required to apply the filter.  These final, filtered concept networks were then analyzed  using standard network science methods. 
We created two sets of randomly-selected object concepts  such that our results would not be specific to particular node  definitions or network sizes. For all analyses, we used rank based (spearman) correlations and an alpha criterion of 0.05.  
Classification Analysis Our primary goal is to extract  measures from concept networks that relate to individual  concept’s flexibility; this will only work if our networks  differ across concepts. In order to establish that this is the  case, we ran a classification analysis to confirm that our  networks could discriminate between new concept  exemplars. Exemplar data were generated from sets of  photographs for each concept; there was at least one image  for each sub-concept, though co-existing states (e.g. dark  chocolate, chocolate chips) precluded a one-to-one  mapping. AMT participants were shown one image per  concept, were presented with the full list of N properties in  multiple-choice format, and were asked to select the  properties that they believed applied to the object in the  image. Individual participants’ responses to each sub concept were represented as N-length property vectors and  were used as test data in the classification analysis. 
By performing eigendecomposition on each concept  network (i.e., adjacency matrix) we can assess the extent to  which a property vector is expected given an underlying  network structure (e.g., Medaglia et al., 2017). For each  adjacency matrix A, V is the set of NC eigenvectors, ordered  by eigenvalue. M is the number of ordered eigenvectors to  include in analysis, and designates a subset of V. For each  eigenvector v, we find the dot product with signal vector x,  which gives us the projection of x on that dimension in the  eigenspace of A. That is, it gives us an “alignment” value for  that particular signal and that particular eigenvector. We can  include all eigenvectors in M by taking the sum of squares  of the dot products for each eigenvector. The alignment  value for each signal is defined as 
� = �! ∙ � ! ! !!! , (1) 
where � is a property vector, M is the number of  eigenvectors to include in alignment (sorted by eigenvalue),  �! is one of M eigenvectors of the adjacency matrix, and � is the scalar alignment value for signal x with adjacency  matrix A, given the eigenvectors 1-M. In our case, signal x is  a property vector corresponding to a particular exemplar  image, which we align with each of the concept networks.  Each exemplar was restricted to the properties included in  each concept model before transformation; that is, exemplar  data (x) were reduced to NC–length vectors. The concept  network that resulted in the highest alignment value (�) was  taken as the “guess” of the classifier; each exemplar was  either classified correctly (1), or incorrectly (0). We  averaged these data across all exemplars to calculate the  average classifier accuracy. To calculate a baseline measure  of classification accuracy, we created traditional vector  models for each concept. For each concept, we averaged the  
K sub-concept vectors resulting in an NC -length vector  containing mean property strength values. Each concept’s  traditional vector model and network model contained the  same conceptual properties. We ran a separate classification  analysis using these traditional models and a correlational  classifier. Each exemplar property-vector was correlated  with each of the traditional concept vector models; the  concept model that resulted in the highest correlation value  was taken as the guess of the classifier. We calculated  average measures of classifier performance using the same  methods described above, and also calculated classification  accuracy within each concept. 
Network Analysis We extracted network metrics from our  concept networks using the Brain Connectivity Toolbox  (Rubinov & Sporns, 2010). The set of nodes in each  network is designated as N, and n is the number of nodes.  The set of links is L, and l is the number of links. The  existence of a link between nodes (i,j) is captured in �!":  �!" = 1 if a link is present and �!" = 0 if a link is absent.  The weight of a link is represented as �!", and is normalized  such that 0 ≤ �!" ≤ 1. �! is the sum of all weights in the  
2520
network. The network metrics we extracted included node  strength, node degree, modularity (�), core-periphery  structure, and diversity coefficients.  
Nodes within a network differ in the number and strength  of their connections to other nodes. Node degree (�) is the  number of connections that each node has with other nodes  in the network (Eq. 2; Rubinov & Sporns, 2010). In  weighted (i.e., non-binary) networks, node strength (�!) is  calculated by summing the weights of the connections with  other nodes (Eq. 3; Rubinov & Sporns, 2010). We  separately averaged node strength and node degree within  each network to obtain mean strength and degree measures  for each concept network. 
�! = �∈� �!" (2) 
�!! = �∈� �!" (3) 
Modularity (�) is a metric that describes a network’s  community structure. We can attempt to partition a  weighted network into sets of non-overlapping nodes (i.e.,  modules) such that within-module connections are  maximized and between-module connections are  minimized. Some networks exhibit more of a modular  structure than others; �! is a quantitative measure of  modularity for each weighted network (Eq. 4; Rubinov &  Sporns, 2010). 
�! = !!! �!" − !!!!!! 
!! �!! !,!∈� ,!! , (4) 
where �!!,!! = 1 if nodes i,j are in the same module (m),  �!" is the specific strength between nodes i,j, and !!!!!! 
!! 
scales �!" by the total strengths of nodes i,j across the  network. Given a network’s community structure, we can  observe how individual nodes participate with each of the  modules in the set of modules (M): Nodes may have  connections to many different modules, or have very few  such connections. The diversity coefficient (ℎ!±) is a  measure ascribed to individual nodes that reflects the  diversity of connections that each node has to modules in  the network. This is a version of the participation  coefficient, and is calculated using normalized Shannon  entropy; we have previously used entropy to model property  flexibility, and so predicted that diversity would be a good  candidate for a network-based measure of conceptual  flexibility. The diversity coefficient (Eq. 5; Rubinov &  Sporns, 2011) for each node is defined as  
ℎ!± = − ! 
!"# ! �!± 
!∈� � log �!±(�), (5) 
where �!± � = !!±(!) 
!!± , �!± � is the strength of node � 
within module �, and � is the number of modules in  modularity partition �. We averaged diversity coefficients  
across nodes in a network to obtain a mean measure of  diversity for each concept network.  
Core-periphery structure is another way to describe the  structure of a network. Here, we attempt to partition a  network into two non-overlapping sets of nodes such that  connections within one set are maximized (i.e., the “core”)  and connections in the other are minimized (i.e., the  “periphery”). Core-periphery fit (�!) is a quantitative  measure of how well each network can be partitioned in this  way (Eq. 5), and can be defined as  
�! = !!! !,!∈� �!" − �!� − � !,!∈� �!" − �!� 
� 
(5) 
where �! is the set of all nodes in the core, �!is the set of  nodes in the periphery, � is the average edge weight, �!is a  parameter controlling the size of the core, and �!is a  normalization constant (Rubinov et al., 2015).  
Methods: Set 1 
The 5 concepts used in Set 1 were CHOCOLATE, BANANA, BOTTLE, TABLE, and PAPER. 
Participants on Amazon Mechanical Turk (N=66) provided general properties for each concept along with  sub-concepts. An additional group of participants (N=198) made property judgments on specific sub-concepts, and an  additional group of participants (N=60) generated test data  for the classification analysis by making property judgments  on individual images.  
The final property list included 129 properties. The  number of sub-concepts for each concept were as follows:  chocolate=14, banana=15, bottle=11, table=14, paper=20.  
In the classification analysis, test data comprised a total of  300 property-vectors, with 60 exemplars/concept.  
Methods: Set 2 
The 10 concepts used in Set 2 were KEY, PUMPKIN, GRASS, COOKIE, PICKLE, KNIFE, PILLOW, WOOD, PHONE, and CAR. Participants on Amazon Mechanical Turk (N=60) provided general properties for each concept along with  sub-concepts. An additional group of participants (N=108) made property judgments on specific sub-concepts, and an  additional group of participants (N=30) generated test data  for the classification analysis by making property judgments  on individual images.  
The final property list included 276 properties. The  number of sub-concepts for each concept were as follows:  key=19, pumpkin=18, grass=16, cookie=22, pickle=17,  knife=15, pillow=16, wood=22, phone=16, car=20.  
In the classification analysis, test data comprised 300  property-vectors, with 30 exemplars/concept. 
Results 
Classification Results 
In order to determine whether our concept networks  contained concept-specific information, we ran a 
2521

Figure 1: Classification results for 5 concepts in Set 1  (left) and 10 concepts in Set 2 (right). Dashed line  indicates chance performance.  
classification analysis using eigendecomposition for both  Set 1 and Set 2. We ran multiple analyses using different  ranges of eigenvectors, which were sorted by eigenvalue  (positive to negative). We started by only using the first  eigenvector in each of the concept networks and determined  whether this dimension alone could be used to classify the  property vector. One dimension was enough to classify  exemplars in Set 2 (Mean Accuracy=0.27; SE=0.03;  Chance=0.10) but not Set 1 (M=0.11; SE=0.02;  Chance=0.20). Increasing the number of dimensions  improved classification performance for both sets (Fig. 1): for example, classification performance is significantly  above chance when only 10 dimensions are used in Set 1  (M=0.38; SE=0.03; Chance=0.10) and Set 2 (M=0.38;  SE=0.03; Chance=0.20). As more dimensions were included  in the analysis, classification performance approaches that  of the vector-based classifier. The increased success of the  vector-based model (Set 1: M=0.85, SE=0.03, Chance=.20;  Set 2: M=0.84, SE=0.03, Chance=0.10) suggests that the  presence or absence of individual features is highly  informative for discriminating between concepts. However,  the success of the network-based model suggests that our  concept networks do contain concept-specific information,  motivating us to look within a concept for structural  elements that relate to conceptual flexibility. It is this main  goal that we pursue in the subsequent analyses. 
Network Measures of Conceptual Structure 
Networks across the two sets differed in node assignments,  since they were constructed using different properties.  However, once classification and network measures were  extracted, we could pool the concepts together (N=15) and  examine relationships between these network-related  measures and other variables of interest. 
We extracted network measures from the concept  networks and explored how they relate to cognitive  measures of conceptual flexibility and stability. Hoffman et  al. (2013) use word co-occurrence statistics to quantify the  context-dependent variations in word meanings found in  language. The authors provide a measure of semantic  diversity (SemD) that captures this variability, and we  extracted SemD values for our 15 concepts. We also  extracted their reported mean cosine similarity of a word’s  
Figure 2: SemD predicts mean-diversity of concept  networks.  
contexts and used this as a measure of semantic stability  (which we refer to as SemS). As expected, SemD negatively  correlated with SemS across our 15 concepts (r(15)=-0.96,  p=<0.0001). 
One of our primary goals was to extract a network  measure that reflects conceptual flexibility. We used SemD  (Hoffman et al., 2013) as a benchmark for conceptual  flexibility and determined whether our hypothesized  network measures of flexibility correlated with SemD across  our 15 concepts. A priori, we hypothesized that the mean  diversity (i.e., the average of a concept network’s diversity  coefficients across nodes) could reflect conceptual  flexibility. This network measure captures the extent to  which properties within a concept associate with different  modules, or property clusters. Another possible candidate  measure was network modularity, which reflects the extent  to which a concept’s network can be partitioned into  separate property clusters. Network modularity (M=0.72,  SD=0.04) was not significantly associated with either SemD  (r(15)=0.22, p>0.4) or SemS (r(15)=-0.19, p>0.5). On the  other hand, mean diversity was positively associated with SemD (r(15)=0.56, p=0.03; Fig. 2) and negatively  associated with SemS (r(15)=-0.60, p=0.02). Mean diversity  (M=0.07, SD=0.02) was not significantly associated with  either mean node strength (r(15)=0.08, p>0.7) or mean node  degree (r(15)=0.42, p=0.12). These results suggest that the  network measure of mean diversity is a strong candidate for  a quantitative measure of conceptual flexibility. 
We also assessed the core-periphery structure for each  concept network, which determines how well a network can  be divided into a highly-connected core and a sparsely connected periphery. If the core of a concept network corresponds to the notion of a context-independent  conceptual “core”, we predicted that more stable (i.e., less  flexible) concepts would have networks with a stronger  core-periphery structure. Consistent with this prediction,  core-periphery structure (M=0.56, SD=0.08) was positively  associated with SemS (r(15)=0.54, p=0.038), though the  
2522
relationship with SemD was only marginally significant  (r(15)=-0.50, p=0.059). Furthermore, mean diversity and  core-periphery structure were negatively correlated (r(15)=- 0.61, p=0.02), suggesting that these measures may be used  to capture conceptual flexibility and stability, respectively.  We also found that core-periphery structure was positively correlated with classification accuracy using the standard  vector model (r(15)=0.56, p=0.03). This suggests that  standard cognitive models perform better on more stable  concepts, highlighting the need for a model that can  adequately capture conceptual flexibility. 
Discussion 
Here our goal was to model basic-level concepts using  graph-theoretical networks. We argue that the within concept statistics encoded in these models capture useful,  concept-specific information. Using standard network  science tools, we further reveal the usefulness of these  models by extracting formal metrics that relate to cognitive  notions of conceptual flexibility and stability. 
A model structured using within-concept statistics  provides a framework in which varied yet appropriate  instantiations of a concept may be flexibly activated. An  APPLE network may contain a strong connection between  CRUNCHY + FRESH and between SOFT + BAKED, enabling the  conceptual system to know what sets of properties should be  activated in a particular APPLE instance — for example, in  the representations evoked by “apple picking” versus “apple  pie.” The property-covariation statistics for a given concept  will determine which sets of properties tend to be co activated, and how individual properties relate to those sets  and to each other. We thus sought to use our compositional  concept network models, which contain within-concept  statistics, to extract quantitative measures of these  phenomena. We found that mean-diversity and core 
periphery structure can be interpreted as measures of  conceptual flexibility and stability, respectively: a concept  network-model’s mean-diversity positively predicts  semantic diversity (SemD; Hoffman et al., 2013), a  network-model’s core-periphery fit positively predicts  semantic stability (mean cosine similarity; Hoffman et al.,  2013), and these two network measures are negatively  related to each other across our concepts. We also found that  traditional property-vector models were better at capturing  the representation of stable versus flexible concepts,  suggesting that a different kind of conceptual model may be  necessary to capture the intrinsic flexibility of the  conceptual system. We argue that a network-based model of  basic-level concepts is one such option.  
Here we have constructed concept network models,  confirmed their ability to capture concept-specific  information, and extracted network measures that relate to  cognitive measures of conceptual flexibility and stability.  We believe the application of network science to conceptual  knowledge will provide a set of tools that will enable the  intrinsic flexibility of the conceptual system to be explored  and quantified.  
Acknowledgments 
This research was funded by an NSF Graduate Research  Fellowship awarded to S.S. and R01 DC015359-02 awarded  to S.T.S. 
References  
Barsalou, L. W. (1982). Context-independent and context dependent information in concepts. Memory &  Cognition, 10(1), 82-93. 
Bassett, D. S., & Bullmore, E. D. (2006). Small-world brain  networks. The Neuroscientist, 12(6), 512-523. 
Borgatti, S. P., & Everett, M. G. (2000). Models of  core/periphery structures. Social Networks, 21(4), 375- 395. 
Cree, G. S., McRae, K., & McNorgan, C. (1999). An  attractor model of lexical conceptual processing:  Simulating semantic priming. Cognitive Science, 23(3),  371-414. 
De Deyne, S., Navarro, D. J., Perfors, A., & Storms, G.  (2016). Structure at every scale: A semantic network  account of the similarities between unrelated  concepts. Journal of Experimental Psychology:  General, 145(9), 1228. 
Hoffman, P., Ralph, M. A. L., & Rogers, T. T. (2013).  Semantic diversity: A measure of semantic ambiguity  based on variability in the contextual usage of  words. Behavior Research Methods, 45(3), 718-730. 
Massara, G. P., Di Matteo, T., & Aste, T. (2016). Network  filtering for big data: triangulated maximally filtered  graph. Journal of Complex Networks, 5(2), 161-178. 
McRae, K., De Sa, V. R., & Seidenberg, M. S. (1997). On  the nature and scope of featural representations of word  meaning. Journal of Experimental Psychology:  General, 126(2), 99. 
Medaglia, J. D., Huang, W., Karuza, E. A., Kelkar, A.,  Thompson-Schill, S. L., Ribeiro, A., & Bassett, D. S.  (2017). Functional alignment with anatomical networks is  associated with cognitive flexibility. Nature Human  Behaviour, 2(2), 156. 
Rubinov, M., & Sporns, O. (2010). Complex network  measures of brain connectivity: uses and  interpretations. Neuroimage, 52(3), 1059-1069. 
Rubinov, M., & Sporns, O. (2011). Weight-conserving  characterization of complex functional brain  networks. Neuroimage, 56(4), 2068-2079. 
Rubinov, M., Ypma, R. J., Watson, C., & Bullmore, E. T.  (2015). Wiring cost and topological participation of the  mouse brain connectome. Proceedings of the National  Academy of Sciences, 112(32), 10032-10037. 
Steyvers, M., & Tenenbaum, J. B. (2005). The Large-scale  structure of semantic networks: Statistical analyses and a  model of semantic growth. Cognitive science, 29(1), 41- 78. 
Tyler, L. K., & Moss, H. E. (2001). Towards a distributed  account of conceptual knowledge. Trends in Cognitive  Sciences, 5(6), 244-252. 
2523
Causal Learning from Trending Time-Series 
Kevin W. Soo (kevin.soo@pitt.edu) 
Benjamin M. Rottman (rottman@pitt.edu) Department of Psychology, University of Pittsburgh 3939 O’Hara Street, Pittsburgh, PA 15260 USA 
Abstract 
Two studies investigated how people learn the strength of the  relation between a cause and an effect in a time series setting  in which both variables exhibit temporal trends. In prior  research, we found that people control for temporal trends by  focusing on transitions, how variables change from one  observation to the next in a trial-by-trial presentation (Soo &  Rottman, 2018). In Experiment 1, we replicated this effect,  and found further evidence that people rely on transitions  when there are extremely strong temporal trends. In  Experiment 2, we investigated how people infer causal  relations from time series data when presented as time series  graphs. Though people were often able to control for the  temporal trends, they had difficulty primarily when the cause  and effect exhibited trends in opposite directions and there  was a positive causal relationship. These findings shed light  on when people can and can’t accurately learn causal relations  in time-series settings. 
Keywords: causal learning, temporal trend, time-series 
Introduction 
Much real-world causal induction involves learning about  relationships between causes and their effects as they unfold  over time. This can be a complex task because variables  may undergo temporal trends that obscure the underlying  causal relationships (Yule, 1926). For example, a patient  may experience increasing pain from a chronic disease over  several months and take increasing amounts of pain  medication to cope (a positive correlation), even though the  medicine reduces pain on shorter timescales.  
Recently, there have been a couple studies focusing on  how people learn causal relations from time-series data that  exhibit trends (Rottman, 2016; Soo & Rottman, 2018;  White, 2015). In the present research, we investigated how  people learn the strength of causal relationships when the  cause and effect are continuous-valued, and exhibit strong  trends over time. We evaluated if people are able to make  correct causal inferences despite the trends, and what factors  affect their ability to make accurate causal inferences. 
Learning Causal Strength from Time-Series The problem of causal learning from time-series data is  that when a cause (X) and an effect (Y) exhibit trends over  time, time is a confound. Due to the confound, the simple  correlation of the absolute states of X and Y, cor(X, Y),  often fails to capture the true causal strength. We refer to  this model of causal strength induction from states, cor(X,  Y), as rStates. 
Soo and Rottman (2018) proposed another model of  how people estimate causal strength from time series data,  
which is called rTransitions. rTransitions estimates causal strength  by taking the correlation of the changes in X and the  changes in Y, cor(∆X, ∆Y). ∆ refers to the first order  difference score, the change in a variable from one  observation to the next.1 
Unlike rStates, we have argued that rTransitions uncovers the  true causal influence of X on Y when a linear temporal  confound is present. Soo and Rottman (2018; Appendix A)  provide proofs and simulations demonstrating how rTransitions 
partials out linear temporal trends in the variables. This is  the same reason that time series analysts use difference  scores to control for non-stationarity (Shumway & Stoffer,  2011). For this reason, we say that using rTransitions helps  people accurately estimate causal strengths. 
Soo and Rottman (2018) demonstrated that when  assessing the influence of a cause on an effect from time  series data, peoples’ judgments are sensitive to both rStates and rTransitions, though they are more sensitive to rTransitions,  meaning that on the whole people tend to correctly infer  causal strength despite temporal trends. (We regard these  inferences as “correct” because we have previously argued  that rTransitions actually uncovers the true causal strength when  there are linear temporal trends.) 
Rottman and Soo (2018) presented participants with  observations of a cause and effect. All stimuli had rStates =  .70 or -.70. The datasets were reordered to create versions  with all positive transitions (from one observation to the  next, X and Y changed in the same direction, producing a  strongly positive rTransitions), or all negative transitions (X and  Y changed in opposite directions, creating a strongly  negative rTransitions), or the trials were randomized, producing  a mix of transitions. (The first three columns of Figure 1  display the different orderings of the 20 data points.) The  data were presented to participants in a trial-by-trial fashion  with X and Y represented using vertical gauges (Figure 2).  Although participants’ estimates of causal strength were  influenced by both transitions (rTransitions) and states (rStates),  the effect of transitions was considerably stronger.  
Rottman and Soo (2018) also investigated two different  versions of rTransitions. One captured the magnitude of the  change, and another captured only the direction of the  change (∆X and ∆Y are encoded as +1 for increases and -1  for decreases). 
 
1This model assumes that the influence of X on Y occurs  without a delay; the model associates the change in X from Time 1  to 2 with the change in Y from Time 1 to 2. These studies did not  investigate situations in which the change in X produces a change  in Y at a later time, which we leave for future research. 
2524
Negative transitions Random Positive transitions Monotonic trend 


	

	

	

	

	

	

	r
	

	

	Transitions
	 
	= -1
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	

	

	Transitions
	 
	

	= .60
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	

	

	Transitions
	 
	= 1 
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	

	

	Transitions
	 
	= 0
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	Y
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	Y
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	Y
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	X
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	X
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	X
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	

	

	Transitions
	 
	= -1
	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	Transitions
	

	

	 
	

	

	= -.60 
	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	

	

	Transitions
	 
	= 1
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	r
	

	

	Transitions
	 
	= 0
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	Y
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	Y
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	Y
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	X
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	X
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	X
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	



100 
X
80 
r
S
Y
t
a
t
e
s
60 
 
p
=
o
 
s 
.
7
0 
40 
20 
0 
100 
X
80 
r
S
t
a
t
e
60 
s
 
n
=
e
 
g 
-
.
7
40 
0 
Y
20 
0 
0 5 10 15 20 0 5 10 15 20 0 5 10 15 20 0 5 10 15 20 Time 
Figure 1: Time-series graphs of an example dataset used in Experiment 1, and Experiment 2 (without the monotonic trend condition).  All datasets within the top row, and within the bottom row, have the exact same 20 states, but different orderings. 
Though the two models are often highly correlated, we  found that only the version that captured the direction of the  changes explained unique variance in participants’  judgments. Thus, in the current studies we only focus on  this simpler version of rTransitions. 
What Happens with Extremely Strong Trends? In Experiment 1, we sought to further test the theory that  people focus on transitions for causal learning with time  series data. In particular, we examined situations in which  one variable exhibits an extremely strong monotonic trend  such that from one trial to the next, it always increases (or  always decreases) across time. We used the same datasets  from prior studies, but sorted them by X or Y, such that one  of those variables always increased or decreased. One motivation for studying this case is theoretical. As  explained below, the rTransitions model predicts a causal  strength of zero despite there being very strong rStates predictions, which further helps to discriminate these two  models. Furthermore, the case of monotonic trends can be  investigated using the same datasets from prior studies by  reordering the trials, allowing us to hold rStates constant. Another motivation is revealed upon looking at the  “monotonic trend” condition in Figure 1; it is a situation in  which one variable exhibits a smooth monotonic trend and  the other exhibits a noisy but roughly linear trend. Given  that smooth processes exist in the real world, we thought  this was an interesting time series case to study. The rightmost column in Figure 1 shows the new  monotonic trend condition with a monotonic trend in X.  Consider the top-right panel in Figure 1. Both X and Y  increase over time and the correlation between the two is  
quite strong (rStates = .70). However, just because two  variables increase together does not mean that one causes  the other; it could be that they are both just exhibiting  trends. In contrast, consider the positive transitions  condition in which rStates = .70. In that graph, both X and Y  increase overall. Additionally, within a shorter timescale,  increases in X are accompanied by increases in Y, and vice  versa. This pattern provides strong evidence for a positive  causal relation.  
Based on the rTransitions model, the monotonic trend  condition does not provide evidence for a causal relation. If  X always increases from one observation to the next, there  is no variance in ∆X (i.e. all the ∆X scores are +1), so  cor(∆X, ∆Y) cannot be computed. For this reason, we  treated the prediction of rTransitions as zero in the trend  condition.2 We predicted that their causal strength  judgments would be close to zero because the variable exhibiting the monotonic trend does not exhibit much  variance after accounting for the trend. Experiment 1  investigated whether participants would give causal strength  judgments close to zero in the monotonic trend condition, or  whether their judgments would be influenced by the strong  correlation of the absolute states (rStates = .70 or -.70).  
 
2 For the version of rTransitions in which the magnitude of change  scores are encoded, not just the direction, the value of cor(∆X, ∆Y)  is close to zero for all the datasets in this study, so the predictions  are essentially the same for both versions of rTransitions. 
2525
Figure 2: Visual presentation of stimuli in Experiment 1 and  in the “trial-by-trial gauges” condition in Experiment 2. 
Presentation Format Moderates Use of Transitions 
How can time-series data be presented to people to optimize  their causal inferences? In our previous research, we found  that people were able to make fairly accurate judgments  from a trial-by-trial presentation that involved two gauges  representing the magnitude of the cause and the effect  (Figure 2). Peoples’ ability to infer causal relations fairly  well in a trial-by-trial format is good news because it  mimics how we often experience events in our daily lives.  
We further demonstrated that people are much better in a  naturalistic format (in which the gauge level represents  magnitude) than when presented with trial-by-trial numbers  representing magnitude, presumably because transitions are  more salient when presented naturalistically. 
However, lay people also often need to reason about data  presented graphically, such as economic data in news  reports (Fox & Hendler, 2011), and time-series graphs are  the standard visualization for such data (Friendly, 2006;  Javed, McDonnel, & Elmqvist, 2010). Experiment 2  investigated how well people infer causal relations  controlling for temporal trends from time-series graphs. 
We predicted that observing the data in a time-series  graph would decrease the salience of transitions relative to  the trial-by-trial presentation, making it harder for people to  accurately infer causal relations. Instead, they might focus  on the correlation between the absolute states of X and Y. 
In Experiment 2, we compared causal judgments from  participants observing stimuli presented in a trial-by-trial  visual format (Figure 2) vs. a static time-series graph format  (Figure 1). In addition, we created an intermediate format  which involved a times-series graph, but instead of  participants viewing the entire graph at once, the 20  observations were revealed sequentially. We hypothesized  that revealing the data sequentially could make the  transitions more salient, thereby leading to more accurate  judgments than the static graph format. 
Experiment 1 
Experiment 1 tested whether learners used transitions in  addition to states to estimate the causal strength between a  cause (X) and an effect (Y) in a time-series setting. We used  datasets in which the states were held constant, but the order  of observations was manipulated to produce varied patterns  of transitions (Figure 1). We predicted that participants’  
causal strength judgments would be strongest for datasets  with all positive or negative transitions, followed by  datasets with random orderings, and would be weakest for  datasets with a monotonic trend in either the cause or effect  because the rTransitions value was zero. 
Method 
Subjects 50 participants were recruited on MTurk and were  paid $1.40. The experiment lasted between 7-10 minutes.  Design and stimuli Each learning dataset had 20  observations of X and Y, and each variable could take on  values between 0 and 100. The design was a 2 (positive vs.  negative rStates) × 5 (negative transitions, random order,  positive transitions, monotonic trend in X, or a monotonic  trend in Y) within-subjects design (see Figure 1). 
The datasets were created in the following way. Using the  corgen function from the R package ecodist, we generated  20 datasets with rStates = .70. Copies of each dataset with  rStates = -.70 were made by flipping the values of X around  the midpoint of the scale (X = 50). For the random order  conditions, these datasets were presented with the trials in a  random order. In the positive states random order condition  most of the transitions were positive (Mean rTransitions = .59,  SD = .12), but in the negative states random order transition  most of the transitions were negative (Mean rTransitions = -.59,  SD = .12). This is because with random trial orders, rStates and rTransitions are correlated. 
The 20 trials of these datasets were reordered to produce the other four conditions. In the positive transitions  conditions, the trials were reordered so that increases in X  were always accompanied by increases in Y (rTransitions = 1).  In the negative transitions conditions, X and Y always  changed in opposite directions (rTransitions = -1). Finally, the  conditions with monotonic trends in X or Y were ordered  such that either X or Y always increased or decreased across  the 20 trials; all these datasets had rTransitions = 0. (Datasets  that had repeated values of X or Y (e.g., X was exactly 56  on two trials) were slightly modified (e.g., one trial was  changed to 58) so that the trials could be ordered to increase  monotonically, and this change in the dataset was made to  all the conditions).  
Lastly, the observation order was counterbalanced to be  presented forwards or in reverse (i.e. from 1-20 or 20-1 in  Figure 1) randomly for each scenario a participant viewed. Procedure Participants evaluated how the dosage of a drug  (X) influenced the size of a microorganism (Y) over 20  observations (“days”). On each new day, participants  clicked on a button to view a new drug dosage that was  injected and the microorganism’s resulting size. X and Y  were displayed using gauges (Figure 2). After clicking the  button on each day, the button was disabled for two seconds  before the participant was allowed to advance.  
After 20 days, the gauges disappeared and participants  judged the causal strength of the drug on a scale from 8  (“high levels of the drug strongly cause the microorganism  to increase in size”) to -8 (“high levels of the drug strongly  
2526