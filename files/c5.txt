Figure 1: Distributions used in Goldstein and Rothschild (2014). 
n 
o
i
t
u
b
i
r
t
s
i
D
 
d
e
v
i
e
c
r
e
P
 
e
h
t
 
f
o
 
e
c
n
a
i
r
a
V
13 


	●
	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	

	



12 
11 
10 
9 
8 
7 
6 
5 
● 
4 
3 
2 
1 
● 
0 
1.9 2.4 2.6 8.3 Variance of Sampled Distribution 
fall into the following categories?”. ‘Social contacts’ were defined as “all adults you were in personal, face-to-face con tact with at least twice this year.” (quoted from the codebook of the second wave of the study). 
The authors were interested in how social sampling im pacts beliefs about population characteristics. In their anal yses, they assumed that available samples of the population were made of their social circles. Here, we rely on the same assumption. 
We focus on one specific aspect of the social circle and perceived population distributions: their variance. For each of the ten characteristics, we regressed the variance of the perceived population distribution on the variance of the so cial circle distribution. The slope coefficient is significantly positive for all ten characteristics. It is also positive in a re 
Figure 2: Analysis of the Goldstein and Rothschild (2014) data: Box plot of the impact of the higher variance of the sampled distribution on the variance of the perceived distri bution. 
Longitudinal Internet Studies for the Social Sciences (LISS) data 
We analyzed data from the Longitudinal Internet Studies for the Social Sciences (LISS) panel. These data are from a representative sample of the Dutch population and were col lected by CentERdata in collaboration with Galesic, Olsson, and Rieskamp (2012). The project explored the relationship between the social circles of the respondents (the individuals with whom they interact most frequently) and their percep tions of the national population as a whole. In this study, the authors asked respondents about ten characteristics related to their financial situation, friendships, health, work stress and education. The respondents reported their beliefs about the distribution of these characteristics on a 7-point scale. They were also asked to estimate the distribution in the general population of the Netherlands with questions such as “What percentage of adults living in The Netherlands fall into the following categories”. In a second wave, participants were asked to provide the distribution in their social circle with questions such as “What percentage of your social contacts 
gression that pools the data about all ten characteristics and includes characteristic fixed effects (coefficient = 0.15, see Table 1). It is worth noting that the coefficients are somewhat far from 1. This indicates that the distribution in the social circle is not the only factor affecting the perceived population distribution. This is not surprising because it is unrealistic to expect that people’s only source of information about the population is their social circles. People interact with many others who are not part of their immediate social circles, read and watch about others in the media, etc. Yet, these results provide a clear indication that the variance of the sampled distribution affects the variance of the perceived population distribution. 
Understimation of True Variability In a recent paper, Konovalova and Le Mens (2017) demonstrated that for a number of measures of variability, sample variability (VS) is more likely to be below the true variability than above the true variability (VR): P(VS < VR) > P(VS > VR). This prediction holds in particular for the case where the measure of variabil ity is sample variance. We tested this prediction using the LISS panel data. For each characteristic, respondents were asked to indicate their position on the seven-level scale. This allowed us to construct the true population distribution. The data were collected in two waves. In each wave, participants indicated their position in the distribution. The results dis 
1947
Table 1: Columns 1-2: Results of the regression analysis for the variance of the perceived distribution in LISS data. DV: Variance of the perceived population distribution (VP); IV: Variance of the social circle (VS). The results are shown for each domain (estimated constants are omitted) and for the whole panel with characteristic fixed effects. ∗∗∗ : p < 0.01,∗∗ : p < 0.05,∗: p < 0.1. Standard errors are in the paren theses. Columns 4-5: comparison between the variance of the perceived population distribution (VP), the variance of the social circle distribution (VS) and the variance of the real pop ulation distribution (VR) in LISS Panel Data. 
VS 
	N 
	P(VP < VR) 
	0.10*** 
(0.02) 
	1,407 
(0.04)
	.87 
	0.12*** (0.02) 
	1,408 (0.03)
	.52 
	0.13*** (0.03) 
	1,407 (0.02)
	.72 
	0.12*** (0.03) 
	1,404 (0.03)
	.70 
	.16*** 
(0.02) 
	1,408 
(0.03)
	.67 
	0.16*** (0.03) 
	1,410 (0.02)
	.26 
	0.19*** (0.04) 
	1,409 (0.02)
	.72 
	0.21*** (0.03) 
	1,299 (0.03)
	.78 
	0.13*** 
(0.04) 
	1,087 
(0.03)
	.33 
	0.18*** 
(0.10) 
	277 
(0.06)
	.20 
	0.15*** (0.01) 
	12,516 - 
	.61 - 
	



Characteristic P(VS < VR) Amount .96 of Stress 
Personal .90 Income 
Household .94 Income 
Wealth .94 
Number of .93 Friends 
Level of .87 Education 
Number of .92 Problems 
Number of .93 Meetings 
Number of .88 Conflicts 
Number of .74 Dates 
Pooled data .92- 
cussed in the text are based on a real distribution constructed from the responses of participants about their position col lected in the first wave. The results are essentially the same for the distribution based on the second wave responses. 2 
Table 1 reports the proportion of respondents for which the social circle distribution had a variance lower than the vari ance of the true population distribution (see column P(VS < VR)). This was higher than 50% for all ten characteristics, as well as for the pooled data. A similar pattern was found re garding the proportion of respondents for which the perceived population distribution had a variance lower than the variance of the true population distribution (see column P(VP < VR)). This was higher than 50% for most characteristics. In the pooled data, the proportion of underestimation is 0.61. In summary, there is a general tendency for perceived variabil 
2There is a bit of irony in calling the ‘true population distribu tion’ a distribution constructed on the basis of a sample of smaller size than the true population (the population of the Netherlands). But because this sample is large, (about 1,400 people), its sample variance is very likely to be almost identical to the population vari ance. 
ity to be lower to true variability, although the asymmetry is not as strong as for the sampled variability. 
Sample Size and Perceived Variability 
Konovalova and Le Mens (2017) also demonstrated that the underestimation tendency discussed at the end of the previous section systematically varies with sample size: It is strong when the sample size is small and milder when sample size increases. We formalize this in the following prediction: the probability that sample variability is smaller than true vari ability is higher than chance and goes down with sample size. Moreover, if, as we showed in the previous section, sample variability systematically affects perceived variability, then we should observe a similar tendency for perceived variabil ity. 
Existing Evidence 
Existing evidence bearing on this prediction is limited. Ac cording to our literature search, the only published study that provides a direct test of this prediction is Experiment 2 in Kareev et al. (2002). Participants saw two populations of equal variance (this was unknown to the participants) then they were asked to indicate which of the two was the less variable. The stimuli were the same as in their Experiment 1 (discussed in an earlier section). Participants were asked to judge which of the two populations was more variable (on a unique dimension). Unbeknown to the participants, the two populations had the same distribution. They saw a sample from each population. For one population, participants saw the whole population (28 items). We call it the ‘large sample population’. For the other, they draw a random sample of 7 items. We call it the ‘small sample population.’ The major ity of participants indicated the small sample population as the less variable. Participants also completed an incentivized task where the optimal choice was to select the less variable population (they were told that two items will be drawn from the selected population and that they would receive a bonus if they were close enough). Again, the majority of participants selected the small sample population. Overall, these results indicate that the participants perceived the small sample pop ulation as less variable than the large sample population. 
Although this study provides evidence that the perceived variability of a distribution increases with sample size, an alternative explanation is possible. Without the information about the actual sample variability observed by the partici pants, it is not possible to rule out the hypothesis that the peo ple perceive a large sample population as more variable even if the observed sample was not more variable. To address this limitation, we ran a new experiment. 
Experiment 
Design. Our design is inspired by features of the experi ment in Goldstein and Rothschild (2014) and of Experiment 2 in Kareev et al. (2002). The flow of the experiment was as follows. After providing consent, participants received the 
1948
Table 2: Proportion of participants who indicated the large sample bag as the more variable. 95% Confidence intervals are in the brackets. 
All 
Observations 
	Conditional on 
Large Sample Bag Variance: VL > VS 
	Conditional on 
Large Sample Bag Variance: VL < VS 
	.61 [.55, .67] 
.70 [.65, .75] .53 
[.48, .59] 
	.68 [.61, .75] 
.79 [.72, .85] .64 
[.56, .71] 
	.52 [.43 .60] 
.58 [.49, .67] .40 
[.32, .49] 
	303 
	173 
	130 
	



Question Difference in Proportions 
Q1 .17 [.05, .28] 
Q2 .21 [.10, .32] 
Q3 .24 [.12, .35] 
# part. – 
following general instructions: “Imagine we have two ex tremely large bags: one with RED ping pong balls and one with BLUE ping pong balls. Each ball (both red and blue) has a value between 1 and 10 written on it. During the ex periment, you will observe balls first from one bag and then from another. In the end, you will have to judge which bag has the larger variety of numbers on the balls.” Then, par ticipants observed a random sample from one bag and in the following block a random sample from the other bag. The sample sizes were 5 and 50. The pairing of the color and the sample size was randomized as well as the order in which the two samples were presented. The samples were drawn from the same distribution. We used a symmetrical distribu tion which ranged from 2 to 9 with the following frequen cies: [0.01,0.06,0.17,0.26,0.26,0.17,0.06,0.01]. This dis tribution is a re-scaled and discretized beta distribution with parameters α = β = 5. 
Each participant observed a unique random sequence from the distribution. Before each sample, the participants saw a fixation cross for 450 milliseconds. Then digits appeared on the screen in quick succession (each digit remained on the screen for 600 milliseconds). 
After participants observed the samples from the two bags, they answered three questions pertaining the perceived vari abilities of the two bags. 
• Q1: This question was incentivized. Participants were told: “Suppose you select two balls from one of the two bags. Let us call A and B the numbers on the balls. Let D be the difference between these two numbers. You will get a bonus of D points. That is, the larger the difference be tween the two numbers, the higher your bonus (the bonus cannot be negative).” At the end of the experiment, two balls were randomly drawn from the chosen bag and par ticipants were paid a bonus proportional to D. The goal was thus to select the bag with the higher variability. 
• Q2: Participants were presented with a continuous slider where they indicated which bag had the larger “variety of numbers on the balls”. The minimal value of the slider was −100 (e.g., ‘The Red bag has more variety’). The maximal value was 100 (e.g.,‘The Blue bag has more variety’) and had a midpoint at 0 (e.g.,‘The Red and Blue bags have the 
same variety’). (The colors at the end of the scales were randomized and the numeric values were not shown to the participants). 
• Q3: Participants were asked to imagine they would pick two balls from each of the two bags. Then they were asked to indicate the bag for which they predicted the two num bers to be closer to each other. 
Participants. We recruited 303 participants using Amazon Mechanical Turk. Participants received a fixed payment for their time and a bonus based on their responses to Q1. 
Predictions. Manipulation check: We anticipated that for most participants the sample variability (variance) of the large sample bag (VcL) would be larger than the sample variability of the small sample bag (VcS): P(VcL > VcS) > .5. Prediction about perceived variability: Most participants will select the large sample bag as the more variable bag. Prediction about the effect of sample variability: The proportion of participants choosing the large sample bag will be higher when the large sample bag has the higher variability than when it has the lower variability. 
Results. The results are consistent with our prediction. We report our analyses by using the corrected sample variance as the estimator of sample variability. 
Manipulation check: For 57% of the participants, the sam ple variance of the large sample bag VcL was larger than the corrected sample variance of the small sample bag VcS: P(VcL > VcS) = .57,95%CI = [.51,.63]. 
Sample size and perceived variability: Most participants perceived the large sample bag as more variable than the small sample bag. For Q1, 61% of the participants chose the bag of which they observed a larger sample. This pro portion is significantly above 50% (95%CI = [.55,.67]). For Q2, 70% of the participants selected a response on the scale that indicated that the large sample bag had “more vari ety” (95%CI = [.65,.75]). The mean response was 33.33 (95%CI = [26.5,40.2]). This is significantly higher than the mid-point of 0. For Q3, 53% of the participants indicated that 
1949
balls from the bag of which they observed a smaller sample were closer to each other. This proportion is only marginally significantly different from 50% (95%CI = [.48,.59], p = .13). 
Sample variability and perceived variability: We com puted the proportion of participants who chose the large sam ple bag as the more variable when its sample variance was larger. For Q1 it is .68 (95%CI = [.61,.75],n = 173). The cor responding proportion conditional on the larger bag having the lower sample variance is .52 (95%CI = [.43,.6],n = 130). The difference in proportions is significantly higher than 0: d = .17,95%CI = [.05,.28]. Similar results hold for Q2 and Q3 (see Table 2). 
Summary Most participants perceived the large sample op tion as more variable than the small sample option even though the samples were generated from the same underly ing distribution. Sample size had a positive effect on sam ple variability and the difference in sample variabilities had a positive effect on the difference in perceived variabilities. The tendency to perceive the large sample option as the more variable is thus at least partly explained by the difference in sample variabilities. 
Discussion & Conclusion 
Existing research acknowledges the importance of sample variance and size but implicitly assumes that the mapping between the sample and its mental representation is perfect (Osherson, Smith, Wilkie, Lopez, & Shafir, 1990; Konoval ova & Le Mens, 2017). In this paper, we tested this assump tion and provided direct (from experimental data) and indi rect (from the analysis of survey data from a nationally rep resentative panel of respondents) evidence of the relationship between sample variance and perceived variability. Addition ally, our analysis shows that people’s sample and perceived variance tends to underestimate the real variability. We also provided direct evidence that sample size has a positive effect on perceived variability and that this relation is at least partly mediated by sample variance. 
We assumed that variance (sample variance or variance of the perceived distribution) is a psychologically relevant mea sure of variability. Our experiment provides suggestive ev idence it is the case in at least some settings. Yet, exist ing research has shown that other measures of variability are sometimes more relevant. For example, Weber et al. (2004) convincingly argued that in risky choice situations, the co efficient of variation (CV) is a better measure of perceived variability than variance. Uncovering under what task envi ronment sample variance, the coefficient of variation or other estimators of variability are the most relevant psychological constructs is an interesting avenue for future research. 
Acknowledgements 
Le Mens benefited from financial support from Spanish MINECO Grants PSI2013-41909-P and #AEI/FEDER UE 
PSI2016-75353, a Ramon y Cajal Fellowship (RYC-2014- 15035), and a Grant IN[15]_EFG_ECO_2281 from the Fundacion BBVA. E. Konovalova was funded by Spanish MINECO Grant PSI2013-41909-P to G. Le Mens. 
References 
Beach, L. R., & Scopp, T. S. (1968). Intuitive statistical inferences about variances. Organizational Behavior and Human Performance, 3(2), 109–123. 
Busemeyer, J. R., & Myung, I. J. (1992). An adaptive ap proach to human decision making: Learning theory, deci sion theory, and human performance. Journal of Experi mental Psychology: General, 121(2), 177. 
Denrell, J. (2005). Why most people disapprove of me: ex perience sampling in impression formation. Psychological review, 112(4), 951. 
Galesic, M., Olsson, H., & Rieskamp, J. (2012). Social sam pling explains apparent biases in judgments of social envi ronments. Psychological Science, 0956797612445313. 
Goldstein, D. G., & Rothschild, D. (2014). Lay understand ing of probability distributions. Judgment and Decision Making, 9(1), 1. 
Hamilos, C. A., & Pitz, G. F. (1977). The encoding and recognition of probabilistic information in a decision task. Organizational Behavior and Human Performance, 20(2), 184–202. 
Hertwig, R., Barron, G., Weber, E. U., & Erev, I. (2004). Decisions from experience and the effect of rare events in risky choice. Psychological science, 15(8), 534–539. 
Hogarth, R. M., & Einhorn, H. J. (1992). Order effects in belief updating: The belief-adjustment model. Cognitive psychology, 24(1), 1–55. 
Kareev, Y., Arnon, S., & Horwitz-Zeliger, R. (2002). On the misperception of variability. Journal of Experimental Psychology: General, 131(2), 287. 
Konovalova, E., & Le Mens, G. (2017). Selective information sampling and the in-group heterogeneity effect. Proceed ings of the 39th annual conference of the Cognitive Science Society, 39. 
Le Mens, G., Kareev, Y., & Avrahami, J. (2016). The eval uative advantage of novel alternatives: An information sampling account. Psychological science, 27(2), 161–168. 
Osherson, D. N., Smith, E. E., Wilkie, O., Lopez, A., & Shafir, E. (1990). Category-based induction. Psychological review, 97(2), 185. 
Tversky, A., & Kahneman, D. (1992). Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and uncertainty, 5(4), 297–323. 
Von Neumann, J., & Morgenstern, O. (2007). Theory of games and economic behavior. Princeton university press. Weber, E. U., Shafir, S., & Blais, A.-R. (2004). Predict ing risk sensitivity in humans and lower animals: risk as variance or coefficient of variation. Psychological review, 111(2), 430. 
1950
How people detect incomplete explanations 
Joanna Korman and Sangeet Khemlani 
{joanna.korman.ctr, sangeet.khemlani}@nrl.navy.mil Navy Center for Applied Research in Artificial Intelligence US Naval Research Laboratory, Washington, DC 20375 USA 
Abstract 
In theory, there exists no bound to a causal explanation – every  explanation can be elaborated further. But reasoners rate some  explanations as more complete than others. To account for this  behavior, we developed a novel theory of the detection of  explanatory incompleteness. The theory is based on the idea  that reasoners construct mental models of causal explanations.  By default, each causal relation refers to a single mental model.  Reasoners should consider an explanation complete when they  can construct a single mental model, but incomplete when they  must consider multiple models. Reasoners should thus rate  causal chains, e.g., A causes B and B causes C, as more  complete than “common cause” explanations (e.g., A causes B  and A causes C) or “common effect” explanations (e.g., A  causes C and B causes C). Two experiments validate the  theory's prediction. The data suggest that reasoners construct  mental models when generating explanations. 
Keywords: explanatory reasoning, incompleteness, causal  reasoning, mental models 
Introduction 
Suppose that you begin to sneeze on a hike through the  woods. Here is one explanation for your experience: 
1a. Being outside caused you to breathe in pollen.  b. Breathing in pollen caused sneezing. 
On the one hand, the explanation may seem complete. On the  other hand, every explanation can be elaborated further:  assiduous readers may wonder what caused you to be outside  in the first place. Their curiosity suggests that reasoners carry  out a process to detect whether an explanation is incomplete.  No theory of causal reasoning exists that accounts for the  process, and so the present paper proposes a novel theory of  how reasoners assess explanatory completeness. 
Some philosophers of science hold that the notion of a  “complete” explanation is nonsensical. Hempel, for instance,  observed that an explanation can be judged complete “only if  an explanatory account…had been provided for all of its  aspects”, but that the notion of completeness was “self 
defeating” because any explanation can have “infinitely  many aspects” (Hempel, 1965/2002). And other theorists  concur: for instance, Rescher argued that “the finitude of  human intellect” demands that we do not equate the adequacy  of an explanation with how complete it is (Rescher, 1995, p.  8; see also Josephson, 2000; Railton, 1981, p. 239). 
However, while explanatory completeness may be an  intractable notion in the abstract, the finitude of human  intellect does not prevent reasoners in daily life from judging  whether some explanations are more complete than others.  Pioneering work by Miyake (1986) showed that when people  
explain a particular phenomenon (e.g., how a sewing machine  works), they often vacillate between feeling, on the one hand,  that their understanding of the phenomenon is satisfactory  and complete, and on the other, that their understanding is in  need of elaboration. Moreover, Miyake’s investigations  demonstrated that when constructing explanations, there  comes a point at which no further elaboration is possible,  either because the relevant information is uncertain or  unavailable, or because reasoners may fail to recognize what  they do not know. As Keil (2006) observes, the  overwhelming complexity of the world puts highly detailed  explanations of phenomena beyond the reach of individuals,  and so people have no choice but to get by with incomplete,  partial explanations. More recently, when Zemla and  colleagues (2017) asked participants to evaluate natural  explanations, they found that assessments of an explanation’s  incompleteness predicted judgments of the explanation’s  quality – the more incomplete an explanation was judged, the  worse it was perceived (r = -.65). But, as Zemla et al.’s  analysis suggests, explanatory completeness and quality can  diverge: it may be possible to generate explanations that are  complete but of poor quality. Likewise, it is routine in  scientific investigation to generate convincing but tentative  explanations, i.e., those that explain available facts but whose  internal mechanisms leave relevant causal relations  unspecified. Contemporary astronomers, for instance, posit  the existence of an as-yet-unobserved ninth planet to explain  why the Solar System wobbles away from its center (Batygin  & Brown, 2016). Such an explanation is “good” insofar as it  accounts for many different observations, but it is incomplete  without an articulation of what the planet is made of and how  it affects its nearest celestial bodies. Hence, assessments of  completeness can diverge from assessments of quality: an  explanation’s quality depends on corroboratory evidence,  while an explanation’s completeness depends on identifying  and connecting relevant causal relations. 
Detecting incompleteness with mental models Detecting explanatory completeness is an online process  that requires reasoners to mentally represent an explanation  and assess its structure for potentially unspecified causal  relations. In what follows, we present a novel theory that  accounts for the mental representations reasoners use to  assess some explanations as relatively more complete than  others. The theory is based on the idea that humans build  small-scale mental simulations – mental models – when they  reason. Its central prediction is that reasoners should  systematically distinguish complete from incomplete  
1951
explanations when they are unable to build an integrated  explanatory mental model.  
The mental model theory – the “model” theory, for short – posits that people reason on the basis of small, discrete mental  representations of possibilities. The theory applies to  reasoning in a variety of domains, including explanatory  reasoning (Johnson-Laird, Girotto, & Legrenzi, 2004;  Khemlani & Johnson-Laird, 2011, 2012), and reasoning  about causal, spatiotemporal, and abstract relations  (Goldvarg & Johnson-Laird, 2001; Goodwin & Johnson 
Laird, 2005). The theory makes three central claims: first,  mental models are representations of a conjunction of iconic  possibilities (Khemlani, Byrne, & Johnson-Laird, in press).  Iconicity implies that the structure of a model corresponds to  the structure of what it represents (see Peirce, 1931-1958,  Vol. 4). But models can also include abstract symbols, e.g.,  the symbol for negation (Khemlani, Orenes, & Johnson Laird, 2012). Second, reasoners distinguish mental models – 
which are initial, incomplete representations that represent  only what is true of a given description – from fully-explicit  models that represent both what is true while keeping track of  what is false in a given description. The theory posits two  primary processes of inference: the first, an intuitive  construction process, rapidly builds and scans initial mental  models, but it is subject to various heuristics and biases. The  second, a slower, deliberative process, revises the initial  models into fully-explicit models, and it can eliminate  systematic errors in reasoning (see, e.g., Khemlani &  Johnson-Laird, 2017). A third assumption of the theory is that  reasoners tend to be parsimonious: the more models that are  required to solve a problem, the harder that problem will be,  and most reasoners spontaneously draw conclusions based on  a single mental model. 
The model theory explains how reasoners represent and  make inferences from causal relations (Johnson-Laird &  Khemlani, 2017; Khemlani, Barbey, & Johnson-Laird,  2014), which underlie causal explanations. It posits that  people understand a causal relation as a set of possibilities.  For instance, the full meaning of a causal relation with an  unknown outcome, such as “going outside causes X”, refers  to a conjunction of three separate models of possibilities,  depicted in this schematic diagram: 
outside X 
¬ outside X 
¬ outside ¬ X 
where ‘¬’ denotes negation. Each row in the diagram  represents a different temporally ordered possibility, e.g., the  first row represents the possibility in which the person goes  outside first and then X occurs. The statement rules out the  situation in which the person goes outside and X does not  occur. The model theory accordingly posits that basic causal  relations are interpreted deterministically (Frosch & Johnson Laird, 2011).  
A strong prediction of the theory is that when prompted to  list the possibilities consistent with a given causal statement,  reasoners should list the three possibilities above. Several  
studies corroborate the prediction (e.g., Bello, Wasylyshyn,  Briggs, & Khemlani, 2017; Goldvarg & Johnson-Laird,  2001; Khemlani, Wasylyshyn, Briggs, & Bello, under  review). In daily life, however, people do not reason based on  the full meanings of causal statements. Instead, they rely on  a single mental model to represent “going outside causes X”,  e.g., 
outside X  
A single model permits rapid inferences because reasoners  need to maintain only one possibility in memory. It also  permits the rapid construction of a causal chain of events. The  theory posits, for instance, that when reasoners comprehend  the causal description in (1a-b), they should build an initial  model of (1a) first, e.g., 
outside breathing-pollen  
and then they should integrate a model of (1b) with the model of (1a), e.g., 
outside breathing-pollen sneezing 
to create a single model of the phenomenon. One advantage  to representing the causal sequence as a single possibility is  that reasoners can scan the possibility to rapidly draw  temporal inferences, e.g., 
2a. The person breathed in pollen before sneezing.  b. The person sneezed after he went outside. 
The inference in (2a) comes about as a result of scanning the  possibility from right to left. The inference in (2b) reflects a  scan of the possibility from left to right. Hence, an  explanatory mental model in the form of an integrated  representation of a causal possibility is a productive representation in that it yields sensible temporal and causal  inferences. 
We propose the principle of explanatory completeness,  which extends the model theory of causal reasoning to  account for how reasoners detect incompleteness. The principle defines a complete causal explanation as a mental  model of a single possibility that represents one or more  causes and one or more effects. One of the effects constitutes  the explanandum, i.e., the thing to be explained. In contrast,  incomplete explanations are those that refer to two or more  models of possibilities that may or may not share causes and  effects. When generating explanations, reasoners should  spontaneously construct complete explanatory models  instead of incomplete ones.  
The principle posits that reasoners should deem an  explanation complete if it can be represented by a single  causal mental model, e.g., of (1a-b): 
outside breathing-pollen sneezing 
The principle yields a novel prediction: causal descriptions  known as “common cause” and “common effect”  
1952
explanations (Read, 1988; Rehder & Hastie, 2004; Salmon,  1978) should be considered less complete than “causal  chains” (e.g., 1a-b). For instance, consider the “common  effect” explanation in (3): 
3. Being outside caused sneezing and having a cold caused  sneezing. 
The model theory predicts that mental models of the  description in (3) should be iconic, i.e., they should reflect the structure of what they represent. Since the description in  (3) concerns two separate, unrelated causes, reasoners should  construct two separate models to represent the statement, e.g.: 
outside sneezing 
having-a-cold sneezing 
One model of (3) would not suffice, because it would  represent the situation in which being outside and having a  cold caused sneezing. 
An analogous argument holds for the “common cause” in  (4): 
4. Being outside caused sneezing, and being outside   caused frostbite. 
It requires reasoners to represent two distinct models: 
outside sneezing 
outside frostbite 
Some reasoners may spontaneously consult background  knowledge to infer whether the two possibilities can be  reconciled, but, failing that, the principle of explanatory  completeness predicts that the two possibilities should be  considered incomplete. 
We describe two experiments that tested the principle of  explanatory completeness. The experiments compared causal  chains with common effect explanations, as in (3), and  common-cause explanations, as in (4), and they served to  provide a definitive test of the model theory of explanatory  completeness. The principle of explanatory completeness  predicts that only causal chains should be represented by a  single mental model, and so causal chain structures should be  considered more complete than the latter two structures. 
Experiment 1 
Experiment 1 tested how reasoners assess the completeness  of explanations. The model theory predicts that they should  consider explanations in the form of causal chains (e.g., A  causes B and B causes C) to be more complete than those in  the form of common cause (e.g., A causes B and A causes C)  or common effect structures (e.g., A causes C and B causes  C). 
Method 
Participants. 51 participants completed the experiment for  monetary compensation through Amazon Mechanical Turk. 
Fifty of the participants were native English speakers, and all  but six had taken one or fewer courses in introductory logic. 
Task. The experiment invited participants to think of  themselves as teachers who had to evaluate their students’  explanations for why a particular novel event, C, took place.  Participants evaluated whether a putative causal explanation  for C was complete by using a slider bar to indicate a number  on a Likert scale from 1 (definitely incomplete) to 5  (definitely complete).  
Materials. The content of the events (A, B, and C) was drawn  from four separate domains (natural, biological, social, and  mechanical). Each set of materials was a collection of  candidate properties or behaviors of a novel entity. These  properties and behaviors were designed such that any one  property or behavior could serve as a cause or a resulting  effect of any other. The materials are available at  https://osf.io/3ezb5. For instance, one set of materials  concerned a mechanical device used in factories called a  “Zindo,” and so some participants were instructed to evaluate  students’ explanations for why the Zindo narrows an  aperture. For example, participants might have evaluated the following explanation: 
Releasing a valve [A] causes the Zindo to engage a pump [B]. Engaging a pump [B] causes the Zindo to narrow an aperture [C]. 
On each problem, the experiment was programmed to  randomly assign the three properties or behaviors (releasing  valve, engaging a pump, and narrowing an aperture) to the  event positions (A, B, and C) according to the structures of  the problems in the study. 
Design and procedure. Participants carried out eight  problems altogether. Half of the problems concerned  explanations that yielded one model (causal chains), and the  other half concerned explanations that yielded multiple  models. Two of the four causal chain problems comprised  two premises, e.g., A causes B and B causes C, while the other  two comprised a single premise, e.g., A causes C, where A,  B, and C stand for various properties and behaviors of  imaginary entities. 
The other half of the problems concerned explanations that  should yield multiple models, i.e., explanations that the  theory construes as incomplete. Two of the four multiple model problems concerned common cause explanations and  the other two concerned common effect explanations.  Common cause problems provided explanations adhering to  the schematic: A causes B and A causes C, while common effect problems adhered to the schematic: A causes C and B  causes C. The theory predicts that reasoners should be unable  to construct an integrated mental model from common cause  and common effect explanatory structures, and so they should  be judged relatively less complete. 
Participants acted as their own controls and carried out all  eight problems in a fully repeated measures design. The  
1953
experiment was implemented in using the “nodus-ponens” experimental framework for Node.js (Khemlani, 2017).  Participants completed two practice trials (one yielding a  single mental model, another requiring multiple models), and  they received the rest of the problems in a randomized order. 
Results and discussion 
Figure 1 presents the completeness ratings participants gave  for each of the three types of problems presented in  Experiment 1. As a whole, participants rated those problems  that were predicted to yield one model – i.e., causal chains – 
as more complete than those predicted to yield multiple  
s s
e
n
e
t
e
l
p
m
o
C
5 4 3 2 1 
models (M = 3.13 vs. M = 2.93), but the difference between  
Causal chain: 
One premiseCausal chain: 
Common ef ect 
the two groups was unreliable (Wilcoxon test, z = 1.52, p =  .13). We suspect that the lack of reliability between the two  groups was a result of a confound in the design: only causal  chains appeared as one-premise problems. When the analysis  was restricted to only problems that comprised two premises,  participants provided higher ratings for causal chains (M =  3.56), which can be represented with a single explanatory  mental model, than for common cause (M = 2.84, Wilcoxon  test, z = 3.67, p < .0001, Cliff’s δ = .72) or common effect problems (M = 3.02, Wilcoxon test, z =2.64, p = .008, Cliff’s δ = .54), both of which require multiple  models. The pattern corroborates the principle of explanatory  completeness. 
Participants gave much lower ratings for causal chain  problems containing only a single premise (M = 2.71) than  for those containing two premises (z = 3.96, p < .0001, Cliff’s  δ = .85). Indeed, their ratings for one-premise causal chain  problems did not differ reliably from common cause or  common effect problems (z = 1.62, p = .11, Cliff’s δ = .23). The result ran counter to the principle of explanatory 
completeness. But it did accord with the results of previous studies, which showed that people prefer explanations that  concerned both causes and their effects to explanations that  concerned either causes or effects alone (Legrenzi &  Johnson-Laird, 2005). For instance, participants in Legrenzi  and Johnson-Laird’s (2005) study had to select from a set of  plausible explanations for why a package was not received.  They rated this explanation: 
The package went astray because it had the wrong address. as more probable than this one: 
The package went astray. 
The results of Experiment 1 are sensible in light of Legrenzi  and Johnson-Laird’s (2005) finding, but they imply that a) the  results of Experiment 1 are confounded, because one-model  and two-model problems were unbalanced with respect to the  number of premises they contained, and that b) the principle  
Common cause 
Two premises 
Figure 1. Violin plot of participants’ responses to the three  conditions in Experiment 1. The width of each shape is proportional  to participants’ response frequencies.  
of explanatory completeness has a boundary condition: explanations that consist of single explanatory cause, e.g.,  explanations of the form A causes C, should be considered  incomplete. Experiment 2 addressed both issues by dropping  shorter descriptions from the design. 
Experiment 2 
Experiment 1 provided partial evidence that people consider  explanations that require a single model as more complete  than those requiring multiple models. However, the study  showed that people tend to prefer more elaborated causal  chains (e.g., A causes B and B causes C) to shallow causal  chains (e.g., A causes C). Indeed, one-premise causal chains  fail to provide an explanation containing both a novel effect  and a cause that preceded that effect (Legrenzi & Johnson Laird, 2005).  
Experiment 2 sought to replicate and extend the findings of  Experiment 1 by presenting participants with only two premise problems. Hence, Experiment 2 eliminated a  confound of Experiment 1, and it served as a stronger test of  the principle of explanatory completeness: if an explanation’s perceived completeness depends on specific features of  representations – the number of possibilities represented – and not just the presence or absence of an effect and its  preceding cause, then reasoners’ explicit judgments of  completeness should depend on those representations.  
Method 
Participants. 50 participants completed the experiment for  monetary compensation through Amazon Mechanical Turk.  All of the participants were native English speakers, and all  but eight had taken one or fewer courses in introductory logic. 
Preregistration and data availability. The predicted effects  were pre-registered through the OSF platform:  https://osf.io/sx38c/register/564d31db8c5e4a7c9694b2c0. 
1954
The data, experimental code, and materials for Experiment 2  are available at: https://osf.io/3ezb5/. 
Design and procedure. The design and procedure for  Experiment 2 were identical to that of Experiment 1, except  that Experiment 2 included only two-premise problems across all conditions. As in Experiment 1, half of the  problems described causal chains, and the other half were  split evenly between common-cause and common-effect  structures.  
Results and discussion 
Figure 2 presents the completeness ratings participants  gave for each of the three types of problems presented in  Experiment 2. As in Experiment 1, participants provided  higher ratings for causal chains, which can be represented  with a single explanatory mental model (M = 3.26), than for  common cause (M = 2.64, Wilcoxon test, z = 3.19, p = .001,  Cliff’s δ = .62) or common effect problems (M = 2.83,  Wilcoxon test, z = 2.05, p = .04, Cliff’s δ = .43).  
To control for the variance contributed by materials and individual participants, data were subjected to a generalized  linear mixed model regression analysis that treated participants’ judgments of completeness as the outcome variable and the three types of problem as a fixed effect, and it controlled for material and participant noise. The analysis revealed that the problem types reliably predicted judgments  of completeness (B = -0.49, p < .001), further corroborating  the theory’s prediction. 
5 
4 
s 
s
e
n
e
complete? We argue that, in contrast to philosophical  accounts of explanatory completeness, this phenomenon is  fundamentally psychologistic: that is, it can only be  understood on the basis of subjective, cognitive constraints.  We extended the model theory of causal reasoning to explain  completeness judgments: it posits that a complete  explanation refers to a representation of a single possibility,  whereas an incomplete explanation refers to representations  of multiple possibilities. 
The theory uniquely predicts that reasoners should  consider explanations of the form of simple causal chains to  be more complete than explanations in the form of “common  cause” and “common effect” structures (Read, 1988; Rehder  & Hastie, 2004; Salmon, 1978). Two experiments confirmed  the theory’s prediction, and they suggest that reasoners  construct iconic mental representations of causal relations  when they generate and evaluate explanations (Khemlani &  Johnson-Laird, 2011). 
No psychological theory of causal reasoning is fixed in  stone, and any of them can be adapted to yield the present  prediction. Indeed, explanatory causal chains have been  examined in previous work on causal islands (Johnson &  Ahn, 2015), explanatory simplicity (Pacer & Lombrozo,  2017), and explanatory coherence (Thagard, 1989). Yet no  account prior to the present one has focused on how and why  reasoners distinguish complete from incomplete  explanations. Unlike other theories of causal reasoning, the  model theory precisely characterizes the increased  representational burden that incomplete explanations impose  on reasoners: it is easier for people to reason from a single  possibility than it is to maintain multiple possibilities and to  draw inferences from them (Johnson-Laird, 1983; Khemlani  & Johnson-Laird, 2017). The model theory thus makes the  unique prediction that reasoners should detect incomplete  explanations when the burden of representing more than one  possibility is present. 
Other accounts focus less on how reasoners maintain  
t
e
lp
m
o
C
3 
2 
1 
Causal chain Common cause 
Common effect 
multiple representations and instead on alternative  mechanisms to explain causal inference. For instance, some  theorists argue that causal reasoning can be best characterized  by causal Bayesian networks (Sloman, 2005; Sloman,  Barbey, & Hotaling, 2009). To explain the present data, such  an account would need to be extended with mechanisms that  maintain, align, and compare multiple networks at a time. A  complete causal net would refer a single, integrated network,  
Figure 2. Violin plot of participants’ responses to the three  conditions in Experiment 2. The width of each shape is proportional  to participants’ response frequencies.  
General discussion 
Reasoners construe “complete” explanations as being better  than incomplete explanations (Zemla et al., 2017). And, early  studies showed that construing an explanation as incomplete  allows reasoners to target questions in order to fill in the  explanation’s gaps (Miyake, 1986). But on any objective  notion of completeness, all explanations are incomplete. So  what makes people judge an explanation as more or less  
whereas an incomplete causal net would refer to multiple  networks whose interdependent links are expected but  unspecified. No such theory has been proposed, but it is a  reasonable extension of other researchers’ proposals (see Ali,  Chater, & Oaksford, 2011). A limitation of this idea,  however, is that causal networks might treat causal chains,  common cause structures, and common effect structures as  equivalently complete, because all three structures refer to a  single, integrated network. As the present experiments show,  reasoners distinguish between causal chains and other kinds  of structures: chains are deemed more complete. 
1955
Acknowledgments 
This work was supported by an NRC Research Associateship  Award to J.K. and funding from the Office of Naval Research  to S.K. We thank Paul Bello, Monica Bucciarelli, Ruth  Byrne, Felipe de Brigard, Tony Harrison, Laura Hiatt, Phil  Johnson-Laird, Robert Mackiewicz, and Greg Trafton for  advice. We also thank Kalyan Gupta, Kevin Zish, and  Knexus Research Corp. 
References 
Ali, N., Chater, N., & Oaksford, M. (2011). The mental  representation of causal conditional reasoning: Mental models or  causal models. Cognition, 119, 403-418. 
Batygin, K., & Brown, M. E. (2016). Evidence for a distant giant  planet in the solar system. The Astronomical Journal, 151, 22. Bello, P., Wasylyshyn, C., Briggs, G., & Khemlani, S. (2017).  
Contrasts in reasoning about omissions. In G. Gunzelmann, A.  Howes, T. Tenbrink, & E. Davelaar (Eds.), Proceedings of the  39th Annual Conference of the Cognitive Science Society. Austin,  TX: Cognitive Science Society. 
Frosch, C.A., & Johnson-Laird, P.N. (2011). Is everyday causation  deterministic or probabilistic? Acta Psychologica, 137, 280–291. Goldvarg, Y., & Johnson-Laird, P.N. (2001). Naive causality: a  mental model theory of causal meaning and reasoning. Cognitive  Science, 25, 565−610. 
Goodwin, G.P., & Johnson-Laird, P.N. (2005). Reasoning about  relations. Psychological Review, 112, 468-493. 
Hempel, C. (2002). Two models of scientific explanation. In Yuri  Balashov & Alexander Rosenberg (eds.), Philosophy of Science:  Contemporary Readings (pp. 45-55). London: Routledge.  (Original work published 1965) 
Johnson, S., & Ahn, W. (2015). Causal networks or causal islands?  The representation of mechanisms and the transitivity of causal  judgment, Cognitive Science. 1-36. 
Johnson-Laird, P.N. (1983). Mental models. Cambridge:  Cambridge University Press. Cambridge, MA: Harvard  University Press. 
Johnson-Laird, P.N., & Khemlani, S. (2017). Mental models and  causation. In M. Waldmann (Ed.), Oxford Handbook of Causal  Reasoning (pp. 1-42). Elsevier, Inc.: Academic Press. 
Johnson-Laird, P.N., Legrenzi, P., & Girotto, V. (2004). How we  detect logical inconsistencies. Current Directions in  Psychological Science, 13, 41-45.  
Josephson, J. R. (2000). Smart inductive generalizations are  abductions. In Abduction and induction (pp. 31-44). Springer  Netherlands. 
Keil, J. (2006). Explanation and understanding. Annual Review of  Psychology, 57, 227-54.  
Khemlani, S. (2017). nodus-ponens: A full-stack framework for  running high-level reasoning and cognitive science experiments  in Node.js. Retrieved from: www.npmjs.com/package/nodus ponens. 
Khemlani, S., Barbey, A., & Johnson-Laird, P. N. (2014). Causal  reasoning with mental models. Frontiers in Human  Neuroscience, 8, 849. 
Khemlani, S., Byrne, R.M.J., & Johnson-Laird, P.N. (in press).  Facts and possibilities: A model-based theory of sentential  reasoning. Manuscript in press at Cognitive Science. 
Khemlani, S. & Johnson-Laird, P.N. (2011). The need to explain.  Quarterly Journal of Experimental Psychology, 64, 2276-88.  Khemlani, S., & Johnson-Laird, P. N. (2012). Hidden conflicts:  Explanations make inconsistencies harder to detect. Acta  Psychologica, 139, 486–491. 
Khemlani, S., & Johnson-Laird, P.N. (2017). Illusions in reasoning.  Minds & Machines, 27, 11-35 
Khemlani, S., Orenes, I., & Johnson-Laird, P.N. (2012). Negation:  a theory of its meaning, representation, and use. Journal of  Cognitive Psychology, 24, 541-559. 
Khemlani, S., Wasylyshyn, C., Briggs, G. & Bello, P. (under  review). Mental models and omissive causation. Manuscript  under review. 
Miyake, N. (1986). Constructive interaction and the iterative  process of understanding. Cognitive Science, 10, 151-177. Pacer, M. & Lombrozo, T. (2017). Ockham’s razor cuts to the root:  Simplicity in causal explanation. Journal of Experimental  Psychology: General, 146, 17651-1780. 
Peirce, C. S. (1931-1958). Collected papers of Charles Sanders  Peirce. 8 vols. C. Hartshorne, P. Weiss, and A. Burks, (Eds.).  Cambridge, MA: Harvard University Press. 
Railton, P. (1981). Probability, explanation, and information.  Synthese, 48, 233–256. 
Read, S. (1988). Conjunctive explanations: The effect of a  comparison between a chosen and a nonchosen alternative.  Journal of Experimental Social Psychology, 24, 146-162. 
Rehder, B., & Hastie, R. (2004). Category coherence and category based property induction. Cognition, 91, 113-153. 
Rescher, N. (1995). Satisfying reason: Studies in the theory of  knowledge. Kluwer Academic Publishers: Dordrecht. Sloman, S. A. (2005). Causal models: How people think about the  world and its alternatives. Oxford University Press, USA. Sloman, S.A., Barbey, A.K. & Hotaling, J. (2009). A causal model  theory of the meaning of “cause,” “enable,” and “prevent.”  Cognitive Science, 33, 21-50. 
Thagard, P. (1989). Explanatory Coherence. Behavioral and Brain  Sciences, 12, 435-467.  
Zemla, J.C., Sloman, S., Bechlivanidis, C., & Lagnado, D.A. (2017).  Evaluating Everyday Explanations. Psychonomic Bulletin and  Review, 24, 1488-1500.  
1956
Tuning to the Task at Hand:  
Processing Goals Shape Adults’ Attention to Unfolding Activity 
Jessica E. Kosie (jkosie@uoregon.edu)  
Department of Psychology 
University of Oregon, Eugene, OR 97403, USA 
Dare A. Baldwin (baldwin@uoregon.edu)  
Department of Psychology 
University of Oregon, Eugene, OR 97403, USA 
Abstract 
Human activity generates dynamic, multi-modal sensory  streams. Effectively processing this complex flow of  information on-the-fly is essential if one is to remember and  respond to others’ action, anticipate what they might do next,  and learn how to perform new actions. Selectively attending to  information-rich regions of activity seems key to fluent  processing. However, what counts as information-rich likely  depends on numerous factors including relevance to the causal  structure of the activity, local opportunity for repeated viewing,  and processing goals of the observer. We explored the  influence of these factors on observers’ attention to a dynamic,  novel activity sequence. A performance context elicited  nuanced differences in processing in contrast to a remember context. Specifically, individuals given a perform context  tuned in to causally distinct regions of the action stream and  fine-level event details. These findings provide altogether new  information regarding how processing rapidly reorganizes  around novel activity and responds to the processing task at  hand. 
Keywords: event processing; action segmentation; context  effects 
Consider the activity of knitting. No doubt you’ve heard of  this activity, can recognize someone who is engaging in it,  and at least globally understand the actor’s goals (i.e.,  transforming a strand of yarn via a complex, repetitive, and  very extended sequence of stitches into a piece of patterned  material). For those who aren’t knitters, the details are  opaque, but the general gist of the activity is understood. But  what if a non-knitter opted to acquire this skill? Suddenly  knitting behavior would be processed in a very different way,  presumably with a focus on discovering what motions are  actually needed to transform yarn into garments. Precisely  what are these changes in processing that the learner initiates?  The present research took steps toward answering this  question. Finding such answers is foundational to cognitive  science, shedding light on basic processes that make observational learning possible, with the hope of ultimately  enabling us to assist those for whom observational learning  is difficult or disrupted. We begin by reviewing current  research on event processing and then present a novel study  in which we explore the influence of observers’ processing  goals on their online attention to unfolding activity. 
Segmentation is Key to Fluent Event Processing Most research in the domain of event processing focuses on  activities that are at least moderately familiar to observers.  This body of research suggests that, in processing familiar  activity, observers chunk unfolding sensory streams into  discrete units that are demarcated by event boundaries.  Typically, these event boundaries coincide with transitions  between one unit of action and another; for example, the  moment at which an actor’s hand contacts the handle of a  mug when reaching for a cup of coffee. Observers  overwhelmingly agree when asked to explicitly identify the  location of such boundaries in unfolding activity sequences  (e.g., Newtson, 1973; Zacks, Tversky, & Iyer, 2001; Kurby  & Zacks, 2008) as well as when they are asked to scale their  segmentation judgments up or down in terms of the grain at  which they identify boundaries (e.g., Zacks & Swallow,  2007). To illustrate this granularity, the above-mentioned  mug-grasping event might represent a fine-level event  boundary in a coffee-making event sequence. In the same  action sequence, the “coffee making” event might begin with  a coarse boundary at which an actor, having just entered the  kitchen, removes a bag of grounds from the cupboard. The  coarse boundary demarcating the end of the event sequence  – and representing structure within the sequence at more of a  “gist” level – might occur once the actor has finished pouring  herself a cup of coffee and replaces the coffee pot.  
Across a variety of implicit probes of processing, including  behavioral tasks, fMRI, and pupillometry, researchers have  demonstrated that such targeting of event boundaries occurs  automatically as observers view unfolding event sequences 
(Newtson & Engquist, 1976; Schwan & Garsoffky, 2004;  Zacks et al., 2001; Tanaka & Baldwin, in preparation). Recently, Hard, Recchia, and Tversky (2011) demonstrated  that observers advancing at their own pace through a  slideshow composed of frames extracted at a regular  increment (e.g., 500 msec) from streaming activity “dwell”  longer on slides depicting event boundaries relative to slides  depicting within-event content. Further, the amount of time  spent dwelling on slides directly corresponds to the level of  event hierarchy represented by the slide content. That is,  viewers dwell longest on slides representing coarse-level  boundaries, dwell less to slides that occur at fine-level  
1957
boundaries, and dwell least on slides representing non boundary content. 
It is also worth noting that viewers’ sensitivity to event  boundaries – whether measured via explicit judgments or  implicit measures such as dwell time – predicts other aspects  of their event processing, such as their memory for event  sequences and the ability to enact such sequences themselves 
(Kurby & Zacks, 2011; Sargent et al., 2013; Zacks, Speer,  Vettel, & Jacoby, 2006; Bailey, Kurby, Giovanetti, & Zacks,  2013; Hard et al., 2011). Thus skill at detecting event units as  activity unfolds across time is relevant to memory for that  activity and the ability to enact it oneself, which are both  hallmarks of observational learning. 
Event Boundaries are Low-Predictability Regions Event boundaries thus appear to be moments in the event  stream that are key to observers’ fluent processing of  unfolding activity sequences. A current conception of the role  that event boundaries play in processing is that they represent  information-rich regions of the event stream precisely  because event boundaries are points that coincide with  reductions in the ability to predict what will happen next as  activity unfolds (Kosie & Baldwin, 2016; Kurby & Zacks,  2008; Ross & Baldwin, 2015; Zacks, Kurby, Eisenberg, &  Haroutunian, 2011). For example, once a reach for a coffee  mug has been detected, much is highly predictable, at least  until the coffee mug has been grasped. At this juncture, the  actor could pursue any number of subsequent acts. She might bring the mug to her mouth to take a drink, move the mug to  the sink to wash it, hand the mug to a friend, and so forth.  Attending to activity at this low predictability juncture would  enable observers to glean important new information about  what occurs next. Increasing attention at event boundaries  therefore enables observers to gather vital information that  guides subsequent processing.  
When activity is familiar, this account seems highly  intuitive. However, to return to our initial example, if one has  little understanding of the actual mechanics of knitting, the  ability to target event boundaries seems a significantly more  difficult task. On first viewing of highly novel activity, it is  unlikely that one can efficiently target event boundaries as  almost everything is low predictability and thus information 
rich. Recently, Kosie and Baldwin (2016; under revision)  used the dwell-time paradigm to demonstrate that observers’  processing of novel events reconfigures rapidly. Observers  were instructed to advance at their own pace through  slideshows depicting novel and familiar methods of shoelace  tying. On first viewing of the novel method, observers failed  to show the typical systematic increase in attention to event  boundaries. But by the second viewing of the novel tying  method, observers elevated attention to event boundaries,  indicating rapid boundary identification and consequent  reorganization of attention to favor boundaries. In addition,  novice observers tended to linger on the causally distinctive  regions of the event stream that were particularly important  for performing the novel activity, in this case the features of  the shoelace tying event differentiating novel from familiar  
methods. Perhaps increasing attention to causally distinctive  regions of the event stream enabled observers to extract the  fine-level structure important for carrying out the novel  activity. 
Importantly, in the research just described, observers were  given no instruction to guide their event viewing other than  to advance at their own pace through the unfolding activity.  In particular, they were given no guidance about how to  attend to the shoelace tying event, or to what purpose. Upon  completion of this study, however, a subset of participants  were told that they would have the opportunity to learn to  enact the novel method of shoelace tying. As part of this pilot  study, these participants were invited to advance once more  through the slideshow depicting the novel activity and then  were given the opportunity to try the method themselves.  When participants advanced through the slideshow with the  goal of learning to perform the actions themselves, their  dwell times increased substantially relative to the dwelling  they had displayed on their previous, uninstructed, viewing.  Further, these increases in dwell time were especially  pronounced in relation to causally distinctive regions of  activity. However, these pilot findings don’t clarify expressly why such dwell-time changes emerged; for example, it is  unclear whether an enactment goal specifically generated  change in dwell-time patterns, or whether any guidance in  how to pay attention would elicit similar alteration.  
Prior research supports the notion that context markedly  influences processing of event sequences. For example, in  their change blindness research Simons and Chabris (1999)  famously showed that, when given instructions that focused  attention on detail within an activity stream, many  participants utterly failed to notice a man in a gorilla suit  traipse past in a video of unfolding activity. In contrast, the  man in the gorilla suit was readily noticed by the vast  majority when the context emphasized more global  processing of the activity. Especially relevant to the issues of  specific interest here, Blakemore and Decety (2001) reported  that cortical activation patterns detected in fMRI differed when participants watched an activity sequence with the  instruction to later perform it, relative to the instruction to  remember it. However, details about what changes in terms  of processing during perform versus remember contexts  remain unclear. The dwell-time paradigm offers a potential  window on the details of such processing differences. 
Overview of the Current Study 
We employed the dwell-time paradigm to investigate the  extent to which instructions to remember versus perform yielded differences in observers’ processing of a novel  activity sequence. Participants were asked to view the  slideshow used in Kosie and Baldwin (2016; under revision)  that depicted a novel shoelace tying sequence. Before  participants began, half were instructed to watch the activity  so that they could later perform it themselves while the other  half of participants were instructed to watch so that they  could later remember it. Participants then used a computer  mouse to advance at their own pace through the slideshow, in  
1958
which the actor first tied her right shoe and then her left shoe (thus they had two viewings of the novel activity). After all  participants had advanced through the slideshow they were  asked to demonstrate, on a wooden shoe with laces, the  
method of shoelace tying that they had just viewed.  We anticipated a lower mean per-slide dwell time for  remember than perform instructions. Relative to perform instructions, the remember processing context was expected  to yield dwell-time patterns more like those observed in earlier research in which instructions were to simply watch  the novel activity. In replication of our prior research, we  expected that, when given remember instructions: a) observers would attend longer to event boundaries, with attention particularly enhanced to coarse-grain level  boundaries, and b) dwell times would be particularly elevated  to distinctive regions of the activity, and especially on second  viewing. However, we also predicted that perform instructions might elicit increased attention to causally  distinctive content, perhaps resulting in higher dwell times to  fine-level event boundaries and distinctive regions. 
Method 
Stimuli 
In the current study, participants viewed only one slideshow  (depicting the novel method of shoelace tying used in Kosie  & Baldwin, 2016; under revision). This novel twist method  of shoelace tying involved the actor making an initial knot,  slipping her pinky fingers under the laces, making a pincer  grasp, twisting the pincers around to meet in the middle,  grabbing the laces, pulling them through to create a bow, and  double-knotting the shoe. A video depicting this novel  method of shoelace tying can be viewed at:  https://osf.io/8rpkf/. The slideshow was created by extracting  one still frame every second from a 115-second video of an  actor demonstrating the twist method (the resulting slideshow  thus consisted of 115 unique slides). The extraction rate of  one frame per second is consistent with prior research using  the dwell-time paradigm (e.g., Hard et al., 2011). 
Slide Classification 
Two expert coders, with extensive experience in event  processing research, first defined regions of the slideshow as  causally distinctive (e.g., unique to the twist method of  shoelace tying) versus non-distinctive (e.g., common to any  method of shoelace tying, such as the initial knot at the  beginning and double-knot at the end). Individual slides were  then classified as depicting boundaries or within-unit content,  and boundary slides were further classified at the coarse grained or fine-grained level of hierarchical structure. These  judgments were validated by a sample of naïve research  participants. As is typical of naturalistic activity, the precise  number of slides falling into the distinctive / non-distinctive  
 
1 Data from a subsequent repetition of this entire task are not  included in the current analyses but will be reported in a later  manuscript.  
and coarse / fine / within categories differed across viewings (see Table 1). The slide classification process is described in  further detail in Kosie & Baldwin, 2016 and Kosie &  Baldwin, under revision. 
Table 1: Number of slides at each level of structure across  viewings and for distinctive and non-distinctive regions. 


	Distinctive 
	Non-Distinctive
	

	

	First  
Viewing
	Second  
Viewing
	First  
Viewing
	Second  
Viewing
	Total
	Coarse 
	0 
	0 
	5 
	6 
	11
	Fine 
	5 
	5 
	8 
	9 
	27
	Within 
	15 
	16 
	25 
	20 
	76
	Total 
	20 
	21 
	38 
	35 
	114
	



Note: One slide was classified as the “switch” from first to  second viewing and is thus not included in these values. 
Participants and Procedure 
130 undergraduates (69% female, Mage = 19 years)  participated in exchange for course credit. During an initial phase designed to familiarize participants with the self-paced  slideshow format, participants advanced at their own pace  through two brief slideshows unrelated to shoelace tying.  They were then told that they would use the computer mouse  to advance at their own pace through another slideshow (the  shoelace tying activity). At this juncture, participants were  given either remember or perform instructions. Participants  in the remember condition were told: “You will later be tested  for your ability to remember the action that occurred in the  slideshow. Please watch the slideshow so that you can  remember the action later.” Participants in the perform 
condition were given the exact same instructions, but with the  word perform instead of remember. The inclusion of either  the word remember or perform in these instructions was the  sole difference between the two conditions; participants’  experiences were otherwise identical. 
After hearing these instructions, participants advanced at  their own pace through the novel method of shoelace tying1.  Participants’ dwell times, or latency between mouse clicks  from one slide to the next, were recorded using PsychoPy  (Pierce, 2007), a user-friendly experimental control system  written in Python. After slideshow viewing, regardless of  condition, participants were handed a wooden shoe and asked  to demonstrate the novel method of shoelace tying.  
Results 
Data Preparation 
Raw dwell times were subjected to the standard treatment for  dwell-time data (i.e., Hard et al., 2011; Kosie & Baldwin,  2016; under review). First, as is typical of reaction-time data,  
1959
dwell times (in milliseconds) were log transformed to remove  positive skew. Next, outlying dwell times (> 3 SD above the  group mean) were removed. Individual participants were  excluded if more than 10% of their dwell times met this  criterion, resulting in the exclusion of one participant. To  account for participants’ tendency to speed up as slideshows  progress, data from the remaining 129 participants (63 
receiving remember and 66 receiving perform instructions) were individually fitted to a power function. Residuals from  these power functions were used as the dependent-variable in  analyses targeting within-subjects effects (i.e., boundary vs.  within; distinctive vs. non-distinctive).  
When necessary, a Greenhouse-Geisser correction was  applied to degrees of freedom to address sphericity  violations. To adjust for multiple comparisons, Bonferroni  correction was applied to all post hoc pairwise comparisons. 
No Global Dwelling Increase for Perform Versus  Remember 
We first examined the overall influence of instructions to  remember versus perform on observers’ processing of the  novel event stream. In this analysis, we simply asked whether  mean per-slide dwell time differed for slideshows in which  participants were instructed that they would later be asked to  remember or later asked to perform the novel shoelace tying  method. For these analyses, we used participants’ log10 
dwell times as the process of residualization substantially  attenuates overall group differences. Mean per-slide log10  dwell time for participants receiving remember instructions (M = 2.71, SD = 0.19) did not significantly differ from that of  participants who received perform instructions (M = 2.73, SD = 0.20), t(127) = -0.68, p = 0.50, d = -0.12, 95%CI[-0.09,  0.04]. Though the instructions to remember or perform did  not differentially affect participants’ average per-slide dwell  time, mean per-slide dwell times across both levels of instruction (M = 2.72, SD = 0.19) were significantly higher  than dwell times to the same novel activity in previous  research (in which instructions were simply to observe the  activity sequence) (M = 2.53, SD = 0.19), t(260) = -8.15, p <  .001, d = -1.01, 95%CI[-0.24, -0.15]. Across the two studies,  it seems that processing instructions in general elicit  increased overall dwelling, but instructions to remember or  perform do not differentially influence this global increase in  dwelling. We next turned to exploring the effects of  instructions on more nuanced facets of processing. 
Individuals Given Perform Instructions Target  Distinctive Content 
In our next analysis, we examined the extent to which attention to the distinctive versus non-distinctive regions of  the activity sequence differed with respect to instructions and  viewing. The analysis of interest here was a 2 (Instructions:  Remember vs. Perform) x 2 (Viewing: First vs. Second) x 2  (Region: Distinctive vs. Non-Distinctive) ANOVA with  instructions varying between subjects and viewing and region  varying within-subjects. Our dependent-variable for this  analysis was average residualized dwell time.  
Most notably, we found a significant interaction between  instructions and slideshow region, F(1, 127) = 8.28, p = .004,  �"# = .06, illustrated in Figure 1 (with means and standard  deviations). There was no main effect of viewing, nor did  viewing interact with instructions or region, ps > .06, �"#s <  .02. Simple-effects comparisons exploring the locus of the  interaction between instructions and region, revealed that  perform instructions elicited a significant elevation in dwell  times to the distinctive relative to non-distinctive region p =  .05, d = -0.60, whereas remember instructions did not do so, p = .63, d = 0.35. Furthermore, dwelling to the distinctive  region was significantly elevated by perform relative to  rememberinstructions, p = .02, d = 0.51, whereas dwelling to  the non-distinctive region was significantly reduced by  perform versus remember instructions, p = .02, d = 0.50.  
In sum, individuals given remember instructions did not  differentiate distinctive versus non-distinctive event content  in relation to how they deployed their attention. However,  perform instructions elicited selectively elevated attention to  distinctive event content while reducing attention to non 
distinctive content. Together, these findings indicate that  participants responded to the perform instruction by tuning in  to distinctive content, while ignoring information not relevant  to the task at hand (i.e., to learn to enact the novel method of  shoelace tying). Also noteworthy was that these patterns  emerged to an equivalent degree across first and second  viewings. None of the effects involving viewing were  significant, suggesting that, when given perform instructions, 
an increase in attention to distinctive regions occurs on first  viewing of novel activity and remains stable. 
  
0.002 (0.02) -0.005 (0.04) -0.006 (0.03) 0.011 (0.06) 
  

Figure 1. Average residualized dwell times (+/- SE) to  distinctive and non-distinctive regions across remember and  perform instructions. Means and SDs reported below bars. 
Context Influenced Granularity of Processing Also of particular interest was the extent to which instructions influenced attention to slides at varying levels of  hierarchical structure and how these effects changed across  repeated viewing. Thus, the goals of our next set of analyses  were threefold: 1) examine replication of previous dwell-time  patterns (i.e., boundary and hierarchical advantage effects), 
1960
2) explore the extent to which these effects differed across  regions of the novel activity sequence, and 3) investigate the  influence of instructions to remember versus perform on  these attentional patterns. Because coarse-level boundaries  occur only in non-distinctive portions of the event stream, the  region factor could not be included in this analysis. 
A 2 (Instructions: Remember vs. Perform) x 2 (Viewing:  First vs. Second) x 3 (Slide Type: Coarse vs. Fine vs. Within)  mixed-design ANOVA (with average residualized dwell  times as the dependent variable) revealed no significant main  effects of instructions or viewing, ps > .30. However, a  significant main effect of slide type emerged, F(1.49, 188.87)  = 15.07, p < .001, �"# = .11, replicating previous dwell-time  research. A more focused examination of this main effect  revealed that average residualized dwell times were longer to  boundary than within-unit slides at both the coarse, p < .001,  d = 0.37, and fine, p < .001, d = 0.62, levels of structure, but  coarse and fine level boundaries did not significantly differ  from one another, p = .49, d = 0.13. Thus, averaging across  instruction type and viewing, observers exhibited a boundary  advantage (replicating previous research using the dwell time  paradigm), but average dwell times did not differ with respect  to hierarchical structure (failing to replicate the previously  observed hierarchical advantage). 
However, dwell times related to the slide type variable  interacted with both instructions, F(1.49, 188.87) = 8.23, p =  .001, �"# = .06, and viewing, F(1.60, 203.94) = 7.16, p = .002,  �"# = .05. These effects are depicted in Figure 2, which  includes means and standard deviations. For those who  received the remember instructions, the effect of slide type  changed significantly across viewing, F(1.56, 96.74) = 6.78,  p = .004, �"# = .10. Specifically, on first viewing, dwell times  to coarse, fine, and within-unit slides did not differ, ps > .71,  ds < 0.35. By the second viewing, however, dwell times  exhibited the predicted hierarchical linear trend; greater to  coarse-level boundaries than both fine-level boundaries, p <  .001, d = 0.80, and within-unit slides, p < .001, d = 0.96, and  dwell times to fine-level boundaries greater than dwell times  to within-unit slides, p = .003, d = 0.85. Also, for participants  receiving the remember instructions, dwell times to coarse  level boundaries increased across first and second viewing  (though this increase was not statistically significant when  controlling for multiple comparisons, p = .16, d = 0.43).  Dwell times to fine-level boundaries did not differ across  viewing, p = .96, d = 0.29, while dwell times to within-unit  slides decreased, p = .01, d = 0.59. Conversely, for  participants who received the perform instructions, the effect  of slide type was significant, F(1.61, 104.64) = 7.90, p = .001, �"# = .11, but did not interact with viewing F(2, 122) = 2.12,  p = .12, �"# = .03. Further analyses of the main effect of slide  type revealed that dwell times to coarse-level boundaries  were shorter than dwell times to fine-level boundaries, p =  .47, d = -0.18, and longer than dwell times to within-unit  slides, p = 0.05, d = 0.25, though neither of these effects were  significant. The locus of this effect thus seemed to be that,  across both viewings, dwell times to fine-level boundaries  
were significantly longer than dwell times to within-unit  slides, p < .001, d = 0.87. 
Taken together, these results indicate a marked contrast in  participants’ attentional profile in relation to remember versus perform instructions: when participants were told they  would later have to remember the novel activity, they  progressively increased attention to the coarse level of  structure across viewings. In contrast, participants who were  told they would later have to perform the novel activity  attended to the fine level of structure across viewings. That  is, it appears that instructions to perform elicit processing of  the details required to successfully perform this novel method  of shoelace tying, while instructions to remember elicited  more gist-level processing.  
  
  

0.011 (0.05) -0.003 (0.02) 0.001 (0.02) 0.032 (0.04) 0.004 (0.03) -0.009 (0.02) 
0.005 (0.06) 0.013 (0.04) -0.001 (0.03) 0.009 (0.06) 0.019 (0.04) -0.014 (0.02) 
Figure 2. Average residualized dwell times (+/- SE) to  coarse, fine, and within-unit slides across instructions and  viewing. Means and SDs reported below bars. 
Discussion 
Offering participants a processing goal (i.e., to remember or  perform) elevated their overall attention to a novel activity  sequence relative to previous studies in which participants  viewed the same event in the absence of a processing goal.  Interestingly, in some respects attentional profiles were  unaffected by processing instructions. For example, we found  that observers targeted boundary slides with increased  attention, and that this effect was robust across instructions to  remember or perform. In other respects, different instructions  yielded unique attentional profiles. For example, when given  remember instructions, observers increased attention to  boundaries at the coarse-grained level and did not  preferentially attend to distinctive or non-distinctive regions.  Conversely, when participants were given perform instructions, they targeted both distinctive regions and fine level event boundaries with increased attention. 
In the current study, coarse-level boundaries occurred only in non-distinctive regions of activity. Therefore, it was not  possible to directly disentangle whether participants given  the perform instructions were specifically targeting fine- over  coarse-level event boundaries or if the higher dwell times to  fine-level boundaries were simply elicited by observers’ 
1961
increased attention to the distinctive region. Though  challenging in naturalistic action, future work would benefit  from using a variety of activity sequences that contain both  coarse- and fine-level boundaries across distinctive and non 
distinctive regions of novel activity sequences. Despite the above-mentioned limitation, it can be  concluded that a simple one-word difference in instructions  elicits changes in online processing of a novel activity. Why  might this occur? Recently, Flores, Bailey, Eisenberg, and  Zacks (2017) demonstrated that simply instructing observers  to segment activity with respect to boundaries resulted in  improved memory for event sequences. Perhaps instructions  to perform function similarly, eliciting increased attention to  fine-level event boundaries (relative to instructions to  remember) and perhaps, consequently, improvements in  memory and performance. 
An important next step is thus an exploration of the ways  in which instructions to remember or perform and the  resulting attentional patterns influence observers’ ability to  learn the novel shoelace tying activity. Additionally, if  differences in instructions influence the granularity at which  observers attend to novel action, it seems probable that  memory would reflect such differences in processing. For  example, those instructed to remember might be more likely  to recall gist-level details about an activity, but little about  more fine-grained information, while those instructed to  perform might exhibit the opposite pattern and perhaps be  more likely to recall fine-level details. We are currently  investigating these possibilities. 
The findings we report here are the first steps to  understanding how differences in context influence  observers’ attention to unfolding activity. We additionally  showcase the value of the dwell time paradigm for gathering 
detailed information about the consequence of such  attentional influences. These results set the stage for asking a  variety of new questions about how learners acquire facility  with novel actions. 
Acknowledgements 
The authors would like to thank Rose Maier, Jenny Mendoza,  Robbie Ross, Shahar Shirtz, and Jason Wallin for valuable  conceptual input regarding this research.  
References 
Bailey, H. R., Kurby, C. A., Giovannetti, T., & Zacks, J. M.  (2013). Action perception predicts action performance.  Neuropsychologia, 51(11), 2294-2304. 
Blakemore, S. J., & Decety, J. (2001). From the perception  of action to the understanding of intention. Nature Reviews  Neuroscience, 2(8), 561. 
Flores, S., Bailey, H. R., Eisenberg, M. L., & Zacks, J. M.  (2017). Event segmentation improves event memory up to  one month later. Journal of Experimental Psychology:  Learning, Memory, and Cognition, 43(8), 1183. 
Hard, B. M., Recchia, G., & Tversky, B. (2011). The shape  of action. Journal of experimental psychology: General,  140(4), 586. 
Kosie, J.E. & Baldwin, D.A. (2016). A twist on event  processing: Reorganizing attention to cope with novelty in  dynamic activity sequences. Proceedings of the 37th annual  meeting of the Cognitive Science Society, Philadelphia. 
Kosie, J.E. & Baldwin, D.A. (under revision). Attention  rapidly reorganizes to structure in a novel activity  sequence. Unpublished manuscript, University of Oregon. 
Kurby, C. A., & Zacks, J. M. (2008). Segmentation in the  perception and memory of events. Trends in cognitive  sciences, 12(2), 72-79. 
Kurby, C. A., & Zacks, J. M. (2011). Age differences in the  perception of hierarchical structure in events. Memory &  cognition, 39(1), 75-91. 
Newtson, D. (1973). Attribution and the unit of perception of  ongoing behavior. Journal of Personality and Social  Psychology, 28(1), 28. 
Newtson, D., & Engquist, G. (1976). The perceptual  organization of ongoing behavior. Journal of Experimental  Social Psychology, 12(5), 436-450. 
Peirce, J. W. (2007). PsychoPy—psychophysics software in  Python. Journal of neuroscience methods, 162(1), 8-13. Ross, R. A., & Baldwin, D. A. (2015). Event Processing as  
an Executive Enterprise. Emerging Trends in the Social  and Behavioral Sciences: An Interdisciplinary,  Searchable, and Linkable Resource. 
Sargent, J. Q., Zacks, J. M., Hambrick, D. Z., Zacks, R. T.,  Kurby, C. A., Bailey, H. R., ... & Beck, T. M. (2013). Event  segmentation ability uniquely predicts event memory.  Cognition, 129(2), 241-255. 
Schwan, S., & Garsoffky, B. (2004). The cognitive  representation of filmic event summaries. Applied  Cognitive Psychology, 18(1), 37-55. 
Simons, D. J., & Chabris, C. F. (1999). Gorillas in our  midst: Sustained inattentional blindness for dynamic  events. Perception, 28(9), 1059-1074. 
Tanaka, Y., & Baldwin, D. (in preparation) Implicit measures  of event segmentation using pupillary response.  Unpublished manuscript, University of Oregon. 
Zacks, J. M., Braver, T. S., Sheridan, M. A., Donaldson, D.  I., Snyder, A. Z., Ollinger, J. M., ... & Raichle, M. E.  (2001). Human brain activity time-locked to perceptual  event boundaries. Nature neuroscience, 4(6), 651-655. 
Zacks, J. M., Tversky, B., & Iyer, G. (2001). Perceiving,  remembering, and communicating structure in events.  Journal of Experimental Psychology: General, 130(1), 29. 
Zacks, J. M., Speer, N. K., Vettel, J. M., & Jacoby, L. L.  (2006). Event understanding and memory in healthy aging  and dementia of the Alzheimer type. Psychology and  aging, 21(3), 466. 
Zacks, J. M., & Swallow, K. M. (2007). Event  segmentation. Current directions in psychological science,  16(2), 80-84. 
Zacks, J. M., Kurby, C. A., Eisenberg, M. L., &  Haroutunian, N. (2011). Prediction error associated with  the perceptual segmentation of naturalistic events. Journal  of Cognitive Neuroscience, 23(12), 4057-4066. 
1962
Levels of Analysis in Computational Social Science 
Peter M. Krafft (pkrafft@berkeley.edu) 
Thomas L. Griffiths (tom griffiths@berkeley.edu) 
Department of Psychology, University of California, Berkeley Social Science Matrix, University of California, Berkeley 
Abstract 
Marr’s levels of analysis constitute one influential approach to the central program of cognitive science—the multilevel anal ysis of cognition as information processing. The distinctive aspects of Marr’s framework are an emphasis on identifying the computational problems and constraints faced in cognition, and conceptual machinery to relate cognitive mechanisms to that computational level of analysis. Although related ideas have been explored in a range of social science disciplines, Marr’s framework, and particularly its notion of the precise formulation of computational problems and solutions, has yet to be applied widely in social analysis. In the present work we develop a formulation of Marr’s levels for social systems, provide examples of this approach, and address potential criti cisms. The consequence is a computational perspective on the sociological school of structural functionalism, and an appara tus for conducting multiscale analysis of social systems. 
Keywords: Computational social science; Marr’s levels of analysis; structural functionalism; analytical sociology; com putational social theory 
Introduction 
Marr (1982) famously argued that any information processing system can be analyzed at three levels, that of (1) the compu tational problem the system is solving; (2) the algorithm the system uses to solve that problem; and (3) how that algorithm is implemented in the “physical hardware” of the system. This decomposition offers both functional and mechanistic perspectives on information processing systems. Marr’s main aim was understanding psychology and the human brain, and his levels of analysis have proven to be a useful conceptual tool for generations of cognitive scientists after him. 
Considering that aspects of human cognition can be pro ductively viewed as information processing, and that social groups consist in part of sets of people who exchange infor mation, it is natural think about how Marr’s levels of analysis could be productively applied in the analysis of social sys tems. An immediate difficulty occurs with a na¨ıve applica tion, however. Taking the disciplinary commitments of cog nitive science for granted, we can clearly model social sys tems as distributed computer programs. Yet, there is no guar antee at all that the resulting computer programs implement any coherent distributed solution to particular computational problems. Far from all human collective behavior, or for that matter far from all combinations of synthetic intelligent agent behavior, has any functional purpose. Well-recognized examples of collective dysfunction resulting even from in telligent agents include information cascades (Bikhchandani, Hirshleifer, & Welch, 1992), phantom traffic jams (Kerner & Konhauser, 1993), and the tragedy of the commons (Ostrom, ¨ 2015). The na¨ıve application of Marr’s levels of analysis to social systems therefore only extends as far as an algorithmic 
level of analysis—representing social systems as distributed computer programs. The na¨ıve application does not neces sarily extend through to the computational level, in which the combination of agent behavior, taken holistically, would have to yield coherent distributed computation at the population level. To address this difficulty, we pursue a program of iden tifying which social behaviors and structures can be produc tively conceptualized as having computational roles. 
There are several existing approaches in the social sciences related to Marr’s framework. The field of organization sci ence has explicitly adopted information processing perspec tives since the seminal work of Herbert Simon. Simon, who was an early thinker on the topic of information processing in the context of human behavior (Simon, 1978), also applied these ideas to organizations. In one famous passage, Simon writes: “In the post-industrial society, the central problem is not how to organize to produce efficiently ... but how to organize to make decisions, that is, to process information” (Simon, 1973, p. 269–270). Financial markets are also com monly understood as information processing systems. In a classic economics paper, Hayek states: “the economic prob lem of society ... is a problem of the utilization of knowledge not given to anyone in its totality” (Hayek, 1945, p. 519–520). 
Marr’s algorithmic and implementation levels are akin to mechanistic explanations. Mechanistic explanations are pop ular in the classical area of mathematical sociology, such as in Schelling’s seggregation model (Schelling, 1971) or Gra novetter’s threshold model (Granovetter, 1978), and remain popular in the modern area of analytical sociology (Hedstrom¨ & Bearman, 2009). Recent progress in the field of economics and computation highlights the algorithmic side of the math ematical notion of game-theoretic equilibrium (Daskalakis, Goldberg, & Papadimitriou, 2009). Mechanisms have also been a target of inquiry in organization science, such as in the study of transactive memory (Wegner, 1987). 
These existing lenses in the social sciences fit naturally within Marr’s framework, and therefore point towards a syn thesis of a cognitive, information-processing view of a wide variety of social systems. At the same time, many of these classic works did not draw explicit parallels to distributed computation, or did not leverage the hierarchies of abstrac tion familiar to computer scientists that Marr deploys. Cog nitive scientists have begun to explicitly explore the appli cation of Marr’s levels to social systems. Hutchins (1995) pioneered the application of Marr’s levels to social systems in his ethnography of distributed cognition in team behavior on a naval vessel. To Hutchins, the computation performed by a naval vessel was that of navigation—calculating where 
1963
you are and determining how to get where you want to go. Hutchins provided a detailed account of how this function is accomplished by the crew members and their interactions with each other and with artifacts on the ship. 
Hutchins’ example makes it clear that the explicit applica tion of Marr’s levels can be productive in the context of teams and organizations. However, one of the reasons this exam ple easily fits into Marr’s framework is because teams and organizations have well-defined group boundaries and have functions that are explicit in the goals of these groups. These goals then dictate the information processing challenges the groups face. An important outstanding question is to what extent Marr’s approach can be applied to more loosely orga nized social systems that are often the subject of sociology. 
The functionalist lens, used in sociology for a variety of less strictly organized and less explicitly engineered so cial systems, provides reason to believe that there is space for such an attempt to be fruitful. Structural or sociologi cal functionalism—i.e., the pursuit of understanding social structures and behavior in terms of how they solve social problems—is one of the classic theoretical perspectives in so ciology. Many early sociologists held views that a variety of social phenomena played functional roles in society. For in stance, Spencer (1898) advocated for an equilibrium view of society and drew extensive analogies between social and bi ological function. Durkheim (1893) presented a functionalist argument that division of labor acts as a mechanism of so cial solidarity promoting a cohesive social bond. Although functionalism was and continues to be controversial in soci ology (Weber, 1922; Giddens, 1984), scholars still lean on it in modern studies. Yet, unlike in organization science, ex plicit information processing analogies are barely ever used in sociology. 
In the present work, we explicate the application of Marr’s levels to loosely organized social systems, review examples of recent work that fit within this paradigm, address chal lenges to this approach, and explore its potential and limi tations. The main benefit of Marr’s approach is that com putation provides an expressive language for high-level, ab stract theory, while providing the conceptual machinery to re late that abstract level to mechanistic explanations. Computa tional social theory can therefore be precisely specified, and tested via its relation to algorithmic and behavioral descrip tions. At the same time, Marr’s charge to identify compu tational problems that information processing systems solve could provide inspiration for research questions in computa tional social science. 
Illustrative Examples 
Before more carefully defining Marr’s levels for social anal ysis, we begin with three motivating illustrative examples. 
Waiting in Line 
A simple example that illustrates Marr’s three levels of anal ysis in a social system is waiting in line. A line, for instance outside a professor’s office, consists of a group of people, 
Computational Level: 
FIFO Queue Problem 
Serve people in order of arrival. 
Algorithmic Level: 
Distributed Linked List Data Structure 
Maintains arrival order. 
Implementation Level: 
Figure 1: Marr’s levels of analysis for waiting in line. 
each standing behind another. This social behavior imple ments the computation of a first-in, first-out (FIFO) queue. A FIFO queue is a simple function used in computer science, for example to prioritize computer processes in the CPU. A FIFO queue takes as input a stream of entries, maintains the order of those entries, and outputs entries in that order. The representation that is used to solve the FIFO queue problem in the case of waiting in line is to maintain a linked list data structure between elements of the queue, and pop elements off the list as needed. A linked list is another data struc ture used computer science, in which each entry contains a “pointer” to the next element in the list. To “pop” a linked list means to remove the head element. In the example of waiting in line, the distributed algorithm that implements this linked list is for each person in the line to keep track of who is ahead of them. The physical implementation used to keep track of who is ahead of you in the line is simply to stand behind that person. Figure 1 illustrates this example. 
There are many failure modes to standing in line. Two peo ple can arrive at a similar time or be in a similar position and not be certain who is ahead of whom. Some people cut in line. Sometimes lines fail to form at all or totally collapse and become disorganized crowds of people waiting. There is also cultural variation in how much importance or value people place on lines as a useful mechanism. Taking Marr’s approach abstracts away these details and exposes the under lying information processing challenge at the heart of stand ing in line. Our ability to reason about the computational function of waiting in line can also suggest other engineered 
1964
solutions. Waiting in line is not the only solution to the FIFO queue problem. For example, some delis, grocery stores, and government offices implement ticket and announcement sys tems that obviate the need to keep your own place in line. 
Status Hierarchies 
As another example, many species of animals maintain some kind of social hierarchy, influencing the interactions between animals in a group and the way that they allocate resources such as food. At a computational level, this structure can be viewed as a solution to the problem of performing resource allocation with a minimum of conflict—an alternative to a costly free-for-all whenever resources become available. At the algorithmic level, there are many kinds of algorithms that can be used to impose an ordering on a group through pair wise comparison (i.e. fights or displays)—a whole branch of theoretical computer science is devoted to questions about sorting. However, here the implementation details matter: most sorting algorithms involve maintaining some kind of global record of the current ordering of the items being sorted. In an animal group, each animal needs to maintain such a record independently. Thus it makes sense to think about distributed algorithms in which individual animals operate as computational elements. Flack and Krakauer (2011) applied exactly this approach to modeling the decisions of monkeys to engage in fights, viewing these individual decisions as form ing “adaptive social circuits”. 
Rumors and Collective Sensemaking 
As a final motivating example, a classical and now well supported sociological theory of rumors conceptualizes ru mors as a natural part of a process of collective sensemaking (Shibutani, 1966; Bordia & DiFonzo, 2004; Huang, Starbird, Orand, Stanek, & Pedersen, 2015). According to this view, people try to make sense of the world together when they find themselves in uncertain environments. A computational perspective of rumors based on this view is as functioning to communicate hypotheses about the state of the environment (Krafft, Zhou, Edwards, Starbird, & Spiro, 2017). This per spective frames rumors as oriented towards a distributed in ference problem of inferring the state of the world given the evidence at hand. 
Marr’s Levels for Social Systems 
Having motivated computational and algorithmic perspec tives of social systems through our examples, we now expand upon the usage of Marr’s levels of analysis in social systems. 
Computational Level 
The first level of analysis Marr defined is the computational level. The computational level describes the problem that an information processing system is oriented towards solving. The information processing function that the social system accomplishes may be explicit due to design or implicit, as in Merton’s manifest versus latent functions (Merton, 1949). For this level of analysis to apply, the group must face some 
computational problem. The computational problems in our examples were implementing a FIFO queue, resource alloca tion, and distributed inference. Other common computational problems in social systems include aligning group mem ber preferences and solving coordination problems (Krafft, 2018). Unlike in cognition, in which computational problems are frequently posed by the external environment, many com putational problems faced by groups are endogenous. The need to coordinate is one example. The need to coordinate is an inherent result of existing as differentiated people. An other type of endogeneity is in problems that are created by history dependence. For instance, Durkheim offers that one view of the division of labor could be that by increasing our ability to create goods to relieve our increasing fatigue, divi sion of labor functions in part to meet the needs created by its very existence (Durkheim, 1893). 
The computational level of analysis is important because it allows the researcher to answer “why” questions—to under stand why people behave in a certain way. In order to justify a teleological interpretation of a social function, that function should either be explicitly intended or otherwise be evidently addressing a problem that threatens the group. For instance, we can say that conventions about which side of the street to drive on exist in order to solve a coordination problem. Some coherent distributed computations do not meet this criterion of solving a computational problem associated with an inten tion or a need of the group. In the tragedy of the commons, rational agents are computing an equilibrium, and therefore accomplishing a computational function, but this outcome is neither intended nor meeting a need. Therefore this collective behavior cannot be productively interpreted as functional, and Marr’s computational level does not apply. 
Another important qualification in the social case is that the computational problem is one faced by the group, com munity, or society. Every individual in a group has their own problems and goals, and some behavior will be oriented to wards those individual needs and not any shared needs of the group. Selfish behavior of this sort is one reason why we can not treat all compositions of rational behavior as functional group behavior. This issue is at play in the tragedy of the commons and other social dilemmas from game theory. 
The definition of social functions is also only with respect to the boundaries of the group being analyzed, and does not represent a moral judgment. Accomplishing a computational function in one group can cause problems for other groups; consider the case of one group finding a new place to build a settlement and displacing another group. In line with We ber’s interpretive approach (Weber, 1922), insofar as we are aiming to understand why people are engaging in certain so cial behaviors, we must interpret function with respect to the values of the people in the group being analyzed. 
Algorithmic Level 
Marr’s second level of analysis is the algorithmic level. The algorithmic level describes the way in which a computational problem associated with an information processing system is 
1965
solved. An algorithm involves both the representations of in formation used and the transformations of those representa tions. In social systems, the fundamental algorithms at play are most readily conceptualized as distributed algorithms, in which multiple people are participating as agents akin to net worked computer processors. This perspective of social pro cesses as distributed algorithms is closely related to agent based modeling (Macy & Willer, 2002), the study of social mechanisms in analytical sociology (Hedstrom & Bearman, ¨ 2009), and the study of natural algorithms in theoretical com puter science (Chazelle, 2009). 
The critical criterion for an algorithmic explanation within Marr’s framework is that the behavior being examined offers a proper solution to the computational problem posed in the computational level of analysis. This criterion pushes beyond purely descriptive studies of social mechanisms, as in many agent-based or rational models, towards a formal relationship between mechanisms and social functions. In the example of waiting in line, the FIFO queue is accomplished if each per son keeps their place. While deviant behavior such as line cutting could be included in an agent-based model, a strict al gorithmic analysis does not accommodate cases when some people cut in line for no reason other than their own self interest, because this behavior undermines the correct com putation of the FIFO queue. 
Implementation Level 
The final level of analysis Marr defines is the implementation level. An algorithm is an abstract process-level description. The implementation level explains how the algorithm is im plemented through actual interaction of basic elements. In social systems, the definition of the implementation level is contingent on what elements of the system are taken as prim itive. Typically, social systems are reduced to psychologi cal processes, and connections to neural processes are left to cognitive scientists. This division leaves the implementation level to be concerned with psychological processes, details of social interaction, and contextual elements such as geogra phy, social network structure, and artifacts in the environment as building blocks. The implementation level can be thought of as a second, lower-level algorithmic analysis. 
Benefits of the Approach 
There are several potential gains to be had from employing Marr’s levels of analysis to understand social systems. One benefit is a deductive approach to discovering mechanisms. In analytical sociology, the discovery of mathematical de scriptions for social mechanisms is often post hoc and in ductive from observations. Marr’s levels provide a deductive, reverse-engineering approach. In this approach, the compu tational problem being faced by a group is specified first, and then algorithms to solve that problem are explored. For in stance, in the case of conceptualizing rumors as distributed inference, we can look to the literature on algorithms for dis tributed inference in search of mechanisms. To understand 
coordination, there is a wealth of literature in computer sci ence on engineering distributed systems. 
A second benefit is a rigorous approach to providing math ematical evidence for functionalist sociological theories. Tak ing the rumor example again, suppose we wanted to provide evidence that rumors function as a mechanism of collective sensemaking. Suppose we can show that a distributed in ference algorithm as a behavioral model explains observed behavior better than alternative mechanisms, such as a con tagion model or a thermodynamic model. The evidence for that distributed algorithm then in turn provides evidence for the functional interpretation of rumors since there is a math ematical relationship between the algorithmic model and the problem of distributed inference. 
A final benefit is for design. Once a social problem is spec ified precisely as a computational problem, then we can do more than just understand how current social behavior might address this problem. We can also search for alternative social behaviors or structures that better solve the problem accord ing to some criteria. The value of precise computational spec ification is that this search through design space can be auto mated. An example of this approach is in automated mecha nism design (Conitzer & Sandholm, 2003). 
Challenges to the Approach 
There are several interrelated challenges and potential cri tiques of the indiscriminate application of Marr’s approach to social systems. We now address what we view as the major challenges. Our responses to these challenges center around an argument that a program of Marr’s approach to social systems aims to produce useful, idealized hierarchical mathematical descriptions, but should not be conducted with out also paying careful attention to the specifics of the social context being studied and the political aspects of that inquiry. 
Multiagent Systems versus Human Social Systems 
One potential criticism that we can readily dismiss involves the difference between human social systems and artificial multiagent systems or distributed computer systems. Com puter networks offer quite different affordances and con straints as compared to social systems. For instance, comput ers can easily communicate their entire internal states with complete precision to each other. Communication is much harder for people, but at the same time, people have a richer range of distinctive forms of communication, including sym bolic and cultural systems. Social networks, the physical ity of human interaction, social norms and institutions, and many other contextual factors form additional components that must be considered in the case of social systems. Al though distributed computer systems and distributed social systems clearly have widely differing constraints and affor dances, the mathematical language we use to describe both types of systems, the classes of algorithms that are employed, and some fraction of the computational problems each type of system faces could still be similar. 
1966
Methodological Individualism 
A classic criticism of functionalism is that of methodological individualists or “reductionists”. The view of methodologi cal individualism would assert that a group-level functional ist perspective is unnecessary for explaining the behavior of social systems. Under such a view, any group-level structure supervenes on the individual-level beliefs, intentions, plans, and behaviors. A social system therefore cannot be properly understood as having a function. To have a function means that the social system as a whole has a causal role in a broader ecosystem. But according to the reductionist view, the social system as a whole plays no causal role in the system dynam ics. The only causally relevant entities are the components. 
There are several responses to such a criticism. The re sponse requiring the weakest logical commitments is that function can serve as a useful description that succinctly summarizes the behavior of the system, without making any causal claims. The usefulness of the description alone justi fies a functionalist inquiry. When conceptualizing social sys tems “as if” they had functions allows us to better understand them, then such concepts are valuable. Another response is to assert that there can be multiple scales of causal explanations, and functions serve a causal role at an aggregate level. For in stance, in a counterfactual world where people have no way to implement a FIFO queue at the professor’s office, then the operations of the group—who gets in when—would be fun damentally different. Therefore the operation of office hours can rightfully be conceptualized as having a dependence on the ability of people to implement a FIFO queue. 
A related response is that certain functions are irreducible emergent properties of the social system, meaning that the behavior of the social system cannot be properly understood without understanding its emergent functions. This argument asserts that there is downward causality from emergent func tion to the constituents of the system. For instance, consider two competing hunting groups whose members must hunt together to be successful, and suppose the members of one group have synchronized clocks. It is the ability of the group to accomplish the task of coordination that allows the group to be more effective, not anything about the individuals in and of themselves. If the clocks did not accomplish the function of coordination, the individuals would not benefit. 
Non-adaptive Functions 
We argued in our definition of the computational level of anal ysis that the computational functions being analyzed must be beneficial to the group in order for the function to have a tele ological interpretation, which is an implicit aim of Marr’s computational level. Some collective behavior implements coherent computation that is either harmful or epiphenom enal. For instance, Schelling’s (1971) segregation model showed how small individual biases could lead to a popu lation clustering itself according to attributes such as race. Clustering or sorting could then be said to be an information processing function implemented by Schelling’s mechanism. 
At the same time, we might think that segregation is actually a maladaptive characteristic of a population. In a more recent example, a group of analytical sociologists presented a mul tiscale analysis of adolescent sexual behavior, and showed that the behavioral mechanisms of these people led to net works that tended to have structures similar to spanning trees (Bearman, Moody, & Stovel, 2004). Spanning trees are good for the sexual health of the community in some ways but bad in other ways, and thus do not serve a clear function. These analyses benefit from the same mathematical machinery that we use in the computational level analysis, but fall outside its scope in our definition. 
Dysfunctional Collective Behavior 
Another concern is individual behaviors that lead to incoher ent or unstructured collective behavior, and individual or col lective behaviors that appear functionally oriented but fail to accomplish any function. Social behavior that leads to in coherent or unstructured collective behavior, such as people going about their own individual business within their homes, simply may not have group-level structure that lends itself to illuminating interpretation via Marr’s levels. One prominent and perhaps surprising example of this sort is agent-based models. Although agent-based models can be described as computer programs, their aggregate dynamics are sometimes chaotic or unstructured. The scope of Marr’s levels therefore is not as wide as the class of all processes that can be de scribed as distributed computer programs. Other behaviors may appear functionally oriented but are suboptimal or to tally dysfunctional. Here, Marr’s approach simply may not apply if the social system does not have group-level informa tion processing characteristics. 
Sociological Critiques 
A final set of threats to applying Marr’s levels to social sys tems are inherited from other challenges to sociological func tionalism. Despite still being influential in contemporary so ciology, functionalism has been criticized for abstracting and obscuring many key details of social phenomena. Conflict theorists have emphasized how functionalism diminishes the struggle of marginalized groups, the importance of revolu tionary change, and the role of individual human agency in society. In a somewhat separate line of critique, Giddins’ structuration theory explores how function and structure co evolve continuously across space and time and cannot be neatly separated (Giddens, 1984). 
We follow Weber (1922) in responding to these criticisms by noting firstly that a functional description can still be use ful for certain ends, although non-functional aspects must be considered for a complete treatment of any system; and a functionalist analysis may still be illuminating to see how a population deviates from an idealized solution. That said, we must always keep in mind the balance between the clarity provided by abstraction and the frequent importance of the details that are abstracted away. 
1967
Conclusion 
Analysis of social systems is challenging in part due to the diversity and complexity of the people in these systems and their interactions. Abstraction of social processes should be approached with caution but can help to highlight generaliz able insights and underlying principles at play. In the present work we have outlined the application of Marr’s levels of analysis to a broad range of social systems. This framework provides machinery for abstraction, and for relating abstract levels to lower levels of explanation. 
Given our discussion of criticisms in the previous section, we can make an informed attempt at outlining the scope of Marr’s approach for social systems. Marr’s levels have clear utility and have been used in cases where groups have an explicit shared goal of executing an information processing task, such as in teams and organizations. We have argued that Marr’s levels of analysis can also be useful in cases where people are self-organized—whether by coincidence, by inten tion, or through biological or cultural evolution—to execute coherent information processing. Cases that are less appro priate are when group behavior is unstructured, incoherent, or structured but not oriented towards information processing. 
There are several classes of computational problems and algorithms that may be useful in deploying Marr’s levels of analysis for social systems. Multiagent systems is one of the most relevant areas (Shoham & Leyton-Brown, 2008). The area of multiagent systems provides a wide variety of formalisms that are useful for both specifying problems and algorithms, including multiagent decision problems (Bernstein, Zilberstein, & Immerman, 2000) and computational models of shared cooperative activity (Grosz, Hunsberger, & Kraus, 1999). There are also many distributed algorithms outside the literature on multiagent systems, such as fault-tolerant distributed algorithms for consensus (Lynch, 1996). Distributed machine learning is another promising area to draw upon. Future work could deploy Marr’s levels of analysis to further explore links between developments in these areas and the study of social systems. 
Acknowledgments. Special thanks to Josh Tenenbaum, Sandy Pentland, David Krakauer, and Jessica Flack who helped stimulate an initial investigation into these ideas; to Josh for his suggestion to think about the example of waiting in line; and to Nick Logler, Steph Ballard, and Lavi Aulck for their special assistance. This work was supported by DARPA Cooperative Agreement D17AC00004. 
References 
Bearman, P. S., Moody, J., & Stovel, K. (2004). Chains of affec tion: The structure of adolescent romantic and sexual networks. American Journal of Sociology, 110(1), 44–91. 
Bernstein, D. S., Zilberstein, S., & Immerman, N. (2000). The com plexity of decentralized control of Markov decision processes. Proceedings of the Sixteenth Conference on Uncertainty in Ar tificial Intelligence, 32–37. 
Bikhchandani, S., Hirshleifer, D., & Welch, I. (1992). A theory of fads, fashion, custom, and cultural change as informational cas cades. Journal of Political Economy, 100(5), 992–1026. 
Bordia, P., & DiFonzo, N. (2004). Problem solving in social inter actions on the internet: Rumor as social cognition. Social Psy chology Quarterly, 67(1), 33–49. 
Chazelle, B. (2009). Natural algorithms. Proceedings of the Twenti eth Annual ACM-SIAM Symposium on Discrete Algorithms, 422– 431. 
Conitzer, V., & Sandholm, T. (2003). Applications of automated mechanism design. UAI-03 Workshop on Bayesian Modeling Ap plications. 
Daskalakis, C., Goldberg, P. W., & Papadimitriou, C. H. (2009). The complexity of computing a Nash equilibrium. SIAM Journal on Computing, 39(1), 195–259. 
Durkheim, E. (1893). Division of labor in society. Paris: Alcan. Flack, J. C., & Krakauer, D. C. (2011). Challenges for complex ity measures: A perspective from social dynamics and collective social computation. Chaos: An Interdisciplinary Journal of Non linear Science, 21(3), 037108. 
Giddens, A. (1984). The constitution of society: Outline of the theory of structuration. University of California Press. Granovetter, M. (1978). Threshold models of collective behavior. American Journal of Sociology, 83(6), 1420–1443. 
Grosz, B. J., Hunsberger, L., & Kraus, S. (1999). Planning and acting together. AI Magazine, 20(4), 23. 
Hayek, F. A. (1945). The use of knowledge in society. The American Economic Review, 35(4), 519–530. 
Hedstrom, P., & Bearman, P. (2009). ¨ The Oxford handbook of ana lytical sociology. Oxford University Press. Huang, Y. L., Starbird, K., Orand, M., Stanek, S. A., & Pedersen, H. T. (2015). Connected through crisis: Emotional proximity and the spread of misinformation online. Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing, 969–980. 
Hutchins, E. (1995). Cognition in the Wild. MIT Press. Kerner, B. S., & Konhauser, P. (1993). Cluster effect in initially ¨ homogeneous traffic flow. Physical Review E, 48(4), R2335. Krafft, P. (2018). A simple computational theory of general col lective intelligence. Topics in Cognitive Science (topiCS) Special Issue on Computational Approaches to Social Cognition. Krafft, P., Zhou, K., Edwards, I., Starbird, K., & Spiro, E. S. (2017). Centralized, parallel, and distributed information processing dur ing collective sensemaking. Proceedings of the 2017 CHI Con ference on Human Factors in Computing Systems, 2976–2987. Lynch, N. A. (1996). Distributed algorithms. Morgan Kaufmann. Macy, M. W., & Willer, R. (2002). From factors to actors: Compu tational sociology and agent-based modeling. Annual Review of Sociology, 28(1), 143–166. 
Marr, D. (1982). Vision: A computational approach. MIT Press. Merton, R. K. (1949). Social theory and social structure. The Free Press. 
Ostrom, E. (2015). Governing the commons. Cambridge University Press. 
Schelling, T. C. (1971). Dynamic models of segregation. Journal of Mathematical Sociology, 1(2), 143–186. 
Shibutani, T. (1966). Improvised news: A sociological study of rumor. The Bobbs-Merrill Company. 
Shoham, Y., & Leyton-Brown, K. (2008). Multiagent systems: Al gorithmic, game-theoretic, and logical foundations. Cambridge University Press. 
Simon, H. A. (1973). Applying information technology to organi zation design. Public Administration Review, 33(3), 268–278. Simon, H. A. (1978). Information-processing theory of human prob lem solving. In W. K. Estes (Ed.), Handbook of learning and cog 
nitive processes (Vol. 5, pp. 271–295). Hillsdale, NJ: Lawrence Erlbaum Associates. 
Spencer, H. (1898). The principles of sociology. New York: D. Appleton and Company. 
Weber, M. (1922). Economy and society: An outline of interpretive sociology (Vol. 1). 
Wegner, D. M. (1987). Transactive memory: A contemporary anal ysis of the group mind. In Theories of group behavior (pp. 185– 208). Springer. 
1968
Wiggle, Wiggle, Wiggle: How Visual Cues Influence Thematic Role Assignment in Children and Adults 
Julia Marina Kröger (jkroeger@cit-ec.uni-bielefeld.de) 1 
Katja Münster (muenstek@hu-berlin.de) 2 
Michele Burigo (mburigo@cit-ec.uni-bielefeld.de) 1 
Pia Knoeferle (pia.knoeferle@hu-berlin.de) 2 
1 Center of Excellence Cognitive Interaction Technology (CITEC), Bielefeld, Germany 
2 Department of German Studies and Linguistics, Berlin, Germany 
Abstract 
German 5-year-olds are able to rapidly recruit depicted ac tions to assign thematic roles in unambiguous sentences when these actions can be inspected throughout sentence presenta tion (Münster, 2016; Zhang & Knoeferle, 2012). In two visual world eye tracking studies, we investigated whether these find ings extend to locally structurally ambiguous utterances and to short-lived action presentation. In addition, we compared the action depiction to a character’s wiggling motion. The ac tion and the wiggle served as cues to the agent (subject) in difficult-to-understand OVS sentences. Participants listened to structurally ambiguous object-verb-subject (OVS) sentences about, for instance, a bug being pushed by a bull while in specting a bull, a bug, and a worm. We manipulated the scene at verb-onset such that either a) no action no wiggle, b) no action one wiggle, c) one action no wiggle, or d) one action one wiggle appeared. Both of these animations caused the adults and the children to visually anticipate the agent role filler (corresponding to the subject in the OVS sentence) be fore its mention. However, in answering post-trial who-does what-to-whom comprehension questions, the children did not (unlike suggested by previous findings) benefit from the action depictions. Together the eye-gaze and post-trial comprehen sion results suggest that the nature of cue presentation (e.g., the abrupt onset of an action or a wiggle and limitations on cue presence) plays an important role in both the immediate visual attention and somewhat later interpretation effects of such vi sual cues during children’s language comprehension. 
Keywords: Visual-world paradigm, eye movements, child lan guage comprehension, thematic role assignment, depicted ac tions, wiggle, non-linguistic visual cues 
Introduction 
Adult comprehenders can exploit a variety of non-linguistic cues in their incremental interpretation of spoken utterances. Visual referential context, contrast between objects, object affordances, depicted actions, or events can each rapidly influence spoken language comprehension (e.g., Chambers, Tanenhaus, & Magnuson, 2004; Knoeferle, Crocker, Scheep ers, & Pickering, 2005; Sedivy, Tanenhaus, Chambers, & Carlson, 1999; Tanenhaus, Spivey-Knowlton, Eberhard, & Sedivy, 1995). The utterance, in turn, can guide visual atten tion to objects in the scene, and that attention can be ‘antici patory’ such that adult listeners visually anticipated a referent even before it was mentioned (Altmann & Kamide, 1999). 
For children, however, some but not all of these aspects of situated language (processing) are present from day one. First evidence for the close temporal coordination of visual atten tion and auditory input comes from a study on 6-month-olds 
(Richardson & Kirkham, 2004). These experienced an object (e.g., a toy) jointly with a sound (e.g., boing boing) and im mediately after listened to a spatially non-informative boing sound without the toy present. The infants inspected the side of the screen that the associated toy had just occupied more than the other side of the screen. Similarities in children’s and adults’ visual attention behaviour also emerged during utterance comprehension. Much like adults, 10-11-year-olds (Nation, Marshall, & Altmann, 2003) and 2-year-olds (Mani & Huettig, 2012) rapidly anticipated an upcoming target (a cake vs. a bird as a distractor object) during eats the when they listened to The boy eats the big cake (vs. The boy sees the big cake); but at the age of two this was only the case for skilled (vs. unskilled) language producers (Mani & Huet tig, 2012). Eye-movements in this paradigm also revealed differences between child and adult language processing. For instance, while 36-month-olds much like adults rapidly gazed at a blue car when responding to questions such as ’Can you find the blue car?’ in the presence of a red and a blue car, 30- month-olds shifted their gaze more often towards an incorrect referent (Fernald, Thorpe, & Marchman, 2010). 
Further differences emerged in referential context effects during structural disambiguation (Trueswell, Sekerina, Hill, & Logrip, 1999). Five-year-olds listened to ambiguous (e.g., Put the frog on the napkin in the box) and unambiguous (e.g., Put the frog that’s on the napkin in the box) instructions and inspected contexts which contained either one or two possible referents for the frog (one-referent context: a frog, a horse, an empty napkin, a box; two-referent context: a frog on a napkin, another frog, an empty napkin, and a box). In the ambiguous instruction, on the napkin could either be interpreted as the location or as the destination of the frog. The 5-year-olds interpreted the napkin as the frog’s destination even when the two-referent context biased towards a location interpretation. Unlike adults, the five-year-olds were unable to infer from the referential context (two frogs) that on the napkin modified the frog. These and related findings support the idea that child language processing differs from adult language processing. 
However, children’s thematic role assignment in struc turally unambiguous German sentences was influenced by depicted action events (Münster, 2016; Zhang & Knoeferle, 
1969
2012). While listening to unambiguous subject-verb-object (SVO: e.g., Der Bär schubst sogleich den Stier. - ‘The bear (subj) pushes immediately the bull (obj).’) and object-verb subject (OVS: e.g., Den Bär malt sogleich der Wurm. - ‘The bear (obj) paints immediately the worm (subj).’) sentences, 4- 5-year-olds inspected scenes containing a bear, a worm, and a bull. Actions were (vs. weren’t) depicted (e.g., for the verb push the bear either held its hands towards the bull (vs. close to its own body). When actions were depicted, children vi sually anticipated the patient (i.e., the worm vs. agent: the bull) in SVO sentences before its mention (during sogleich, ‘soon’) and the agent (vs. patient) in OVS sentences (com pared with when the actions were not depicted). The results for the adult control group were similar but adults started to inspect the target agent one word earlier (during the verb). Depicted actions further improved children’s (but not adults’) responses to post-sentence comprehension ‘who does what to whom’ questions for the OVS sentences. It seems children can rapidly recruit depicted action events at least for inter preting structurally unambiguous utterances. Adults can even recruit them for incremental thematic role assignment in lo cally structurally ambiguous SVO and OVS sentences (Knoe ferle et al., 2005). 
Prior research has further investigated the effects of dif ferent types of information in scenes on language compre hension: speaker gaze vs. a dot cursor (Brennan, Chen, Dickinson, Neider, & Zelinsky, 2008), speaker gaze vs. an arrow (Staudte, Crocker, Heloir, & Kipp, 2014), actor gaze vs. recent action events (Abashidze, Knoeferle, & Carminati, 2015), depicted actions vs. a recent emotional speaker face (Münster, Carminati, & Knoeferle, 2015), and speaker gaze shifts vs. depicted actions (Kreysa, Knoeferle, & Nunneman, 2014). Although all of these visual cues rapidly informed language comprehension in adults, some had similar whereas others had distinct effects on language comprehension (e.g., depicted actions and speaker gaze shifts elicited looks to a target character with the same time course when they were both employed as deictic cues; the time courses differed when the verb had to be processed more in-depth semantically; an emotional prime face only seemed to affect the listeners’ vi sual attention when an action was also depicted). The extent to which distinct visual cues can guide comprehenders’ vi sual attention and influence their language comprehension is largely an open question, as is the extent to which they are processed in a similar fashion by children and by adults for disambiguating non-canonical sentences. The latter are diffi cult to process due to an SVO over OVS word order bias in German. It is further unclear to which extent these cues in fluence thematic role assignment when they (unlike in prior research) appear for only a short time during comprehension, similar to some linguistic cues. 
The Present Research 
The present research, thus, assessed whether depicted action events (that are mediated by the verb) rapidly influence chil dren’s thematic role assignment in locally structurally am 
biguous OVS sentences when the action is only co-present for a short period of time. We explored the influence of fur ther distinct cues (a wiggling motion of a character). A wig gling motion presents an interesting comparison since it is not mediated by the verb but co-located with the agent (and might thus attract the listeners’ attention to the agent). The wiggle could function as a pragmatic/focusing cue to the ex tent that comprehenders infer that the wiggling (vs. not wig gling) character is the agent, disambiguating sentence struc ture. Does a wiggling target character help children to cor rectly assign thematic roles (eliciting agent inspection) or do they fail to draw pragmatic inferences as suggested by Trueswell et al. (1999) where children had to infer that the napkin modified one of the two frogs? If not per pragmatic inferences, a wiggling character might first attract the com prehenders’ attention through the abrupt motion, resembling an action, implicating thematic role assignment processes. 
The participants inspected a scene (Fig. 1) and listened to OVS sentences (Fig. 2). Figure 2 depicts cue presentation. If children and adults rely on distinct short-lived visual cues for correct thematic role assignment, they should look more to the target character (the agent: the bull) during or shortly after they have heard the verb when a visual cue had been present (vs. absent) during the verb. If one cue is stronger than the other, we expect a difference in looks to the target character for the depicted action and the wiggle condition. If the addition of visual cues (depicted action plus wiggle) has beneficial effects, we expect a preference to inspect the agent in the depicted action plus wiggle condition compared to the depicted action or wiggle (one-cue) condition. 
In addition to eye gaze we measured comprehension via post-sentence comprehension questions. We expected to find a difference between children and adults. In ambiguously case marked OVS sentences, case marking on the second noun phrase disambiguates the sentences. Prior research has suggested that adults can use case marking for correct thematic role assignment (Kamide, Scheepers, & Altmann, 2003; Matzke, Mai, Nager, Rüsseler, & Münte, 2002; Zhang & Knoeferle, 2012). If so, adults should make correct re sponses independent of cue presence. Children’s ability to use case marking (in the absence of helpful visual context), however, seems to be limited to visual contexts that provide further information such as world knowledge (Özge, Mün ster, Knoeferle, Küntay, & Snedeker, 2016 but Kröger, Mün ster, & Knoeferle, 2017; Dittmar, Abbot-Smith, Lieven, & Tomasello, 2008; Schipke, Friederici, & Oberecker, 2011). Our visual contexts did not provide any such further informa tion, and children should be at chance in responding in the no cue condition. If children are, however, able to use visual cues for the correct interpretation of ambiguous OVS sentences, we should replicate the findings from Zhang and Knoeferle (2012): Improved accuracy when actions are depicted (vs. not depicted), perhaps even more in passive voice compre hension questions (Münster, 2016). If the wiggle effects re semble action effects, we expect more correct responses when 
1970
the wiggle is present (vs. absent). If one cue is stronger than the other, we should observe a difference in the amount of correct responses between the action and the wiggle cue. If two visual cues are better than one, we expect more correct responses in condition d) one action one wiggle compared to the single-cue conditions b) and c)). 
Experiment 
Participants 
24 young monolingual German adults (mean age = 27.8) and 24 monolingual five-year old German kindergarten children participated in the experiment. All of them had normal or corrected vision and hearing. Adults received 5 Euros and children received a toy and a certificate. Adults and the chil dren’s parents gave written informed consent and the children gave oral informed consent. The ethics committee of Biele feld University approved the experiment. 
Materials 
A linguistically trained female native German speaker recorded 24 ambiguously case marked transitive German object-verb-subject sentences. All sentences were ambigu ously case marked on the first noun phrase (i.e., either femi nine or neuter case - identical in nominative and accusative) and were assigned an OVS biasing prosodic contour (L*+H accent on the first noun phrase). Prosody was not part of the design, and we did not expect to find effects of prosody (see Kröger et al., 2017). Case marking on the second noun phrase was unambiguous and thus disambiguated who does what to whom. For each sentence, we created four visual scenes con taining three clipart animal characters. In condition a) no ac tion no wiggle, the scene contained the role fillers only (Fig. 1). In condition b) no action one wiggle, the agent wiggles up and down a fixed number of pixels. Condition c) one ac tion no wiggle depicts the agent performing an action (e.g., for the verb schubsen ’push’ the character was holding his hands out). In condition d) one action one wiggle the agent performs an action and wiggles at the same time (Table1). All cues were only present during the verb. 
Figure 1: Example image: condition a) no action no wiggle.   
The middle character was always mentioned at the begin ning of the sentence and was thus role ambiguous: it could act upon or being acted upon by one of the adjacent charac ters (the NP1 was ambiguously case marked and did thus not disambiguate who does what to whom). In Figure 1 the bull is the agent of the scene and the worm the patient. We counter balanced the role fillers such that in another scene the worm 
is the agent and the bull the patient. We avoided stereotypi cality (a bull is not a more stereotypical pusher of a bug than a bug in relation to a worm). The scenes were counterbalanced for left and right direction. In an additional 72 filler items we varied the number of depicted role fillers such that either one, two, or three role fillers were depicted and we used different sentence structures (SVOO, directOVSO, indirectOVSO) and different adverbs (manner, frequency, place). To avoid a clear OVS-biasing prosodic structure, half of the filler items were assigned an OVS-biasing prosody (L*+H on NP1) and half an SVO-biasing prosody (L*+H on NP1, H* on verb). One half of the filler items occurred in one of the experimental conditions and in the other half actions unrelated to the verb were depicted and characters other than the agent wiggled. For children, filler items were reduced to 8. 
Table 1: Conditions 
Condition Sentence Structure Visual Cue 
a ambOVS no action no wiggle b ambOVS no action one wiggle c ambOVS one action no wiggle d ambOVS one action one wiggle 
Procedure 
During the experiment, we monitored participant’s eye move ments with an Eyelink 1000 eye tracker. In the remote setup with a 16mm lens, the sampling rate was 500 Hz monocu lar and the average accuracy 0.5◦. Scenes were presented on a DELL laptop (screen resolution 1920x1080 pixels). Before the experiment, the experimenter conducted a manual calibra tion using a five-dot scheme. Participants saw the scene 2000 ms before sentence onset. The comprehension question, ei ther in active or in passive voice (active: Wer schubst hier? ’Who pushes here?’; passive: Wer wird hier geschubst ’Who is being pushed here?’), followed 1500 ms after sentence off set. All visual cues were time-locked to verb onset (Figure 2) because at this point in time the verb referenced the de picted action. The wiggle also occurred at verb onset so that we could perform a direct comparison between the different cues. The trials were separated by a drift correct point to ver ify calibration. Before the experimental items and the final calibration, practice items (N=4) introduced the experiment. The duration of each testing session was approximately 40 minutes for adults and 20 minutes for children. 
Analysis 
For the analysis, we predefined two word regions of interest: verb (verb onset to adverb onset) and adverb region (adverb onset to NP2 onset). We were interested in the verb region to observe the effects of the visual cues. We chose the adverb region for post-verbal effects. Within each scene, we prede fined two areas of interest: the left and right role filler (e.g., the bull - the agent and the worm - the patient). We did not in clude the middle role filler in the analyses because our depen dent measure was the anticipation of the NP2 role fillers (see 
1971
  

Figure 2: Visual cue presentation: Depicted actions: 1a) no cue 1b) cue depiction 1c) no cue. Wiggle: 2a) no cue, 2b) cue depiction (target character wiggles up and down 10 pixels - the arrow is for visualisation only), 1c) no cue. 
also Knoeferle et al., 2005). For the two time windows, we computed mean-log ratios of looks (see Arai, Van Gompel, & Scheepers, 2007; Carminati & Knoeferle, 2013). These log ratios represented the preference of looks towards the agent over the patient (ln(agent)/ln(patient)). Negative numbers in dicate more looks towards the patient (vs. agent) and posi tive numbers more looks towards the agent (vs. patient). The mean-log ratios of looks were subjected to an analysis of vari ance (ANOVA) by subjects and by items with a 2 (action) x 2 (wiggle) design. Post-sentence comprehension questions include correct (1) and false/no (0) responses. Based on the number of possible responses, we calculated the percentages of corrects responses by condition. We analysed the accuracy data using Generalised-Mixed-Effects Models (Bates, Mäch ler, Bolker, & Walker, 2014). 
Results 
Eye Movements. The analyses revealed main effects of ac tion and wiggle and an interaction of action and wiggle dur ing the verb and adverb region (all ps < .01) in both age groups (Figures 3, 4). In both word regions and age groups, paired-sample t-tests after Bonferroni (.05/6) revealed signif icant differences for the no-cue condition versus each of the visual cue conditions (verb, adverb: ps < .01). Adults and children preferred to look at the agent more when one or two of the cues were present compared to when no cue was. De scriptively, the adults’ mean-log ratios were higher for the verb than adverb region, indicating a more pronounced pref erence to look at the agent (vs. patient) during the verb than adverb. For children, paired-sample t-tests after Bonferroni (.05/6) showed a significant difference between condition b) no action one wiggle and condition d) one action one wiggle (ps < .01) during the adverb. Children’s preference to look at the agent (vs. patient) was boosted by the wiggle in the no action but not the action conditions. In children, the mean-log ratios were higher during the adverb than verb region. 
Accuracy. For adults the overall accuracy was 68.9%. The analyses of their scores revealed a marginal interaction (p = .07; the wiggle modulated accuracy in the action present but not the action-absent conditions; one action one wiggle 75% vs. the other conditions (a) 66.7%, b) 66%, c) 68.1%). Chil dren’s accuracy was 41.7%. An effect of voice reflected that children responded more accurately to active than passive voice questions (p < .001). The active voice data revealed a marginal effect of wiggle (p = .09). The effect of action was neither reliable overall nor in the active-question data. Children responded more accurately to active-voice questions when the wiggle was present (vs. absent). 
  

Figure 3: Adults: Mean log-ratios of looks towards the agent over the patient during the verb and adverb region in all four conditions. Error bars: 95% confidence intervals. 
  

Figure 4: Children: Mean log-ratios of looks towards the agent over the patient during the verb and adverb region in all four conditions. Error bars: 95% confidence intervals. 
Discussion 
We investigated the influence of distinct short-lived vi sual cues on thematic role assignment in ambiguously case marked German OVS sentences in children and adults. 
Eye-movements. The results corroborate the rapid de picted action effects reported by Zhang and Knoeferle (2012) and Münster (2016). But unlike in Zhang and Knoeferle (2012) and Münster (2016), looks to the target character in children were not delayed by one word region in our experi ment. We did observe some delay, however: Descriptively, for adults the presence of visual cues resulted in a higher preference to look at the agent during the verb (vs. adverb) 
1972
whereas children’s preference was higher in the adverb than verb region. The difference in the time course of gaze patterns likely resulted from presentation differences. In our study, the action and wiggle cues were limited to the verb, perhaps elic iting children’s more immediate attentional response, while they had been present throughout the sentence in prior re search. In addition to the action effects, a main effect of wig gle emerged, as well as an interaction of action and wiggle, all during the verb. While the action-based anticipation of the target agent was not modulated by wiggle presence in the children, when no action was present, children inspected the target agent more when the wiggle was present vs. absent. 
Accuracy. For adults, a marginal interaction emerged: When the action was present, an added wiggle (vs. no wig gle) elicited more correct responses; by contrast, wiggle pres ence did not influence accuracy when no action was present. Surprisingly, adult’s overall accuracy was very low (68.9%) although case marking on the second noun phrase disam biguated the sentences. The low accuracy on critical items may have resulted from language-scene mismatches in the fillers. These may have led the adults to interpret the case marking on the second noun phrase of OVS sentences as a ‘mismatch’, thinking it must be SVO, resulting in incorrect role assignment and responses to the questions. 
For children, we did not replicate the improved accu racy (with vs. without action depiction) reported previously (Zhang & Knoeferle, 2012). Unlike in the adult data, we found an effect of voice in the child accuracy data such that children responded significantly more often correctly to questions in active than passive voice. Children might have used the relationship between the visual cue and the agent: The correct response to active voice questions was the agent. Since the visual cue was either the agent performing an action or the agent wiggling, children may have used this relation ship in responding to active voice questions. Follow-up anal yses on the active-question data revealed a marginal effect of wiggle such that the wiggle had a positive effect on accura cies for active voice questions. Perhaps the children used the wiggle to keep the agent representation in working memory, facilitating access in response to the questions. 
Our eye-gaze results, however, do not corroborate the idea that the wiggle in particular boosts attention. In the adverb region, children looked significantly more often to the agent (vs. patient) when one action (vs. one wiggle) was depicted. Perhaps the wiggle increased the salience and / or focus of the agent representation in children with some delay only, elicit ing increased accuracy when the agent was the question target but not eliciting more inspection in real time. Future experi ments could assess this interpretation. 
Why then did the depicted action not boost children’s re sponses to comprehension questions as was the case in Mün ster (2016); Zhang and Knoeferle (2012)? One of the reasons why we failed to observe beneficial effects of depicted actions might be that our actions were depicted only for a short period of time. A wiggling target character could, however, also in 
terfere with thematic role assignment. Children acquire verb argument structure and associated abstract knowledge from an early age (e.g., Bencini & Valian, 2008; Messenger, Brani gan, McLean, & Sorace, 2012; Peter, Chang, Pine, Blything, & Rowland, 2015). Upon hearing a known transitive verb, children may know that the verb requires two arguments (e.g., agent and patient). The depicted action does indeed represent a two-argument event (e.g., the bug pushes the bull) and is thus compatible with the argument structure of the verb. The wiggle could, however, introduce a one-argument event (e.g., the bull wiggles) and thus be incompatible with the argument structure of the verb, perhaps reducing its immediate effects on eye gaze compared with the action depiction. But the wig gle effects on question accuracy suggests that participants at least by sentence-end had integrated the wiggle into the argu ment structure of the verb, perhaps because it had been - in its presentation - time-locked to the verb. 
In summary, our results support the idea that children’s and adults’ visual attention is immediately (at the verb) guided by the visual cues. But children’s post-trial response accuracy differed from previous findings and differed from that of the adults. Children - unlike in prior research seemed to be af fected more by the the wiggle in their responses while adults’ accuracy was highest for the combination of the two visual cues. Perhaps the temporal limitations in the presentation of the cues resulted in an immediate boost but with the negative effect that the children processed the actions less in-depth, eliminating the previously-observed benefit on their accuracy in responding to who-does-what-to-whom questions. Since children around the age of five still seem to struggle in in terpreting ambiguous and non-canonical sentence structures (SVO preference), the use of visual support (even if short lived) may be helpful to encourage language development. 
Acknowledgments 
This research was funded by the Project “FoTeRo” in the Focus center XPrag (DFG) and by the Cognitive Interac tion Technology Excellence Cluster (277, DFG). We thank Franziska and Doris Müller for their help in recruiting child participants and finding testing locations at kindergartens. 
References 
Abashidze, D., Knoeferle, P., & Carminati, M. N. (2015). Eye-tracking situated language comprehension: Imme diate actor gaze versus recent action events. In Pro ceedings of the 37th Annual Meeting of the Cognitive Science Society (pp. 31–36). 
Altmann, G. T., & Kamide, Y. (1999). Incremental interpre tation at verbs: Restricting the domain of subsequent reference. Cognition, 73(3), 247–264. 
Arai, M., Van Gompel, R. P., & Scheepers, C. (2007). Prim ing ditransitive structures in comprehension. Cognitive Psychology, 54(3), 218–250. 
Bates, D., Mächler, M., Bolker, B., & Walker, S. (2014). Fit ting linear mixed-effects models using lme4. Journal of Statistics Software, 67(1), 1-48. 
1973
Bencini, G. M., & Valian, V. V. (2008). Abstract sen tence representations in 3-year-olds: Evidence from language production and comprehension. Journal of Memory and Language, 59(1), 97–113. 
Brennan, S. E., Chen, X., Dickinson, C. A., Neider, M. B., & Zelinsky, G. J. (2008). Coordinating cognition: The costs and benefits of shared gaze during collaborative search. Cognition, 106(3), 1465–1477. 
Carminati, M. N., & Knoeferle, P. (2013). Effects of speaker emotional facial expression and listener age on incre mental sentence processing. PloS ONE, 8(9), e72559. 
Chambers, C. G., Tanenhaus, M. K., & Magnuson, J. S. (2004). Actions and affordances in syntactic ambigu ity resolution. Journal of Experimental Psychology: Learning, Memory, and Cognition, 30(3), 687–696. 
Dittmar, M., Abbot-Smith, K., Lieven, E., & Tomasello, M. (2008). German children’s comprehension of word or der and case marking in causative sentences. Child De velopment, 79(4), 1152–1167. 
Fernald, A., Thorpe, K., & Marchman, V. A. (2010). Blue car, red car: Developing efficiency in online interpreta tion of adjective–noun phrases. Cognitive psychology, 60(3), 190–217. 
Kamide, Y., Scheepers, C., & Altmann, G. T. (2003). Integra tion of syntactic and semantic information in predictive processing: Cross-linguistic evidence from german and english. Journal of Psycholinguistic Research, 32(1), 37–55. 
Knoeferle, P., Crocker, M. W., Scheepers, C., & Pickering, M. J. (2005). The influence of the immediate visual context on incremental thematic role-assignment: Evi dence from eye-movements in depicted events. Cogni tion, 95(1), 95–127. 
Kreysa, H., Knoeferle, P., & Nunneman, E. M. (2014). Ef fects of speaker gaze versus depicted actions on visual attention during sentence comprehension. In Proceed ings of the 36th Annual Meeting of the Cognitive Sci ence Society (pp. 2513–2518). 
Kröger, J. M., Münster, K., & Knoeferle, P. (2017). The influence of prosody and case marking on thematic role assignment in ambiguous action scenes: Adults versus children. In Proceedings of the 39th Annual Meeting of the Cognitive Science Society (pp. 2463–2468). 
Mani, N., & Huettig, F. (2012). Prediction during language processing is a piece of cake—but only for skilled pro ducers. Journal of Experimental Psychology: Human Perception and Performance, 38(4), 843–847. 
Matzke, M., Mai, H., Nager, W., Rüsseler, J., & Münte, T. (2002). The costs of freedom: an erp–study of non-canonical sentences. Clinical Neurophysiology, 113(6), 844–852. 
Messenger, K., Branigan, H. P., McLean, J. F., & Sorace, A. (2012). Is young children’s passive syntax semantically constrained? evidence from syntactic priming. Journal of Memory and Language, 66(4), 568–587. 
Münster, K. (2016). Effects of emotional facial expressions and depicted actions on situated language processing across the lifespan. Doctoral Thesis, Bielefeld Univer sity. 
Münster, K., Carminati, M. N., & Knoeferle, P. (2015). The effect of facial emotion and action depiction on situ ated language processing. In Proceedings of the 37th Annual Meeting of the Cognitive Science Society (pp. 1673–1678). 
Nation, K., Marshall, C. M., & Altmann, G. T. (2003). Inves tigating individual differences in children’s real-time sentence comprehension using language-mediated eye movements. Journal of Experimental Child Psychol ogy, 86(4), 314–329. 
Peter, M., Chang, F., Pine, J. M., Blything, R., & Rowland, C. F. (2015). When and how do children develop knowledge of verb argument structure? evidence from verb bias effects in a structural priming task. Journal of Memory and Language, 81, 1–15. 
Richardson, D. C., & Kirkham, N. Z. (2004). Multi modal events and moving locations: eye movements of adults and 6-month-olds reveal dynamic spatial in dexing. Journal of Experimental Psychology: General, 133(1), 46. 
Schipke, C. S., Friederici, A. D., & Oberecker, R. (2011). Brain responses to case-marking violations in german preschool children. Neuroreport, 22(16), 850–854. 
Sedivy, J. C., Tanenhaus, M. K., Chambers, C. G., & Carlson, G. N. (1999). Achieving incremental semantic inter pretation through contextual representation. Cognition, 71(2), 109–147. 
Staudte, M., Crocker, M. W., Heloir, A., & Kipp, M. (2014). The influence of speaker gaze on listener comprehen sion: Contrasting visual versus intentional accounts. Cognition, 133(1), 317–328. 
Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K. M., & Sedivy, J. C. (1995). Integration of visual and linguistic information in spoken language comprehen sion. Science, 1632–1634. 
Trueswell, J. C., Sekerina, I., Hill, N. M., & Logrip, M. L. (1999). The kindergarten-path effect: Studying on line sentence processing in young children. Cognition, 73(2), 89–134. 
Zhang, L., & Knoeferle, P. (2012). Visual context effects on thematic role assignment in children versus adults: Evidence from eye tracking in german. In Proceedings of the 38th Annual Meeting of the Cognitive Science Society (pp. 2593–2598). 
Özge, D., Münster, K., Knoeferle, P., Küntay, A., & Snedeker, J. (2016). Predictive use of german case markers in german children. In Proceedings of the 40th Annual Boston University Conference on Language Develop ment (pp. 291–303). 
1974
Shaping Model-Free Habits with Model-Based Goals 
Paul M. Krueger (pmk@berkeley.edu) 
Thomas L. Griffiths (tom griffiths@berkeley.edu) 
Department of Psychology, University of California, Berkeley 
Abstract 
Model-free (MF) and model-based (MB) reinforcement learn ing (RL) have provided a successful framework for under standing both human behavior and neural data. These two sys tems are usually thought to compete for control of behavior. However, it has also been proposed that they can be integrated in a cooperative manner. For example, the Dyna algorithm uses MB replay of past experience to train the MF system, and has inspired research examining whether human learners do some thing similar. Here we introduce an approach that links MF and MB learning in a new way: via the reward function. Given a model of the learning environment, dynamic programming is used to iteratively approximate state values that monotoni cally converge to the state values under the optimal decision policy. Pseudorewards are calculated from these values and used to shape the reward function of a MF learner in a way that is guaranteed not to change the optimal policy. We show that this method offers computational advantages over Dyna in two classic problems. It also offers a new way to think about integrating MF and MB RL: that our knowledge of the world doesn’t just provide a source of simulated experience for train ing our instincts, but that it shapes the rewards that those in stincts latch onto. We discuss psychological phenomena that this theory could apply to, including moral emotions. 
Introduction 
You’re at a dinner buffet and intend to choose a healthy salad to help achieve your dietary goal of losing weight and stay ing fit. Nonetheless, you are unable to resist taking a piece of pie. Eating the pie is pleasurable but afterwards you feel guilt. Why are our habits so often misaligned with our goals, and how might emotions like guilt mediate this misalignment? The interaction between habits and goals – how the former support or undermine the latter – is a critical and common place dilemma faced by people, and an important area of re search in psychology and neuroscience (Aarts & Dijksterhuis, 2000; Dolan & Dayan, 2013). Here we present a reinforce ment learning architecture that can be used to describe the in teraction between a simple learning system (e.g. habits) and a higher-level, more sophisticated one (e.g. goals). 
Dual-process theories – expressing human cognition as the result of two interacting systems, such as systems that pro duce habits vs. goals – explain a range of fundamental proper ties of human decision-making and judgment. Inspired by re sults in machine learning, recent research in psychology and neuroscience has explored how the brain might contain two systems that use different approaches to the problem of learn ing from environmental rewards, known as model-free (MF) and model-based (MB) reinforcement learning (RL) (Daw & Dayan, 2014; Daw, Niv, & Dayan, 2005; Otto, Gershman, Markman, & Daw, 2013). MF learning relies on direct trial and-error interaction with the environment (Sutton, Barto, & Williams, 1992), while MB learning leverages knowledge about the causal structure of the environment (Barto, Bradtke, 
& Singh, 1995). MF learning offers a simple, computation ally cheap approach to learning, while MB learning is more sophisticated and resource-intensive. In the domain of deci sion making, MF and MB learning have been used respec tively to describe dual-processes including habits vs. goals, reflexive vs. reflective choice, retrospective vs. prospective decisions, and Pavlovian vs. instrumental learning (Boureau, Sokol-Hessner, & Daw, 2015; Dolan & Dayan, 2013). 
Understanding the cognitive and neural relationship be tween MF and MB learning – and, by extension, between var ious dual-processes – remains an unresolved question. His torically, animal psychologists viewed these two approaches as distinct and competing hypotheses, with behaviorists ar guing in favor of reflexive, MF learning based on stimulus response associations (Thorndike, 1933), and Tolman and others positing an internal representation of the environment, or “cognitive map” (Tolman, 1948). Nowadays, while be havioral and neural data indicate that human learning relies on both systems (Daw et al., 2005; Dayan & Berridge, 2014; Glascher, Daw, Dayan, & O’Doherty, 2010), it is typically ¨ assumed that they compete for control of behavior. However, it is also possible for them to cooperate. The Dyna archi tecture achieves such cooperation by integrating MF learning with MB planning (Sutton, 1991). In Dyna, as MF learning occurs, transitions between states of the environment and the resulting rewards are stored in a model. That model is used to replay these past experiences to further train MF state-action values. Recent behavioral data from people performing a ret rospective revaluation task is consistent with a cooperative architecture like Dyna (Gershman, Markman, & Otto, 2014). 
Here we introduce Model-Based Pseudoreward Approx imation (MBPA), a method for cooperative interaction be tween MF and MB learning. The MB system generates pseu dorewards that shape the reward function used in MF learn ing. According to the shaping theorem (Ng, Harada, & Rus sell, 1999), conditions exist under which the optimal deci sion policy will remain invariant to such modifications of the reward function, opening the possibility that pseudorewards can be used to guide agents toward optimal behavior. That is, since the optimal policy is guaranteed to remain unchanged, pseudorewards can potentially be used to guide the agent to the optimal policy. Using these principles, we show that pseu dorewards can provide a link between MF and MB learning through modification of the reward function. 
MBPA offers an appealing alternative to Dyna, both con ceptually and practically. With Dyna, the MB replay of past experience suggests that planning (by internal simulation) is one way that different learning systems might be linked in hu 
1975
man cognition. MBPA offers an alternative approach, based on changing the reward function, which can be tested exper imentally in humans. In particular, this offers a new way to think about the relationship between dual-process theories that involve MF and MB learning, with pseudorewards pro viding the crucial link. In the case of eating sweets when one’s goal is to be on a diet, the emotion of guilt serves as the (negative) pseudoreward, generated by the MB goal to re train the MF habitual system. Remorse could serve a similar function when one behaves unethically. 
We begin by reviewing the Dyna architecture for inte grated MF and MB learning. We then introduce our method and its theoretical background. We present two simulations which show the effectiveness of our method and how it com pares with Dyna. The first simulation involves learning in a maze environment, and the second simulation uses the classic mountain car problem. We end by discussing how this inte grated approach may serve as a metacognitive solution to the rational use of cognitive resources (Griffiths, Lieder, & Good man, 2015), and how it may shed light on the function of emo tion in mediating the relationship between dual-processes. 
Background 
In this section we introduce the modeling framework for MF and MB reinforcement learning, and describe a popular algo rithm that cooperatively integrates the two. 
Markov Decision Processes 
We describe sequential decision problems that can be mod eled as a Markov Decision Process (MDP). The MDP is de fined as the 5-tuple: M = {S,A,P,R , γ}, where S is the set of states, A is the set of actions, and for each (s,a) ∈ S ×A, P(s,a,s0) is the probability of transitioning to state s0 when action a is selected in state s, R (s,a,s0) is the reward received for transitioning from state s to s0, and γtis the discount factor for rewards t time steps in the future, where 0 ≤ γ ≤ 1 (Sutton & Barto, 1998). A policy, π, is a mapping of states, S, onto actions, A: π : S 7→ A. A value function, Vπ(s), is the ex pected amount of discounted reward generated by following policy π beginning at state s: 
where α is the learning rate that determines how quickly the agent learns from new experience. The terms [R(s,a,s0) + γmaxa0 Q(s0,a0) − Q(s,a)] are called the temporal difference error. Initially all Q(s,a) are zero, and Q-learning can even tually learn an optimal policy π∗ over time. The agent uses a decision policy, such as the ε-greedy policy which is used in our simulations. At each state s, with probability 1 − ε, the agent chooses the action a ∈ A with the highest value Q(s,a). With probability ε it chooses an action uniformly at random (ε calibrates the explore-exploit tradeoff). 
Model-based Reinforcement Learning 
Unlike MF RL, MB RL has knowledge of the environment in terms of the transition probabilities between states, P, and the reward contingencies for state-action pairs, R . One of the most common MB methods for finding an optimal policy π∗ is dynamic programming which calculates the value of state s under policy π according to the Bellman equation: 
Vπ(s) = Rπ(s)(s,π(s),s0) +γ∑ 
Pπ(s)(s,a,s0)Vπ(s0)), (3) 
s0 
and finds the value of each state V∗(s) under the optimal pol icy π∗ by recursively updating these values using the Bellman optimality equation: 
aRπ(s)(s,a,s0) +γ∑s0Pπ(s)(s,a,s0)V∗(s0)). (4) 
V∗(s) = max 
Dyna 
Dyna uses MF learning combined with a MB system that re plays past experiences, which are used to train the MF system (Figure 1a). After each real action taken in the environment, the model stores the state-action pair and reward received. It then randomly selects n past state-action pairs and replays them. These planned actions are used to update the MF sys tem as if they were real actions. In Dyna-Q, the MF system uses one-step tabular Q-learning (which is what we use in our simulations). The number of simulated planning steps, n, is a parameter that can be set to any positive integer value. Dyna 
Vπ(s) = ∑ s0 
Pπ(s)(s,a,s0)(Rπ(s)(s,a,s0) +γVπ(s0)). (1) 
typically begins with no knowledge about the causal struc ture of the environment (that is, transitions between states 
An optimal policy, π∗, is a policy that maximizes the value function: π∗(s) = argmaxaVπ(s). 
Model-free Reinforcement Learning 
RL is concerned with learning an effective policy from re wards alone. MF methods require no knowledge about the en vironment, and the agent learns which state-action pairs lead to reward through trial-and-error. One of the most common MF methods, which is employed throughout the simulations in this paper, is Q-learning (Sutton & Barto, 1998). When the agent takes action a from state s, leading to state s0and reward R(s,a,s0), a value Q(s,a) is learned via the update 
Q(s,a) ← Q(s,a) +α(R(s,a,s0) +γmax 
a0Q(s0,a0)−Q(s,a)), (2) 
and reward contingencies), but builds this knowledge based on experience. However, Dyna can also inherit a model of the environment, but this actually slows MF learning. 
In addition to being a useful algorithm for integrating di rect learning with indirect replay, Dyna has been proposed as a model of human cognition – behavioral experiments have found evidence in humans consistent with a Dyna architecture (Gershman et al., 2014). Participants performed a sequen tial decision task with separate learning phases that tested be havioral revaluation. When given either more time between phases or a smaller cognitive load, the magnitude of revalua tion was larger, consistent with MB replay of past experience. There are also neurophysiological data that suggest Dyna-like cooperation between the two systems. Lansink et al. (2009) 
1976
  

(a) Dyna archetecture. 
  

(b) Model-Based Pseudoreward Approximation. 
Figure 1: Schematic illustrations of two approaches to coop erative RL: (a) Dyna and (b) our method, MBPA. 
identified hippocampal neurons in rats encoding spatial lo cation and striatal neurons encoding reward. During sleep, the activation of those hippocampal cells correlated with and proceeded activation of the same striatal cells that encoded the value of those locations. 
Model-Based Pseudoreward Approximation 
Dyna integrates MF and MB RL by simulating past expe rience. We now consider Model-Based Pseudoreward Ap proximation (MBPA), a different way to merge the two. Our method uses dynamic programming to approximate state val ues. These values are used to calculate pseudorewards ac cording to the shaping theorem. By shaping the reward func tion, pseudorewards provide a link between MB planning and MF learning. While MBPA can be initialized without a model of the environment, the cognitive phenomena we wish to de scribe entail situations where the model is already learned, but the MF system is misaligned with it. For example, one may have goals based on a known model of the environment, but habitually behave inconsistently with such goals. MBPA describes how the model can be used to align the two systems. 
Pseudorewards and the shaping theorem 
Pseudorewards offer a way of conferring extra information to an agent about the reward landscape. Essentially, a small re ward is given to the MF agent (a Q-learner in our simulations) whenever it takes an action that helps the agent move towards the goal (or, conversely, a negative reward is given for mov ing away from the goal). Instead of the agent receiving actual reward R(s,a,s0) when moving from state s → s0, the agent receives an augmented reward R0(s,a,s0) where 
R0(s,a,s0) = R(s,a,s0) +F(s,a,s0). (5) Pseudorewards are defined using shaping functions, F. In Ng et al. (1999), conditions for which the optimal policy π∗ 
(a)  (b) 
  

Figure 2: (a) Maze environment. Colors correspond to state values under the optimal policy (S = start state, G = goal state). (b) Monotonic convergence of estimated state values. Each subplot corresponds to a state in the maze. Red lines are upper-bound estimates, blue lines are lower-bound estimate, and dashed lines are optimal state values. 
remains invariant under a shaping function are developed. In particular, F necessarily must be a potential-based shaping function to possess this invariance property: 
F(s,a,s0) = γΦ(s0)−Φ(s), (6) 
where Φ is a real-valued function, Φ : S → R. If the shaping function is not potential-based, it is possible that Q-learning will converge to a suboptimal solution. The simplest exam ple of invariant pseudorewards uses the difference in optimal values between the agent’s current state and next state: 
F(s,a,s0) = γV∗(s0)−V∗(s). (7) 
This method is called the optimal policy pseudoreward – it encourages the agent to move down the optimal path from its current state. With an ε-greedy decision policy, if ε = 0, the agent would move directly to the goal along the shortest path. 
With optimal policy pseudorewards the agent can maxi mize long-term reward simply by taking the most rewarding action at each step. However, in real-world scenarios, it may be unrealistic for a human to have such complete information. Computing the optimal policy may require many iterations of the Bellman equation, or solving a linear program. 
Approximating the value function 
Optimal policy pseudorewards require knowing the value function under the optimal policy, but that may be costly to compute. Alternatively, the optimal value function can be ap proximated, requiring less computation. Bounded Real-Time Dynamic Programming (BRTDP) is a planning algorithm that attains certain performance guarantees if its lower- and upper-bounded estimates of state values converge monotoni cally toward state values under the optimal policy (McMahan, Likhachev, & Gordon, 2005). This monotonic convergence toward optimal values is guaranteed to occur if the lower and upper bounds are initialized properly. Here we take advan tage of this monotone property to calculate approximate state values using dynamic programming. Specifically, any num 
1977
ber, n, of iterations of the Bellman equation can be used to approximate state values, and as n increases, the state values converge toward optimal values. These values after n itera tions are used to approximate pseudorewards using the shap ing theorem. Thus, there is a tradeoff, determined by n, be tween the proximity of pseudorewards to their optimal value and the amount of computation. As discussed later, learning which n minimizes overall computation is a bounded ratio nality optimization that can be solved with metacognition. 
Linking MF and MB RL with the reward function 
Figure 1b provides a schematic illustration of MBPA, wherein dynamic programming is used to approximate pseudore wards, which in turn shape the reward function and policy of the MF agent. We are interested in describing situations in which humans already have a model of the environment and use this information to train their MF instincts. A model con taining state-action pairs and reward contingencies is used to estimate state values using n iterations of the Bellman equa tion. These values are used to calculate pseudorewards with a potential-based shaping function, then added onto real re wards whenever the agent chooses an action. In this way, the MF agent is guided by pseudorewards that are generated us ing MB RL. In the remainder of the paper we present simula tions focused on evaluating MBPA and comparing it to Dyna. 
Simulation 1: Maze learning 
Methods 
Our first simulation involved an agent learning in a maze en vironment (Sutton, 1991). The agent (a simple Q-learner), began each episode in the upper-left corner of a maze, and was rewarded one point for reaching the lower-right corner (Figure 2a). The state space consisted of 121 locations, 50 of which were walls, in the grid shown in Figure 2a, and ac tions consisted of each of the four cardinal directions. The agent was trained for fifty episodes, with each episode end ing when the goal was reached or 2,000 steps were taken. An ε-greedy decision policy was used with ε = 0.25. The colors in Figure 2a correspond to state values under the optimal pol icy. Rewards were discounted with γ = 0.95, and therefor the value of each state is 0.95d, where d is the minimum number of steps to the goal. In all simulations, simulations were run one-hundred times and averaged. 
mcmahan2005bounded Approximate pseudorewards Dynamic programing was used to approximate state values by iterating over the Bellman equation. In McMahan et al. (2005) conditions are defined under which initial state values will provably converge monotonically toward optimal values. Here, all states were initialized with a lower bound of zero and an upper bound of one, which in our environment is known to bound state values. Figure 2b shows that the approximate state values for each state do indeed converge monotonically. The point at which each state reaches its optimal value is exactly equal to the minimum number of steps that state is from the goal, d. At each state, the 
pseudoreward for each action was calculated according to the shaping theorem as the difference between the value of the current state and the value of the next state given that deterministic action. Either the lower-bound or the upper-bound of state values after n iterations of Bellman updates was used to approximate pseudorewards. 
Trading off MF and MB computation The closer pseudore wards are to their optimal values (to some precision), the easier the learning for the MF agent. However, whereas Q learning is simple and quick, the MB method of approximat ing state values is slower and computationally costly. There fore, we found the most efficient tradeoff between MB pseu doreward approximation and MF learning. This was done by computing the CPU time required for each algorithm to learn. 
Results 
Figure 3a shows the number of steps per episode needed to reach the goal, averaged across 50 episodes, as a function of the the number of Bellman updates used to approximate pseudorewards. As expected, learning is quicker when pseu dorewards are closer to their optimal values. We also show performance of the Dyna agent as a function of the number of planning steps taken after each real step. While approximate pseudorewards are calculated just once using n iterations, the n planning steps used by Dyna are taken after every single step of every episode. 
The number of real steps alone taken by the Dyna agent do not converge as low as the MBPA agent. With sufficiently precise pseudorewards, the MBPA agent, on the other hand, can learn the shortest path on the very first episode. Specif ically, 24 Bellman updates are required for this, because the start state is 24 steps away from the goal state; after 24 it erations of the Bellman equation, optimal state values have propagated back from the goal state to the start state. 
Next, we calculated the actual time required to learn the shortest path. While the pseudoreward method may take fewer steps to reach the goal than Dyna, it does not neces sarily mean that it is faster; planning steps (which use scalar operations to update Q-values) are about two orders of mag nitude quicker than Bellman updates (which require matrix multiplication). However, Figure 3b shows that MBPA is still faster than Dyna. The fastest learning occurs when 24 itera tions of the Bellman equation are used; any more than this is unnecessary and the CPU time increases. 
Simulation 2: Mountain car problem Methods 
Simulation 2 explored learning in a standard mountain car environment (Moore, 1990). The agent begins in a valley be tween two mountains with the goal of reaching the top of the right mountain. The agent must learn to apply force such that it oscillates between the mountain slopes, building momen tum until it reaches the top. States consisted of discretized lo cations and velocities. Actions consisted of discretized forces applied tangentially to the direction of movement. The agent 
1978
  

(a) 
  

(b) 
Figure 3: (a) MBPA requires fewer steps to reach the goal than Dyna during maze learning. (b) MBPA learns the short est path more quickly than Dyna with maze learning. 
used Q-learning during 200 learning episodes, where each episode ended when the car reached the goal state or 1,000 steps were taken. When the agent reached the goal it was conferred a reward of one. An ε-greedy decision policy was used where ε = 0.01×0.99i−1, where i is the episode number. As before, MBPA was compared with Dyna. 
Results 
Simulation 2 showed a similar pattern of results as Simula tion 1. The upper-bound and lower-bound estimates of state values converged to optimal values within 48 iterations of the Bellman equation because 48 is the furthest possible num ber of steps away from the goal. The total number of Dyna steps (real steps plus planning steps) far exceeds the number of steps using MBPA, and the number of real steps alone does not converge as low as the number of steps taken with MBPA. 
The CPU time required to learn the shortest path was simi larly faster for MBPA. Although Dyna requires more steps to learn, because its computations are scalar-based Q-updates, it is relatively quick, whereas Bellman approximation requires more costly matrix multiplication. Still, MBPA learns faster. 
Discussion 
We have introduced MBPA, a new method for cooperatively integrating MF and MB RL. This method relies on BRTDP to iteratively estimate state values that converge monotoni cally to values under the optimal policy. These approximate 
values are used to calculate pseudorewards according to the shaping theorem, such that the reward function is altered but the optimal policy is invariant. This modified reward func tion is used for MF learning. Our simulations demonstrate that this method performs comparably to and even better than the Dyna algorithm, a popular cooperative RL method. 
The relationship between MF and MB RL has received much attention in cognitive neuroscience research. For exam ple, some work has focused on the neural arbitration between the two systems (Daw et al., 2005), while other work has proposed an underlying unification of both systems (Miller, Shenhav, & Ludvig, 2016). At the computational level of analysis (Marr, 1982), it has been suggested (Boureau et al., 2015) that negotiating these two systems could be understood as a metacognitive solution to a problem of resource rational ity (Griffiths et al., 2015). From this perspective, cooperative RL can be understood as a means for transferring computa tionally intensive MB knowledge to the MF system for quick and easy implementation. The metacognitive optimization in MBPA is the tradeoff between MB state value approximation and the effectiveness of training the MF system. Our results show that certain degrees of state value approximation min imize the computation needed to learn, which results in less computation than Dyna. This point of minimal computation in Figure 3 represents the optimal resource rational solution. 
MBPA links MF and MB RL cooperatively by shaping the reward function via pseudoreward. Another interesting ex ample of the interplay between habits and goals is in moral decision-making. It has been suggested that the dual-system approach to moral psychology is well described by the dis tinction between MF and MB RL, with the former describing the emotional, instinctive, action-oriented, habitual system and the later mapping onto the cognitive, rational, outcome oriented, and goal-based system (Crockett, 2013; Cushman, 2013). MBPA may provide a direct link between these two systems, with the MB cognitive system producing particu lar emotions that function as pseudorewards, shaping the MF emotional system. For example, when one’s moral behavior deviates from one’s moral compass, leading to an untoward outcome, remorse could be generated to correct the action oriented propensity that produced the misguided behavior. 
Another interesting application of cooperative RL and metacognitive rationality is in the formation of sub-goals, or “options” (Huys et al., 2015). Sub-goals offer a way of sim plifying complex, high-dimension environments into simpler strategies and MF heuristic-based decisions. MBPA could of fer a mechanism for approximating state values of a complex decision space, and transferring this knowledge to a simpler, computationally cheap MF system through reward shaping. 
By providing a new way to link MF and MB RL, MBPA offers a new way to think about how the two systems might interact. As discussed earlier, Dyna is readily likened to us ing MB imagination to train a MF system, which has a natu ral psychological interpretation. What might be an analog of MBPA in human cognition? In particular, how might pseu 
1979
dorewards – which provide the critical link between systems – manifest cognitively? For any given task or goal-directed behavior, certain emotions often have the effect of altering the reward landscape and functioning as pseudorewards. MBPA proposes that some emotions may represent the (approxi mate) values of states that are stored in a model, and then used to train MF learning by adding bonuses (positive emotions) or punishments (negative emotions) to certain actions. It is al ready known that emotions influence MF learning, as in the case of fear conditioning or positive reinforcement (Fields, Hjelmstad, Margolis, & Nicola, 2007; Maren, 2001). These emotions are usually elicited by some external factor; what we are suggesting with MBPA is that the emotions can be produced internally, using an already-learned model of the environment, such as high-level goals. 
While we are primarily suggesting that MBPA may func tion in human cognition, it is interesting to note that hu mans employ analogous strategies externally. “Temptation bundling” is a strategy whereby a positive association is used to override a negative one (Milkman, Minson, & Volpp, 2013). For example, if one feels averse to exercise but has the goal to get fit, one may watch a favorite television show while on the treadmill; the aversive reward landscape of exercise is positively shaped through deliberate coupling with rewarding behavior. The positive emotions generated from the TV show function as pseudorewards to guide the person along a more optimal route toward exercise and fitness. 
Finally, because our interest is in describing the relation ship between acquired MB knowledge and goals with MF behaviors or habits, our MBPA algorithm uses a MB sys tem with knowledge of the casual structure of the environ ment. MBPA can alternatively learn a model of the envi ronment rather than inherit it, but it is not designed to ex cel under such circumstances. Conversely, Dyna can inherit such knowledge, but it actually performs worse than the Dyna agent presented here, because replay becomes less efficient. “Prioritized sweeping” (Moore & Atkeson, 1993) is a more efficient version of Dyna, but for the problems we present, we found that MBPA still performs faster and in fewer steps. 
Dual-process theories are abundant in psychology, but there is a dearth of computational theories for understanding the precise relationship between dual systems. MBPA offers a new way to understand interaction between MB and MF systems, with natural cognitive and affective psychological interpretations. We hope that MBPA will inspire new ques tions to be pursued experimentally. 
References 
Aarts, H., & Dijksterhuis, A. (2000). Habits as knowledge struc tures: automaticity in goal-directed behavior. Journal of per sonality and social psychology, 78(1), 53. Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning to act using real-time dynamic programming. Artificial Intelli gence, 72(1), 81–138. Boureau, Y.-L., Sokol-Hessner, P., & Daw, N. D. (2015). Decid ing how to decide: Self-control and meta-decision making. Trends in cognitive sciences, 19(11), 700–710. 
Crockett, M. J. (2013). Models of morality. Trends in cognitive sciences, 17(8), 363–366. 
Cushman, F. (2013). Action, outcome, and value a dual-system framework for morality. Personality and social psychology review, 17(3), 273–292. 
Daw, N. D., & Dayan, P. (2014). The algorithmic anatomy of model-based evaluation. Phil. Trans. R. Soc. B, 369(1655), 20130478. 
Daw, N. D., Niv, Y., & Dayan, P. (2005). Uncertainty-based compe tition between prefrontal and dorsolateral striatal systems for behavioral control. Nature neuroscience, 8(12), 1704–1711. Dayan, P., & Berridge, K. C. (2014). Model-based and model-free pavlovian reward learning: revaluation, revision, and revela tion. Cognitive, Affective, & Behavioral Neuroscience, 14(2), 473–492. 
Dolan, R. J., & Dayan, P. (2013). Goals and habits in the brain. Neuron, 80(2), 312–325. 
Fields, H. L., Hjelmstad, G. O., Margolis, E. B., & Nicola, S. M. (2007). Ventral tegmental area neurons in learned appetitive behavior and positive reinforcement. Annu. Rev. Neurosci., 30, 289–316. 
Gershman, S. J., Markman, A. B., & Otto, A. R. (2014). Retro spective revaluation in sequential decision making: A tale of two systems. Journal of Experimental Psychology: General, 143(1), 182. 
Glascher, J., Daw, N., Dayan, P., & O’Doherty, J. P. (2010). States ¨versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learn ing. Neuron, 66(4), 585–595. Griffiths, T. L., Lieder, F., & Goodman, N. D. (2015). Rational use of cognitive resources: Levels of analysis between the com putational and the algorithmic. Topics in cognitive science, 7(2), 217–229. 
Huys, Q. J., Lally, N., Faulkner, P., Eshel, N., Seifritz, E., Gersh man, S. J., . . . Roiser, J. P. (2015). Interplay of approximate planning strategies. Proceedings of the National Academy of Sciences, 112(10), 3098–3103. 
Maren, S. (2001). Neurobiology of pavlovian fear conditioning. Annual review of neuroscience, 24(1), 897–931. 
Marr, D. (1982). Vision. san francisco: W. h. H. Freeman. McMahan, H. B., Likhachev, M., & Gordon, G. J. (2005). Bounded real-time dynamic programming: Rtdp with monotone upper bounds and performance guarantees. In Proceedings of the 22nd international conference on machine learning (pp. 569– 576). 
Milkman, K. L., Minson, J. A., & Volpp, K. G. (2013). Holding the hunger games hostage at the gym: An evaluation of tempta tion bundling. Management science, 60(2), 283–299. Miller, K., Shenhav, A., & Ludvig, E. (2016). Habits without values. bioRxiv, 067603. 
Moore, A. W. (1990). Efficient memory-based learning for robot control. Unpublished doctoral dissertation, University of Cambridge, Cambridge, UK. 
Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning with less data and less time. Machine Learning, 13(1), 103–130. 
Ng, A. Y., Harada, D., & Russell, S. (1999). Policy invariance un der reward transformations: Theory and application to reward shaping. In Icml (Vol. 99, pp. 278–287). 
Otto, A. R., Gershman, S. J., Markman, A. B., & Daw, N. D. (2013). The curse of planning dissecting multiple reinforcement learning systems by taxing the central executive. Psycholog ical science, 0956797612463080. 
Sutton, R. S. (1991). Dyna, an integrated architecture for learning, planning, and reacting. ACM SIGART Bulletin, 2(4), 160– 163. 
Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning: An introduction. MIT press. 
Sutton, R. S., Barto, A. G., & Williams, R. J. (1992). Reinforcement learning is direct adaptive optimal control. IEEE Control Sys tems, 12(2), 19–22. 
Thorndike, E. L. (1933). A proof of the law of effect. Science. Tolman, E. C. (1948). Cognitive maps in rats and men. Psychologi cal review, 55(4), 189. 
1980
Adaptive planning in human search 
Moritz J. F. Krusche1, Eric Schulz2, Arthur Guez3 & Maarten Speekenbrink4 1Warwick Business School, University of Warwick, Coventry, UK 2Department of Psychology, Harvard University, Cambridge, Massachusetts, USA 3Gatsby Computational Neuroscience Unit, University College London, London, UK 4Department of Experimental Psychology, University College London, London, UK 
Abstract 
How do people plan ahead when searching for rewards? We investigate planning in a foraging task in which participants search for rewards on an infinite two-dimensional grid. Our results show that their search is best-described by a model which searches at least 3 steps ahead. Furthermore, partici pants do not seem to update their beliefs during planning, but rather treat their initial beliefs as given, a strategy similar to a heuristic called root-sampling. This planning algorithm corre sponds well with participants’ behavior in test problems with restricted movement and varying degrees of information, out performing more complex models. These results enrich our understanding of adaptive planning in complex environments. Keywords: Planning; Decision Making; Tree Search; Forag ing; Reinforcement Learning; Monte Carlo Sampling 
Introduction 
An important trait of intelligent agents is their ability to plan ahead before performing actions, resulting in deliberate be havior that avoids costly mistakes. During planning, chains of hypothetical actions are played out until a certain depth based on what is known about the reward structure of the environment (Huys et al., 2015). For instance, De Groot (1978) found that amateur chess players can plan between 4 − 6 steps ahead when considering their next move. While flexible, planning is computationally expensive, and optimal solutions are frequently intractable (Dolan & Dayan, 2013). Recently, Balaguer et al. (2016) found that people can think ahead to solve complex problems by clustering steps into dif ferent contexts. Still, surprisingly little is known about how people plan ahead when searching for rewards. In part, this may be due to the inherent difficulty of separating exploration from planning. 
We investigate participants’ search for rewards in a com plex two-dimensional grid world. The task has a rich combi natorial structure in which the reward on a location depends on row- and column-parameters, and is particularly challeng ing for many approximate planning algorithms proposed in the machine learning literature. Our results indicate that par ticipants learn in this task and improve their performance over time. Further computational model comparison shows that a search algorithm with a planning horizon of at least 3 steps describes participants’ decisions better than other cue-based or associative learning models. Importantly, this model uses a sampling heuristic which initializes beliefs once at the start and then reasons about what to do on subsequent steps, rather than also updating beliefs during the planning process. This provides a tractable solution to complex and dynamic plan ning scenarios. Our results advance our notion of how people plan ahead in a computationally challenging search task. 
Planning as tree-search 
Tree-search algorithms are search algorithms that are used to plan ahead in complex reinforcement learning problems (Brown et al., 2012). Treating each state as a node of a tree, these algorithms plan ahead by expanding nodes via specific sampling routines. As exhaustive search of all possible action and state sequences is generally impossible, tree-search algo rithms attempt to sample the most promising paths, ignoring improbable states and unfavorable actions. Because of their ability to solve challenging reinforcement learning problems, tree-search routines are highly popular in machine learning (Silver et al., 2016). 
Several psychological studies have investigated the way people might perform tree-like planning before executing an action. In a relatively simple two-stage decision task, peo ple show evidence of model-based planning, requiring them to think ahead for two steps in order to obtain maximum re wards (Daw et al., 2011). 
In more complicated and longer sequential decision tasks, there is evidence that people adapt their search to aspects of the problem or task demands. For instance, Huys et al. (2012) showed that subjects adopted a simple tree-search strategy in which they curtailed any further evaluation of a sequence as soon as they encountered a large prospective loss (called pruning). Huys et al. (2015) used a model-based behavioral analysis to provide a detailed examination of participants’ performance in a moderately deep planning task and found that participants plan by establishing subgoals in a way that achieves a nearly maximal reduction in the cost of computing values of choices. Keramati et al. (2016) developed a three stage decision task and found that increased time pressure led to shallower planning, suggesting that a speed-accuracy trade-off controls the depth of planning with deeper search leading to more accurate evaluation. Interestingly, their anal ysis revealed that subjects integrate habit-based cached val ues directly into goal-directed evaluations. Van Opheusden et al. (2017) also found that people perform shallower tree search under time pressure, but that they search more as they improve during learning. Taken together, these studies show that people can use clever heuristics to adapt the depth of their search by “pruning” relatively poor branches of the tree or using cached habit-based values to avoid further computation along a branch. 
Here, we assess participants’ decisions in a challenging re ward search task with (potentially) infinite states and deplet ing resources, providing challenging state-action-state dy namics. 
1981

Figure 1: Screenshots of the potato farming game. The color and size of the plants as well as the color and texture of the soil provide visual cues for a tile’s quality. Further cues are delivered through the upper panel UI. The game can be played at https://git.io/vpSKp 
Figure 2: Visual cues based on past success and exploration. Dis played soil and plant types served as quality indicators for rows and columns (counterbalanced). The best soil/ plant type can be seen on the right, the worst on the left. Shades of gray indicate information quality, with 3 being unexplored and 1 maximally explored. 
The potato farming task 
To investigate planning in complex environments, we adapted a task first conceived as a challenging machine learning prob lem (Guez et al., 2013). In order to make it suitable for hu man participants, we framed the task as a foraging problem and implemented it as a browser-based game. Participants control a farmer on a grid-like field in pursuit of potatoes. Movement is possible horizontally or vertically using the 4 arrow keys (Figure 1). Every tile on the grid may yield a single potato when visited, and is thereafter depleted. The underlying structure of the task is determined by sampling, independently, for each row i a probability pi ∼ Beta(α1,β1) and for each column j a probability qj ∼ Beta(α2,β2). For a tile in row i and column j, the probability of success (a potato) is determined by the product of the two probabilities p(potato) = pi ×qj. 
While in theory infinite, the number of possible moves was limited to 100 (open) or 8 (test maps). Only a viewport of 7×7 tiles was shown during the game, with the farmer char acter on the center tile. Upon movement, both farmer and viewport shifted in the movement direction and the new cen ter tile was harvested with the probability of success as stated above. Payoff values were —known to participants— tempo rally discounted with τ = 0.985 per move to further create op portunity costs for exploration, resulting in a 50% reduction of the original payoff per reward after 45 moves. The game contained distinct sound effects and animations that made re ward pursuit more engaging. 
In order to help participants infer the quality of rows and columns, tiles were displayed with visual cues. Different 
plant and soil types for each tile represented inferred column and row parameters, based on past reward frequencies (Fig ure. 2). Specifically, there were 5 quality levels which were represented by distinct soil tones and textures, and by dif ferent plant shapes and sizes. Darker soil and larger plant types represented higher inferred quality. Additionally, the degree of information certainty, based on past exploration, was shown through overlaid shades of gray, with more gray representing less explored tiles. 
Information certainty levels were determined by a mono tonic rule based on the number of past moves within a row or column. The criteria were: high uncertainty (0 visits of row or column), medium uncertainty (between 1 and 4 visits), and low uncertainty (more than 4 visits). In contrast, inferred quality levels were presented based on a pseudo-Bayesian up dating rule that took into account past exploration and success rates within a column or row. For every row or column k, this was calculated as 
qk = αk +∑Potatoesk 
αk +βk +∑Explored Tilesk. (1) 
At the first move of every map, the player is na¨ıve about the reward structure (Figure 1, left). After every subsequent move, the inferred quality and information levels for each vis ited row and column are updated (Figure 1, right). In order to maximize rewards, players must seek to find a route over the most rewarding tiles, for instance by traversing a column or row with a high parameter pi or qj. 
The experiment was conducted online, and partici pants were recruited using the Prolific Academic plat form (https://prolific.ac), a UK-based crowdsourcing plat form solely focused on scientific studies. A total of 176 par ticipants took part in the experiment, 8 of whom did not sent data, either due to technical problems (5) or for unknown rea sons (3). Thus, 168 participants were included in the analysis (101 female, mean age=32.1). Participants were paid a flat participation fee of £2 and an additional bonus dependent on the number of potatoes harvested. The average reward over all participants was £2.51, and the average time taken was 19 minutes. Ethics approval was obtained from the UCL Re search Ethics Committee. 
The experiment contained 2 stages. First, participants nav igated 5 open maps, each of which was dynamically gener ated and allowed for 100 unrestricted moves. Maps were cre ated by sampling the row (pi) and column (qj) probabilities from one of two beta-distributions as a between-subjects con dition. For one group the parameters were α1 = 1, β1 = 2, α2 = 2, and β2 = 1 (henceforth the 2-1-group, Figure 3 right), and for the other group they were α1 = α2 = β1 = β2 = 0.5 (henceforth the 0.5-0.5-group, Figure 3 left). This was done to create different reward structures, where rewards in the 2-1 condition were more clustered around rows or columns. 
During the second stage, we presented 8 pre-designed test maps that included unnavigable tiles, displayed as water. The test maps were presented in random order. Every test map was created based on a simple trade-off between a proximal 
1982
e 
m
o
c
tu
o
 
n
a
e
M
0.32 0.30 0.28 0.26 
A 
1 2 3 4 5 Block 
Beta 0.5−0.5 1−2 
y 
t
i
li
ba
b
o
r
p 
n
a
e
M
0.35 0.30 0.25 0.20 
B 
0 25 50 75 100 Trial 
Beta 0.5−0.5 1−2 
Figure 3: Between-subjects conditions for open maps. Probabili ties were derived by multiplying realizations of two different Beta distributions, i.e. the 2-1 and the 0.5-0.5 group. In the 2-1 group, following column j implies a collection of 2qj/3 reward on average (2/3 is the mean of a Beta(2,1)-distribution) whereas following any row i implies a collection of pi/3 reward on average. In the 0.5- 0.5 group, the row and column probabilities are more extreme and rewards more uniformly distributed over the map. 
and almost certain reward and a superior, but distal option covering several tiles at the edge of the display. A limit of only 8 moves forced participants to pursue either option, and they could plan their moves from the start: In contrast to the open maps, information about both uncertainty and quality levels was revealed from the start (by using pseudo-counts, suggesting prior experience with columns and rows). There were two levels for both the degree of movement restriction and the simulated information certainty (see Figure 5). We hypothesized that higher certainty would lead to better plan ning and that more restrictions would lead to improved plan ning (as less options have to be considered). 
Behavioral results 
Open maps 
We first analyzed performance in the open maps. Figure 4A shows participants’ average number of harvested potatoes over the 5 consecutive rounds of open map scenarios and Figure 4B shows the average rewards for the 100 trials (i.e., moves) per open map averaged over participants and rounds. To further assess the effect of trials, rounds, and condition, we regressed those variables onto rewards (i.e., whether or not a potato was gained) in a logistic regression. The results of this model are shown in Table 1. 
Table 1: Results of logistic regression for behavior in open maps. Results are based on fixed effects estimates. 
Estimate Std. Err. z-value P(>|z|) 
Intercept -1.150 0.0238 -48.32 <.000 Round 0.040 0.0054 7.41 <.001 Trial 0.004 0.0003 15.47 <.001 Group 0.5-0.5 0.126 0.0152 8.26 <.001 
As expected, participants improved over rounds (β = 0.039, p < .001) and trials (β = 0.004, p < .001), indicat 
Figure 4: Behavioral results for open maps. A: Participants’ average reward per block. B: Participants average reward per trial. 
Table 2: Results of mixed-effects regression for behavior in test maps. Shown estimates are simple fixed effects. 
Estimate Std. Err. t value P(>|t|) 
Intercept 3.79 0.076 49.83 <2e-16 High info 0.19 0.087 2.24 .02 Restricted 0.38 0.088 4.30 1.83e-05 
ing that they were able to learn in this task. Furthermore, participants in the 0.5-0.5 condition performed better on av erage than participants in the 2-1 condition. This means that performance is better if rewards are more extreme and evenly distributed rather than clustered within rows or columns. 
Test maps 
Next, we analyzed participants’ performance in the test maps. Figure 5 shows a heat map of participants’ moves for each type of test map. Participant trajectories frequently aimed to wards the distant, more promising tiles instead of the proxi mal but less promising ones, indicating that they were indeed planning ahead. 
To further assess participants’ behavior in the test maps, we created 2 dummy variables, one indicating high vs. low infor mation and one indicating high vs. low movement restriction. Subsequently, we regressed these two variables onto partici pants’ total scores per test maps. Results of this regression (Table 2) indicate that participants performed better in test maps with higher information certainty. As can be seen in Figure 5, such maps feature more salient distal rewards. Even though the distal reward is always superior, increased salience might inhibit spontaneous movement and increase the likeli hood of planning. Additionally, further restricting movement also improved performance. Thus, participants’ might be able to further focus their planning on promising paths if the num ber of options is limited. 
Model comparison 
To further assess planning, we defined 4 candidate models that differed in how they plan ahead and generate predictions about a movement’s expected value, and assessed how well they describe participants’ moves on the open maps. 
1983
Figure 5: Test maps and corresponding heat maps. Two levels of movement restriction, visualized by water tiles, as well as two levels of information certainty, resulted in 4 combinations with distal rewards along one corner. Each combination also featured a 90 degree spatial rotation (not shown here) for a total of 8 maps. Adjacent heat maps highlight participant movement: The most common route always goes to 
the better distant location, indicating planning. Both more restriction of movements and more information lead to better planning. 
Candidate models 
The first model is a simple Associative Learning model. This model learns to select directions more frequently over time based on how often they have led to success in the past. It is completely feature-free and involves no planning whatsoever. Instead, each option’s estimated value at trial t + 1 is driven by an update of its valence based on the discrepancy between current valence and outcome, i.e. the prediction error: 
Vt(Move) = Vt−1(Move) +γ (Outcomet −Vt−1(Move)) 
where γ is a free parameter governing the speed of the update over trials, i.e. how strongly the prediction error relates to adjustments of belief. 
The second model is a Neural Network model. We fit this model to participants’ data from all but one blocks and then perform leave-one-block-out cross-validation. In particular, this model takes as input the current observable feature infor mation in a game (the whole 7×7 matrix) at a time point t to predict a move at time point t + 1. To do so, we take a par ticipant’s data for all but one block, find the best parameters to predict movements in this learning set, and then use the resulting neural network to make out-of-sample predictions for participant’s moves in the left-out block. This procedure is repeated for each participant and every block. The neural network consists of 1 hidden layer that can vary between a size of 1 to 4 nodes (best size chosen given all but the left-out blocks). The neural network model provides a good compar ison to other, more explicit planning models as it takes in all available features at a time but is not based on any explicit planning (although it can capture planning implicitly). 
The third model is a Bayesian Monte Carlo search model. This model takes in the current history of a participant’s 
moves and outcomes so far and then calculates the estimates of the row and column parameters (pi and qj) using the pseudo-Bayesian updating formula described in Equation 1. Afterwards, it plans ahead by executing random moves, col lecting the sampled realizations of rewards from the multi plied probabilities, always performing a Bayesian update af ter each move and sampled outcome. Moreover, this model also correctly assigns a value of 0 to all previously visited tiles when planning future moves, thereby taking into account depleting resources. It is nonetheless still a relatively simplis tic planning model as it does not better its moves as it looks ahead. We approximate the value of moves by using 10,000 random moves of a depth of d = {2,3,4,5} steps to assess how far participants plan ahead in our task. Although par ticipants might plan further ahead than 5 steps, we did not include models of higher depth into our model comparison due to the computational complexity of assessing these mod els in our task (running a model of depth 5 for all partici pants currently takes around 2 days on a cluster with 64 active nodes). We use 10,000 random moves not because we assume that participants might actually mentally simulate that many trajectories, but rather to achieve an appropriate estimate for each move using Monte Carlo samples (i.e., our model would not work well with only a few samples due to the combina torics of the task). 
The final model is a Heuristic Monte Carlo search model. This models is similar to Bayesian Monte Carlo search, but instead of performing a Bayesian update after each simulated move, it only samples realizations of values for pi and qj once at the start and then executes all actions based on the initial samples. This strategy is related (but not equivalent) to an ap proach called root sampling as the probabilities are only sam 
1984
pled once at the root of the planning tree before the search commences (Guez et al., 2013). This heuristic can greatly simplify planning, especially in complex environments and therefore will be used as a heuristic planning model in our comparison. We again approximate the value of moves by us ing 10,000 random moves of a depth of d = {2,3,4,5} steps. 
For all models, we use a softmax function to convert the value of an action Vt(Move) into a choice probability 
Pt(Move) = exp(Vt(Move)/τ) 
∑Nj=1 exp(Vt(Movej)/τ) 
where τ is a free temperature parameter. As τ → 0 the highest value action is chosen with a probability of 1, and when τ → ∞, all options are equally likely. 
We calculate, for every participant and round, a model’s AIC(M ) = −2log(L(M )) + 2k and use this to compute a pseudo-R2 measure as an indicator for goodness of fit, com paring each model Mk to a random model Mrand: 
R2 = 1−AIC(Mk)/AIC(Mrand). 
Modeling results 
Figure 6 shows the results of our model comparison pro cedure. The Heuristic Monte Carlo search models de scribed participants’ moves better than both the neural net work (t(167) = 2.89, p < .01, d = 0.22) and the Associa tive Learning model (t(167) = 23.31, p < .001, d = 1.80). The Bayesian Monte Carlo Search model also performed bet ter than the Neural Network model (t(167) = 2.63, p < .01, d = 0.20) and the Associative Learning model (t(167) = 21.78, p < .001, d = 1.68). The Neural Network model de scribed participants’ moves better than the Associative Learn ing model (t(167) = 7.38, p < .001, d = 0.57). Importantly, the Heuristic Monte Carlo search model performed better than the Bayesian Monte Carlo search model (t(167) = 4.72, p < .001 d = 0.36). Overall, 104 participants were best de scribed by the heuristic Monte Carlo search model, whereas only 64 participants were best described by the Bayesian Monte Carlo search model. None of the participants was best described by either the neural network or the associa tive learning model. Further analyzing the heuristic Monte Carlo search model, a planning horizon of 3 described partic ipants significantly better than a horizon of 2 (t(168) = 9.35, p < .001, d = 1.39), whereas planning horizons of higher than 3 did not lead to any further significant improvements (all p > .05). Thus, a Heuristic Monte Carlo search model with a planning horizon of a size of at least d = 3 provides a satisfactory description of human behavior in our task. How ever, we are currently not able to discriminate between plan ning horizons of more than 3 steps. Although one would nor mally conclude that given the same model class any AIC that is marginally better also implies better model fits, it is not al ways the case that selecting models this way automatically implements Occam’s razor such that often times functional parsimony should also be considered (Rasmussen & Ghahra mani, 2001). Moreover, we do not have an appropriate way 
Table 3: Model comparison results. 
Model AIC Loss P. of ex. Associative Learning 1353 -1.35 .000 Neural Network 1194 -1.19 .005 Bayesian Monte Carlo (3 steps) 1107 -1.11 .010 Heuristic Monte Carlo (3 steps) 1100 -1.09 .985 
of accounting for the fact that deeper planning is computa tionally more expensive although all of these models have the same number of parameters; deeper planning always leads to a large increase of run times in our model comparison. There fore, based on parsimony, we can currently only conclude that a planning horizon of at least 3 steps seems to be sufficient to explain participants’ behavior well in the open maps, but not exactly how many steps people plan ahead in our task. Ta ble 3 shows the models’ overall AIC, trial-wise log-loss, and protected probability of exceedance, i.e. the likelihood that the proportion of participants captured by one model exceeds the proportion of participants captured by all other models (Stephan et al., 2009). This shows again that the Heuristic Monte Carlo model provides a comparatively good fit to par ticipants’ data. 
Next, we assessed how well the different models performed at predicting participants’ moves in the test maps. For this, we used the parameters estimated from the open maps to per form out-of-sample predictions for participants’ decisions in the test maps, calculating the overall median performance of each model per participant over all test maps. As before, the Bayesian Monte Carlo model performed better than the Neural Network model (t(167) = 2.56, p < .05 d = 0.20) and the Associative Learning model (t(167) = 4.7, p < .001 d = 0.36). The Heuristic Monte Carlo model also led to bet ter predictions for the test maps than the Neural Network (t(167) = 2.54, p < .05 d = 0.20) and associative learning model (t(167) = 3.55, p < .001 d = 0.27). As before, the Neural Network lead to better predictions for the test maps than the Associative Learning model (t(167) = 3.55, p < .001 d = 0.27). The Heuristic Monte Carlo search model captured participants’ behavior equally well as the Bayesian Monte Carlo search model (t(167) = 1.87, p = .07, d = 0.19). A horizon of 3 steps again turned out to be sufficient to explain participants’ behavior, describing participants’ decisions bet ter than a horizon of 2 (t(167) = 2.78, p < .001 d = 0.21) and was again indistinguishable from a horizon of 4 or 5 (all p > .05). Taken together, these results imply that a simple model without belief updating, which plans the next move by sampling random sequences of moves with a horizon of at least 3 steps, describes human behavior in our task bet ter than a purely associative reinforcement learning model, a simple neuronal network model, and other models of search with smaller horizons or more sophisticated belief updating. 
Discussion and conclusion 
Planning ahead to search for rewards is an ubiquitous part of our everyday lives. Yet the process by which people do so has previously not gained much scientific attention. We 
1985
Figure 6: Results of the model comparison procedure. Left: Model fit for different models and horizon length. Error bars represent the standard error of the mean. Points show mean fit per participant. Right: Number of participants best described by each model. 
investigated participants’ planning in a challenging foraging task with depleting rewards. Our results revealed that partic ipants managed to learn in this task, improving their perfor mance over time and rounds. Using computational modeling, we defined several models of planning and search and com pared them based on how well they described participants’ moves in our experiment. This comparison revealed that peo ple are best-described by a simple heuristic model of search that —instead of updating beliefs on every step— initializes beliefs only at the start and plans ahead for at least the next 3 moves. As this mechanism of planning has been found to lead to competitive performance and similar strategies can lead to optimal behavior (Guez et al., 2013), people seem to plan ahead heuristically yet efficiently in this complex search task. In future studies, we aim to assess the importance of gener alization in a modification of this task in which outcomes are spatially correlated (Wu et al., 2017), compare more sophis ticated mechanisms of exploration (Schulz et al., 2017a) as well as probe how introducing losses might influence partici pants’ search (cf. Huys et al., 2015; Schulz et al., 2017b). 
Moreover, we intend to tease apart the different models of planning further by creating test sets to optimally discrimi nate between the models. We have also developed an updated version of the game that makes the visual aids even more ex plicit (see https://git.io/vpSPf). Importantly, our models only involved very simplistic planning by random roll-out; com paring more sophisticated tree-search models is therefore the most promising next step ahead. 
Acknowledgements 
MK and ES contributed equally. We thank Peter Dayan and the Max Planck Research Group iSearch for helpful comments. MK is supported by the ESRC and Warwick Business School. ES is supported by the Harvard Data Science Initiative. 
References 
Balaguer, J., Spiers, H., Hassabis, D., & Summerfield, C. (2016). Neural mechanisms of hierarchical planning in a virtual subway 
network. Neuron, 90(4), 893–903. 
Browne, C. B., Powley, E., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P., Tavener, S., Perez, D., Samothrakis, S., & Colton, S. (2012). A survey of Monte Carlo Tree Search meth ods. IEEE Transactions on Computational Intelligence and AI in games, 4(1), 1–43. 
Daw, N. D., Gershman, S. J., Seymour, B., Dayan, P., & Dolan, R. J. (2011). Model-based influences on humans’ choices and striatal prediction errors. Neuron, 69(6), 1204–1215. 
De Groot, A. D. (1978). Thought and choice in chess, vol. 4. Walter de Gruyter GmbH & Co KG. 
Dolan, R. J., & Dayan, P. (2013). Goals and habits in the brain. Neuron, 80(2), 312–325. 
Guez, A., Silver, D., & Dayan, P. (2013). Scalable and efficient bayes-adaptive reinforcement learning based on monte-carlo tree search. Journal of Artificial Intelligence Research, 48, 841–883. 
Huys, Q. J., Eshel, N., O’Nions, E., Sheridan, L., Dayan, P., & Roiser, J. P. (2012). Bonsai trees in your head: How the Pavlovian system sculpts goal-directed choices by pruning decision trees. PLoS Computational Biology, 8(3), e1002410. 
Huys, Q. J., Lally, N., Faulkner, P., Eshel, N., Seifritz, E., Gershman, S. J., Dayan, P., & Roiser, J. P. (2015). Interplay of approximate planning strategies. Proceedings of the National Academy of Sci ences, 112(10), 3098–3103. 
Keramati, M., Smittenaar, P., Dolan, R. J., & Dayan, P. (2016). Adaptive integration of habits into depth-limited planning defines a habitual-goal–directed spectrum. Proceedings of the National Academy of Sciences, 113(45), 12868–12873. 
Rasmussen, C. E., & Ghahramani, Z. (2001). Occam’s razor. In Ad vances in neural information processing systems, (pp. 294–300). Schulz, E., Konstantinidis, E., & Speekenbrink, M. (2017a). Putting bandits into context: How function learning supports decision making. Journal of Experimental Psychology: Learning, Mem ory, and Cognition, (p. 081091). Schulz, E., Wu, C. M., Huys, Q. J. M., Krause, A., & Speekenbrink, M. (2017b). Generalization and search in risky environments. bioRxiv. 
Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershel vam, V., Lanctot, M., et al. (2016). Mastering the game of Go with deep neural networks and tree search. Nature, 529(7587), 484–489. 
Stephan, K. E., Penny, W. D., Daunizeau, J., Moran, R. J., & Fris ton, K. J. (2009). Bayesian model selection for group studies. Neuroimage, 46(4), 1004–1017. 
van Opheusden, B., Galbiati, G., Bnaya, Z., Li, Y., & Ma, W. J. (2017). A computational model for decision tree search. Wu, C. M., Schulz, E., Speekenbrink, M., Nelson, J. D., & Meder, B. (2017). Exploration and generalization in vast spaces. bioRxiv, (p. 171371). 
1986
Physical and Causal Judgments for Object Collisions Depend on Relative Motion 
James R. Kubricht1 Hongjing Lu1,2 
Department of Psychology1 Department of Statistics2 
University of California, Los Angeles 
Abstract 
Human judgments about the physical attributes of—and causal relationship between—two colliding objects have been stud ied extensively over the past seventy years. Recent computa tional evidence suggests that judgments about the mass ratio of two colliding objects, as well as their perceived causal re lation, can be explained by a coherent framework based on a Newtonian physical model and probabilistic inference result ing from noisy observations of object movements. However, it remains unclear how the physical and causal reasoning sys tems interact with the motion perception system when forming these judgments. The current study aims to examine whether high-level judgments are guided by object motion represented as relative motion with reference to a moving background, or as absolute motion with reference to a stationary position in the world. Both experimental evidence and model simulation results support the notion that physical and causal inference in object collisions depend on relative motion rather than abso lute motion. 
Keywords: Intuitive physics; causality; mass judgment; refer ence frame; Bayesian inference 
Introduction 
Over the past seventy years, researchers have examined how human inferences about the attributes of—and causal rela tionship between—colliding objects vary according to spa tiotemporal properties in observed displays (Cohen, 2006; Gilden & Proffitt, 1994; Leslie, 1982; Michotte, 1963; Nat soulas, 1961; Runeson, 1983; Runeson, Juslin, & Olsson, 2000; Saxe & Carey, 2006; Schlottmann & Anderson, 1993; Scholl & Nakayama, 2002; Todd & Warren Jr., 1982; White, 2006). In a typical launching event, an initially moving disc (motor object; or Object A) collides with an initially station ary one (projectile object; or Object B) and causes it to move forwards in the direction that it is pushed. Physically, the mo tor object interacts with the projectile object by imparting its momentum upon it; the sum of the motor and projectile ob jects’ momentum remains constant over time: i.e., the princi ple of conservation of momentum. 
Michotte (1963) found that when people observe launching events, they report an immediate and irresistible impression that the motor object causes the projectile to move forwards. However, participants’ causal ratings were consistently atten uated when either (1) a spatial gap was placed between the colliding objects; (2) the projectile object’s movement was delayed; or (3) the projectile object moved faster/slower than the motor object following impact (see Figure 1). These find ings indicate that causal impressions are highly sensitive to the spatiotemporal characteristics of observed events. How ever, Runeson (1983) later pointed out that causal impres sions were too subjective to reliably measure and instead 
turned his attention towards relative mass judgments. Fol lowing Gibson’s (1966) doctrine of direct perception, he the orized that if people reason according to the principle of con servation of momentum, their judgments about which of two colliding objects is heavier should solely depend on their un biased and accurate estimates of each object’s pre- and post collision velocity. 
Runeson’s predictions were subsequently tested by Todd and Warren (1982) who found that people are instead consis tently biased towards reporting that the motor object is heav ier (i.e., the motor object bias). Moreover, people are more susceptible to this bias when the objects are relatively inelas tic: e.g., deformable vs. rigid balls. To explain these findings, researchers posited that observers form judgments according to simplified heuristic rules based on salient perceptual cues: e.g., which object moves faster after impact and the degree to which each object deflects off of the other (Gilden & Prof fitt, 1994; Runeson et al., 2000). Although the heuristic ap proach qualitatively explains trends in the reported behavioral data, a more recent approach has demonstrated that people do appear to reason about relative mass in accordance with the principle of conservation of momentum, given that their per ception is prone to error and prior beliefs about informative physical variables are held: i.e., the noisy Newton hypothe sis (Sanborn, Mansinghka, & Griffiths, 2013; Sanborn, 2014). 
The Noisy Newton Framework 
The noisy Newton framework was proposed to explain peo ple’s predictions about dynamic physical situations without the implementation of arbitrary heuristic rules. It has been employed across a wide range of physical domains, rang ing from the movement of non-solid substances to causal reasoning through counterfactual simulation (see Kubricht, Holyoak, & Lu, 2017 for a review). The framework supposes that people possess an intuitive physics “en gine” (Battaglia, Hamrick, & Tenenbaum, 2013) encoded in neural circuitry (Fischer, Mikhael, Tenenbaum, & Kanwisher, 2016) which approximately emulates the laws of physics to simulate spatially represented variables forwards in time (see Battaglia, Pascanu, Lai, & Rezende, 2016; Chang, Ull man, Torralba, & Tenenbaum, 2016; Grzeszczuk, Terzopou los, & Hinton, 1998 for a computational approach). More over, since people’s observations are inherently noisy, in ferred estimates of observable variables are consistently bi ased towards prior expectations. 
In the case of object collisions, Sanborn et al.’s (2013) implementation of the noisy Newton framework adopts the generic prior in motion perception (i.e., favoring slow motion in object motion) and a likelihood function which compares 
1987
(A) (B) 
Spatial Gap 
e 
m
i
T
(C) 
Temporal  
 Delay 
or 
1 2 
1 2 
Figure 1: Three common manipulations to spatiotemporal properties of a collision event display in causal perception tasks. The dashed grey lines correspond with different time points during the collision event, and the arrows attached to the discs indicate their magnitude and direction of movement (i.e., velocity). (A) When a spatial gap is placed between the inside edges of two colliding discs at the moment of impact, perceived causality diminishes. (B) Introducing a pause (temporal delay) between when the motor object stops and the projectile object begins moving also attenuates perceived causality. (C) The numbers (1 or 2) indicate two possible outcomes; the projectile object moves either slower than the motor object following collision (Outcome 1) or it moves faster (Outcome 2). People report greater causal impressions after observing Outcome 1 relative to Outcome 2. 
the observed velocity with the derived velocity from a phys ical model. The noisy Newton approach explains the motor object bias and predicts larger biases for relatively inelastic collisions. In addition, the noisy Newton model can be ex tended to account for causal judgments by comparing how well a noisy Newtonian model explains observations com pared with a non-physical model (Sanborn et al., 2013; see Appendix for model details). 
Importantly, the noisy Newton framework does not specify how observable input variables should be represented: e.g., in a dynamic stimulus, object motion can be represented as relative motion with reference to a moving background, or as absolute motion with reference to a stationary position in the world. Furthermore, the physical inference may vary de pending on whether the reasoning system adopts relative or absolute motion signals. For instance, imagine that you are looking out of the left window of a resting train and you see a vehicle move from your left periphery towards a second ve hicle parked on the road nearby. The two vehicles collide, and the second vehicle correspondingly moves in the direc tion that it was pushed. You might get an impression that the two vehicles were equally heavy; but what if the train was traveling in the same direction as the initially moving vehi cle? What if it was traveling in the opposite direction? Would your judgment about the weight of the two vehicles change? Would you be equally likely to report that the first vehicle had launched the second one forwards? Motion perception stud ies have shown that humans can perceive both relative and absolute motion with different degrees of sensitivity (Smeets & Brenner, 1994). For cognitive tasks probing the ability of physical and causal reasoning, it is important to understand what perceptual variables are selected and used for high-level judgments. 
The central effort of the current experiments is to exam ine what motion information is extracted from visual inputs for physical and causal judgments. Previous work on object collision judgments have exclusively used stationary back grounds, providing no distinction between relative and ab 
solute motion. However,in daily life, perceived landmarks are constantly moving across our visual field as we move through—and interact with—the environment. In such cases, representing motion relative to those moving landmarks could provide a different explanation of physical dynamics than ab solute motion does. Across two experiments, we (1) mea sured human performance in physical and causal judgment tasks when viewing object collisions on a moving back ground, and (2) compared noisy Newton model predictions given absolute and relative motion inputs to test the hypoth esis that humans encode relative motion when forming mass judgments and inferring causality. 
Experiment 1: Mass Judgments 
The goal of the first experiment was to determine (1) whether a vertical background grid moving with or against the motion of two colliding objects influences mass ratio judgments; and (2) if so, whether the noisy Newton model for mass collisions with relative motion inputs can explain participants’ perfor mance. 
Participants 
A total of 20 undergraduate students (14 female; Mean age = 21.2) were recruited from the University of California, Los Angeles (UCLA) Department of Psychology subject pool and were compensated with course credit. 
Materials and Procedure 
Collision event videos were presented on a 19” Dell E198WFP LCD monitor with a refresh rate of 40 Hz at 1440 × 900 resolution. Videos were viewed at a distance of ap proximately 70 cm. In each video, an initially moving object (termed as motor object) collided with a stationary (uB = 0) object (termed as projectile object). The pre-collision veloc ity of the motor object varied across eight values: uA = 1.9, 2.3, 2.6, 3.0, 3.4, 3.7, 4.1, and 4.5 cm/sec. The final velocities of the two objects were determined by Newtonian principles 
1988
(A) 
" r
1 
Data 
1 Model 
(B) 
0.75 
g 
e
i
n
i
v
s
a
o
e
o
H
h
 
t
0.75 
(C) 
C 
n
o
it
r
o
p
o
r
P
c
e
jb
O 
r
o
t
o
M"
0.5 0.25 0 
Leftward BG Rest BG 
Rightward BG 
0.5 0.25 0 
1/3 2/3 1/1 3/2 3/1 Mass Ratio (mA/mB) 
1/3 2/3 1/1 3/2 3/1 Mass Ratio (mA/mB) 
Figure 2: The three panels depict a collision event prior to impact where the motor object (left) travels towards the pro jectile object (right). The vertical gray lines indicate a back ground grid which either (A) moves leftward against the di rection of the collision event, (B) remains stationary, or (C) moves rightward in the direction of the collision event. The black and gray arrows indicate the motor object and back ground grid velocities, respectively. 
using a fixed restitution value of e = 0.9 and eight mass ra tio values: mA/mB = 1/3, 1/2, 2/3, 4/5, 5/4, 3/2, 2/1, 3/1. In each video, the background also either moved against the direction of the collision (leftward; -2 cm/sec), with the di rection of the collision (rightward; 2 cm/sec), or it remained at rest (0 cm/sec; see Figure 2). These manipulations yielded 8 (motor speed) × 8 (mass ratio) × 3 (background move ment) = 192 collision stimuli presented in a within-subjects design. Trials were presented in a randomized order, and no feedback was provided. Each stimulus video lasted 4 sec with impact occurring 2 sec into each collision event; the impact location was always at the center of the display. The col lision videos were rendered using MATLAB Psychophysics Toolbox 3. The motor and projectile objects were depicted as black (RGB = 0 0 0) discs with 2.7 cm diameter. The verti cal grid lines spanned the height of the screen (25.4 cm) and were colored gray (RGB = 150 150 150). Each line was 0.08 cm wide with a horizontal line separation of 2.7 cm. 
Prior to the testing trials, participants were informed that they would be watching a series of videos where two discs interact with one another. They were told that there would be vertical lines behind the two discs in each display and that they would either move leftward/rightward or remain at rest. In each trial, participants viewed a collision video and then reported which of the two objects (left or right) they thought was heavier. Participants were provided with the opportunity to take two breaks which occurred 1/3 and 2/3 of the way through the experiment, which lasted approximately 20 min utes. 
Human Results 
The proportion of participants choosing the motor object as appearing heavier in each mass ratio and background move ment condition is displayed in the left panel of Figure 3. Par ticipants’ responses—either 0 or 1—were averaged across the pre-collision motor velocity (uA) conditions prior to analy- 
Figure 3: The measured (left panel) and model predicted (right panel) proportions of participants choosing the motor object as appearing heavier. Separate lines indicate whether the background (BG) moved leftward/rightward or remained at rest. Proportions are averaged across pre-collision velocity (uA) conditions. 
sis. A two-way repeated measures ANOVA was conducted on the response proportions to determine whether mass ratio and background movement influenced mass judgments. Results from the analysis indicated a significant interaction between mass ratio and background movement, F(14,6) = 7.37, p = .01, indicating that the impact of background movement on mass judgments varied according to mass ratio. As evident in Figure 3, participants were more likely to report that the motor object was heavier than the projectile object when the background moved leftward against the direction of the col lision (Figure 2A), and less likely when it moved rightward in the same direction (Figure 2C). In other words, the point of subjective equality (PSE; i.e., the mass ratio where each judgment is equally likely) occurred at a minimum mass ratio with leftward background movement, PSE = 0.62, a moder ate ratio when the background was at rest, PSE = 0.70, and a maximum ratio with rightward background movement, PSE = 0.99. In the following section, we explore whether the noisy Newton model for mass ratio judgments can explain this be havioral trend. 
Model Results 
The noisy Newton model for mass ratio judgments (Sanborn et al., 2013) takes as input the velocities of the motor and projectile objects and outputs the likelihood of an observer choosing the motor object as appearing heavier. In the orig inal noisy Newton model, the input of observed velocity is specified relative to a fixed point on the display; we will refer to these velocities as absolute velocities. This model can account for the motor object bias and predicts that the probability of choosing “motor object heavier” changes as a sigmoid function of the true mass ratio. The noisy New ton model with absolute velocity inputs is represented by the black curve in Figure 3 (right panel) and reveals a fit of r2(22) = 0.91 (95% CI = [0.80, 0.95]). However, critically, the model’s performance is not influenced by the presence and direction of background movement—nor do the model predictions differ—since the absolute velocity inputs do not 
1989
change across the three background movement conditions. Therefore, the model predicts the same PSE in each back ground condition, PSE = 0.95. 
Alternatively, the noisy Newton model can take as input the motor and projectile velocities specified relative to a moving point fixed to the background grid. The result is relatively large velocities when the background moves leftward and relatively small velocities when it moves rightward. Since observation noise in the noisy Newton model increases for larger velocity magnitudes, the influence of the slow motion prior is greatest in the leftward background condition and smallest in the rightward background condition. As shown by the separate curves in the right panel of Figure 3, the noisy Newton model with relative velocity inputs explains people’s increasing bias towards reporting “motor object heavier” in the leftward versus rightward background movement condi tion. The model also provides a superior fit to human judg ments, r2(22) = 0.97 (95% CI = [0.91, 0.98]), and predicts human PSEs: Leftward PSE = 0.54, Rest PSE = 0.95, Right ward PSE = 1.09. The model results for Experiment 1 used the same parameters reported in Sanborn et al. (2013): i.e., σ = 2, kv = .1, wv = .15. 
Experiment 2: Causal Ratings 
Our first experiment showed that the magnitude of the mo tor object bias depends on the background movement direc tion in a collision event. The noisy Newton model with rela tive motion inputs accounts for human mass ratio judgments well across a range of testing conditions. The purpose of the second experiment was to determine whether the same back ground manipulation affects perceived causality, and whether the noisy Newton model can account for human performance. 
Participants 
A total of 29 undergraduate students (20 female; Mean age = 20.5) were recruited from the University of California, Los Angeles (UCLA) Department of Psychology subject pool and were compensated with course credit. 
Materials and Procedure 
The apparatus was the same as in Experiment 1. The stim uli in Experiment 2 were also the same as previously indi cated, except two differences: (1) the motor object was al ways stationary after impact (i.e., vA = 0 cm/sec) and (2) the motor object moved comparatively faster: uA = 6, 11, and 15 cm/sec. Instead of using mass ratio, restitution, and each ob ject’s pre-collision velocity to determine their post-collision velocities in each trial, the ratio of the motor object’s pre collision velocity to the projectile object’s post-collision ve locity (see Figure 1C) was directly manipulated across trials: uA/vB = 0.5, 0.7, 1, 1.4, 2. In addition, a temporal delay (see Figure 1B) was placed between the moment of impact and the projectile object’s initial movement: t = 0, 70, 140, 210, 280 msec. These manipulations yielded 3 (motor speed) × 5 (velocity ratio) × 5 (temporal delay) × 3 (background move ment) = 225 collision stimuli presented in a within-subjects design. The trials were presented in a randomized order and no feedback was provided. The experiment lasted approxi mately 30 minutes. 
Participants began the experiment by viewing a set of in structions informing them that they would be viewing videos of two (equally heavy) discs in motion. Once again, they were informed that there would be vertical grid lines behind the discs that would move leftward/rightward or remain at rest. Following each video, participants were asked, “Did the left object launch the right object?” and responded on a scale from 1 (Definitely No) to 9 (Definitely Yes) with a middle rating of 5 (Unsure). 
Human Results 
As in the previous experiment, we averaged individual par ticipants’ ratings across the three trials with different pre collision motor velocity (uA). Mean ratings in each of the temporal delay, background movement, and velocity ratio conditions are displayed in the top panels of Figure 4. A three-way repeated measures ANOVA was conducted on the mean causal ratings with three within-subjects factors. There was a significant two-way interaction between temporal de lay and velocity ratio, F(16,13) = 2.90, p = .03, indicating that the impact of velocity ratio on causal ratings depended on the magnitude of temporal delay. The three-way interac tion and remaining two-way interactions were not statistically significant. 
The impact of velocity ratio on causal ratings was ex amined in each temporal delay condition. First, we exam ined the condition without temporal delay (t = 0 msec) and found that causal ratings were significantly impacted by ve locity ratio, F(4,25) = 4.33, p < .01, which replicated Mi chotte’s original finding that causal perception of the launch ing effect depends on the ratio between the two objects’ pre and post-collision speeds. However, when a noticeable tem poral delay was introduced, participants rated their causal impression primarily based on the length of the temporal delay—with much less attention given to velocity ratio—as there was no significant simple main effect of velocity ratio in the t = 70,140,210,280 msec temporal delay conditions, F(4,25) = 2.73, .58, 1.07, 1.36; p = .052, .68, .39, .28, re spectively. 
The impact of relative vs. absolute motion on causal rat ings of observed launching events was examined in the ab sence of temporal delay (t = 0 msec), because it was in this condition that velocity had an impact on causal ratings. We found that causal ratings, in fact, were impacted by back ground movement at a 0 msec delay, F(2,27) = 4.02, p = .03 (see Figure 4, top left panel). Specifically, ratings in the right ward background condition were significantly smaller than ratings in the rest background condition, F(1,28) = 7.94, p < .01, as well as smaller than the leftward background con dition, F(1,28) = 5.35, p = .03. These results indicate that when the relative motions of two colliding objects (with re spect to a moving background) are slow, people are less likely to report that the motor object launches the projectile object forwards. 
Model Results 
Predictions from the noisy Newton model with absolute ve locity inputs are indicated by the black curves in the bottom panels of Figure 4. The model predictions were compared 
1990
) 
9
-
1
(
 
g
n
i
t
a
R
 
n
a
m
u
H
9 7 5 3 1 
Delay = 0 msec 
Leftward BG 
Rest BG 
Rightward BG 
9 Delay = 70 msec 7 
5 
3 
1 
9 Delay = 140 msec 7 
5 
3 
1 
9 Delay = 210 msec 7 
5 
3 
1 
9 Delay = 280 msec 7 
5 
3 
1 
1/2 1/1 2/1 
Velocity Ratio (uA/vB) 1 
) 
1/2 1/1 2/1 Velocity Ratio (uA/vB) 
1 
1/2 1/1 2/1 Velocity Ratio (uA/vB) 
1 
1/2 1/1 2/1 Velocity Ratio (uA/vB) 
1 
1/2 1/1 2/1 Velocity Ratio (uA/vB) 
1 
1
-
0
( 
g
n
it
a
R
 
l
e
do
M
0.75 
0.5 
0.25 
0 
1/2 1/1 2/1 
0.75 
0.5 
0.25 
0 
1/2 1/1 2/1 
0.75 
0.5 
0.25 
0 
1/2 1/1 2/1 
0.75 
0.5 
0.25 
0 
1/2 1/1 2/1 
0.75 
0.5 
0.25 
0 
1/2 1/1 2/1 
Velocity Ratio (uA/vB) 
Velocity Ratio (uA/vB) 
Velocity Ratio (uA/vB) 
Velocity Ratio (uA/vB) 
Velocity Ratio (uA/vB) 
Figure 4: Human (top) and model predicted (bottom) causal ratings averaged across pre-collision motor speed (uA) for each velocity ratio (uA/vB) condition. Separate plots (left to right) indicate different temporal delay conditions, and separate lines indicate different background (BG) movement conditions. Vertical error bars indicate standard error of the mean. 
with human ratings in the t = 0 msec condition because it was here that background movement had a significant impact. The absolute model reveals a fit of r2(13) = 0.314 (95% CI = [0.004, 0.718]). The model’s predictions are not influenced by the background movement condition, so it cannot explain the behavioral result that rightward background movement yielded lower causal ratings than resting and leftward back ground movement. 
However, the causal noisy Newton model with relative mo tion inputs—as defined in the previous section—can qualita tively explain the impact of background movement on causal perception. Although the model fit with relative velocity in puts is comparable to the absolute velocity model fit, r2(73) = 0.376 (95% CI = [0.013, 0.761]), the predicted causal ratings are systematically influenced by background move ment (see separate curves in bottom panels of Figure 4). While there was no observable difference between the left ward and rest background predictions, the model shows com paratively lower ratings in the rightward background condi tion compared with the leftward condition, which is consis tent with human results. The model also captures Sanborn et al.’s (2013) finding that a 1/1 velocity ratio corresponds with peak causal ratings. Also note that model ratings achieve floor values at a temporal delay of approximately 210 msec. This occurs because large temporal delays disagree with the prior expectation of a 0 msec delay and thus generate a small temporal likelihood term. Human ratings also appear to reach floor values at around the same temporal delay. We chose the following model parameters in Experiment 2 to account for the human data: σ = 972, kv = .319, kt = .004, wv = .059, P(O|NC) = 2 × 10−5. Note that a separate set of model pa rameters were chosen since the range of velocity input values 
was significantly greater than in the previous experiment. Discussion 
The results reported herein demonstrate that (1) the motor ob ject bias in mass ratio judgment is strengthened or attenuated when the background on which colliding objects travel moves either against or with the direction of their motion, respec tively; and (2) impressions of launching are similarly influ enced by moving backgrounds when there is no temporal de lay between the movements of the two objects. The noisy Newton model (Sanborn et al., 2013) for object collisions was implemented and compared with human data in both a mass ratio judgment and causal rating task. For mass ratio judgment, the model with relative motion inputs accounts for human performance well across a range of experimental con ditions. The goodness of the fit suggests that humans use perceived relative motion as the input to high-level cognitive systems when inferring observable physical properties. For causal perception, the model with relative motion inputs ex plains the finding that background movement with the motion of colliding objects negatively impacts causal ratings. 
In summary, our results show that impressions about the at tributes of—and relationships between—entities in the world are systematically influenced by low-level spatiotemporal characteristics in observed scenes. However, it remains un clear whether the influence of more abstract contextual prop erties (e.g., Mayrhofer & Waldmann, 2014) on causal impres sions can be explained by their spatiotemporal characteris tics alone. Another question is whether human counterfactual reasoning (Gerstenberg, Goodman, Lagnado, & Tenenbaum, 2015; Gerstenberg, Peterson, Goodman, Lagnado, & Tenen baum, 2017) in object collision tasks are also systematically 
1991
influenced by background movement. It would be beneficial for future work to explore these possibilities. 
Acknowledgements 
The current work was supported by a National Science Foun dation (NSF) Graduate Research Fellowship, University of California, Los Angeles (UCLA) Dissertation Year Fellow ship, and NSF grant BSC-1655300. 
Appendix: Noisy Newton Model Details The noisy Newton model for mass judgment uses Bayes’ rule to cal culate a posterior distribution of collision attributes, A, given noisy observable information O: 
P(A|O) = P(O|A)P(A) 
P(O), (1) 
where P(A) represents prior knowledge people have about hidden attributes in collision events. Those attributes are mass, mA and mB, and restitution, e, which is a constant between 0 and 1 that represents the elasticity in a collision. The model assumes that all restitution values are equally likely and objects are more likely to be light than heavy: e ∼ Uniform(0,1); mA, mB ∼ Exponential(1). The P(O|A) term indicates the likelihood of observed velocities (O = uA, uB, vA, vB) given a potential set of attributes (A = e, mA, mB). Here, uA and uB are the pre-collision velocities of Objects A and B, and vA and vB are the post-collision velocities. Post-collision velocities are calculated based on the pre-collision velocities, the object masses, and the collision’s restitution coefficient via the following equations: 
vA =mAuA +mB(uB +e(uB −uA)) 
mA +mB(2) 
va =mBuB +mA(uA +e(uA −uB)) 
mA +mB(3) 
A noisy observation model then links true, hidden variables O¯ with observed variables O such that their difference ε is normally dis tributed in logarithmic space: ε ∼ Gaussian(0, k2x). Given a weighted logarithmic transformation function f(x) = sign(x)log(w|x|+1), the difference between observed and true observations is expressed as ε = f(O)− f(O¯). 
With the noisy observation model, the P(O|A) in Equation 1 can be expanded to include both O and O¯: 
Z 
made the assumption that causal and noncausal models were equally likely: i.e., P(C) = P(NC). 
References 
Battaglia, P. W., Hamrick, J. B., & Tenenbaum, J. B. (2013). Simu lation as an engine of physical scene understanding. Proceedings of the National Academy of Sciences, 110(45), 18327–18332. Battaglia, P. W., Pascanu, R., Lai, M., & Rezende, D. J. (2016). 
Interaction networks for learning about objects, relations and physics. In Advances in neural information processing systems (p. 4502-4510). 
Chang, M. B., Ullman, T., Torralba, A., & Tenenbaum, J. B. (2016). A compositional object-based approach to learning physical dy namics. In Proceedings of the 5th international conference on learning representations (p. 1-15). 
Cohen, A. L. (2006). Contributions of invariants, heuristics, and exemplars to the visual perception of relative mass. Journal of Experimental Psychology: Human Perception and Performance, 32(3), 574-598. 
Fischer, J., Mikhael, J. G., Tenenbaum, J. B., & Kanwisher, N. (2016). Functional neuroanatomy of intuitive physical infer ence. Proceedings of the national academy of sciences, 113(34), E5072-E5081. 
Gerstenberg, T., Goodman, N. D., Lagnado, D. A., & Tenenbaum, J. B. (2015). How, whether, why: Causal judgments as counter factual contrasts. In Proceedings of the 37th annual conference of the cognitive science society. 
Gerstenberg, T., Peterson, M. F., Goodman, N. D., Lagnado, D. A., & Tenenbaum, J. B. (2017). Eye-tracking causality. Psychologi cal Science, 28(12), 1731-1744. Gibson, J. J. (1966). The senses considered as perceptual systems. Boston MA: Houghton Mifflin. 
Gilden, D. L., & Proffitt, D. R. (1994). Heuristic judgment of mass ratio in two-body collisions. Perception & Psychophysics, 56(6), 708–720. 
Grzeszczuk, R., Terzopoulos, D., & Hinton, G. (1998). Neuroanima tor: Fast neural network emulation and control of physics-based models. In Proceedings of the 25th annual conference on com puter graphics and interactive techniques. Kubricht, J. R., Holyoak, K. J., & Lu, H. (2017). Intuitive physics: Current research and controversies. Trends in Cognitive Sciences, 21(10), 749-759. 
Leslie, A. M. (1982). The perception of causality in infants. Per ception, 11(2), 173-186. Mayrhofer, R., & Waldmann, M. R. (2014). Indicators of causal agency in physical interactions: The role of prior context. Cogni tion, 132(3), 485-490. Michotte, A. (1963). The perception of causality. New York, NY: Basic Books. 
Natsoulas, T. (1961). Principles of momentum and kinetic energy in the perception of causality. The American Journal of Psychology, 
P(O|A) = 
O¯0P(O|O¯0)P(O¯0|A)dO¯0, (4) 
74(3), 394-402. 
where the P(O¯|A) term is further separated into initial and final ve locities: i.e., P(O¯|A) = P(v¯A, v¯B|A)P(u¯A,u¯B). Note that pre-collision velocity does not depend on the collision attributes. Instead, values for ¯uA and ¯uB are drawn from the slow motion prior such that ¯uA, u¯B ∼ Gaussian(0, σ2). Post-collision velocities are then calculated from Equations 2 and 3. 
The noisy Newton model can also be used to predict the marginal probability of a causal relationship, C, given noisy observable infor mation, O: 
P(C|O) = P(O|C)P(C) 
P(O|C)P(C) +P(O|NC)P(NC). (5) 
The P(O|C) term in Equation 5 can be expanded to the following integral: 
Z 
Runeson, S. (1983). On visual perception of dynamic events. Stock holm, Sweden: Almqvist Wicksell. Runeson, S., Juslin, P., & Olsson, H. (2000). Visual perception of dynamic properties: cue heuristics versus direct-perceptual com petence. Psychological Review, 107(3), 525–555. Sanborn, A. N. (2014). Testing bayesian and heuristic predictions of mass judgments of colliding objects. Frontiers in psychology, 5. 
Sanborn, A. N., Mansinghka, V. K., & Griffiths, T. L. (2013). Rec onciling intuitive physics and newtonian mechanics for colliding objects. Psychological review, 120(2), 411. 
Saxe, R., & Carey, S. (2006). The perception of causality in infancy. Acta Psychologica, 123(1), 144-165. 
Schlottmann, A., & Anderson, N. H. (1993). An information inte gration approach to phenomenal causality. Memory Cognition, 21(6), 785-801. 
Scholl, B. J., & Nakayama, K. (2002). Contextual effects on the perception of collision events. Psychological Science, 13(6), 493- 498. 
P(O|C) = 
O¯0,A0P(O|O¯0)P(O¯0|A0,C)P(A0)dO¯0dA0. (6) 
Smeets, J. B., & Brenner, E. (1994). The difference between the perception of absolute and relative motion: A reaction time study. 
Note that temporal delay, t, can be included as an observable variable with log-normal uncertainty and a delta function prior centered at 0 msec: P(t¯) = δ(t¯). For the P(O|NC) term, Sanborn et al. (2013) set this value as a free parameter in their model. The authors also 
Vision research, 34(2), 191–195. 
Todd, J. T., & Warren Jr., W. H. (1982). Visual perception of relative mass in dynamics events. Perception, 11(3), 325-335. White, P. A. (2006). The causal asymmetry. Psychological Review, 113(1), 132-147. 
1992
A Dispositional Account of Aversive Racism 
Carole J. Lee (c3@uw.edu) 
Department of Philosophy, Box 353350 
Seattle, WA 98195 USA 
Abstract 
I motivate and articulate a dispositional account of aversive  racism. By conceptualizing and measuring attitudes in terms  of their full distribution, rather than in terms of their mode or  mean preference, my account of dispositional attitudes gives 
ambivalent attitudes (qua attitude) the ability to predict  aggregate behavior. This account can be distinguished from  other dispositional accounts of attitude by its ability to  characterize ambivalent attitudes such as aversive racism at  the attitudinal rather than the sub-attitudinal level and its 
deeper appreciation of the analogy between traits and  attitudes. 
Keywords: implicit attitudes; implicit bias; dispositional  attitudes; attitudes 
Introduction 
Aversive racism is characteristic of individuals who  consciously endorse egalitarian ideals but harbor less  favorable feelings towards the relevant racial group – feelings which may or may not “be admitted inwardly”  (Kovel, 1988, pp. 54-5) and cause subtle patterns of  discriminatory behavior against members of that group  (Dovidio & Gaertner, 2004). There are many reasons, both  intellectual and practical, to make our account of what it is 
to have an attitude answerable to this phenomenon. Socially,  aversive racism is thought to be partly responsible for  persisting racial gaps on health, education, employment, and  economic outcomes despite Americans’ increasing tendency  over the last half-century to endorse ideals of equality  (Bobo, 2001; Dovidio & Gaertner, 2004). Psychologically,  the case of aversive racism against blacks serves as the  archetypical case for measuring and explaining how explicit  and implicit attitudes can come apart (Greenwald et al., 2009). And, philosophically, norm-discordant conditions  like aversive racism seem “to mandate such a radical  reconceptualization of the relation between cognition and  behavior that traditional notions like belief seem quaint and  inadequate” (Gendler 2008b, p. 642). 
What characterization of “attitude” best accounts for the  attitudes held by aversive racists? In progressive debates  about how to draw our “periodic table of attitudes”  (Gendler, 2008b, p. 560), philosophers have pursued two  strategies. One strategy preserves some core notion of belief  (as propositional, norm-sensitive, and consciously 
accessible) while adding a new, contrasting category – such  as aliefs (Gendler, 2008a, 2008b), patchy endorsements  (Levy, 2015), structured beliefs (Mandelbaum, 2015), or co activated representational contents (Holroyd, 2016) – to the  
taxonomy.1 Although these theorists disagree about how  best to distinguish their newly posited attitude of art from  beliefs, they adopt a common strategy for characterizing  aversive racists: aversive racists hold egalitarian beliefs that  are discordant with the new attitude type. An important  advantage of this style of approach is that it allows us to  explicate aversive racism in terms of scientifically informed  but folk-ready categories.2 However, a recurring concern  about this approach is skepticism about “whether the  phenomena that we see are sufficient to motivate wheeling  in the big gun of a new fundamental taxonomical category”  for attitudes (Egan, 2011, pp. 67-8) rather than  accommodating them with conceptual resources already at  our disposal (Mandelbaum, 2013; Kwong, 2012). 
The second strategy for explicating aversive racism hews  to a single attitude category. It adverts to the lower-level  basis of the attitude – such as belief-fragments (Egan, 2008,  2011), mental states/processes (Machery, 2016), and finer 
grained dispositions (Schwitzgebel, 2010, 2013) – to  identify aversive racism as discordance among those sub attitudinal elements. An advantage of this view is that it  sidesteps positing a new taxonomical category. However, it  does so by silencing our ability to ascribe aversive racism at  the attitudinal rather than sub-attitudinal level: attitudes are  not ascribable to those with the fragmented (Egan, 2011),  ambivalent (Machery, 2016), or in-between (Schwitzgebel, 
2002, 2010, 2013) dispositions of aversive racists. I will introduce an account of attitude that enjoys the  advantages of and avoids the disadvantages of these  taxonomical strategies. I will explain how we can describe  aversive racism at the attitudinal (rather than the sub attitudinal) level while positing only one kind of attitude  type. However, rather than cast aversive racism into a  traditional mold (Kwong, 2012), my solution looks forward  by leveraging innovative methods for measuring  psychological constructs to better characterize aversive  racism and other norm-discordant attitudes. 
 
1 Unlike Gendler, Mandelbaum and Levy believe that implicit  attitudes are, like explicit beliefs, propositional and norm-sensitive.  Despite this, they do not take implicit attitudes to “belong to the  same natural kind” as beliefs (Mandelbaum, 2015, p. 636) or to be  sufficiently sensitive to other mental representations “to properly  be considered beliefs” (Levy 2015, p. 800). 
2 Social psychologists have preferred to explain aversive racism  by adding a new type of attitude, namely implicit attitudes (for a  dissenting view, see Fazio, 2007). This allows them to describe  aversive racists as those who simultaneously hold egalitarian  explicit attitudes and racist implicit attitudes towards the same  social group (Son Hing, Li, & Zanna, 2002). 
1993
The particular view I will introduce adopts a dispositional  account of attitude. Like other dispositional accounts  proposed by philosophers (Machery, 2016; Schwitzgebel, 2010, 2013), I will explicate my view by drawing an  analogy between attitudes and personality traits. However, I  will deepen this analogy in a way that reflects, not just how  the structure of traits and attitudes mirror each other, but  how meta-theoretical debates about and methods for  characterizing traits and attitudes should mirror each other.  Moreover, unlike other dispositional accounts – which deny 
the very possibility of attributing ambivalent attitudes  (Machery, 2016, p. 124; Schwitzgebel, 2010, p. 544) – this  view has the capacity to describe the contradictory  tendencies of ambivalent attitudes such as aversive racism  qua attitude. 
Dispositional Accounts of Attitudes 
According to a dispositional approach to conceptualizing  attitudes, attitudes are tendencies to cognize and behave  towards an object (Cronbach & Meehl, 1955; Krosnick,  Judd, & Wittenbrink, 2005; Eagly & Chaiken, 2007;  Greenwald & Nosek, 2008). Dispositions are kept  conceptually separate from and remain agnostic about  claims about the representations and processes underwriting  them (Fazio, 2007; Borsboom, Mellenbergh, & van  Heerden, 2004). Dispositional constructs posited in  psychology include personality traits such as the Big Five  (openness, conscientiousness, extraversion, and  neuroticism).3 
The Analogy between Traits and Attitudes 
Personality traits and attitudes – when conceived as  dispositional constructs – have a number of structural  features in common. Philosophers who advocate for a  dispositional approach to attitudes have leveraged some of  these commonalities to explicate their views in illuminating  ways (Schwitzgebel, 2002, 2013; Machery, 2016). What  these views have in common with each other and with the  dispositional approach adopted by social psychologists  (Krosnick, Judd, & Wittenbrink, 2005; Eagly & Chaiken,  2007; Greenwald & Nosek, 2008) are the following basic  ideas. Traits/attitudes are broad track dispositions to cognize  and behave in certain ways. These dispositions are modal generalizations (concerning not just how people do in fact  cognize and behave but how they would tend to across some  relevant range of conditions). These  dispositions/generalizations hold ceteris paribus. Individuals  can be said to have more or less of a trait/attitude or not,  where individual differences in the degree to which  someone has a trait/attitude can be used to describe and  predict behavior and cognition. Asking individuals to self report their own trait/attitude is just one of many methods  
 
3 Constructs are simply theoretical posits that figure in  psychological generalizations and explanations (Shadish Jr., Cook,  & Campbell, 2002). For a classic discussion on the validation of  dispositional constructs, see Campbell and Fiske (1959). 
for measuring the presence/degree of the dispositional  construct of interest. Individuals can sincerely but falsely  report the presence/degree to which they hold a trait/attitude  as in cases of self-ignorance and self-deception; and, self  reports can vary by context (Breckler & Wiggins, 1989).  More generally, “manifestations of attitudes, as assessed by  any measurement procedure” are “manifested imperfectly  both by our measurement procedures and by other  observable behaviors that it in part motivates” (Krosnick, Judd, & Wittenbrink, 2005, p. 23). As such, any method  used to measure traits/attitudes are understood to be  imperfect. 
How are attitudes, understood as dispositional constructs,  related to the mental states and processes posited by mental  state theorists who prefer to posit cognitive theories of  attitude? In my view, the way to answer this question is to,  again, think analogically to the study of personality traits.  Like the attitudes literature, the personality trait literature  underwent meta-theoretical, conceptual, and methodological  debates about whether to characterize their psychological  posit of interest at the level of dispositional construct or  representation/process (Fazio, 2007; Mischel & Shoda,  1998). In what I’ll call the “standard approach” to solving  this dilemma, personality theorists characterize traits as  dispositions that are underwritten by representations and  processes that serve as the psychological basis for those  dispositions (Epstein, 1994). Likewise, social psychologists  (Greenwald & Nosek, 2008; Eagly & Chaiken, 2007) and  some philosophers (Machery, 2016) who advocate for a  dispositional approach to characterizing attitudes suggest  that attitudes are dispositions that are underwritten by  representations and processes – representations and  processes that mental state theorists aim to uncover. 
Sub-Attitudinal Accounts of Aversive Racism 
Social psychologists who posit two types of dispositional  attitude (one implicit and one explicit) can characterize  aversive racism as a conflict at the attitudinal level: e.g.,  between positive explicit attitudes versus racist implicit  attitudes towards the same group). However, philosophers  who posit dispositional accounts of attitude have been  taxonomically more conservative, preferring to posit one  rather than two attitude types. In what follows, I will explain  why, according to these philosophical views, aversive  racism is describable only at the sub-attitudinal rather than  the attitudinal level. I will then explicate my own view,  which draws on new methods for characterizing personality  traits, describes aversive racism at the attitudinal level, and,  in so doing, articulates my solution to the taxonomical  puzzle. 
Aversive Racism as an In-Between Attitude The heart of Eric Schwitzgebel’s dispositional account is the  idea that “[t]o have an attitude is, primarily, to have a  dispositional profile that matches, to an appropriate degree  and in appropriate respects, a stereotype for that attitude,  typically grounded in folk psychology” (Schwitzgebel,  
1994
2013, p. 78). Each dispositional, folk-psychological  stereotype can be broken down into sub-attitudinal  dispositions, including behavioral, cognitive, and  phenomenal dispositions (Schwitzgebel, 2002). For  example, being extraverted is just to have further  stereotypical dispositional tendencies like enjoying meeting  new people, enjoying parties, “to be talkative, and to take  the lead in social situations” (Schwitzgebel, 2013, p. 81).  Likewise, regarding one’s colleagues as a talented group is  to be disposed to feel proud to be among them, be  unsurprised when they win awards, and seek them out for  insight, among other things (Schwitzgebel, 2013). 
Schwitzgebel rightly observes that “[f]ew of us are 100%  extravert or 100% introvert, 100% high-strung or 100%  mellow” – that we tend to match such stereotypical  dispositions imperfectly (Schwitzgebel, 2013).  Analogously, he observes that we can fail to match  stereotypical attitude dispositions imperfectly  (Schwitzgebel, 2013). In imperfect cases, Schwitzgebel  suggests that “[r]oughly speaking, the greater the  proportion of stereotypical dispostions a person possesses,  and the more central these are to the stereotype, the more  appropriate it is to describe him as having the belief in  question” (Schwitzgebel, 2001, p. 81, italics mine):  methodologically, the injunction is to attribute an attitude  when a subject has the majority of the stereotypical sub attitudinal dispositions or just the central ones, whatever  those turn out to be for that particular context. 
How does Schwitzgebel’s account of attitude describe  aversive racism? On his view, aversive racism can’t be  characterized as a contradictory attitude since contradictory  attitudes are “in general impossible” (Schwitzgebel, 2010, p.  544): we can’t describe a subject as simultaneously having  the majority/central stereotypical sub-attitudinal dispositions  for and against p. Instead, Schwitzgebel suggests that we  treat aversive racism as an in-between attitude  (Schwitzgebel, 2010, 2013).4 For in-between attitudes, “it’s  not quite right, as a general matter, either to ascribe or to  deny” attitudes/traits “simpliciter” (Schwitzgebel, 2010, pp.  535-7). Instead of trying to describe such cases at the  attitudinal level, he suggests that we move instead to “more  complicated appeals to specific dispositions or sets of  dispositions” (Schwitzgebel, 2002, p. 266): in the case of  aversive racism, we should describe individuals in terms of  sub-attitudinal behavioral, phenomenal, and cognitive  dispositions (e.g., the tendency to report holding egalitarian  views while also tending to differentially attribute  “brilliance” to white rather than black students).  Accordingly, Schwitzgebel’s view accounts for and describe  aversive racism at the sub-attitudinal rather than the  attitudinal level.5 
 
4 Although Schwitzgebel originally characterized his analysis of  in-between cases as cases of in-between belief (Schwitzgebel, 2001), he has since extended the generality of his account to cover  cases of in-between attitude as well (Schwitzgebel, 2013). 
5 In passing, Schwitzgebel suggests that an attitude like aversive  racism could be ascribable at the attitudinal level as soon as the  
Aversive Racism as an Ambivalent Attitude On Edouard Machery’s view, to have an attitude is to have a  broad-track disposition “to behave and cognize (have  thoughts, attend, emote, etc.) toward an object (its formal  object) in a way that reflects some preference” (Machery, 2016, p. 112). Machery takes what I call the standard  approach for solving meta-theoretical questions about how  dispositional constructs and mental states/processes relate to  one another: he suggests that attitudes (qua dispositions) are  underwritten by mental states and processes which serve as  the psychological basis of the attitude. For example, the  degree to which a person can be described as courageous  depends on mental states and processes – including “her  moral beliefs (e.g., whether fear is shameful), on the nature  of her fear reactions, on the strength of her pride, on her  capacity for self-control, etc.” (Machery, 2016, p. 112). Likewise, the degree to which someone can be characterized  as being racist depends on mental states and processes – including “moral beliefs (e.g., for most of us the belief that  racism is wrong or, for some racists, the belief that racism is  right), on non-propositional associations between concepts  (e.g., an association between the concept of a black man and  the concept of danger), on emotions (e.g., fear when  confronted with black men), and on a weak self-control”  (Machery, 2016, p. 112). 
How does Machery deal with the problem of aversive  racism? Aversive racism is a kind of ambivalent attitude,  characterized by cognition and behavior that reflects both  favorable and unfavorable evaluations of the relevant  racial/ethnic group. However, this account denies the  possibility of ambivalent attitudes “except perhaps in  pathological cases” (Machery, 2016, p. 124). To better  motivate and contextualize why Machery might hold this  view, I’ll expand the working analogy between the attitudes  and traits literatures to talk at the methodological level. As I  mentioned before, in personality psychology, the standard  approach conceptualizes traits as dispositional constructs  underwritten by the mental states/processes that form their  psychological basis. Early on, personality theorists  characterized these dispositions as central tendencies – operationalized as a person’s mean or average tendency to  cognize/behave – so as to describe that person as an  individual and to describe how she differs from others.  When conceptualized in this way, a dispositional construct  is more useful and informative the more closely that  person’s cognitions and behaviors track some average  tendency: it would not be very useful to describe an  individual as “extraverted on average” if she fluctuated  
  
relevant folk stereotype has been established (Schwitzgebel, 2013,  pp. 94-5). So long as our folk psychological repertoire has not been  so changed, Schwitzgebel’s view does not account for and describe  aversive racism at the attitudinal level. Even if/when our folk  psychological concepts make such a shift, I think there are good  reasons to prefer my dispositional view, which adopts a more  standard psychological approach for characterizing what lies at the  sub-attitudinal level and grounds attitude dispositions in  scientifically more satisfying ways. 
1995
wildly between extraversion and introversion on different  occasions (Fleeson, 2004, pp. 83-4). 
I think this is why Machery says of ambivalent attitudes  that “[i]f the hypothesized co-referential, differently  valenced mental states” lead people to “act and cognize in a  way that expresses a positive preference in some contexts”  and “a negative preference in other contexts,” then “their  aggregate behavior cannot be predicted (even imperfectly)  by postulating a trait” (Machery, 2016, p. 124, italics mine). 
The more that aversive racist cognitions and actions vary,  the less traction we have, conceptually and  methodologically, to attribute attitudes to them. Machery is  not alone in adopting this method of means: social  psychologists who advocate for the existence of one type of  attitude disposition also advert to an individual’s mean  preference for an object when measuring the strength and  direction of their attitude about that object (Eagly &  Chaiken, 2007).6 
Sub-attitudinal versus attitudinal accounts 
As we have seen, competing dispositional accounts of  attitude can describe aversive racism, but do so by adverting  to sub-attitudinal elements rather than appeal to an attitude  proper. 
Pace these accounts, I will explain how it is conceptually  possible for dispositional accounts to characterize  ambivalent attitudes such as aversive racism. By  conceptualizing aversive racism as an attitude, we provide a  perspicuous way to speak about how individuals belonging  to that category will cognize/behave in the future, how they  are similar to each other, and how they differ from those  who hold different attitudes towards the same racial/ethnic  group. 
A New Dispositional Account 
I think that we can address limitations to Machery’s view by  drawing from advances in psychology. Like Machery, I will  adopt the “standard view” for resolving the dispositional  construct versus mental state/process debate. However, I  will advocate for a finer-grained method for characterizing  dispositional attitudes.7 
 
6 Some social psychologists who advocate for mental state views  also take the means approach, whereby “attitudes are defined as  summary evaluations” (Fazio, 2007, p. 608, italics mine). 
7 Because of hard limits on space, I will not be able to provide  an argument for dispositional accounts of attitude over mental state  accounts here. Schwitzgebel favors his dispositional account over  more traditional mental state approaches because his view, unlike  all-or-nothing mental state approaches, could characterize in 
between atttiudes at the sub-attitudinal level (Schwitzgebel, 2002,  2001, 2010). However, mental state theorists have since adopted  more complex views to accommodate in-between cases (Gendler  2008b; Mandelbaum, 2015; Levy, 2015). Machery uses an  inference to best explanation to argue for a dispositional approach  over a mental state approach (Machery, 2016). However, he and I  disagree about what inferences should be drawn from the mixed  psychometric evidence (Lee, forthcoming). I think that there are  other reasons for preferring a dispositional account, including its  
To get us started with the basic idea, let’s consider a  stylized example from the domain of moods. Let’s imagine  we are trying to characterize the emotional lives of two  individuals. We ask them to report their mood along a single  scale that ranges from the negative range (sad) to the  positive (happy) many times over a multi-week period.  Imagine that the two individuals turn out to have the same  mean/average mood (which lies mid-way on our scale).  However, one individual is almost always in a neutral  emotional state while the other rapidly cycles between being extremely happy and extremely sad in equal amounts. If we  were to characterize their emotional lives simply in terms of  their mean mood, we would lose crucial information that  could be used to capture what distinguishes these distinctive  individuals. 
This is what happens when we characterize dispositions in  terms of mean scores while overlooking information about  their full distribution of scores. When we discard  information about the distribution of scores, we forgo  characterizing and drawing distinctions between finer 
grained psychological categories. My proposal is to amend  the method of means by characterizing dispositions not  simply in terms of their mean tendency but also in terms of  their distribution. 
William Fleeson proposed and fruitfully applied this  methodological injunction to the study of personality traits:  personality traits should be distinguished not simply by their  means, but also by distributions over time and contexts:  personalities should be said to differ not simply when their  means differ but when their distributions differ (Fleeson,  2001). Characterizing traits in terms of means and distributions allows personality psychologists to  accommodate within-person variability while still  characterizing traits as stable distributions, so long as an  individual’s mean and distribution are stable attributes of  that individual. Here, variability in cognition and behavior is  its own kind of stable individual-differences characteristic  (Fiske, 1961; Larsen, 1989; Murray, 1938). So, if an  individual veers wildly between low and high extraversion,  but that fluctuation is a stable property of that individual  across a suitably large range of times and contexts, we can  characterize and distinguish her as a different kind of  extravert than the consistently moderate extravert who has  the same mean extraversion score. 
I propose that we carry over this methodological  injunction to the case of attitudes. Conceptualizing attitudes  in terms of an individual’s mean and distribution of  reflected likings and dislikings gives us an intuitive and  powerful way of characterizing attitudes – especially,  ambivalent attitudes. To see this, let’s consider another  stylized example: how should we characterize the aversive  racist versus an individual who holds relatively neutral  views about the relevant racial/ethnic group?8 Here, the  
  
epistemic modesty, which can have pragmatic benefits from a stakeholder/institutional perspective (Lee, forthcoming). 8 In making this comparison, I adopt the working assumption in  psychology that neutral attitudes can be distinguished from  
1996
neutral individual demonstrates a more consistent  indifference, reflecting neither a liking not a disliking for  the racial/ethnic group in their cognition and behavior, including results from direct tests for explicit attitudes and  indirect tests for implicit attitudes. In contrast, the aversive  racist’s preferences fluctuate between a strong liking and a  strong disliking of the racial/ethnic group on direct and  indirect tests. My approach allows us to distinguish the  attitudes held by the aversive racist and the neutral  individual in terms of differences in the distributions of their  reflected preferences. 
By conceptualizing and measuring attitudes in terms of  their full distributions – rather than rely solely on their mode  or means as Schwitzgebel and Machery do – my account of  dispositional attitudes makes it possible for ambivalent  attitudes qua attitude to predict aggregate behavior. Here,  ambivalent attitudes can describe and predict trends in  cognition/behavior so long as there is stability in an  individual’s distribution of reflected preferences across a  suitably large range of times and contexts. (Ambivalent  attitudes do not describe and predict cognition/behavior  strongly enough to predict individual events – there is too  much intra-individual variation for that.) By bestowing  descriptive and predictive power to ambivalent attitudes qua attitude, my account can thereby describe and ascribe  aversive racism at the attitudinal level, and do so while  positing only one attitude type. 
Conclusion 
In this paper, I have motivated and articulated a  dispositional account of aversive racism. My account can be  distinguished from other dispositional accounts by its ability  to characterize aversive racism at the attitudinal level and its  deeper appreciation of the analogy between traits and  attitudes. 
To evaluate the feasibility and fruitfulness of this account,  future research will need to address further questions about  how to implement this proposed account. First, how are  different attitudes towards an object – characterized by  means and by distributions – distinguished from each other?  For example, on what grounds would we distinguish a  category of strong racist from a weak racist from a neutral  individual, especially if there is intra-individual variability  in scores for each category? Second, how should available  direct and indirect measures/tests for attitudes be  selected/combined to provide an appropriate sample (and  scaling) of attitude scores for characterizing an attitude  
  
ambivalent attitudes by their relative indifference to the object and  the stability of that indifference across contexts (Kaplan, 1972;  Bell, Esses, & Maio, 1996; Jonas, Broember, & Diehl, 2000). As  such, neutral and ambivalent attitudes have different functional  characteristics. For example, ambivalent attitudes can be socially  flexible in ways that neutral attitudes are not, where “the co 
existence of positive and negative components allows people to  express their position by putting forward the component that best  fit the specific normative context” without being forced to change  their “general attitude” (Cavazza & Butera, 2008, p. 2). 
toward an object?9 These questions should be explored  psychometrically, though such evidence may not point to unique solutions, since some approaches may be more  suitable for some purposes than others. 
Acknowledgments 
I am grateful for Royalty Research Fund Grant #A79071  (University of Washington) which afforded research time to  complete this article. For illuminating comments and/or  conversations, many thanks to Liam Kofi Bright, Michael  Brownstein, Anthony Greenwald, Edouard Machery,  Jennifer Nagel, Eric Schwitzgebel, Yuchi Shoda, Samuel  Wang, the reviewers, and the audience at the 2015 Central  American Philosophical Association meeting where I first  presented some of these ideas. I am not writing in my  capacity as a contractor for the U.S. National Institutes of  Health. 
References  
Allport, G. W. (1935). Attitudes. In C. Murchison (Ed.), A  Handbook of Social Psychology. Worcester, MA: Clark  University Press. 
Bell, D. W., Esses, V. M., & Maio, G. R. (1996). The utility  of open-ended measures to assess intergroup  ambivalence. Canadian Journal of Behavioural Science,  28, 12-18. 
Bobo, L. D. (2001). Racial attitudes and relations at the  close of the twentieth century. In N. J. Smelser, W. J.  Wilson & F. Mitchell (Eds.), America Becoming: Racial  Trends and Their Consequences. Washington D.C.:  National Academy Press. 
Borsboom, D., Mellenbergh, J. G., & van Heerden, J.  (2004). The concept of validity. Psychological Review,  111, 1061-1071. 
Breckler, S. J., & Wiggins, E. C. (1989). On defining  attitude and attitude theory: Once more with feeling. In A.  R. Pratkanis, S. J. Breckler, & A. G. Greenwald (Eds.), Attitude Structure and Function. Hillsdale, NJ: Lawrence  Erlbaum Associates, Publishers. 
Campbell, D. T., & Fiske, D. W. (1959). Convergent and  discriminant validation by the multitrait-multimethod  matrix. Psychological Bulletin, 56, 81-105. 
Cavazza, N. & Butera, F. (2008). Bending without breaking:  Examining the role of attitudinal ambivalence in resisting  persuasive communication. European Journal of Social  Psychology, 38, 1-15. 
Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in  psychological tests. Psychological Bulletin, 52, 281-302. Dovidio, J. F., & Gaertner, S. L. (2004). Aversive racism. Advances in Experimental Social Psychology, 36, 1-52. 
 
9 There is some precedent for managing such difficulties by  combining existing measures/traits into an overall measure/test.  For example, the Luria-Nebraska Neuropsychological Test Battery  for measuring brain damage combines together new, adapted, and  previously existing scales such as the Wechsler Adult Intelligence  Scale (Rust & Golombok, 2009) 
1997
Eagly, A. H., & Chaiken, S. (2007). The advantages of an  inclusive definition of attitude. Social Cognition, 25, 582- 602. 
Egan, A. (2008). Seeing and believing: Perception, belief  formation and the divided mind. Philosophical Studies, 140, 47-63. 
Egan, A. (2011). Comments on Gendler’s “The epistemic  costs of implicit bias.” Philosophical Studies, 156, 65-79. Epstein, S. (1994). Trait theory as personality theory: Can a part be as great as the whole? Psychological Inquiry, 5,  120-122. 
Fazio, R. H. (2007). Attitudes as object-evaluation  associations of varying strength. Social Cognition, 25,  603-637. 
Fiske, D. W. (1961). The inherent variability of behavior. In  D. W. Fiske & S. R. Maddi (Eds.), Functions of Varied  Experience. Homewood, IL: Dorsey Press. 
Fleeson, W. (2001). Toward a structure- and process integrated view of personality: Traits as density  distributions of states. Journal of Personality and Social  Psychology, 80, 1011-1027. 
Fleeson, W. (2004). Moving personality beyond the person situation debate: The challenge and the opportunity of  within-person variability. Current Directions in  Psychological Science, 13, 83-87. 
Gendler, T. S. (2008a). Alief and belief. Journal of  Philosophy, 105, 634-663. 
Gendler, T. S. (2008b). Alief in action (and reaction). Mind  & Language, 23, 552-585. 
Greenwald, A. G., & Nosek, B. A. (2008). Attitudinal  dissociation: What does it mean?" In R. E. Petty, R. H.  Fazio, & P. Briñol (Eds.), Attitudes: Insights from the  New Implicit Measures. Hillsdale, NJ: Lawrence  Erlbaum. 
Greenwald, A. G., Poehlman, T. A., Uhlmann, E. L., & Banaji, M. R. (2009). Understanding and using the  Implicit Association Test: III. Meta-Analysis of  Predictive Validity. Journal of Personality and Social  Psychology, 97, 17-41. 
Holroyd, J. (2016). What do we want from a model of  implicit cognition? Proceedings of the Aristotelian  Society, 116, 153-79. 
Jonas, K., Broemer, P., & Diehl, M. (2000). Attitudinal  ambivalence. European Review of Social Psychology, 11,  35-74. 
Kaplan, K. J. (1972). On the ambivalence-indifference  problem in attitude theory and measurement: A suggested  modification of the semantic differential technique.  Psychological Bulletin, 77, 361-72. 
Kovel, J. (1988). White Racism: A Psychohistory. London:  Free Association Books. 
Krosnick, J. A., Judd, C. A., & Wittenbrink, B. (2005). The  measurement of attitudes. In D. Albarracin, B. T. Johnson  & M. P. Zanna (Eds.), Handbook of Attitudes and Attitude  Change. Mahwah, NJ: Erlbaum. 
Kwong, J. M. C. (2012). Resisting aliefs: Gendler on belief discordant behaviors. Philosophical Psychology, 25, 77- 91. 
Larsen, R. J. (1989). A process approach to personality  psychology: Utilizing time as a facet of data. In D. M.  Buss & N. Cantor (Eds.), Personality psychology: Recent  trends and emerging directions. New York: Springer 
Verlag. 
Lee, C. J. (2007). The Representation of Judgment  Heuristics and the Generality Problem. Proceedings of the  29th Annual Conference of the Cognitive Science Society (pp. 1211-1216). Austin, TX: Cognitive Science Society. 
Lee, C. J. (Forthcoming). Collective implicit attitudes: A stakeholder conception of implicit bias. Proceedings of  the 40th Annual Conference of the Cognitive Science  Society. Madison, WI: Cognitive Science Society. 
Levy, N. (2015). Neither fish nor fowl: Implicit attitudes as  patchy endorsements. Noûs, 49, 800-823. 
Machery, E. (2016). De-Freuding Implicit Attitudes. In J.  Saul & M. Brownstein (Eds.), Implicit Bias and  Philosophy Volume 1: Metaphysics and Epistemology.  Oxford: Oxford University Press. 
Mandelbaum, E. (2013). Against alief. Philosophical  Studies, 165, 197-211. 
Mandelbaum, E. (2015). Attitude, inference, association: On  the propositional structure of implicit bias. Noûs, 49, 629- 658. 
Mischel, W., & Shoda, Y. (1998). Reconciling processing  dynamics and personality dispositions. Annual Review of  Psychology, 49, 229-258. 
Murray, H. A. (1938). Explorations in personality: A  clinical and experimental study of fifty men of college  age. New York: Oxford University Press. 
Rust, J., & Golombok, S. (2009). Modern psychometrics:  The science of psychological assessment. 3rd ed. New  York: Routledge. 
Schwitzgebel, E. (2001). In-between believing. The  Philosophical Quarterly, 51, 76-82. 
Schwitzgebel, E. (2002). A phenomenal, dispositional  account of belief. Noûs, 36, 249-275. 
Schwitzgebel, E. (2010). Acting contrary to our professed  beliefs or the gulf between occurent judgment and  dispositional belief. Pacific Philosophical Quarterly, 91,  531-553. 
Schwitzgebel, E. (2013). A dispositional approach to  attitudes: Thinking outside of the belief box. In N.  Nottelmann (Ed.), New Essays on Belief: Constitution,  Content, and Structure. New York: Palgrave MacMillan. 
Shadish Jr., W. R., Cook, T. D., & Campbell, D. T. (2002).  Experimental and Quasi-Experimental Designs for  Generalized Causal Inference. Boston: Houghton Mifflin  Company. 
Son Hing, L. S., Li, W., and Zanna, M. P. (2002). Inducing  hypocrisy to reduce prejudicial response among aversive  racists. Journal of Experimental Social Psychology. 38,  71-77. 
1998
Collective Implicit Attitudes: A Stakeholder Conception of Implicit Bias 
Carole J. Lee (c3@uw.edu) 
Department of Philosophy, Box 353350 
Seattle, WA 98195 USA 
Abstract 
Psychologists and philosophers have not yet resolved what  they take implicit attitudes to be; and, some, concerned about  limitations in the psychometric evidence, have even  challenged the predictive and theoretical value of positing  implicit attitudes in explanations for social behavior. In the  midst of this debate, prominent stakeholders in science have  called for scientific communities to recognize and  countenance implicit bias in STEM fields. In this paper, I  stake out a stakeholder conception of implicit bias that  responds to these challenges in ways that are responsive to the  psychometric evidence, while also being resilient to the sorts  of disagreements and scientific progress that would not  undermine the soundness of this call. Along the way, my account advocates for attributing collective (group-level)  implicit attitudes rather than individual-level implicit  attitudes. This position raises new puzzles for future research  on the relationship (metaphysical, epistemic, and ethical)  between collective implicit attitudes and individual-level  attitudes. 
Keywords: collective implicit attitudes; implicit attitudes;  implicit bias; science policy; dispositional attitudes; attitudes 
Introduction 
The American Association for the Advancement of Science  and the National Academies of Science – non-profit  organizations tasked with advancing science and providing  science-based advice – have called for scientific  communities to recognize and countenance implicit bias as  an impediment on women and minority participation and  advancement in science, technology, engineering, and  mathematics (STEM) fields (Pinholster, 2016; National  Academies of Science, 2015). How do we interpret their claims about implicit bias in the face of vociferous debate 
about what implicit attitudes are and real limitations to canonical methods for measuring them – all while creating  evidence-based policies that are resilient to the sort of fine grained empirical debate and progress that would not  undermine the soundness of this call? 
In this paper, I will stake out a stakeholder conception of  implicit bias that finesses two major challenges: (current  and future) disagreement about what implicit attitudes are,  and the psychometric limits of the Implicit Association Test  (IAT).1 While responding to the second challenge, I will  argue for the notion of collective implicit attitudes and  identify some of the metaphysical, epistemic, and ethical  questions they raise for future philosophical inquiry. 
 
1 Because there is more evidence on the discriminant validity of  implicit attitudes as measured by the IAT as opposed to other  measures for implicit attitudes, I focus on IAT-related evidence. 
Challenge 1: Disagreement about what Implicit  Attitudes Are 
Ideally, stakeholders interested in articulating evidence based policies do so in ways that create room for scientific  disagreement about and continued discovery of finer grained scientific details that do not impact the soundness of  the policy. This practical constraint has interesting  implications on whether stakeholder claims and policies should conceptualize implicit attitudes as mental states or as  dispositions. 
Implicit Attitudes as Mental States 
Social psychologists advocating the mental state approach  to conceptualizing implicit attitudes have imputed  competing cognitive accounts of the hidden processes and  representations that explain how social behavior is  generated from stimuli in the environment (De Houwer,  Gawronski, & Barnes-Holmes, 2013). For mental state view  advocates, attitudes are evaluative judgments stored in long 
term memory (Wilson, Lindsey, & Schooler, 2000) or  constructed, “on the spot” (Schwarz, 2007, p. 650), in  working memory (Gawronsky & Bodenhausen, 2006).  Some mental state theorists advocate for just one kind of  underlying representation to do this work (Fazio, 2007).  Others advocate for the existence of two or more  representations that generate judgments and behavior via  different but interacting types of processes (Wilson,  Lindsey, & Schooler, 2000; Wittenbrink, Judd, & Park, 2001). Yet others suggest that the representational base or  “underlying ingredients” (Krosnick, Judd, & Wittenbrink  2005, p. 24) from which implicit and explicit attitudes are  formed are shared, where observed dissociations between  implicit and explicit attitudes result from different processes  rather than from different, independently stored  representations (Gawronski & Bodenhausen, 2007; Strack  & Deutsch, 2004). In light of such disagreement, some  mental state theorists have suggested that the term “attitude”  could “be used as a general integrative label that subsumes  any aspect of process that is responsible for positive or  negative responses toward a given object” (Gawonski &  Bodenhausen 2007, p. 709, italics mine). Among  philosophers advocating a mental-state-like view, some  suggest we add to beliefs a second type of content-laden  attitude (Gendler, 2008; Levy, 2015; Mandelbaum, 2015;  Holroyd, 2016). For others, “wheeling in the big gun of a  new fundamental taxonomical category” (Egan, 2011, pp.  67-8) may not yet be merited (Kwong, 2012). 
1999
Which of these theories is the right one? The imputation  of representations and processes is constrained by each  other: mental representations can only be retrieved and  generate behavior by means of mental processes (Anderson, 
1976; De Houwer, Gawronski, & Barnes-Holmes, 2013;  Machery, 2007); and, processes can only be triggered by  and transform some representations (Gigerenzer &  Hoffrage, 1995; Lee, 2007). However, because there isn’t  consensus about either the representations or processes  involved, the field of possible, empirically permissible  cognitive theories is large enough that “the same behavioral  data” can be explained “as multiple processes operating on a  single representation, one process operating on multiple  representations, or any admixture of representations and  processes” (Greenwald & Nosek, 2008, p. 80). Each of these  cognitive theories – which posit different numbers and types  of representations and processes – can be made and has  been made consistent with the observed evidence. “[T]here  are plausible arguments for any of these positions”  (Gawronski & Bodenhausen, 2007, p. 708). 
From a stakeholder perspective, formulating a policy  that’s conditioned on a prediction about the longevity or  superior empirical adequacy of a particular mental  state/process theory seems unwise. Mental state theories are  so pervasively underdetermined (Bechtel, 2005) that  disagreement among empirically adequate cognitive theories  may be the norm rather than the exception (Greenwald,  2012). Even if we refrain from drawing a pessimistic  induction over a longer history of unsettled debates among  competing mental state theories for other kinds of cognitive  capacities (Greenwald, 2012; Laudan, 1981), it is important  to note that psychologists have voiced concerns that  disagreement among competing cognitive theories of  implicit attitudes in particular “will never end and should  never end” (Eagly & Chaiken, 2007, pp. 585-6) and may be  “impossible to resolve” (De Houwer, Gawronski, & Barnes Holmes, 2013, p. 3), with analogies drawn to “the  [unresolved] debate between abstractive and exemplar based representations in the cognitive literature” (De  Houwer, Gawronski, & Barnes-Holmes, 2013, p. 13).2 
Implicit Attitudes as Dispositions 
From a stakeholder perspective, conceptualizing a policy  that’s conditioned on a prediction about the longevity or  superior empirical adequacy of any particular cognitive  theory in explaining observed and accepted effects is  unnecessary for their purposes if a dispositional approach to  conceptualizing implicit attitudes is available instead.3 
According to the dispositional approach, attitudes – and  implicit attitudes more specifically – are tendencies to  
 
2 Pace Machery (2009), De Houwer et al agree with Barsalou  that “trying to determine whether people use exemplar or  abstracted representations is futile” and “cannot be evaluated on  the basis of behavioral data” (Barsalou, 1990, pp. 61-2). 
3 For more on the relative stability of and agreement about  psychological effects versus their cognitive explanations, see  Cummins (1983, 2000). 
cognize and behave towards an object, where these  tendencies can be (imperfectly) measured through various  measurement procedures (Cronbach & Meehl, 1955;  Krosnick, Judd, & Wittenbrink, 2005; Eagly & Chaiken, 
2007; Greenwald & Nosek, 2008). Dispositions are kept  conceptually separate from and remain agnostic about  claims about the (number of) representations and processes  underwriting them (Fazio, 2007; Borsboom, Mellenbergh,  & van Heerden, 2004). Thus, stakeholders adopting a  dispositional view would be committing to the idea that  while there is some mental state(s)/process(es) underwriting  implicit attitudes, making sense of their policies does not  require theoretical pre-commitment to any particular cognitive theory at the level of mental states/processes.4 
By adopting a dispositional approach, stakeholders would  be adopting a stance of epistemic modesty. Such a stance  would not be unique to the stakeholder perspective – as a  matter of scientific practice, it is also a position that some  psychological researchers adopt. For example, Alice Eagly  and Shelly Chaiken propose characterizing attitudes as  “evaluative tendencies” and “purposefully avoid further  specification of the inner tendency” since “the description of  this inner tendency inevitably changes as attitude research  develops and different theoretical positions emerge, become  popular, and then may erode” (Eagly & Chaiken, 2007, pp. 585-6). Anthony Greenwald and Brian Nosek (2008) adopt  a dispositional approach because they take questions about  the number of underlying representations and processes to  be, at present, “empirically irresolvable” (Greenwald et al.,  2009, p. 32). Going all the way back to 1935, when Gordon  Allport declared the concept of attitude as “the keystone in  the edifice of American social psychology” (Allport, 1935,  p. 798), he noted that the only “common thread” running  through diverging definitions of the concept “attitude”  (Allport, 1935, p. 805) was the idea that attitudes involved a  kind of disposition: “a mental and neural state of readiness,  organized through experience, exerting a directive or  dynamic influence upon the individual’s response to all  
objects and situations with which it is related” (Allport, 1935, p. 810). 
In general, characterizing attitudes as dispositions does  not demote the insight or priority of research on the  psychological basis of the attitude construct (Machery, 2016) or on psychologists’ and philosophers’ theories about  the cognitive architecture underwriting those attitudes (for  just one nice example of this genre at work, see Huebner,  2016). Nor does it deny the reality of progress in these  domains of research. Indeed, the purpose of characterizing  attitudes as dispositions is to provide an account that is  broad enough to accommodate standard patterns of  scientific disagreement and growth in these discussions. In  the natural lifecycle of an interesting effect, second  generation questions about representations and processes – 
studied by identifying boundary conditions and moderators   
4 Note that the dispositional approach does not construe implicit  attitudes as behaviorist posits since implicit attitudes are  underwritten by representation-rich processing. 
2000
for the effect (Spencer, Zanna, & Fong, 2005; Bechtel,  2005; Zanna & Fazio, 1982; Fischhoff, 1982) – are fruitful.  They generate new evidence that informs and constrains  future cognitive theories (De Houwer, Gawronski, &  Barnes-Holmes, 2013; Jacoby & Sassenberg, 2011) and  refine our understanding of the original effect (De Houwer,  Geldof, & De Bruycker, 2005; Gawronski et al., 2008).  Indeed, a mental state/process theory’s generative role in  such debate and progress is a critical part of evaluating the  value of any given cognitive theory (De Houwer,  Gawronski, & Barnes-Holmes, 2103). As such, stakeholders  adopting a dispositional approach would not, by any means,  be discounting the importance of second-generation  research on community effects (Dasgupta, 2013), context  effects (for a review see Gawronski & Bodenhausen, 2008),  training effects (e.g., Brauer et al., 2012), or the influence of  competing cognitive processes in conditions where there is  sufficient cognitive capacity and motivation (e.g., Payne, 2005; Maddux et al., 2005). Such mental state research  makes important strides towards elucidating the  psychological basis of our attitudes – i.e., the  representations and processes underwriting our evaluative  tendencies – and the circumstances under which an  individual’s egalitarian convictions are more likely to be  reflected in her cognition and behavior. 
Overall, stakeholders interested in articulating evidence based policies that can create room for scientific  disagreement about and continued discovery of finer grained scientific details can invoke a dispositional rather  than mental state conceptualization of implicit attitudes. Doing so does not put stakeholders in the awkward position  of betting on the longevity or superior empirical adequacy  of any particular mental state/process theory. Moreover,  such a position allows stakeholders to respect the ways in  which debates at the level of cognitive theory advance our  understanding of implicit attitudes. 
Challenge 2: Psychometric Limits of the IAT 
Stakeholders must address a second challenge. Some have  invoked psychometric evidence to challenge the predictive  and theoretical value of positing implicit attitudes (Machery  2016; Oswald et al., 2013). In response, I think stakeholders  can draw on a fuller suite of the psychometric evidence to  hold that implicit attitudes are legitimately posited – but, are  best attributed to groups of cognizers rather than to  individuals. As such, this position re-interprets the call to  countenance implicit bias in STEM contexts as a call to  countenance collective implicit bias. I will identify this  view’s methodological and meta-methodological rationale,  its policy implications, and some puzzles it raises about  implicit attitudes. 
Psychometric Challenges 
When it comes to the construct validity of implicit attitudes,  the psychometric evidence is quite mixed. The IAT has a  low test-retest reliability, which may indicate that much of  the variation in its scores is attributable to random errors of  
measurement rather than to the presence of an underlying  construct (for a contrary view, see Cunningham, Preacher,  & Banaji, 2001). The IAT has only small-to-moderate  predictive validity (Greenwald et al., 2009; Oswald et al.,  2013; Greenwald, Banaji, & Nosek, 2015). When we look  beyond the IAT to a fuller set of techniques for measuring  implicit attitudes, we see that these have low convergent  validity with each other (Olson & Fazio, 2003; Rudman & Kilianski, 2000), which may be interpreted as suggesting  that there isn’t a shared, underlying construct that they all  measure. 
On the basis of the evidence above, some have suggested  that we should reconsider whether to posit implicit attitudes  at all (Machery, 2016; Oswald et al., 2013) – a position  standing in direct contrast to the overwhelming view among  psychologists and philosophers that implicit attitudes exist  and are sensibly attributed to individual cognizers (for an  overview, see Gawronski & Bodenhausen, 2006;  Brownstein & Saul, 2016a, 2016b). 
In contrast to both these mainstream and radical views, I  think that stakeholders can hold what may, at first, sound  like an unusual position: when considering the fuller suite of  psychometric evidence, stakeholders can support claims  about the construct validity of implicit attitudes, but only  when describing and predicting group-level behavior rather  than individual behavior. 
Discriminant Validity 
The strongest evidence favoring the positing of implicit  attitudes is evidence of its discriminant validity. This  evidence tends to be ignored or discounted by those  adverting to the psychometric evidence to challenge the  legitimacy of implicit attitudes (Machery, 2016; Oswald et  al., 2013). To propose a new construct, psychologists must  bring to bear evidence that distinguishes it from constructs already in use (Campbell & Fiske, 1959). As such, much of  the research on implicit attitudes has focused on their 
discriminant validity in relation to explicit attitudes. Such  evidence includes low correlations between tests thought to  measure these different constructs (Krosnick, Judd, & Wittenbrink, 2005): meta-analysis measures demonstrate that correlations between the IAT and explicit measures  (designed to measure explicit attitudes) are only small-to moderate (Greenwald et al., 2009). Further evidence for discriminant validity includes dissociations (Greenwald & Nosek, 2008): some factors affect implicit but not explicit  attitudes (Karpinski & Hilton, 2001) while other factors  have been shown to impact explicit but not implicit attitudes (Greenwald et al., 2009). Finally, IAT scores and measures  for explicit attitudes each predict variance not predicted by  the other: the predictive validity of IAT scores begins to  catch up to measures for explicit attitudes when dealing with  socially sensitive topics and then outperforms measures for  explicit attitudes in predicting intergroup behavior  (Greenwald et al., 2009). 
Despite the discriminant validity of IAT scores, the IAT’s  low-to-moderate test-retest reliability and low-to-moderate  
2001
predictive validity measures mean that IAT scores cannot be  used diagnostically to predict individual differences in the  “propensity to discriminate” (Oswald et al., 2013, p. 187) – not without risking “undesirably high rates of erroneous  classifications” (Greenwald, Banaji, & Nosek, 2015, p.  557). As such, some suggest that IAT scores should be used  to characterize cognition and behavior at the group or  societal level (Greenwald, Banaji, & Nosek, 2015).5 
Collective Implicit Attitudes 
Because of limitations in the psychometric evidence,  stakeholders should adopt the view that implicit attitudes are  best attributed at the group rather than at the individual  level. This reinterprets calls to recognize implicit bias in  STEM as calls to address biases embodied and exhibited by  collectives. Under this lens, previous questions conceived in  terms of individuals are reimagined at the explicitly  collective level: how do collective implicit biases reflect  unjust social structures – and, what should institutions  (including stakeholders in STEM) do to address them? As  such, this collective account of implicit attitude foregrounds  that “broader conception of attitude that is elastic enough to  apply. . . to broad patterns of culture” – the conceptual  “meeting point for discussion and research” between  psychologists and sociologists (Allport 1935, p. 798). 
This view also raises a number of difficult philosophical  puzzles. Previous work on collective intentionality has  grappled with a number of important challenges associated  with trying to characterize the relationship between  collective attitudes versus the attitudes of the individuals 
belonging to those groups (Gilbert, 1989; Pettit, 2001, 2007;  List & Pettit, 2011). The notion of collective implicit  attitudes raises a number of analogous questions. How  should we characterize the relationship between collective  implicit biases versus the attitudes of the individuals  belonging to those groups? And, what are the ramifications  of these accounts on assessing the epistemic and moral  responsibility of the collective versus its individuals? 
Finally, there may be some who remain skeptical about  whether the psychometric evidence is sufficient to begin  thinking or talking about launching interventions at all. Note  that, even if the IAT is not a diagnostically terrific screening  tool for predicting which individuals will commit  discriminatory acts, stakeholders can nevertheless adopt  interventions designed to reduce the overall risk of biased  behavior, even among groups who do not have high IAT  scores; and, some interventions may be inexpensive and  beneficial enough to merit their broad acceptance and  adoption. To understand how this might be the case,  consider this analogy to the case of blood pressure. From an  epidemiological perspective, some take blood pressure  readings to be a poor screening tool when it comes to   
5 Note that IAT scores can still inform the evidence base used to  characterize individuals; however, they may be best used fruitfully  towards attributing, not implicit attitudes, but courser-grained  attitudes like aversive racism (Lee, forthcoming; Dovidio &  Gaertner, 2004). 
predicting cardiovascular events such as heart attack or  stroke (Law, Wald, & Morris, 2003). However, because  lowering blood pressure is good for decreasing the risk of  cardiovascular events even among groups without high  blood pressure, and because the cost of interventions used to  lower blood pressure are inexpensive and beneficial, it  makes good sense to implement such interventions broadly  (for those above a certain age) regardless of their blood  pressure reading (Law, Wald, & Morris, 2003). 
Conclusion 
In this paper, I staked out a stakeholder conception of  implicit bias. This position responds to two important  challenges. First, it navigates debates about whether implicit  attitudes should be conceptualized as mental states or as  dispositions by appealing to a form of epistemic modesty  that is savvy to disagreement and growth in psychological  research. This allows stakeholder injunctions (to attend to  implicit bias in scientific communities) to be resilient to  finer-grained forms of scientific debate and progress that  would not impact the ultimate soundness of this call. Second, it recognizes real strengths and weaknesses in the  psychometric evidence for implicit attitudes by  understanding tests for implicit attitudes (in particular, the  IAT) as tools for characterizing group-level rather than  individual-level behavior. This position raises rich and  pressing philosophical questions about how we should  understand the relationship – metaphysical, epistemic, and  ethical – between collective implicit attitudes and  individual-level attitudes. 
Acknowledgments 
I am grateful for Royalty Research Fund Grant #A79071  (University of Washington) which afforded research time to  complete this article. For illuminating comments and/or  conversations, many thanks to Liam Kofi Bright, Michael  Brownstein, Anthony Greenwald, Edouard Machery,  Jennifer Nagel, Eric Schwitzgebel, Yuchi Shoda, Samuel  Wang, the reviewers, and the audience at the 2015 Central  American Philosophical Association meeting where I first  presented some of these ideas. I am not writing in my  capacity as a contractor for the U.S. National Institutes of  Health. 
References  
Allport, G. W. (1935). Attitudes. In C. Murchison (Ed.), A  Handbook of Social Psychology. Worcester, MA: Clark  University Press. 
Anderson, J. R. (1976). Language, Memory, and Thought.  Hillsdale, NJ: Erlbaum. 
Barsalou, L. W. (1990). On the indistinguishability of  exemplar memory and abstraction in category  representation. In T. K. Srull & R. S. Wyer (Eds.), Advances in Social Cognition, Volume III: Content and  Process Specificity in the Effects of Prior Experiences.  Hillsdale, NJ: Lawrence Erlbaum Associates. 
2002
Bechtel, W. (2005). The challenge of characterizing  operations in the mechanisms underlying behavior. Journal of the Experimental Analysis of Behavior, 84,  313-325. 
Borsboom, D., Mellenbergh, G. J., & van Heerden, J.  (2004). The concept of validity. Psychological Review, 111, 1061-1071. 
Brauer, M., Er-rafiy, A., Kawakami, K, & Phills, C. E.  (2012). Describing a group in positive terms reduces  prejudice less effectively than describing it in positive  and negative terms. Journal of Experimental Social  Psychology, 48, 757-761. 
Brownstein, M., & Saul, J. (Eds.). (2016a). Implicit Bias &  Philosophy, Volume 1: Metaphysics and Epistemology. Oxford, UK: Oxford University Press. 
Brownstein, M., & Saul, J. (Eds.). (2016b). Implicit Bias &  Philosophy, Volume 2: Moral Responsibility, Structural  Injustice, and Ethics. Oxford, UK: Oxford University  Press. 
Campbell, D. T., & Fiske, D. W. (1959). Convergent and  discriminant validation by the multitrait-multimethod  matrix. Psychological Bulletin, 56, 81-105. 
Cronbach, L. J., & Meehl, P. E. (1955). Construct validity in  psychological tests. Psychological Bulletin, 52, 281-302. Cummins, R. (1983). The Nature of Psychological  
Explanation. Cambridge, MA: The MIT Press. Cummins, R. (2000). “How does it work?” vesus “What are  the laws?” Two concepts of psychological explanation. In  F. C. Keil & R. A. Wilson (Eds.), Explanation and  Cognition. Cambridge, MA: The MIT Press. 
Cunningham, W. A., Preacher, K. J., & Banaji, M. R.  (2001). Implicit attitude measures: Consistency, stability,  and convergent validity. Psychological Science, 12, 163- 170. 
Dasgupta, N. (2013). Implicit attitudes and beliefs adapt to  situations: A decade of research on the malleability of  implicit prejudice, stereotypes, and the self-concept.  Advances in Experimental Social Psychology, 47, 233- 
279. 
De Houwer, J., Gawronski, B., & Barnes-Holmes, D.  (2013). A functional-cognitive framework for attitude  research. European Journal of Social Psychology, 24,  252-287. 
De Houwer, J., Geldof, T, & De Bruycker, E. (2005). The  Implicit Association Test as a general test of similarity. Canadian Journal of Experimental Psychology, 59, 228- 239. 
Dovidio, J. F., & Gaertner, S. L. (2004). Aversive racism. Advances in Experimental Social Psychology, 36, 1-52. Egan, A. (2011). Comments on Gendler’s “The epistemic  costs of implicit bias.” Philosophical Studies, 140, 47-63. Eagly, A. H., & Chaiken, S. (2007). The advantages of an  inclusive definition of attitude. Social Cognition, 25, 582- 602. 
Fazio, R. H. (2007). Attitudes as object-evaluation  associations of varying strength. Social Cognition, 25,  603-637. 
Fischhoff, B. (1982). Debiasing. In D. Kahneman, P. Slovic,  & A. Tversky (Eds.), Judgment Under Uncertainty:  Heuristics and Biases. Cambridge, U.K.: Cambridge  University Press. 
Gawronski, B., & Bodenhausen, G. V. (2006). Associative  and propositional processes in evaluation: An integrative  review of implicit and explicit attitude change. Psychological Bulletin, 132, 692-731. 
Gawronski, B., & Bodenhausen, G. V. (2007). Unraveling  the processes underlying evaluation: Attitudes from the  perspective of the APE model. Social Cognition, 25, 687- 717. 
Gawronski, B., Deutsch, R., LeBel, E. P., & Peters, K. R.  (2008). Response interference as a mechanism underlying  implicit measures: Some traps and gaps in the assessment  of mental associations with experimental paradigms. 
European Journal of Psychological Assessment, 24, 218- 225. 
Gendler, T. S. (2008). Alief in action (and reaction). Mind &  Language, 23, 552-585. 
Gigerenzer, G., & Hoffrage, U. (1995). How to improve  Bayesian reasoning without instruction: Frequency  formats. Psychological Review, 102, 684-704. 
Gilbert, M. (1989). On Social Facts. Princeton, NJ:  Princeton University Press. 
Greenwald, A. G. (2012). There is nothing so theoretical as  a good method. Perspectives on Psychological Science, 7,  99-108. 
Greenwald, A. G., Banaji, M. R., & Nosek, B. A. (2015).  Statistically small effects of the Implicit Association Test  can have societally large effects. Journal of Personality  and Social Psychology, 108, 553-561. 
Greenwald, A. G., & Nosek, B. A. (2008). Attitudinal  dissociation: What does it mean? In R. E. Petty, R. H.  Fazio, & P. Briñol (Eds.), Attitudes: Insights from the  New Implicit Measures. Hillsdale, NJ: Lawrence  Erlbaum. 
Greenwald, A. G., Poehlman, T. A., Uhlmann, E. L., & Banaji, M. R. (2009). Understanding and using the  Implicit Association Test: III. Meta-analysis of predictive  validity. Journal of Personality and Social Psychology,  97, 17-41. 
Holroyd, J. (2016). What do we want from a model of  implicit cognition? Proceedings of the Aristotelian  Society, 116, 153-179. 
Huebner, B. (2016). Implicit bias, reinforcement learning,  and scaffolded moral cognition. In M. Brownstein & J.  Saul (Eds.), Implicit Bias & Philosophy, Volume 1:  Metaphysics and Epistemology. Oxford, UK: Oxford  University Press. 
Jacoby, J., & Sassenberg, K. (2011). Interactions do not  only tell us when, but can also tell us how: Testing  process hypotheses by interaction. European Journal of  Social Psychology, 41, 180-190. 
Karpinski, A., & Hilton, J. L. (2001). Attitudes and the  Implicit Association Test. Journal of Personality and  Social Psychology, 81, 774-788. 
2003
Krosnick, J. A., Judd, C. A., & Wittenbrink, B. (2005). The  measurement of attitudes. In D. Albarracin, B. T. Johnson  & M. P. Zanna (Eds.), Handbook of Attitudes and Attitude  Change. Mahwah, NJ: Erlbaum. 
Kwong, J. M. (2012). Resisting aliefs: Gendler on belief discordant behaviors. Philosophical Psychology, 25, 77- 91. 
Laudan, L. (1981). A confutation of convergent realism. Philosophy of Science, 48, 19-49. 
Law, M., Wald, N., & Morris, J. (2003). Lowering blood  pressure to prevent myocardial infarcation and stroke: A  new preventive strategy. Health Technology Assessment,  7 (31). 
Lee, C. J. (2007). The Representation of Judgment  Heuristics and the Generality Problem. Proceedings of the  29th Annual Conference of the Cognitive Science Society (pp. 1211-1216). Austin, TX: Cognitive Science Society. 
Lee, C. J. (Forthcoming). A dispositional account of  aversive racism. Proceedings of the 40th Annual  Conference of the Cognitive Science Society. Madison,  WI: Cognitive Science Society. 
Levy, N. (2015). Neither fish nor fowl: Implicit attitudes as  patchy endorsements. Noûs, 49, 800-823. 
List, C., & Pettit, P. (2011). Group Agency: The Possibility,  Design, and Status of Corporate Agents. New York, NY:  Oxford University Press. 
Machery, E. (2007). Concept empiricism: A methodological  critique. Cognition, 104, 19-46. 
Machery, E. (2009). Doing Without Concepts. Oxford,  U.K.: Oxford University Press. 
Machery, E. (2016). De-Freuding implicit attitudes. In J.  Saul & M. Brownstein (Eds.), Implicit Bias and  Philosophy Volume 1: Metaphysics and Epistemology.  Oxford, U.K.: Oxford University Press. 
Maddux, W. W., Barden. J., Brewer, M. B., & Petty, R. E.  (2005). Saying no to negativity: The effects of context  and motivation to control prejudice on automatic  evaluative responses. Journal of Experimental Social  Psychology, 41, 19-35. 
Mandelbaum, E. (2013). Against alief. Philosophical  Studies, 165, 197-211. 
Mandelbaum, E. (2015). Attitude, inference, association: On  the propositional structure of implicit bias. Noûs, 49, pp.  629-658. 
National Academies of Science. (2015). Implicit bias  workshop with Anthony Greenwald and Brian Nosek.  Retrieved from  http://sites.nationalacademies.org/PGA/cwsem/PGA_173 
396. 
Olson, M. A., & Fazio, R. H. (2003). Relations between  implicit measures of prejudice: What are we measuring? Psychological Science, 14, 636-639. 
Oswald, F. L., Mitchell, G., Blanton, H., Jaccard, J., & Tetlock, P. E. (2013). Predicting ethnic and racial  discrimination: A meta-analysis of IAT criterion studies. Journal of Personality and Social Psychology, 105, 171- 192. 
Payne, B. K. (2005). Conceptualizing control in social  cognition: How executive functioning modulates the  expression of automatic stereotyping. Journal of  Personality and Social Psychology, 89, 488-503. 
Petit, P. (2007). Responsibility incorporated. Ethics, 117,  171-201. 
Petit, P. (2011). A Theory of Freedom: From the Psychology  to the Politics of Agency. New York, NY: Oxford  University Press. 
Pinholster, G. (2016). Journals and funders confront implicit  bias in peer review. Science, 352, 1067-1068. 
Rudman, L. A., & Kilianski, S. E. (2000). Implicit and  explicit attitudes toward female authority. Personality and  Social Psychology Bulletin, 26, 1315-1328. 
Saul, Schwarz, N. (2007). Attitude construction: Evaluation  in context. Social Cognition, 25, 638-656. 
Schwitzgebel, E. (2001). In-between believing. The  Philosophical Quarterly, 51, 76-82. 
Schwitzgebel, E. (2002). A phenomenal, dispositional  account of belief. Noûs, 36, 249-275. 
Schwitzgebel, E. (2010). Acting contrary to our professed  beliefs or the gulf between occurent judgment and  dispositional belief. Pacific Philosophical Quarterly, 91,  531-553. 
Schwitzgebel, E. (2013). A dispositional approach to  attitudes: Thinking outside of the belief box. In N. Nottelmann (Ed.), New Essays on Belief: Constitution,  Content, and Structure. New York: Palgrave MacMillan. 
Spencer, S. J., Zanna, M. P., & Fong, G. T. (2005).  Establishing a causal chain: Why experiments are often  more effective than mediational analyses in examining  psychological processes. Journal of Personality and  Social Psychology, 89, 845-851. 
Strack, F., & Deutsch, R. (2004). Reflective and impulsive  determinants of social behavior. Personality and Social  Psychology Review, 8, 220-247. 
Wilson, T. D., Lindsey, S., & Schooler, T. Y. (2000). A  model of dual attitudes. Psychological Review, 107, 101- 126. 
Wittenbrink, B., Judd, C. A., & Park, B. (2001). Evaluative  versus conceptual judgments in automatic stereotyping  and prejudice. Journal of Experimental Social  Psychology, 37, 244-252. 
Zanna, M. P., & Fazio, R. H. (1982). The attitude-behavior  relation: Moving toward a third generation of research. In  M. P. Zanna, E. T. Higgins, & C. P. Herman (Eds.), Consistency in Social Behavior: The Ontario Symposium.  Hillsdale, NJ: Erlbaum. 
2004
The Effects of Age and Event Structure on Timeline Estimation Task  
Saebyul Lee, Su Keun Jeong  
(leesaebyul@kbri.re.kr; skjeong@kbri.re.kr) 
Korea Brain Research Institute, 61 Cheomdan-ro,  
Dong-gu, Daegu, 41068, South Korea 
Abstract 
Most previous studies on time perception have examined  temporal order and distance judgments in isolation using  controlled stimuli. However, in real life, these two elementary  temporal experiences are related. Here, we examine the effects  of age and event structure on temporal estimation and introduce 
a novel timeline estimation paradigm comprising temporal  order and distance judgments with naturalistic stimuli. In two  experiments, we asked participants to view a three-minute-long  video clip and mark the temporal order and distance of a  specific scene of the video on a horizontal timeline. In the first  experiment, we conducted the timeline estimation task with  three different age groups – 6-8-year-olds, 9-11-year-olds and adults – and found age-related differences in the participants’  accuracy and variability of temporal estimation. The  nonlinearity between their estimates and stimulus distance 
decreased as their ages increased. In Experiment 2, we tested  the effect of event structure on participants’ timeline estimation  and observed that more complicated video resulted in more  distorted temporal estimation. In sum, the current study  corroborated the timeline estimation task to be a valuable tool  for assessing temporal judgments across development.  
Keywords: temporal order memory; duration judgment; time  estimation; temporal concept development 
Previous studies on time perception have primarily examined  temporal distance (duration) perception, temporal order  judgments, and episodic/autobiographical memory (Allman,  Teki & Griffith, 2014; Grondin, 2010). Specifically, the  former two areas have been investigated extensively using  different experimental paradigms in isolation. Regarding  temporal distance perception, prior research has used interval reproduction, comparison, and temporal bisection tasks with  simple visual shapes or acoustic tones to examine subject’s  temporal distance perception over milliseconds and seconds.  
However, the experimental procedure of classical  temporal distance perception has significant limitations for  covering a broad range of intervals. For example, since the  temporal bisection task, one of the most widely used tasks in  the temporal distance perception literature, requires  registering the length of the referent stimulus in the short 
term memory, it cannot be extended beyond several seconds  without secondary strategies such as counting and tapping.  Furthermore, pure interval timing beyond several seconds  would be an unnatural human timing process because in daily  life, temporal distance perception over several seconds would  be accompanied by other cognitive processes, such as event  perception and memory. Lastly, methodological demands  encourage the use of conscious time-keeping strategies  
(prospective timing), but these strategies are not commonly  used in everyday life. Therefore, recent studies have argued that some previous findings in temporal distance perception  are incompatible with ordinary interval timing experiences  (Boltz, 2005; Droit-Volet, Trahanias, & Maniadakis, 2017).  
On the other hand, temporal order memory studies have relied on retrospective timing; thus, the participants did not  know that they would be asked to make a time judgment until  after an event had taken place. Therefore, this paradigm  assesses the temporal relation remembered between events,  which is ecologically more valid. Nonetheless, temporal  order memory studies have investigated controlled stimuli, similar to the temporal distance perception studies. Although  such stimuli can provide rigorous experimental control, it is  not always clear whether the results of their use can be  generalized to everyday events. Specifically, given the  importance of people’s attention to time perception (Boltz,  1999; Brown, 2008; Grondin, 2010), time perception with  realistic stimuli may be substantially different from that with the highly-controlled stimuli.  
Therefore, it has been argued that the time estimation  literature should have involved tasks with more ecological  validity (Boltz, 2005; Brown & West, 1990; Carell, 2011;  DuBrow & Davachi, 2016). However, the attempts at 
conducting empirical research with realistic stimuli (Bisson,  Tobin & Grondin, 2012; Tobin, Bisson & Grondin, 2010, Droit-Volet, Trahanias, & Maniadaks, 2017, Nielson et al.,  2015) still have not produced conclusive answers about  similarities and dissimilarities between naturalistic and  highly controlled time perception. In addition, they have not  attempted to investigate temporal distance and order  experiences simultaneously as in real life.  
Given these limitations, we developed a novel temporal  judgment task (a) involving both temporal distance and order  perception (b) using more natural stimuli (c) ranging from  seconds to minutes (d) under both retrospective and  prospective timing (e) without relying on temporal word  knowledge to investigate the effects of age and event  structure on temporal estimation. In this task, we asked  
Figure 1. An example of a timeline task 
2005
participants to study a three-minute-long video clip excerpted  from commercial movies; then, we presented participants  with a still picture from the video clip and a concrete  horizontal line, referred to as a ‘timeline,’ and asked them to  identify the temporal position of the still picture on the  timeline.  
In Experiment 1, we investigated developmental  changes in different age groups – 6-8-year-olds, 9-11-year olds and adults – and these groups’ temporal judgment of  minute-range intervals with the mean estimates and variation  of judgments. In Experiment 2, we investigated whether the  event structure of the stimuli and timing paradigms  (prospective/retrospective) affected the adults’ timeline  estimation performance. 
Experiment 1 
In Experiment 1, we present a novel “timeline estimation”  task, which (a) does not rely on participants’ temporal word  knowledge, (b) uses a realistic event as a stimulus, and (c)  involves both temporal distance and order judgments. We  compared the mean estimates and variations of temporal  judgment across different age groups to investigate the  developmental changes for each judgment. 
Method 
Participants. Experiment 1 included three age groups: 6-8- year-old children, 9-11-year-old children and adults. A total  of 105 children were recruited from schools in Columbus,  Ohio. Parents of the children provided written consent. The  adult participants were 34 undergraduate students who  participated in exchange for a course credit at the Ohio State  University.  
Materials and Procedure. Participants carried out the  timeline estimation task consisting of initial learning, math  problem solving, and testing phases. In the learning phase,  we presented the participants with a three-minute-long video  clip. To control for the confounding effect of narrative on  temporal judgment, we removed the sound of the stimuli. We  instructed the participants to pay attention to and remember  the contents of the video. After the initial learning phase, we  asked the participants to solve five math problems to control  for the recency effect of short-term memory. We modulated  the difficulty of the math problems according to the  participant’s age. We created 30 still pictures from every six  
Analyses. We evaluated the participants’ mean estimates,  percent absolute errors (PAEs), coefficients of variation (CVs), and nonlinearity scores. One method for obtaining an  overall sense of the participants’ estimate efficiency is the  PAE, which was calculated as follows (Siegler & Booth,  2004): 
PAE = |�������� − ��������| 
����� �� ��������� 
Another way of assessing the participants’ efficiency is  by using the CV which was calculated as the standard  deviation of the estimates divided by the mean estimate.  According to one of the most widely accepted ‘scalar  property’ principles in the field of interval timing (Gibbon, 
1977), the CV should remain constant across a range of  intervals if temporal perception follows Weber’s law as other  sensory dimension perceptions do. This property is  considered as evidence of any single mechanism by which  given intervals are timed. Thus, we calculated the CV across  subjects and tested whether it was constant across the length  of a timeline and whether there were any developmental  differences according to the CV change. 
Lastly, in line with the procedure of Cicchini et al.  (2014) in a number-line study, we regressed the participants’ estimates against the target distance using a combined log linear regression model: 
� = � 7(1 − �)� + � ∗ �?@A 
ln(�?@A) ∗ ln(�)D 
where R denotes the response to the given target distance T,  a is a scaling factor, and Tmax is the distance at the right end  of the timeline (180 in the current study). The degree of  nonlinearity is denoted by λ. If λ equals 0, the relation  between the estimates and target distances is perfectly linear,  whereas if λ is 1, the relation is perfectly logarithmic.  
The linear relationship indicates that the participants  perceived the correct temporal order of the given stimuli, as  well as the distance between them, as constant across the time  range. On the other hand, the nonlinear (logarithmic) relation  indicates that the participants overestimated the distance of  the initial events and underestimated the distance of the  
1 8 0 
a) b) 
1 5 0 
seconds of the video clip for all participants and randomly  
1 2 0 
) 
s 
(
chose 40 of these still pictures for each participant to observe.  
e 
t
9 0 
a 
In the testing phase, we gave the participants a timeline  
m 
i
t
s 
estimation task in which we presented a timeline with the 40  
6 0 
E 
still pictures; one picture was shown per trial. In each trial,  
3 0 
we instructed the participants to indicate approximately when  0 
the still picture appeared while they were watching the video  
6 -8 -y e a r-o ld s 9 -1 1 -y e a r-o ld s A du lts 
) V 
C (
n 
o 
it
a 
ir
a 
v 
f o 
t n 
e 
i
c 
if
fe 
o 
C 
2 .0 1 .5 1 .0 0 .5 0 .0 
6 -8 -y e a r-o ld s 9 -1 1 -y e a r-o ld s A du lts 
by marking the corresponding place on the timeline using a  
0 3 0 6 0 9 0 1 2 0 1 5 0 1 8 0 S tim u lu s d is ta n c e (s ) 
1 0 0 .5 1 0 1 .0 1 0 1 .5 1 0 2 .0 1 0 2 .5 S tim u lu s d is ta n c e (s ) 
mouse click (see Figure 1). We did not provide feedback on  their performance.  
2006
 Figure 2. a) Participants’ estimates along the target duration,  b) logarithmic decrease in CV with increase in target duration. 
events near the end of the range. In addition, previous studies  
1 .0 
using the number line estimation task, which has a similar  
a 
task structure to the timeline task, reported a logarithmic to  
d 
b 
m 
linear shift across development (Kim & Opfer, 2015; Siegler  
a 
L 
: 
& Booth, 2004; Siegler & Opfer, 2003). We also aimed to  
e 
r
o 
0 .5 
examine whether there was a similar shift in temporal  
c 
s 
y 
estimation. 
t
i
r
a 
e 
n 
i
l
Results and Discussion 
n 
o 
N 
0 .0 
Mean Estimates and CVs. First, as Figure 2a shows, the  
6 ~ 8 9 ~ 1 1 A d u lts 
mean estimate increased as the target interval increased  across the three different age groups. Although the estimates  and target intervals were not perfectly linear mapped, the  adults and 9-11-year-old children showed a relatively more  linear pattern than the 6-8-year-old children, F(2, 136) = 6.65,  p = .002, η2 = .095, with Geisser-Greenhouse correction (see 
Table 1 and Figure 3). Analogous to the results in number line studies (Booth & Siegler, 2006; Siegler & Opfer, 2003;  Siegler, Thompson & Opfer, 2009), 6-8-year-olds had higher  nonlinearity scores than 9-11-year-olds and adults (see Table  1). A significant age effect was also found for the PAE, F(2,  136) = 6.03, p = .003, η2 = .206.  
In terms of variance, 6-8-year-old children showed the  most variable estimates, but the age difference for variance  did not reach statistical significance (see Table 1). As Figure  2b shows, the CV decreased logarithmically as the target  interval increased across the age groups (for 6-8-year-olds, B 
= -.593, F(1, 27) = 167, p < .001, R2 = .861; for 9-11-year - olds, B = -.782, F(1, 27) = 682, p < .001, R2 = .962; and for  adults, B = -.613, F(1, 27) = 259, p < .001, R2 = .905), which  indicates that the scalar property was violated. This  logarithmic decrease was not compatible with the sub-second interval perception literature (e.g., Allan & Gibbon, 1991;  Droit-Volet, 2002; Droit-Volet, Clement, & Wearden, 2001).  However, Lewis and Miall (2009) used a similar range of  interval and observed the same logarithmic decrease in CV  with an increasing target interval, which indicates that people  may have relied on different timing mechanisms according to  the range of target intervals. 
Moreover, some studies have noted several conditions  that generate a logarithmic decrease in the CV. For example,  people usually use a counting strategy for estimating intervals greater than approximately 1.2 s (Grondin, Meilleur-Wells,  & Lachance, 1999; Killeen & Weiss, 1987); this strategy results in a decrease in CV with increasing target interval (Wearden, 1991). In addition, Wearden and Lejeune (2008)  
Table 1 
Figure 3. Distribution of nonlinearity score across age groups 
reviewed the temporal distance perception literature and  revealed that verbal estimation studies reported a decrease in  CV with increasing target interval, as well as a similar pattern  of mean estimates, similar to the current study. That is, the  participants tended to overestimate short intervals and  underestimate longer intervals (e.g., Penton-Voak et al.,  1996; Wearden et al., 1998). To sum up, although the  variation distribution in the current study did not follow the scalar property, it still showed a continuous pattern without  breakpoints. These results imply that across age groups and  intervals (1s - 180s), the participants might rely on one  common mechanism for timing the intervals.  
The effect of previous estimates. In the number line study  literature, Cicchini, Anobile, and Burr (2014) claimed that the logarithmic estimate comes from the participants’ decision  bias, such as the central tendency of judgments. That is, under  conditions of uncertainty, people’s responses tend to be  biased toward the mean of the stimulus distribution, and this  regression to the mean predicts a logarithmic pattern of  results for the number line task (Cicchini, Anobile & Burr,  2014). Cicchini and colleagues (2014) suggested that trial 
by-trial online updating, which they called “dynamic  encoding,” should exist, supporting the regression to the  mean. Thus, we tested whether any serial dependencies exist  between the response to the current trial and the temporal  distance between the current and previous trials; to do this, 
we explored the potential cause of the nonlinear mapping of  the temporal estimates.  
For our analysis, we regressed the average error of the  estimate against the temporal distance between the current  target interval and the previous one. We found that when a  previous time point was further in the past, the participants  tended to underestimate the current target interval; when a  previous time point was further in the future, they tended to  
Means and Standard Deviations of the Nonlinearity Score, PAE, and CV in Experiments 1 and 2.  
Age group (Condition) Nonlinearity score (�) PAE CV 6-8-year 
Exp. 1 
olds .507 (.331) .216 (.053) .395 (.049) 9-11-year 
olds .319 (.246) .181 (.039) .443 (.065) Adults .317 (.246) .159 (.032) .430 (.064) 
Exp. 2 Adults Dispersed .199 (.231) .152 (.035) .246 (.074) Clustered .378 (.293) .182 (.053) .283 (.086) 
2007
overestimate it. The mean error of the temporal estimate  changed systematically as a function of the temporal distance  between the current and previous target intervals across the  age groups (for 6-8-year-olds, B = -.278, F(1, 56) = 179, p  < .001, R2 = .762; for 9-11 year olds, B = -.176, F(1, 57) =  231, p < .001, R2 = .802; and for adults, B = -.264, F(1, 56) = 77.5, p < .001, R2 = .58). Thus, the estimated interval was  influenced by the previous target interval, which tends to  anchor the next estimate. This strategy might have resulted in  the logarithmic pattern of estimation as Cicchini et al. (2014)  argue. Furthermore, the participants who relied more on a  “dynamic encoding” strategy showed higher error (B = .186,  F(1, 137) = 44.3, P < .001, R2= .245) and higher non-linearity  in their estimates (B = 1.5, F(1, 137) = 100, p <. 001, R2 = .422) than those who relied less on this strategy. The central  tendency seemed to have the effect of increasing the non 
linearity of the estimates. 
Experiment 2 
In Experiment 2, we aimed to address two main issues. The  first one was how remembering and estimating temporal  information of natural events compared across prospective  and retrospective paradigms. When previous research results  on temporal distance perception (e.g., Brown, 1985; Miller,  Hicks, & Willette, 1978; see Zacks et al., 2007 for review)  are generalized to timeline estimation, the estimates of prospective judgments would be larger than those of retrospective judgments.  
The second issue we addressed in Experiment 2 was  how different event structures create different effects on  timeline estimation. Using classical temporal distance perception paradigms with simple tones, Matthews (2013)  demonstrated that increasing the subdivision of the interval  by adding more markers led to increases in the perceived  temporal distance. Zacks and his colleagues (2007) suggested  that perceptual systems split activity spontaneously into  segments, which enable people to treat an extended interval  of time as a single chunk and serve as anchors in long-term  memory encoding (Kurby & Zacks, 2007). If these two  effects apply to timeline estimation with natural stimuli, we  hypothesize that the participants would break a video clip into  subjective sub-events, and each sub-event would then be used as a chunk to estimate the temporal distance of the video;  accordingly, a video with more subjective sub-events would  
expected them to actively track the passage of time while they  viewed the video.  
To investigate the event structure effect on timeline  estimation, we presented two different video clips with  different numbers of sub-events and distributions. Using the  subjective event segmentation procedure (Newtson, 1973),  we asked a separate group of participants to mark points on  the timeline where significant changes occurred in the video  clip. Then, we chose two video clips with the most marked  and the least marked and used them as stimuli in the learning  phase. The video clip marked with the largest number of sub events was ‘Clustered’ so that the marks were clustered near  the beginning of the video. The video clip marked with the  smallest number of sub-events was ‘Dispersed’ so that the  marks were evenly distributed throughout the video.  
Method 
Participants Twenty-two undergraduates at the Ohio State  University participated in exchange for a course credit, and  10 young adults from Daegu, South Korea, were recruited  and participated with $4.70 compensation. There was no  significant difference in performance between these two  groups (T = 0.2). 
Materials and Procedure. Two blocks of the timeline task  were given to the participants. At the beginning of the second block, we informed them that after the learning phase, they  would be given the same temporal judgment task as in the  first block. To manipulate the event structure, we provided  the two different video clips that were described above. The  order of the video clips was counterbalanced across the  participants. We created 30 still pictures from each six 
second interval of the video clip and randomly presented all  of the pictures three times during the testing phase. Thus, the  total number of trials in the testing phase was 90. The other  procedures were the same as in Experiment 1. 
Results and Discussion 
First, as in Experiment 1, an increase in the target interval  resulted in an increase in the participants’ mean estimates and  a logarithmic decrease in the CV (B = -.78, F(1, 28) = 195, p < .001, R2 = .874). That is, the scalar property was still  violated. The participants’ estimates showed serial  dependence on the previous target distance across the two  
result in prolonged distance perception and distort the  
1 .0 
a 
d 
relation between the estimates and stimulus distances.  
b 
m 
To address these two issues, we manipulated the  
a 
L 
: 
instructions and contents of the video clips during the initial  
e 
r
o 
0 .5 
learning phase. In the first block examining retrospective  
c 
s 
y 
timing, we asked the participants to pay attention to the  
t
i
r
a 
contents of the video, but the participants were unaware that  
e 
n 
i
they would later be asked to make temporal judgments about  
l
n 
0 .0 
o 
the video. In the second block examining prospective timing,  N 
we informed the participants before the learning phase that  
C lu s te r e d D is p e rs e d 
they would be asked the same questions as in the first block,  enabling them to pay attention to temporal information. We  
2008
Figure 4. Changes in the distribution of the nonlinearity score  according to the event structure of stimuli. 
video clips (for Dispersed, B = -.125, F(1, 58) = 111, p < .001,  R2 = .658; for Clustered, B = .-184, F(1, 58) = 284, p <. 001,  R2 = .83). This finding indicates that the participants in  Experiment 2 might have used the dynamic encoding strategy 
like the participants as in Experiment 1. Furthermore, the  participants who relied more on the dynamic encoding  strategy showed less accurate (B = 2.38, F(1, 30) = 114, p < . 001, R2 = .792) and more variable estimations (B = .304, F(1,  30) = 34, p < .001, R2 = .531) than those who did not. The use  of a dynamic encoding strategy was also significantly related  to the nonlinearity of the estimates (B = .368, F(1, 30) = 14.2,  p < .001, R2 = .321).  
Next, we observed an effect of the event structure on the  timeline estimation accuracy, T(31) = -3.49, p = .001,  Cohen’s d =-.616, but not on the variability distribution,  T(31) = -1.89, p = .068 (see Table 1). The distribution of the  nonlinearity scores was significantly different between the  two types of video, T(31) = 2.81, p = .009, Cohen’s d = .497.  Specifically, the participants showed a more non-linear  pattern of estimation when they were shown a video with  clustered events (see Figure 4). As Matthew (2013)  suggested, the clustered event distribution of the initial time  period might have led the participants to overestimate the  distance of the initial events, and the relatively sparse event  distribution of the final time period would have resulted in  the underestimation of it. 
As some participants watched a “Clustered” video in the  first block and the other participants watched a “Dispersed”  video in the first block, the block effect (i.e., retrospective vs.  prospective timing) was tested separately for each video type.  However, the block order did not produce any significant  differences in the accuracy [ �EFGHIJGIK 19.2 = 
.263, �RSTGUIJIK 24.5 = .703, with the Welch correction] or variation of the estimates [ �EFGHIJGIK 25.2 = .364, �RSTGUIJIK 29.2 = .212, with the Welch correction] across the video types. Of course, we should caution not to  
conclude too much from these null results because the current  experimental structure cannot separate the  retrospective/prospective timing effect from the practice  effect due to block order. 
However, some authors have shown that retrospective  judgments can become as accurate as prospective judgments  when using natural coherent events (Boltz, 2005) and long  intervals with verbal estimates (Grondin & Laflamme, 2015).  According to our results, we suggest that retrospective and  prospective timing effects may have occurred in only the sub 
second interval range. Similar to previous findings showing the violation of the scalar property in specific ranges of  temporal distance (see Wearden & Lejeune, 2008, for  review), the timing process effect may have occurred in a  specific range of intervals. This conjecture could be a  research question for further studies. 
 
1 We thank Tyler Marghetis for informing us of a recent study  that used a similar timeline task with linguistic stimuli (Tillman et  al., 2017). 
General Discussion 
The main purpose of the present study was to introduce a  novel timeline estimation task and explore its potential  impact. This procedure examined both temporal distance perception and temporal order memory for the same task  using realistic stimuli. To the best of our knowledge, this is  the first examination of these two types of temporal processes using the same procedure with non-linguistic temporal  stimuli 1 . We also extended several findings of previous  interval perception studies and reported novel findings on  development in temporal processing.  
Specifically, in Experiment 1, we conducted a timeline  estimation task with three different age groups – 6-8-year olds, 9-11-year-olds, and adults – and observed that the  accuracy and linearity of temporal estimation increased with  the participants’ age, while the variability decreased.  Specifically, all of the age-related changes in the current  study were observed between ages 8 and 9, which provides  further evidence for the protracted development of temporal  cognition (Friedman & Laycock, 1989; Friedman & Lyon,  2005; Gosse & Roberts, 2013; Pathman et al., 2013; Pathman  & Ghetti, 2014; Zelanti & Droit-Volet, 2011). Because it  does not rely on specific time words, such as before, after,  minutes, and seconds, even preschoolers can perform the  tasks, which could enable us to compare various age groups  within the same experimental paradigm in the future.  
In Experiment 2, we tested the effect of event structure  on timeline estimation and extended Matthew’s (2013)  results to this novel temporal judgment task. As in the simple  tone distance task (Matthew, 2013), the participants  overestimated the intervals with more sub-events, which  resulted in more distorted mapping between the estimates and  target intervals. This parallel finding suggests that our timeline task is appropriate for investigating temporal  distance and order judgments.  
Another strength of our task is that any ranges of time  or types of stimuli could be given to participants in the  learning phase. As in the current study, clips from  commercial movies with various lengths can be used to test  the participants’ efficiency in temporal judgment. It is also  easy to manipulate either the contents or structure of the  stimuli. Thus, this task could be more realistic than previous 
temporal distance perception tasks with simple tones, and it  could be controlled better than other biographical memory  tasks with individual experiences. To sum up, this novel  timeline task would be a valuable tool for many researchers  in uncovering developmental and individual differences in  integrated temporal processing. 
2009
Acknowledgments 
This material is based on work supported by the KBRI Basic  Research Program of the Korea Brain Research Institute  funded by the Ministry of Science and ICT and the National Science Foundation (18-BR-01-07, 18-BR-03-02, & IBS R001-D1-2018-b01). We are grateful to Vladimir Sloutsky  and John Opfer for collecting the data and discussing these  ideas.  
References  
Allan, L. G., & Gibbon, J. (1991). Human bisection at the geometric  mean. Learning and Motivation, 22, 39–58. 
Allman, M. J., Teki, S., Griffiths, T. D., & Meck, W. H. (2014).  Properties of the internal clock: first- and second-order principles  of subjective time. Annual Review of Psychology, 65, 743–71.  
Bisson, N., Tobin, S., & Grondin, S. (2012). Prospective and  retrospective time estimates of children: A comparison based on  ecological tasks. PLoS ONE, 7(3).  
Boltz, M. G. (1999). The processing of melodic and temporal infor mation: Independent or unified dimensions? Journal of New  Music Research, 28, 67-79. 
Boltz, M. G. (2005). Duration judgments of naturalistic events in the  auditory and visual modalities. Perception & Psychophysics,  67(8), 1362–1375.  
Brown S. W. (2008). “Time and attention: review of the literature,” in  Psychological Time ed. Grondin S., editor. (Bingley: Emerald  Publishing.Grondin, S. (2014). About the nonscalar property  for time perception (Vol. 829).  
Brown, S. W., & West, A. N. (1990). Multiple timing and the  allocation of attention. Acta Psychologica, 75(2), 103-121. Carell, M. G. (2011). Timelines of past events: Reconstructive retrieval  of temporal patterns. Advances in Cognitive Psychology /  University of Finance and Management in Warsaw, 7, 49–54.  Cicchini, G. M., Anobile, G., & Burr, D. C. (2014). Compressive  mapping of number to space reflects dynamic encoding  mechanisms, not static logarithmic transform. Proceedings of the  National Academy of Sciences of the United States of America,  111(21), 7867–72.  
Droit-Volet, S. (2002). Scalar timing in temporal generalization in  children with short and long stimulus durations. The Quarterly  Journal of Experimental Psychology, 55A, 1193–1209. 
Droit-Volet, S., Cle´ment, A., & Wearden, J. H. (2001). Temporal  generalization in 3- to 8-year-old children. Journal of  
Experimental Child Psychology, 80, 271–288. 
Droit-Volet, S., Trahanias, P., & Maniadakis, M. (2017). Passage of  time judgments in everyday life are not related to duration  judgments except for long durations of several minutes. Acta Psychologica, 173, 116–121.  
Dubrow, S., & Davachi, L. (2016). Neurobiology of Learning and  Memory Temporal binding within and across events.  Neurobiology of Learning and Memory.  
Friedman, W. J., & Laycock, F. (1989). Children’s analog and digital  clock knowledge. Child Development, 357–371.  
Friedman, W. J., & Lyon, T. D. (2005). The development of temporal reconstructive abilities. Child Development, 76, 1202–1216. Gibbon, J. (1977). Scalar expectancy theory and Weber’s law in animal  timing. Psychological Review, 84(3), 279–325.  
Grondin, S. (2010). Timing and time perception: A review of recent  behavioral and neuroscience findings and theoretical derections.  Attention, Perception & Psychophysics, 72(3), 561–582.  
Grondin S. & Laflamme, S. (2015). Stevens’s law for time: A direct  comparison of prospective and retrospective judgments. Attention, Perception & Psychophysics, 77(4), 1044-1051. 
Grondin, S., Meilleur-Wells, G., & Lachance, R. (1999). When to start  explicit counting in a time-intervals discrimination task:  Acritical point in the timing process of humans. Journal of  Experimental Psychology: Human Perception & Performance,  25, 993-1004.  
Killeen, P. R., & Weiss, N. A. (1987). Optimal timing and the Weber  function. Psychological Review, 94, 455-468. 
Kurby, C. a., & Zacks, J. M. (2008). Segmentation in the perception and  memory of events. Trends in Cognitive Sciences, 12(2), 72–79.  Lewis, P. A., & Miall, R. C. (2009). The precision of temporal  judgement: milliseconds, many minutes, and beyond.  Philosophical Transactions of the Royal Society B: Biological  Sciences, 364(1525), 1897–1905.  
Matthews, W. J. (2013). How does sequence structure affect the  judgment of time? Exploring a weighted sum of segments model.  Cognitive Psychology, 66(3), 259–282.  
Miller, G. W., Hicks, R. E., & Willette, M. (1978). Effects of con current verbal rehearsal and temporal set upon judgments of  temporal duration. Acta Psychologica, 42, 173-179. 
Newtson, D. (1973). Attribution and the unit of perception of ongoing  behavior. Journal of Personality and Social Psychology, 28, 28– 38. 
Nielson, D. M., Smith, T. a., Sreekumar, V., Dennis, S., & Sederberg,  P. B. (2015). Human hippocampus represents space and time  during retrieval of real-world memories. Proceedings of the  National Academy of Sciences of the United States of America,  112(35), 201507104.  
Penton-Voak, I. S., Edwards, H., Percival, A., & Wearden, J. H.  (1996). Speeding up an internal clock in humans? Effects of  click trains on subjective duration. Journal of Experimental  Psychology: Animal Behavior Processes, 22, 307–320 
Piazza, M., Izard, V., Pinel, P., Le Bihan, D., & Dehaene, S. (2004).  Tuning curves for approximate numerosity in the human  intraparietal sulcus. Neuron, 44(3), 547–555. 
Siegler, R. S., & Booth, J. L. (2004). Development of numerical  estimation in young children. Child Development, 75(2), 428– 444.  
Siegler, R. S., Thompson, C. A., & Opfer, J. E. (2009). The  Logarithmic To Linear Shift: One Learning Sequence, Many  Tasks, Many Time Scales. Mind, Brain, and Education, 3(3),  143–150. 
Siegler, R., & Opfer, J. (2003). The Development of Numerical  Estimation Evidence for Multiple Representations of Numerical  Quantity. Psychological Science, 237–243.  
Tillman, K. A., Marghetis, T., Barner, D., & Srinivasan, M. (2017).  Today is tomorrow ’ s yesterday : Children ’ s acquisition of  deictic time words, 92, 87–100.  
Tobin, S., Bisson, N., & Grondin, S. (2010). An ecological approach to  prospective and retrospective timing of long durations: A study  involving gamers.  
Wearden, J. H. (1991). Human performance on an analogue of an  interval bisection task. The Quarterly Journal of Experimental  Psychology, 43, 59–81. 
Wearden, J. H., & Lejeune, H. (2008). Scalar properties in human  timing: Conformity and violations. The Quarterly Journal of  Experimental Psychology, 61(4), 569–587.  
Wearden, J. H., Edwards, H., Fakhri, M., & Percival, A. (1998). Why  “sounds are judged longer than lights”: Application of a model  of the internal clock in humans. Quarterly Journal of  
Experimental Psychology, 51B, 97-120. 
Zacks, J. M., Speer, N. K., Swallow, K. M., Braver, T. S., & Reynolds,  J. R. (2007). Event perception: A mind-brain perspective.  Psychological Bulletin, 133(2), 273–293.  
2010
A Sociocognitive-Neuroeconomic Model of Social Information Communication: To Speak Directly or To Gossip 
Jeungmin Lee1,2, Jerald D. Kralik1,*, Jaeseung Jeong1,2,* 
(*jerald.kralik@gmail.com, jsjeong@kaist.ac.kr) 
1Department of Bio and Brain Engineering, College of Engineering 
2Program of Brain and Cognitive Engineering, College of Engineering 
Korea Advanced Institute of Science and Technology (KAIST), Daejeon, 34141, South Korea 
Abstract 
Communication is a powerful means to disseminate social  information, and gossip is an effective way of obtaining updated information about others. However, without a  comprehensive theoretical framework of social  communication, it is difficult to predict a priori when and why  social information will be disseminated. There are general  theories of human social interaction, however, they do not  sufficiently capture the sociocognitive components underlying  human decision-making in social settings. Therefore, we have  developed a model of social communication, enabling the characterization of specific conditions under which social  information will be spread: for example, when an agent should  directly communicate with the target of the information, gossip 
it to others, or simply do nothing. We describe the model, the  methods used to generate model predictions, and then list nine  predictions derived from it as the current results. We next plan  to test the predictions empirically and develop the model  computationally. 
Keywords: decision-making; theory of mind; social  neuroscience; multi-agent system; artificial social intelligence 
Introduction 
People live in a complex, multi-agent world, and as such,  sophisticated social intelligence is needed. Indeed, to make  accurate predictions about others requires having a model of  their minds — their beliefs, goals and intentions — and  humans have evolved the ability to do so. Moreover, proper  long-term social interaction also requires mental accounting  of what you owe to others (from their help) and what others  owe to you (from your help or their hindrance). At the same  time, rich descriptions of all possible agents become computationally intractable, so our mental models are also  necessarily limited. One strategy, for example, is to maintain  more comprehensive models of those closest to us. 
In any case, gathering information about others is crucial to maintain accurate models of them. Accordingly,  communication is a critical means by which agents share and  update information about each other. In fact, statistical  assessments have found that sharing social information  consumes a significant portion of daily conversation: ~65% (Dunbar, 2003). Furthermore, an important component of this  social information exchange involves events that were not  seen by others. When we describe events to others about an  absent target, we call it gossip (see Foster, 2004). 
Several studies on gossip suggest many reasons for it, such  as social influence, information sharing, cultural learning, and social bonding (Baumeister, Zhang, & Vohs, 2004;  
2011
Beersma & Van Kleef, 2011; Dunbar, 2003; Ellwardt,  Labianca, & Wittek, 2012; Fernandes, Kapoor, &  Karandikar, 2017; Foster, 2004; McAndrew & Milenkovic,  2007; Wu, Balliet, & Van Lange, 2016). Recent evidence also  shows that, at least under some conditions, gossip can be a  more efficient and effective tool than direct punishment for  promoting and maintaining cooperative behavior (Wu,  Balliet, & Van Lange, 2016). However, without a  comprehensive theoretical framework of social  communication, it is difficult to predict a priori when and  why social information will be disseminated, and whether  gossip will occur. 
There are general theoretical frameworks for human social  interaction, most notably social exchange theory (see Foster,  2004). However, current theories do not sufficiently capture  the sociocognitive components underlying human decision 
making in social settings. Moreover, they are normally not  specified well enough to make accurate a priori predictions  about specific human social interactions, such as whether  someone will actually gossip in a given situation. Therefore,  here we present our model of social communication,  developed to characterize the specific conditions under which  different types of social communication will occur: for  example, when an agent should directly communicate with  the target of the information, gossip to others, or simply do  nothing. The overall goal of our research program is to  produce a comprehensive model of human social  intelligence. To do so, we believe explicit modeling at  multiple levels of analysis is necessary. In particular, a  general, more qualitative theoretical framework should first  be provided to layout the critical causal factors and their  general interactions from a more top-down perspective. From  this theoretical model, important predictions can be derived  to generate hypotheses for further empirical research, which  in turn test the model. After this, computational specification  can occur in a more informed, meaningful, and  understandable way, ultimately contacting neural circuitry.  
In the current paper, we describe our top-level theoretical  model and predictions derived from it. In the following  sections we first describe the details of the model, then the  methods used to generate model predictions; we then list nine  predictions derived from it. In ongoing work, we have 
recently conducted a behavioral study with human  participants to test the predictions, and are now specifying the  model computationally. 
The General Model of Social Communication 1. Agents 
The central problem-solving agent (A1) is the focal agent of the social communication process in our model: the one  who takesthe information input and decides what to do based  on the set of possible actions and expected outcomes. To  avoid the clunky “his/her” we will denote A1 as female. 
Receiver (A2) is the agent (or agents) to whom A1 may  transmit information, i.e., communicate with. A2 can be characterized by their relationship to A1, e.g., closeness (family, friends to strangers), relative status, and other group  memberships (such classmates, coworkers, colleagues), with  such characteristics influencing A1’s communication  decisions. Once the information transmission from A1 to A2 is completed, A2 then becomes the next central problem solving agent in a subsequent state, and then must decide  whether to communicate to receivers, and so on. 
Target (A3) is also an essential agent in the process. A3 is the  subject of the information that A1 is contemplating. In other  words, A3 is the agent who took the action that caused the  initial state change. What A3 has done, i.e., the details of the  event surrounding A3’s action — which we call event or  scenario — will influence A1’s decision. Moreover, like A2,  A3 can be categorized based on their relationship to A1 (such  as closeness, status, and other group memberships), which  should also influence A1’s decisions. 
Information source (A0) is another agent in the system. The  central agent, A1, receives the information about the target  agent, A3, via either direct observation or via another source — A0 is the other possible source. Thus, the role of A0 is to  pass the information about A3 to A1. A0 can be a person who  has made a decision to spread the information directly to A1;  A0 can also be a person who decided to spread the  information to many unspecified individuals via various  means such as social or mass media, books, or internet  forums. A1 will evaluate the information received from A0 
based on reliability and credibility of A0 (i.e.,  trustworthiness); the outcome of this evaluation will  determine whether A1 continues to assess the information. 
The role of each actual agent, then, is not fixed. An  individual who is A1 in one state, for example, can become  A0, A2, or A3 in subsequent states. All the agents in the system  have their own goals to achieve, and to approach their goals,  the agents need to have a good understanding of the others  and self. That is, they have to consider what the other agents  in the system are doing in the current state and are going to  do in future states. Because each agent is attempting to move toward her own goal state, the system is highly complex and  dynamic, which in turn makes it challenging for the agents to  build an accurate mental representation of each other;  therefore, constant updating of information regarding every  agent in the system is necessary. We capture this in the  current model by focusing on the central agent, A1, and her “mind”, which also includes her models of the other agents’  minds as well as her model of her own mind. 
2012
The mind of the agents is thus currently represented in the  model by what we describe for the central agent A1, but  indeed all agents would have the same model architecture for  their mind. And for A1 to take the proper action, she must  consider the minds of the others, which we describe below.  Our general mind architecture is described throughout  sections 2-5, but in general it follows the basic  ‘sensation/perception 🡪 cognition (including problem  representation and decision-making) 🡪 action’ circuit (Gazzaniga, Ivry, & Mangun, 2013; Glimcher & Fehr, 2014;  Kralik, 2017). Each component of this circuit is influenced  by both (a) longer-term, more stable characteristics, such as  personal background (e.g., family and educational), personal  traits (like personality in general, such as extroversion vs. 
introversion), cultural (e.g., individualism vs. collectivism),  political, and sexual identities, social traits (e.g., morality and  prosociality orientation), and longer-term goals and interests;  and (b) more short-term, ephemeral characteristics, such as  current immediate goals and mood. Our focus here, however,  is directed toward the basic sensation-to-action circuit, with  particular emphasis on social cognition.  
2. Goals of the Agents 
From A1’s perspective, the goals of all the agents in the  system are valuable pieces of information to make the best  decisions. However, the most important goal that directly  drives A1 to choose a specific action is that of A1 herself. 
In the model, all agents’ actions are presumed to be in  pursuit of goals, with each agent’s action choice depending on what they think will provide the best outcome for  themselves in pursuit of their goals. Goal pursuit in a multi agent environment, however, often requires interaction with  others, especially when help (i.e., cooperation) is needed or  conflict arises; and the expected outcomes of these  interactions must be factored in. In our model, we assume that  benefits (or costs) to others ultimately translate to benefits (or  costs) for the actor via what we call social value or social  equity. For example, if agent A1 helps A2 achieve their goal,  the benefit given to A2 should translate into social equity to  A1 for future help when needed. In this way, reciprocal  altruism is achieved (and fairness upheld). Thus, in general,  there are two types of value — nonsocial and social — that  must be taken into account when considering actions in  pursuit of any given goal.  
At the same time, the goal itself (being pursued by a given  agent) can be either nonsocial or social. Nonsocial goals are  perhaps more typically studied even in multi-agent systems,  such as cooperating or competing in pursuit of positive  rewards (e.g., money) in game-theoretic scenarios like  Prisoner’s Dilemma. In contrast, social goals may also be  pursued directly, such as attempting to build friendships  (translating in the model to acquiring social equity). Both  nonsocial and social goals have primary and secondary elements (Gazzaniga, Ivry, & Mangun, 2013; Glimcher &  Fehr, 2014). Primary social goals are more innately specified,  in which we are “wired” to desire them (both regarding  wanting and liking). For social goals, in general, it is a natural  
tendency to seek social interaction, with primary reward  resulting from it (Barak & Feng, 2016). Secondary elements  are based more on learning and strategy. 
Focusing more specifically on social information  communication, such instances are often instigated by actions  taken by a target of interest, A3, that A1 comes to know about  and then must determine what to do: e.g., whether to tell A2,  i.e., gossip. This information about A3 normally precipitates 
a new problem for A1 to solve. For instance, consider the  scenario of A3 cheating on a final exam. The new problem  posed to A1 may now be one of fairness: i.e., that the resulting  state is now unfair, with the goal being to reestablish it. A1 
then must determine the proper course of action: i.e., whether  to confront A3 directly, tell others (i.e., A2), or do nothing. In  future development we elaborate these concepts of problem  solving and goal pursuit to the solving and pursuit of multiple  problems and goals simultaneously. 
3. Input Information to A1 
There are two general types of information input to A1.  
An event consists of three main components: target, content,  and valence (see Figure 1). The target specifies A3, the agent  who has become a subject of information by taking an action  in a previous state. Again, A3 can be characterized by various  factors such as closeness to A1 (e.g., a close friend, a casual  acquaintance, a total stranger), and various identities,  typically from A1’s perspective (e.g., a classmate, a colleague,  a family, a celebrity). Content is the actual body of  information that describes the target’s action, and often sets  up a new problem to be solved that in turn requires its own  problem representation (e.g., cheating on exam, with problem  of fairness to rectify). The content also often divulges aspects 
of A3 that enables A1 to use in her model of A3’s mind. If A3 cheated, e,g., it likely evokes a concern of selfishness and  lack of empathy. Finally, valence indicates the polarity (i.e.,  positive or negative) of the information.  

Figure 1: Two types of information input to A1: Event & Context.  The event includes information related to who did what, and why it  occurred; The context includes additional details such as setting. 
Once information is generated by A3 taking an action, A1 receives the information by one of two means: (1) direct  observation or (2) via A0. The information source itself will  influence A1’s decision as well, discussed further below.  
2013
Context is comprised of two aspects. The first is the main  multi-agent environment that A1 finds herself in, most  notably, that A2 is present. The second includes other specific  factors, such as location (e.g., school, workplace, restaurant,  conference), or the type of information source (e.g., is it a  newsmagazine or a tabloid magazine; is it from a reliable  source or a random internet forum?). 
4. Information Processing by A1 
Information about the event and context are thus received  by A1 as the input stimuli. A1 then engages in a series of  internal processes to determine what action to take based on  the newly obtained information about A3, which we now  describe and is depicted in Figure 2.  
Figure 2: Internal information processing of A1 from sensory  input to action selection based on sociocognitive considerations. 
4-1. Sensation and Perception: A combination of the two  types of information (i.e., events and context) is detected as  sensory input and then perceptually processed. 
4-2. Evaluation of veracity: After sensory and perceptual  processing, higher-level cognition commences (Gazzaniga,  Ivry, & Mangun, 2013). First, A1 must assess whether the  information warrants further processing: most notably  whether the information can be trusted. To accurately  estimate credibility and reliability of the input information,  A1 must access long-term memory (i.e., prior knowledge)  about the source, target, context, and any other details that  may increase the accuracy of the evaluation. If the  information seems reliable, processing continues.  
4-3. Representation of current state: Reliable information  that has passed the evaluation process is now ready to be used  for updating A1’s internal model of A3’s mind; A1 must also  assess and update the representation of the current state  consisting of all agents (including self). As described under  “The mind of the agents” section, all agents have their own  problem representations, with each including all agents and  models of their minds; and although these are not depicted  for A2 and A3, they nonetheless are represented by A1 in her problem representation, which also illustrates the type of  recursion that takes place in human social cognition (see  Figure 2) (Barak & Feng, 2016; Gazzaniga, Ivry, & Mangun, 
2013; Glimcher & Fehr, 2014). And because of the  uniqueness of each individual, and the number of events that  take place (including many out-of-sight of subsets of agents),  the effort to maintain accurate models of others is daunting  (likely providing evolutionary selection pressures leading to  human high-level social cognition) (Dunbar, 2003). 
4-4. Decision-making: As discussed, A1, like all agents,  must select actions to reach a given goal, with an action  policy that attempts to maximize expected value. For any  given action, then, A1 needs to estimate the consequences of  all action options and to choose the action expected to return  the best outcome. More specifically, the decision-making  process is divided into two key sequential steps: valuation 
and action selection (Figure 2) (Glimcher & Fehr, 2014). 
Valuation. In goal-directed decision-making, each action  option is valuated based on its expected outcome, with A1 attempting to maximize value by reaching the current goal  state efficiently. However, to determine this, A1 must also  consider what the other agents are expected to do, prior to, simultaneously with, and after A1’s action. Regarding  possible prior or simultaneous actions, game-theoretic  strategies can be undertaken to first determine the others’  possible actions, and to then valuate (and select) one’s own  based on these expectations (Glimcher & Fehr, 2014). For the  current paper, A1 does not expect the others to take further  action prior to A1, and so she must only consider what they are expected to do subsequent to her action.  
Currently, there are three possible options A1 can take  involving the social information about A3 (i.e., the target): (1)  A1 talks directly to A3 about the information; (2) A1 tells  others (A2) about A3; or (3) A1 does nothing with the  information. We consider each action option in turn.  
Direct communication. With no intermediary agents  between A1 and A3, direct communication with A3 has both pros and cons. Potential advantages include (a) an  opportunity for A1 to confirm the veracity of the information  with the target directly (assuming honesty); (b) the ability for  A1 to obtain more circumstantial event details, including A3’s  action intent or stance on the event; and (c) a higher  likelihood of influencing A3 (vs. relying on others via indirect  communication), giving A3 an opportunity to correct matters  without the possible repercussions via spread (and potential  amplifications and distortions) across the social network. 
Disadvantages of direct communication include the risk of  A1 being wrong about the information and hurting A3’s  feelings (i.e., decreasing social equity with A3 and perhaps  others based on A3’s future actions). Even if the information  is true, and particularly with negative information, direct  criticism is often considered harsh, rude, or offensive,  potentially leading to repercussions for A1 by both A3 and  others if the information spreads (via A3 or other witnesses). 
To minimize such risks, humans have evolved the ability for  indirect communication (Dunbar, 2003; Foster, 2004). Indirect communication: Gossip. Alternatively, A1 may  choose to tell other agents (i.e., A2) about the information in A3’s absence. That is, A1 can instigate gossip with others. We  note three major advantages of gossiping. First, it can lower  the risk of confrontation, threat, and retaliation from A3,  while at the same time affecting A3’s behavior via social  influence, and in particular, via reputation (Wu, Balliet, &  Van Lange, 2016). Second, it informs others (A2) so that they  can update their world models (and thus increase their  
accuracy), which can enable A2 to either (a) avoid A3, (b) help  rectify the problem produced by A3’s actions, such as righting  injustices (e.g., if A3 were found cheating on exam), or even  (c) rectify A2’s own behavior via social comparison and self 
evaluation (e.g., to help see why certain actions are wrong or  others to emulate). And again, these benefits to A2 are  expected to return value to A1 via social equity (for the future).  Third, informing A2 may in fact enable A1 to obtain more  information about A3, to help decipher the information about  A3 (e.g., with respect to cultural norms, mores, rules, and  laws), and determine whether something should be done  about it — that is, A1 can seek others for advice and  consultation. Indeed, this interaction with A2 can also help A1 
improve the accuracy of her own world model. Despite the many advantages to gossiping, there are indeed  risks. For example, if the information is negative in valence (like catching them cheating or shoplifting), there could be a  threat of retaliation against A1 for damaging A3’s reputation.  Moreover, gossip generally has a bad reputation in and of  itself. Thus, A1 could in fact become a notorious gossiper,  known to “talk behind peoples’ backs”; as a result, social  equity of A1 could significantly drop. Therefore,  sophisticated estimation and prediction of all possible  outcomes must be attempted, but of course cannot be fully  achieved. For example, how many steps into the future (and  number of behaving agents) that can be simulated is  necessarily limited. Such factors show how challenging it is  to make good decisions in our multi-agent world (and how  modeling is necessary as scientists to better understand the  multiple factors and their interactions). 
Do nothing. The last option is for A1 to do nothing, and this choice can be strategic as well. Since the other options (i.e.,  direct and indirect communication) may both entail  significantly high risks of yielding a net negative outcome,  keeping the information private may be the safest option. It  is also possible that the information is not significant enough  in the current state to instigate communication, but yet may  be so in the future, given that the system is constantly  updating and modifying. At some point when the stored  information becomes useful, A1 can retrieve it (from long 
term memory) and repeat the decision-making process again  to decide whether or not to use it. 
Action selection. After the valuation process, A1 will have calculated the expected outcomes of all action options: to  confront A3 directly, do nothing, or tell A2 — i.e., to gossip. At this stage, then, A1 determines which action to select based  on their relative valuations. 
5. Take Action, Face Outcome, and Learn Next, A1 actually executes the action chosen. If A1 chooses  to tell others about the information, the receiver A2 comes  into play, adding more complexity to the system (see Figure  3). That is, there will be consequences after taking the action that now depend on A2. A1 thus needs to monitor the actual  outcome, assess it, and compare it to the expected outcome. The outcome may be close enough to expectation, moving A1 closer to her goal; yet it is also possible that the outcome does  
2014
not match expectation, and may move A1 away from the goal. Either way, learning with take place based on the difference between the actual and expected values (i.e., the error signal). Finally, A1 adjusts the valuations and representations accordingly, leading A1 to a (hopefully) better internal  
understanding of the system and better future decisions (Glimcher & Fehr, 2014). 
Methods 
The complete model is shown in Figure 4, with implicated  brain regions for each main processing step (Barak & Feng,  2016; Gazzaniga, Ivry, & Mangun, 2013; Glimcher & Fehr,  2014; Lee, 2008). To examine the model, we considered  multiple scenarios in which a target individual A3 engages in  some activity, A1 hears about it, and we asked whether the  model would predict relatively more or less gossip  spreading—i.e., would A1 tell A2 about A3? In each scenario,  we manipulated target identity, content, and content valence.  For target identity, we compared ingroup members to  outgroup members and celebrities. Celebrities are an  interesting comparison group because they not only are  farther removed from the gossiper in terms of relationship  closeness (but closer than outgroup, at least in terms of a one way interaction), they are important for other reasons as well,  and in particular, based on their higher status. In short, gossip  spreading rates in the pattern of  “ingroup>celebrities>outgroup” would provide evidence for  the importance of relationship closeness, and patterns of “celebrities>ingroup>outgroup” would provide evidence for  social status. For content, we compared eight different  content-domain dimensions: (1-5) the five well-established  dimensions of morality (care/harm, fairness/cheating,  loyalty/betrayal, authority/subversion, sanctity/degradation) (Haidt, 2007), as well as three other important forms of  sociality, (6) altruism/selfishness, (7) competition (positive  and negative versions), and (8) general social affairs, with the  latter representing more mundane social activities (e.g.,  Person X went to the movies). For content valence, we  included positive acts (e.g., Person Y assisted an elderly  person) versus negative ones (e.g., Person Z shoplifted). 

Figure 3: Final stages of social communication: A1 takes an action  that produces an outcome, inevitably leading to some expectation  error used for subsequent learning. In determining whether to tell  others, A1 must consider how receiver A2 will respond. 
Results & Discussion 
The results we obtained are predictions from the model  derived by considering whether the central agent A1 would  gossip information to receiver A2 about the absent target A3 
2015
upon hearing information about what A3 had done, with the  scenarios about A3 varying based on target identity (ingroup,  celebrity, or outgroup), scenario content, and content valence  (positive or negative). We present the general findings as a  series of nine predictions about gossiping behavior: two for  target identity, four for content valence, and three for scenario  content. 
For target identity, even though celebrities may appear to  garner outsized attention, those people closest to us are  expected to have the largest net effect on our lives in terms of  actual outcome value, and thus information about them  particularly matters. Thus the model’s first prediction is: 
Prediction 1: Based on relationship type, more gossiping should  be spread about ingroup compared to outgroup, and in some cases  ingroup over celebrities as well. 
Although limited thus far in number, studies support this  first prediction (Foster, 2004). In a study about workplace  gossip, for example, gossip about ingroup members was spread and shared more than the gossip about outgroup  members (Ellwardt, Labianca, & Wittek, 2012).  
And yet because status relates to issues of fairness, equality,  and hierarchical relationships, it is important to us. The model  therefore suggests that scenarios involving these content  domains will generate more celebrity-based gossip,  especially when their behavior does not justify their higher  standing. Thus: 
Prediction 2: Status effects should occur whereby certain types of  scenarios should generate more gossiping about celebrities as  compared to the other groups. 
Currently, there is evidence that status influences gossiping  behavior (Foster, 2004), although examination across a wider  range of content domains is needed.  
For scenario valence, not only does popular sentiment  suspect heightened gossiping of negative events, there also is  substantial evidence for it, whereas the evidence for  gossiping about positive scenarios is much more limited  (Baumeister, Zhang, & Vohs, 2004; Beersma & Van Kleef,  2011; Dunbar, 2003; Ellwardt, Labianca, & Wittek, 2012;  Fernandes, Kapoor, & Karandikar, 2017; Foster, 2004;  McAndrew & Milenkovic, 2007; Wu, Balliet, & Van Lange,  2016). Yet if we assume the gossiper is ultimately attempting  to maximize her own value (whether consciously or not),  positive scenarios should in principle be comparable to  negative ones. We thus predict that when provided with a  more comprehensive set of scenarios, as in our case: 
Prediction 3: Positive scenarios will show gossip spreading rates  more comparable to negative ones (with in fact cases where positive  ones spread even more than their negative counterparts). 
More specifically, though, for positively valenced  scenarios to ultimately benefit the gossiper, this positive light  shed by the gossiper on the target should reflect on the  gossiper as well — i.e., the gossiper should benefit from the 
positivity. Thus, we further predict the following: Prediction 4: Greater spreading of positively valenced scenarios  should occur with ingroup targets. 
For negative scenarios, in contrast, one may suspect that  higher status people (i.e., celebrities) would be greater targets  of negativity due either to holding celebrities to higher  
Figure 4: The complete model of social information communication. Brain region abbreviations: fusiform gyrus (FG), posterior superior temporal sulcus  (pSTS), medial prefrontal cortex (MPFC), temporoparietal junction (TPJ), amygdala (AMG), insula, right temporal lobe (rTL), interparietal sulcus (IPS),  anterior paracingulate cortex (aPCC), medial precuneus (med. precuneus), anterior insula (ant. insula), anterior cingulate cortex (ACC), orbitofrontal cortex  (OFC), ventral premotor cortex (vPMC), dorsolateral prefrontal cortex (dlPFC), posterior parietal cortex (PPC), posterior superior temporal cortex (pSTC),  caudate nucleus (CD), ventral striatum (VS), mesolimbic dopamine (DA) system, ventral tegmental area (VTA), premotor cortex (PMC), basal ganglia (BG). 
standards to justify their position and/or attempting to raise  one’s relative position by lowering theirs (at least within the  gossiper’s community), and our model also predicts the same: 
Prediction 5: There should be greater spreading of negativity  about celebrities. 
Although again limited, there is evidence consistent with  Predictions 4 & 5 (Foster, 2004): e.g., one study found that  people spread positive information about allies and negative  information about potential enemies, including strangers and  those with high status (McAndrew & Milenkovic, 2002). 
At the same time, the model highlights the potential  ramifications of spreading negative scenarios about those in  position to retaliate, and thus the following is also predicted: 
Prediction 6: Negativity should be reduced for ingroup targets. Although studies have found evidence pertaining to  Predictions 4-6, our model shows how specific factors will  need to be isolated to clarify the true nature of the current  findings: for example, whether higher positive spreading for  ingroup is due to heightened positivity or lowered negativity (and vice versa for celebrities). Studies have yet to tease apart  these factors sufficiently. 
For scenario content, it is clear that more impactful events  should be expected to generate more gossip, and thus: Prediction 7: Dimensions related to morality are predicted to  generate the most gossip, especially those involving more egregious  threats, like harm and cheating. 
Multiple studies have indeed found evidence for moral  underpinnings of gossip (Fernandes, Kapoor, & Karandikar,  2017; Foster, 2004), although they have thus far focused narrowly on one or a few moral dimensions (e.g., fairness).  Our predictions provide hypotheses for more comprehensive  empirical studies, which we are currently undertaking. 
Indeed, although the moral dimensions are generally  expected to generate more gossip than others, we also predict: Prediction 8: Differences should be found among the morality  domains themselves. 
Finally, when assessing impact (for value maximizing), a  more complete sociocognitive perspective shows that even  more nondescript events could in principle provide high  
value: e.g., if needed to maintain accurate models of those  whose behavior requires high predictability. Such  considerations lead to our final hypothesis: 
Prediction 9: Basic social affairs should in some cases generate  higher spreading rates for ingroup targets, in order to maintain  accurate detailed knowledge about them. 
In other words, we predict that context matters, also  attesting to the importance of developing a comprehensive  model of social interaction and communication to identify  and specify potentially important context effects.  
Along with our current empirical studies to test the model predictions, we are also developing the model  computationally to specify the causal factors and interactions  underlying the communication of social information at the  next level of analysis, with the ultimate goal of providing a  comprehensive understanding of human social intelligence. 
References  
Barak, B. & Feng, G. (2016). Neurobiology of social behavior abnormalities in autism  and Williams syndrome. Nature Neuroscience, 19, 647–655. 
Baumeister, R. F., Zhang, L., & Vohs, K. D. (2004). Gossip as cultural learning. Review  of General Psychology, 8(2), 111-121.  
Beersma, B., & Van Kleef, G. A. (2012). Why People Gossip: An Empirical Analysis  of Social Motives, Antecedents, and Consequences. J. of Applied Social Psych.,  42(11), 2640-70.  
Dunbar, R. I. M. (2003). The Social Brain: Mind, Language, and Society in  Evolutionary Perspective. Annual Review of Anthropology, 32(1), 163-181.  Ellwardt, L., Labianca, G., & Wittek, R. (2012). Who are the objects of positive and  negative gossip at work? A social network perspective on workplace gossip. Social  networks, 34, 193-205. 
Fernandes, S., Kapoor, H., & Karandikar, S. (2017). Do we gossip for moral reasons?  The intersection of moral foundations and gossip. Basic and applied social  psychology, 39(4), 218-230. 
Foster, E. K. (2004). Research on gossip: Taxonomy, methods, and future directions.  Review of General Psychology, 8(2), 78-99.  
Gazzaniga, M. S., Ivry, R. B., & Mangun, G. R. (2013). Cognitive neuroscience: the  biology of the mind. WW Norton & Company. 
Glimcher, P. W., & Fehr, E. (2014). Neuroeconomics: Decision making and the brain.  Oxford: Academic Press. 
Haidt, J. (2007). The new synthesis in moral psychology. Science, 316, 998-1002.  Kralik, J. D. (2017). Architectural design of mind & brain from an evolutionary  perspective. Proc. AAAI 2017 Fall Symposium: A Standard Model of the Mind. Lee, D. (2008). Game theory and neural basis of social decision making. Nature  Neuroscience, 11(4), 404–409. 
McAndrew, F. T. & Milenkovic, M. A. (2002). Of tabloids and family secrets: the evolutionary  psychology of gossip. J. of applied social psych., 32(5), 1064-1082. 
Wu, J., Balliet, D., & Van Lange, P. A. (2016). Gossip Versus Punishment: The Efficiency of  Reputation to Promote and Maintain Cooperation. Sci Rep, 6, 23919. 
2016
Data Availability and Function Extrapolation 
Pablo Leon Villagr ´ a Irina Preda Christopher G. Lucas ´ Informatics Forum, 10 Crichton Street, EH8 9AB, 
Edinburgh, United Kingdom 
Abstract 
In function learning experiments, where participants learn relationships from sequentially-presented examples, people show a strong tacit expectation that most relationships are lin ear, and struggle to learn and extrapolate from non-linear rela tionships. In contrast, experiments with similar tasks where data are presented simultaneously – typically using scatter plots – have shown that human learners can discover and ex trapolate from complex non-linear trends. Do people have dif ferent expectations in these task types, or can the results be attributed to effects of memory and data availability? In a di rect comparison of both paradigms, we found that differences between task types can be attributed to data availability. We show that a simple memory-limited Bayesian model is consis tent with human extrapolations for linear data for both high and low data availability. However, our model underestimates the participants’ ability to infer non-monotonic functions, es pecially when data is sparse. This suggest that people track higher-order properties of functions when learning and gen eralizing. Keywords: function learning, function estimation, resource rationality 
Introduction 
Many everyday situations require us to make predictions with very limited information. Consider a situation in which you are in a holiday flat and want to use the heater. You haven’t used it before but you will have a general idea of how long it will take to heat up. Furthermore, it is natural to assume the relationship between setting and resulting changes in temper ature – the temperature should change in continuous fashion and increase until it reaches the selected temperature. In addi tion, given few, seemingly unrelated bits of information, like for example the state of other appliances, you can generalize and update your beliefs. 
Forming generalizations requires acquiring a representa tion of how known features relate to unknown targets and contrasting this relation with potential alternatives. Humans exhibit a remarkable ability to perform these generalizations and much research in the cognitive sciences and artificial in telligence has centered on understanding or reproducing these phenomena. One of the most prominent fields of generaliza tion research, categorization, has focused on situations where the known characteristics are assumed features of some en tity and the target is the category of the entity (a categori cal label). Function learning takes a more general perspec tive on the generalization target and allows for continuous values. Both categorization and function learning research share fundamental questions about how humans acquire pro ductive representations of these relationships and what sort of representations allow generalization. For instance, what kind of relationships can humans learn and generalize from, and how are extrapolations reflective of particular human bi ases? In function learning experiments, where experimental 
participants learn relationships from sequentially-presented points, people show a strong bias toward inferring linear func tions (Brehmer, 1976; DeLosh, Busemeyer, & McDaniel, 1997; Kalish, Lewandowsky, & Kruschke, 2004). They learn linear relationships more quickly (Brehmer, 1974; Byun, 1995) and have difficulty making non-linear and especially non-monotonic extrapolations (Brehmer et al., 1985; Byun, 1995; Bott & Heit, 2004; Kalish, 2013). This has led to the development of models that attach a special representational status to linear relationships (DeLosh et al., 1997; Kalish et al., 2004), or assume that people have a strong inductive bias favoring linearity (Brehmer et al., 1985). In contrast, when data are presented simultaneously, usually as scatter plots (which we will call function estimation tasks) human learn ers can discover and extrapolate from complex non-linear trends (Wilson et al., 2015; Schulz et al., 2017; Lucas et al., 2015; Little & Shiffrin, 2009). How do we reconcile these experimental results? 
One possibility is that people respond to these presenta tion modes in different ways, for reasons that may be percep tual, cognitively innate, or experience-dependent. An alterna tive possibility is that the same inductive biases and cognitive processes support both function learning and function estima tion, and differences between these tasks can be attributed to differences in their memory demands. 
In function learning experiments participants have to main tain learned data in memory and update and evaluate the ap propriateness of a representation against alternatives, whereas function estimation allows an effortless recall of the data. We hypothesize that, due to these differences, many participants in function learning tasks only maintain sparse representa tions of the data. Given that only a subset of the data is main tained, extrapolations will resemble inductive biases in the absence of data. In contrast, having all data visually avail able, as in function estimation, allows to counteract inductive biases and facilitates extrapolations resembling richer func tions. 
Experiment 
We set up an experiment to contrast extrapolations in function learning and function estimation. To distinguish the contribu tion of presentation from memory requirements imposed by the experiment, we introduced a new experimental condition that shared presentational-, but not memory-related character istics with function estimation. In this new condition data was presented as scatter plots, but data points disappeared from display immediately after submission. Since the condition exhibits similar characteristics to classical function learning tasks we predicted that extrapolations should more closely re 
2017
semble function learning conditions, as participants will have to rely on recollection of the presented data for their extrap olations. We will refer to the scatter plot condition present ing the full data as Scatter+and the new condition as Scatter throughout this paper. We will refer to the traditional function learning conditions as Bar. 
Participants 
We recruited 322 participants via Amazon’s Mechanical Turk service. Participants received 0.4$ for participation and took an average of 8 minutes to complete the experiment. Partici pants were randomly assigned to one of the 9 conditions {flin, fx2 , fcos } × {Scatter+, Scatter-, Bar }, as described below. 
Material 
The data presented in the experiment was generated by one of three functions: linear (flin), quadratic (fx2 ) or periodic (fcos). These functions and their parametrization were designed such as to allow for informative error patterns resulting from hu man inductive biases. Since previous research reported strong biases for linear functions with 0 intercept and 11slope (we will refer to this function as f(x) = x), we selected a shal lower positive slope. The quadratic function was relatively flat in the training block to test if participants would revert to linearity or choose non-linear alternatives. Finally, a peri odic function, was used to evaluate if participants were able to extrapolate in non-monotonic fashion. To allow space for extrapolation beyond the function ranges we normalized the data to span (0,1) in both x, y and then rescaled and centered such as to span 12of the y-axis. For the full set of materials after transformation, see Figure 1a. 
Procedure 
Participants were instructed that they would be presented with data and that given their understanding of the relationship in the data they had to predict new values. Then partic ipants proceeded to a block of training trials (the training block), which provided participants with feedback about the true function. 
Training Block In the Scatter+and Scatter conditions the current test value (x) was marked with a red line spanning the whole vertical range. Participants were prompted to select a y value by clicking on the line. Once selected, the input value was highlighted with a blue point. Selected points could be updated by reselecting a y value. The selected values were submitted by pressing the space key. In the Bar condition current x values were presented as the width of a bar on the left of the screen and participants selected values by select ing the height of a bar on the right. As in the Scatter+and Scatter conditions, participants could readjust these values. In all conditions x values were presented sequentially in as cending order. If the selected y value was within the error margin (±0.05 of the true y), the true value was shown for 600ms in red. Afterwards, a message indicated that the choice was correct and the remaining number of trials was shown. If 
the selected value was not inside the margin the message in dicated an unsuccessful submission. Then the selected value was removed and participants had to resubmit. After erro neous submissions the true y was displayed as a red bar (Bar) or a red dot (Scatter+, Scatter-). Participants had to resubmit values until a admissible y was chosen. Participants received 40 points in total during the training block. 
Linear Quadratic Periodic 
(a) Three functions generated the underlying data: flin = 0.7x+0.2, fx2 = 0.7x2 +0.18, fcos = −0.3 cos(5πx) +0.5 (after normalization and rescaling). 
st 
Te
g 
in
in
Bar Scatter- Scatter+ Tra(b) Procedure for Bar, Scatter and Scatter+conditions. 
Figure 1: Participants were randomly assigned to one of the 9 experimental conditions. All participants performed a train ing block consisting of 40 value pairs with feedback followed by a test block of 40 extrapolations without feedback. 
Test Block The test block followed the same procedure as the training block, but no feedback was provided. After sub mitting 40 values in the test block, participants concluded the experiment by submitting an optional short survey. For the full procedure see Figure 1b. 
Results 
Functions and Presentation Form 
Consistent with previous findings, mean absolute error (MAE) in the test block was largest for fcos, MAE = 0.24, SD = 0.1, n = 108. Errors for fx2 and flin were small, with flin exhibiting the smallest error, MAEx2 = 0.14, SDx2 = 0.09, nx2 = 106, MAElin(x) = 0.11, SDlin(x) = 0.1, nlin(x) = 108. 
The errors in the presentation conditions were compatible with our hypothesis, with Scatter+lowest, MAE = 0.1, SD = 0.1, n = 106 and Scatter and Bar at similar, higher levels, MAEBar = 0.19, SDBar = 0.12, nBar = 110, MAEScatter- = 0.19, SDScatter- = 0.11, nScatter- = 106. For all errors in the subgroups of function and presentation conditions see Figure 2. 
Data Availability and Presentation 
To assess the effect of data availability (DA, a binary vari able denoting if the condition was Scatter+, or either Scatter 
2018
r 
o
r
r
E
t
s
e
T
0.4 0.3 0.2 0.1 0.0 
Linear 
Quadratic 
Periodic 
Scatter+ Scatter− Bar 
ences explainable in terms of condition-independent biases? In the final section we will explore how differences in avail ability, imposed by our experimental design reflect in the par ticipants extrapolations. To analyze these extrapolations we compared human extrapolations to two Bayesian models, one exhibiting low available data and one considering all avail able data. 
Modeling Function Extrapolations 
The computational problem faced in extrapolation tasks con sists in determining new values yn+1 for test values xn+1, con ditional on previously learned xn,yn and a prior belief p(f) 
Figure 2: In all presentation conditions participants exhibited the lowest errors for linear, followed by quadratic and peri odic functions. Boxplots display first, second (median) and third quartiles. Whiskers show the ±1.5 interquartile range (IQR). Each point represents the MAE of one participant. 
or Bar) and function (flin, fx2 , fcos) on errors, while con trolling for the effect of presentation (Scatter denoting if the presentation condition was either Scatter+ or Scatter-, or Bar), we fitted a generalized linear model (GLM): YMAE ∼ β0 +βf ∗(βScatter +βDA). The GLM was specified as a Gaus sian with identity link function and allowed for interactions between Scatter and function as well as DA and function. 
Table 1: Results of the GLM model assessing if function type (flin, fx2 , fcos), presentation (Scatter), or data availability (DA) were predictive of MAE in the test block. The fcos condition had a significant positive effect on MAE. In addition, having all data available (DA, corresponding to condition Scatter+) had a significant, small negative effect. 
β SE z P > |z| 95%CI 
β0 0.13 0.02 8.78 p < 0.001 0.1,0.16 fcos(x) 0.15 0.02 7.28 p < 0.001 0.11,0.2 fx2 0.02 0.02 0.75 0.45 −0.03,0.06 Scatter β < 0.01 0.02 0.22 0.82 −0.04,0.05 DA −0.08 0.02 −3.75 p < 0.001 −0.13,−0.04 Scatterfcos(x) −0.03 0.03 −1.02 0.3 −0.01,0.03 Scatterfx2 0.02 0.03 0.75 0.46 −0.04,0.08 DA fcos(x) −0.01 0.03 −0.24 0.8 −0.07,0.05 DA. fx2 β < 0.01 0.03 0.04 0.97 −0.06,0.06 
over possible functions. We will adopt a Gaussian process perspective on regression, an approach that has been applied successfully in previous function learning research (Lucas et al., 2015; Schulz et al., 2017). 
A Gaussian process specifies a distribution over functions f(x) ∼ GP(µ, k), where µ(x) = E[ f(x)] and k is the covariance kernel k(x, x0) = cov(f(x), f(x0)). The kernel specifies how much values of x0 depend on the other values x and specifies a similarity measure over x. We assume that two sets of priors can capture participant extrapolations in our study — a prior over kernel types describing the space of possible functions fi ∼ F , and a prior for individual kernel parameters θfi. 
Human Function Priors 
To specify a plausible prior over functions F we closely fol lowed Lucas et al. (2015). We used the same prior prob abilities for functions F , favoring f(x) = x (Linear+) over negative linear functions (Linear−), and linear functions over other monotonic functions (RBF, the radial basis function kernel). Since our experiment included periodic data that we did not want to exclude a priori, we added a periodic ker nel (Periodic) with good coverage over the range of x, y. We chose a low prior weight for the periodic to account for the difficulty in learning non-monotonic functions (Bott & Heit, 2004; Kalish, 2013). For a full list of parameter priors θ, see Table 2, for samples of the prior functions, see Figure 4. 
With the priors F and θ we can express the task faced by our participants in general terms: 
Z 
In concordance with previous findings, fcos had a signifi cant positive effect on error. As expected by our hypothesis, 
p(yn+1|xn+1xn,yn, f) = f 
p(yn+1|xn+1, y, f)p(f |x,y)d f (1) 
data availability (DA) had a significant small effect on error, but presentation (Scatter) was not significant. No other main effect and none of the interaction terms had a significant ef fect. For the full GLM results, see Table 1. For all extrapola tions performed by the participants, see Figure 3. 
Learning a Function or Minimizing Error The results are consistent with our hypothesis that differences in errors are attributable to differences in data availability. However, a stronger test of our hypothesis lies in the patterns of extrapolations that people make. Do these patterns differ systematically between presentation conditions, or are differ 
Given appropriate priors and Equation 1 a variety of human inductive biases can be accounted for, from strong biases for f(x) = x, to results in iterated learning experiments (Lucas et al., 2015). 
However, this model assumes that all previously encoun tered data, x,y, are equally available and inform posterior in ference. In some function learning experiments, where par ticipants repeat training until they achieve a very low error rate, these assumptions may be appropriate. In other con texts, including many sequential function learning problems in the natural world, it is less plausible. 
2019
Figure 3: All participant extrapolations (gray lines) in the 9 experimental conditions. Submissions within the admissible error for the training block are displayed on the left-hand side of the dotted vertical line. Extrapolations for the test block are displayed on the right-hand side. Function conditions are presented by column, presentation conditions by row. As background color the posterior densities of the models described in the model section, darker colors correspond to higher posterior density. According to our hypothesis, participants in the Scatter+condition kept a full representation of the training data available, corresponding to the full model (top row). In the two bottom rows the model density is conditional on only the last 5 training points, corresponding to our sparse model. 
Modeling Data Availability 
We contrasted the predictions of a model trained on the full dataset (the 40 training points) with a model that had only a sparse set of data available. As a first approximation of the effect of data availability we assumed that only the last 
k = 5 points in the training block were available in the Bar and Scatter conditions. While the amount of data underlying participants’ extrapolations might differ systematically, our analysis is not particularly sensitive to the size of the subset. In general, larger subsets will emphasize the training data, 
2020
Linear+ 
1 
Linear− 
2 
Quadratic 
1 
Periodic 
1 
RBF 
nLinear Data 
o
i
t
Periodic Data 
Quadratic Data 
0 
0 1 
0 
0 1 
0 
0 1 
0 
0 1 
1 
0 
0 1 
c
 of Fun
.
b pro
d
e
r
r
e
f
1.0 
0.5 
0.0 
s 
s 
# Points 5 
40 
s 
c 
c 
c 
Figure 4: Four samples for each of the functions constituting 
F 
F 
F 
o
o
o
+ 
+ 
+ 
− 
− 
− 
i
i
i
n
r 
r 
r 
r 
r 
r 
t
t
t
B
B
B
C
C
C
I
a
a
a
a
a
a
a
a
a
F . F consisted of a linear kernel biased towards f(x) = x, a 
R
R
R
r
r
r
e
e
e
e
e
e
d
d
d
n
n
n
n
n
n
i
i
i
i
i
i
a
a
a
L
L
L
L
L
L
u
u
u
negative linear, a quadratic, a periodic and a RBF kernel. All 
Q
Q
Q
kernels had additional intercept terms. The distribution over functions F was chosen to closely match Lucas et al. (2015) and was proportional to 8,1,0.1,0.01,0.01. 
Table 2: Priors used to specify the two models. All models had a fixed noise variance of 0.0025, that matched the admis sible error in the test set. The lengthscale of the RBF kernel was θl, while θπ specified the period of the periodic kernel. 
Figure 5: The inferred posterior function probability for each function condition for both sparse (5 points) and full (40) models. The full model assigned high probability to the true underlying function for linear and periodic data. For quadratic data it favored linear functions, reflecting the prior and the seemingly linear training data. The sparse model gen erally reflected the prior. 
The curvature of the quadratic kernel was specified by θc. 
σ2Intercept Slope θc θl θπ 
l 
Linear+ Exp(16) N(0,12) N(1,110 ) – – – 
n 
l
u
o
f
i
t
a
Linear− Exp(16) N(1,12) N(-1,110 ) – – – 
c
fi
i
s
s
Quadratic Exp(16) N(12,1) N(0,1) N(0,2) – – 
e 
a
l
s
r
C
a
Periodic Exp(16) N(12,1) – – N(1,14) N(12,14) 
p
s
RBF Exp(16) N(12,1) – – N(1,14) – 
Linear 
0.60 0.40 
0.38 0.62 
full sparse Condition 
Quadratic 0.23 0.77 
0.27 0.73 
full sparse Condition 
Periodic 
0.94 0.06 
0.78 0.22 
full sparse Condition 
while smaller sets will result in posteriors emphasizing prior inductive biases, since the likelihood of the data plays a di minished role. For the posterior probability for functions for both models see Figure 5. 
We compared both models in terms of their ability to ac count for characteristic biases in human function learning as well as differences between the extrapolations for Scatter and Bar and Scatter-. To evaluate our models, we classified partic ipants’ extrapolations in the test block as either belonging to full or sparse experimental conditions according to the like lihood of the models (trained on the training block). Then we contrasted this classification with the true experimental condition. For confusion matrices for this classification pro cedure see Figure 6. For examples of the classified extrapola tions see Figure 7. 
Model Results 
Both sparse and full models captured the strong inductive bi ases for positive linear functions. Furthermore, our sparse model predicted the strong inductive bias for f(x) = x in Scatter and Bar conditions, aligning well with the partici pants’ data (see Figure 3). 
For fx2 both full and sparse models reflected the strong prior for positive linearity. As a result the full model did not capture the extrapolations of participants in Scatter+. While the model extrapolated in linear fashion from the available data, participants performed steeper, quadratic-like extrapo 
Figure 6: We contrasted our classification with the true ex perimental conditions. Our classification captured the effect of data availability for flin. However, it exhibited systematic misclassification for fx2 and fcos. In fx2 we were able to clas sify participants as belonging to Scatter- or Bar, but failed to recognize Scatter+. In fcos our procedure misclassified partic ipants in the sparse conditions, but captured extrapolations in the Scatter+condition. 
lations (see Figure 3). The sparse model was more predictive of the participants extrapolations in Scatter conditions, ex trapolating in steep linear fashion. For fcos the sparse model did not capture the participants extrapolations well (see Fig ure 6). While the model did favor positive linearity and extrapolated accordingly, many participants exhibited non monotonic, high variance extrapolations (see Figure 3). In contrast, the full model captured the highly periodic extrapo lations in the Scatter+condition and closely resembled human extrapolations. 
Discussion 
We hypothesized that differences between function learning and function estimation experiments can be attributed to par ticipants having direct access to all data points in the latter. More precisely, we sought to test the idea that the same in ductive biases are at work in both settings, but that the re duced access to data in function learning designs causes these 
2021
1.0 0.5 
Linear Data 
0 1 
Periodic Data 
0 1 
# Points 
5 40 
Quadratic Data 0 1 
allows us to characterize these interrelations more precisely and can highlight general similarities between fields like cat egorization and function learning (Lucas et al., 2015; Jakel, ¨ Scholkopf, & Wichmann, 2008). ¨ 
References 
Bott, L., & Heit, E. (2004). Nonmonotonic extrapolation in function learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 30(1), 38. 
Brehmer, B. (1974). Hypotheses about relations between 
Figure 7: Five extrapolations with the highest categorization scores in each function condition. We categorized partici pants’ extrapolations by contrasting the likelihood of our full and sparse models. 
biases to play a stronger role in shaping participants’ extrap olations. As we anticipated, participants’ behavior in both Scatter and Bar was almost indistinguishable, demonstrat ing the same qualitative patterns, which were clearly different from those in the Scatter+conditions. 
However, we found mixed support for the more detailed hypotheses reflected in our Bayesian model. Behavior in all linear function conditions was as we predicted, with partici pants in Scatter and Bar conditions tending to extrapolate ac cording to the f(x) = x function that past research has shown in favored a priori, rather than the true function. 
In the quadratic conditions, our model captured partici pants’ behavior in the Scatter-, but not in Scatter and Bar conditions, where participants were more likely than the model to infer a non-linear relationship. There are many pos sible explanations, one of which is that our simplistic assump tions about participants’ memory failed to capture the loss of precision in the locations of points. 
Perhaps the most interesting deviation between the model’s predictions and participants’ judgments is in the fcos condi tions. Contra the model’s predictions – as well as our ex pectations – individual participants were quick to infer non monotonic functions even in the Scatter and Bar conditions. This also admits several explanations, but one intriguing pos sibility is that people are better at tracking high-level, quali tative properties of functional relationships than the details of those relationships’ parameterizations. 
If higher-level properties allow for non-monotonic extrap olations, how do humans acquire these representations and in which situations do they prove beneficial? One could make an argument for cognitive economy – coarse-grained represen tations and extrapolations might serve a learner’s goals well enough, while maintaining detailed task-specific representa tions is an intractable or sub-optimal policy for a resource limited agent. We are currently exploring the relevance of resource-efficient non-parametric models to human behavior in these tasks, where representational complexity scales with an agent’s goals and the complexity of the task (for a re lated result in categorization, see Fischer and Holt (2017)). Adding a computational-level perspective to these questions 
scaled variables in the learning of probabilistic inference tasks. Organizational Behavior and Human Performance, 11(1), 1–27. 
Brehmer, B. (1976). Learning complex rules in probabilis tic inference tasks. Scandinavian Journal of Psychology, 17(1), 309–312. 
Brehmer, B., Alm, H., & Warg, L.-E. (1985). Learning and hypothesis testing in probabilistic inference tasks. Scandi navian journal of psychology, 26(1), 305–313. 
Byun, E. (1995). Interaction between prior knowledge and type of nonlinear relationship on function learning (Un published doctoral dissertation). Purdue University. 
DeLosh, E. L., Busemeyer, J. R., & McDaniel, M. A. (1997). Extrapolation: The sine qua non for abstraction in function learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 23(4), 968. 
Fischer, H., & Holt, D. V. (2017). When high working mem ory capacity is and is not beneficial for predicting nonlinear processes. Memory & cognition, 45(3), 404–412. 
Jakel, F., Sch ¨ olkopf, B., & Wichmann, F. A. (2008, Apr 01). ¨ Generalization and similarity in exemplar models of cate gorization: Insights from machine learning. Psychonomic Bulletin & Review, 15(2), 256–271. 
Kalish, M. L. (2013). Learning and extrapolating a periodic function. Memory & Cognition, 41(6), 886–896. Kalish, M. L., Lewandowsky, S., & Kruschke, J. K. (2004). Population of linear experts: Knowledge partitioning and function learning. Psychological Review, 111(4), 1072. Little, D. R., & Shiffrin, R. (2009). Simplicity bias in the esti mation of causal functions. In Proceedings of the cognitive science society (Vol. 31). 
Lucas, C. G., Griffiths, T. L., Williams, J. J., & Kalish, M. L. (2015). A rational model of function learning. Psycho nomic bulletin & review, 22(5), 1193–1215. 
Schulz, E., Tenenbaum, J. B., Duvenaud, D., Speekenbrink, M., & Gershman, S. J. (2017). Compositional inductive biases in function learning. Cognitive Psychology. 
Wilson, A. G., Dann, C., Lucas, C., & Xing, E. P. (2015). The human kernel. In Advances in neural information pro cessing systems (pp. 2854–2862). 
2022
Inferences about Uniqueness in Statistical Learning 
Anna Leshinskaya (alesh@sas.upenn.edu) and Sharon L. Thompson-Schill (sschill@psych.upenn.edu) Department of Psychology, University of Pennsylvania 
Stephen A. Levin Building, 425 S. University Ave 
Philadelphia, PA 19104 
Abstract 
The mind adeptly registers statistical regularities in  experience, often incidentally. We use a visual statistical  learning paradigm to study incidental learning of predictive  relations among animated events. We ask what kinds of  statistics participants automatically compute, even when  tracking such statistics is task-irrelevant and largely implicit.  We find that participants are sensitive to a quantity governing  associative learning, ΔP, independently of conditional probabilities and chunk frequencies, as previously considered.  ΔP specifically reflects the uniqueness, as well as strength, of  conditional probabilities; we find that uniqueness is equally  affected by a single strong alternative predictor as by several weak predictors. Performance is well captured with an  adapted version of the Rescorla-Wagner delta learning rule  (Rescorla & Wagner, 1972). We conclude that incidental 
predictive learning is governed by considerations of  uniqueness, and that this is computed by normalizing  conditional probabilities by events’ base-rates. This opens the  possibility of common mechanisms between statistical  learning, associative learning, and causal inference.  
Keywords: statistical learning; associative learning 
Introduction 
Our minds adeptly register stable patterns in experience. For  example, we spontaneously encode the predictive relations  among sequentially presented stimuli (Saffran, Aslin, &  Newport, 1996; Turk-Browne, Jungé, & Scholl, 2005). This  phenomenon, statistical learning, takes place without  conscious effort, feedback, or reward. It suggests the  existence of a learning mechanism operating in the  background of our minds to produce mental models of our  world. Two major questions are just how inferentially  complex this mechanism might be, and what are its relations  to other learning phenomena. 
The literature on causal reasoning, contingency learning,  and classical conditioning (for a review: Mitchell, De  Houwer, & Lovibond, 2009) universally describes a core  phenomenon of some inferential complexity: learners do  more than register that two stimuli co-occur, but also  compute whether they predict each other uniquely and  independently, as if attempting to determine a causal model.  Suppose two events A and B coincide, such that after most  occurrences of A, B occurs. However, B also occurs without A at a very high rate. One would not represent a strong link  between A and B in this case. This consideration is captured  by a foundational learning formula, ΔP (Allan, 1980;  Rescorla & Wagner, 1972; Shanks, 1985): 

This equation states that learning is a product of both how  often B follows A, as well as how often it appears without  it. This consideration is at the core of the Rescorla-Wagner  learning rule, which accounts for phenomena concerning  uniqueness in classical conditioning and contingency  learning, termed cue selection or blocking effects (Kamin,  1968; Rescorla & Wagner, 1972; Shanks, 1985). After  learning that stimulus B coincides with an outcome (B+),  learning that both A and B yield an outcome (AB+) leads to  weak associative strength between A and the outcome; this  less the case than if participants saw only AB+ trials. Thus,  judgments about the predictive importance of A are affected  by whether a different stimulus is also predictive. That is,  learners care about the unique predictiveness of stimuli.  
Surprisingly, whether participants’ learning follows this  uniqueness principle in statistical learning tasks has not  been tested (c.f., Sobel & Kirkham, 2006, 2007). The  extension is not trivial because statistical learning tasks  differ substantially from those of causal reasoning and  classical conditioning. There are two important differences.  The first is that in statistical learning of temporal relations,  stimuli typically appear one by one, and do not appear in  compounds like in classical blocking paradigms. The  uniqueness of a prediction from A to X would thus depend  on whether X follows stimuli other than A (e.g., B) on  separate trials. While different in form, this still captures the  deeper principle behind cue selection or blocking: that  causes should increase the probability of their effects above  and beyond what one might expect otherwise. However, the  influence of such BX trials on AX representations would  require a more sophisticated computation than the Rescorla Wagner model in standard form (Kruschke, 2008) for  reasons we discuss in depth later, and furthermore, may not  occur as robustly as classic blocking.  
 A second difference is that learning in statistical learning  tasks is largely incidental. In associative and causal tasks,  the goal to predict the relevant outcomes is strongly  incentivized by task instructions or the inherent value of  stimuli (shocks or rewards). By contrast, in statistical  learning paradigms, participants passively observe streams  of events, with no strategic advantage or instruction to  identify predictive relations. The number of stimuli, and  their rapid, continuous presentation, prevents explicit  tracking of their rates of co-occurrences. Learning thus takes  place incidentally, with contents typically unavailable for  conscious report (Brady & Oliva, 2008; Kim, Seitz,  Feenstra, & Shams, 2009). This is unlike all causal  reasoning experiments and many conditioning experiments  
2023
(Mitchell et al., 2009). But while the learning situations  differ, principles of learning may be preserved (Sobel &  Kirkham, 2007). 
In Experiment 1, we demonstrate that statistical learning  is subject to considerations of uniqueness: that learning  reflects not just the conditional probability relating two  events, a cause and an effect, but whether that relation is  unique. Experiment 2 suggests that non-uniqueness can  arise from either a strong alternate predictor, or the overall  base-rate of the effect. We then adapt the Rescorla-Wagner learning model (Rescorla & Wagner, 1972) to account for  these results. Overall, we suggest that during incidental  learning, conditional probabilities are spontaneously  normalized by events’ base-rates, and that learning takes  place when these relative values are high. This results in  sensitivity to uniqueness. In this way, we suggest that there  is more in common between statistical and associative  learning than previously considered. Experiment materials,  data, and code are available at https://osf.io/up8qz/. 
Experiment 1 
We tested whether learners are sensitive to uniqueness in a  visual statistical learning (VSL) task. Participants saw two  distinct event sequences, each composed of a unique set of  animated events (Figure 1A). Each sequence contained one  strongly predictive event pair—a cause and an effect— whose uniqueness we varied. In both sequences, the first  term in the ΔP formula above was matched: the probability  that the effect appeared given that the cause appeared on the  previous trial was equally high in both1. However, in the 
low ΔP sequence, we increased the value of the second  term, P(effect|~cause), by having the effect follow two other  events and itself more often than in the high ΔP sequence.  Thus, the two conditions were matched in terms of the  transition probability from cause to effect, as well as in the  number of times a cause-effect pair appeared overall (chunk  frequency), but differed in terms of how uniquely the cause,  rather than other events, predicted the effect. We expected  learning to be worse in the low ΔP condition.  
Method 
Participants 100 participants were recruited and tested via  Amazon Mechanical Turk. Participants provided electronic  consent and procedures were approved by the Institutional  Review Board of the University of Pennsylvania.  Compensation was $3, with a bonus of up to $2.50 based on  task accuracy. Participants were excluded if they had  previously participated in a related experiment or this one  (10), for failing an attention measure (8), for missing data  (1) or reporting a technical glitch (1). 80 participants were  included (43 female, age M = 33, range 19 – 62).  
 
1 ΔP has been used to describe simultaneous co-occurrences as  well as sequential ones. For example, a patient taking a medicine  and experiencing a headache afterwards is a common example of  the latter (Cheng, 1997). 
Stimuli & Design Stimuli were sequences of animated  events which took place surrounding or involving a  continually present object. Each participant was shown two  types of sequences, low ΔP and high ΔP, each cued by a  distinct object. Each sequence was 500 events long, split  into a passive preview (100) and two cover task segments  (200 each), and contained eight unique events (1.2s  duration), plus a static event showing object standing still  (3.6s). The eight events formed 4 pairs, which were subtly  visually altered versions of each other (e.g., blue vs. pink  bubbles). One alternate appeared 10% of the time instead of  the other; this was for the purposes of the cover task (see  below). Eight different events composed the other  sequence. The specific events and novel object assigned to  each sequence type were selected randomly for 20 sets of  materials; then, yoked materials were created by swapping  the event assignments between the two sequence types.  Each yoked set was then used twice, once for each possible  order of presentation of the two sequences, creating  materials for 80 participants fully counterbalanced for order  and stimuli. The order of events in each sequence type was  governed by a distinct pairwise transition matrix (Figure  1B); this was specified over the 4 event types plus static (the rare alternate replaced its pair on 10% of randomly chosen  instances). Each matrix specified that the effect followed the 
Figure 1. A) Static images depicting several of the stimuli,  with common vs. rare alternates depicted in the top vs.  bottom row, and the two objects which cued the distinct  sequences. B) Mean transition matrices governing the  appearance of events in each condition, and event  frequencies below. 
2024
cause with a high conditional probability (~98%), whereas  other transitions were lower. The critical manipulation was  of the probability of the effect given other events, including  
itself, computed as the proportion of time any event other  than the cause was followed by the effect vs. was not. In the  high ΔP sequence, the effect was rarely preceded by any  other event, yielding a high ΔP (97%). In the low ΔP sequence, the effect was often preceded by one of the two  other, non-static events or itself, yielding a lower ΔP (61%).  Individual sequences were generated stochastically  according to an idealized transition matrix; the mean  obtained matrix values are shown in Figure 1B. The  sequence conditions were closely matched on the  conditional probability of seeing the effect given the cause  (high, 97.8%; low 97.4%), and their chunk frequency  (number of times participants saw a cause-effect pair; high  63.28; low 62.18). The conditional probability of the cause  given the effect was lower for the low ΔP sequence (high  .074, low .027) so that the number of times they saw the  effect-cause pair (high 5.12; low 6.02) was relatively  matched. We address any concerns about minor differences  in the sequence properties in the Results.  
Procedure Participants’ cover task was to learn to identify  the “common” vs. “rare” version of each event type. To  ensure task comprehension, static images depicting both  versions were shown (but not which were which), and a 20- 
trial practice task required them to hit the spacebar in  response to the start of each distinct event; 80% accuracy  was required to continue. Subsequently, they watched a  preview video to learn to identify the common vs. rare  events, followed by 2 videos in which they were asked to hit  ‘r’ for rare and ‘o’ for common. They then saw the second  sequence type, starting again with static images of the new  events, the practice task, preview, and 2 task videos. They  were given feedback on cover task accuracy following each  task video. Order of the sequence types was  counterbalanced across subjects within yoked stimulus set.  
Following all videos, a surprise forced-choice test probed participants’ knowledge of the cause-effect relation in both  sequences separately. The critical questions (repeated 3 times and responses averaged) showed the cause followed  by the effect in one video, and the effect followed by the  cause in the other; participants had to choose the video that  seemed more typical or familiar. We chose this as the test  question so as to match the two videos on individual stimulus frequency, and to match question difficulty across  conditions (ensuring they have equal relative transition  probabilities). Only the common stimulus versions were  used in testing. The stimulus pairs appearing in these  questions were also matched in chunk frequency between  the conditions, and accordingly had a slightly larger  difference in transition probability in the low ΔP condition  (which would make it easier, counter to our hypothesis).  Two filler questions were also presented to avoid giving the  impression that the test was stuck on a single question. 
To probe explicit (verbalizable) access to the sequence  statistics, participants were given a freeform question asking  “Did certain events follow each other more often than  others? Describe any you noticed for the first set and for the  second set of videos”. They were also asked, “How  confident are you that you detected any systematic order to  the events in the [first/second] set of videos?”, for each set,  and responded on a 1-5 rating scale, with 1 = Definitely  False, 3 = Unsure, and 5 = Definitely True.  
Results 
Participants performed well on the cover task for both  sequences (high ΔP M = 86.99, SE = 1.03; low ΔP M =  87.37, SE = 0.94; t(79) = -0.39 p = .698). On the critical  questions of the forced choice test, participants were above  chance for the high ΔP sequence (M = 61.83%, SE = 3.90%,  t(79) = 2.79, p = .007, d = 0.31) but below chance for the  low ΔP sequence (M = 41.67%, SE = 3.89%, t(79) = -2.16,  p = .034, d = -0.24), which were significantly different from 
each other (CI [8.43, 29.90], t(79) = 3.55, p < .001, d =  0.55), as shown in Figure 2. This supports the idea that participants had a weaker representation of the cause-effect  relationship in the low ΔP condition—despite the fact that in  both conditions, cause-effect transitions occurred twelve  times as often as effect-cause transitions. To rule out that  this was due to the minor difference in the number of times  participants saw a cause-effect transition relative to an  effect-cause transition in the two conditions, we computed  the difference in the number of times each participant saw a  cause-effect pair vs. an effect-cause pair between the two  conditions (M = 2). This difference was uncorrelated with  the difference in accuracy between the two conditions (r(78)  = -0.03, p = .791). There was no effect of training order  (which sequence participants saw first), p = .273. 
Participants’ confidence that they noticed any systematic  order among the events was not reliably above ‘unsure’ for  either condition (high M = 3.20, SE = 0.13, t(79) = 1.57, p =  .121; low M = 3.06, SE = 0.13, t(79) < 1 ), with no effect of  condition (t(79) = 1.52, p = .132). In their freeform  responses, 20/80 participants described a relation between  the cause and effect for one sequence, but only 2/80 did so  for both. However, participants were more likely to describe  it for the high ΔP events (19/80) than the low ΔP events  (5/80; Χ2 (1) = 9.61, p = .002). Thus, the high ΔP condition  Figure 2. Forced-choice test accuracy by condition in  Experiments 1 and 2. ** = p < .001. 
2025
enabled participants to better notice the predictive pattern.  In contrast, participants were not likely to report effect cause patterns in either condition: there were no cases of  this for the low ΔP condition, and one in the high ΔP  condition. This argues against the idea that they strongly  believed in the effect-cause relation in the low ΔP condition. 
Discussion 
During a VSL task, participants’ learning of a highly likely  transition between two events (a cause and an effect) was  weaker when the effect was also preceded by other events  (low ΔP condition), relative to when the effect was uniquely  predicted by the cause (high ΔP condition). The cause-effect  transition had a higher chunk frequency and transitional  probability than the effect-cause transition in both  conditions: participants saw cause-effect pairs a similarly  high number of times, and effect-cause pairs a similarly  small number of times. However, when asked which was  more typical, participants chose the cause-effect pair  reliably only in the high ΔP condition.  
This finding indicates that participants’ incidental  learning is automatically informed by computations of  uniqueness, in that neither participants’ cover task nor the  test questions demanded it or benefitted from it. Answers  based on chunk frequency or conditional probability were  both valid, and computationally simpler. Thus, the  computation of ΔP was a product of participants’ incidental  learning process. Furthermore, a high ΔP between cause and  effect led to a higher rate of reporting of this pattern when  asked to describe any systematic order to the events. It  seems unlikely that participants had noticed that the low ΔP  cause was nearly always followed by the effect, but were  less willing to report it. We thus conclude that the rate of  awareness was itself influenced by ΔP.  
These results are in line with a related finding that participants have poor memory—not just low causal  ratings—for non-unique (“blocked”) cause-effect relations  (Mitchell, Lovibond, Minard, & Lavis, 2006). They are also  consistent with demonstrations of more traditional blocking  effects in infants in a paradigm somewhere in between  classical conditioning and statistical learning (Sobel &  Kirkham, 2006, 2007). Here we show that effects of  uniqueness hold in a traditional statistical learning  paradigm, characterized by sequentially presented events, 
incidental learning, absence of incentive or reward, and  conditions which exceed the capacity to track event  statistics explicitly. 
A puzzling fact of these data is the below-chance  performance in the low ΔP condition: participants selected  the effect-cause transition more often than cause-effect. It  did not appear that participants strongly believed in this  effect-cause transition, as they did not mention it even once  in their freeform responses. This suggests that participants  may have had an inhibited (implicit) belief in the cause 
effect relation.  
An additional open question is the source of this blocking-like effect. Here and elsewhere, it is ambiguous  
whether the weakened belief in a low ΔP cause-effect pair is  due to a strong associative representation of an alternate  event-effect pair, or from an increased base-rate of the  effect’s occurrence. For example, participants might have  developed a strong belief that random event 1 or 2 actually  caused the effect, and subsequently inhibited their belief in  other possible predictors. Alternatively, participants could  compute ΔP by normalizing the conditional probabilities of  the effect-cause pair by the base-rate of both the effect and  the cause, having tracked that the effect event occurs often  overall. We test this possibility in Experiment 2.  
Experiment 2 
As in Experiment 1, participants were exposed to two VSL  sequences, each containing a strong predictive relation  between a cause and effect. In the two-cause stream, the  effect also followed a second, equally strong predictor, but  no other events. In the many-cause stream, the effect  followed the three other events and itself with a medium  probability (~18%). Thus, the cause-effect pair in both  conditions had an equal ΔP value (.80), but from different  sources: a strong alternative or a high overall base-rate. If  learning is impaired specifically due to a salient alternative  cause, participants should perform worse in the two-cause  stream relative to the many-cause stream.  
Method 
Participants 107 participants were recruited and tested via  Amazon Mechanical Turk. Participants provided electronic  consent and procedures were approved by the Institutional  Review Board of the University of Pennsylvania.  Compensation was $3, with a bonus of up to $2.50 based on  task accuracy. Participants were excluded if they had previously participated in a related experiment or this one  (7), for failing an attention measure (19), or for missing data  (1). 80 participants were included (47 female, age M = 34,  range 19 – 71).  
Stimuli & Procedure Stimuli and procedures were similar to Experiment 1, except that each sequence contained 5  events plus static, and the first task video was slightly  shorter (150 events). The transition matrices were similar,  except that the two-cause condition had a 96% transition  probability between random1 and effect; and the many 
cause condition had a ~18% transition probability between  each non-static event and the effect. Conditions had similar  counts for cause-effect and effect-cause pairs, and similar ΔP value between cause and effect (.80). 
Results 
Participants performed well on the cover task for both  sequences (two-cause: M = 85.43, SE = 1.11; many-case: M = 86.63, SE = 1.09, t(79) < 1). On the critical trials in the  forced-choice test (Figure 2), performance was not different  from chance in either condition (two-cause: M = 51.25%,  SE = 4.17, t(79) < 1; many-cause: M = 48.33%, SE = 4.04,  t(79) < 1) with no difference between them (t < 1).  
2026